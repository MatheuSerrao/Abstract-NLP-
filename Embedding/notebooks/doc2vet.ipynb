{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "with open('../tokens', 'rb') as pickle_file:\n",
    "    tokenized_sent = pickle.load(pickle_file)\n",
    "\n",
    "random.shuffle(tokenized_sent)\n",
    "\n",
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "test_tokens = tokenized_sent[:10000]\n",
    "train_tokens = tokenized_sent[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "tagged_train_data = [TaggedDocument(token[2], [i]) for i, token in enumerate(train_tokens)]\n",
    "tagged_test_data = [i[2] for i in test_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvector_size = Dimensionality of the feature vectors.\\nwindow = The maximum distance between the current and predicted word within a sentence.\\nmin_count = Ignores all words with total frequency lower than this.\\nalpha = The initial learning rate.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train doc2vec model\n",
    "model = Doc2Vec(tagged_train_data, vector_size = 512, min_count = 3, epochs = 40)\n",
    "\n",
    "'''\n",
    "vector_size = Dimensionality of the feature vectors.\n",
    "window = The maximum distance between the current and predicted word within a sentence.\n",
    "min_count = Ignores all words with total frequency lower than this.\n",
    "alpha = The initial learning rate.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(27, 0.33752503991127014),\n",
       " (40256, 0.2967877686023712),\n",
       " (37934, 0.29261383414268494),\n",
       " (9408, 0.26136210560798645),\n",
       " (47857, 0.2575366795063019),\n",
       " (16155, 0.2561749517917633),\n",
       " (28947, 0.25353842973709106),\n",
       " (32847, 0.252544641494751),\n",
       " (28615, 0.2518404424190521),\n",
       " (7050, 0.24318243563175201)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc = tagged_test_data[0]\n",
    "test_doc_vector = model.infer_vector(test_doc)\n",
    "model.dv.most_similar(positive = [test_doc_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (5024): «cooperation is an enabler for autonomous vehicles a promising application of cooperative driving is platooning where trucks drive with low distances it aims at increasing the road and fuel efficiency whilst guaranteeing safety the safe and efficient coordination of the control requires the regular and reliable exchange of v2v messages the performance of the vehicular application has been shown to be strongly affected by the variation of the performances of the communications system to be able to adapt their functional settings to these variations vehicles need the ability to predict it we present a prediction model for the packet time platoon messages in an ieee network this performance indicator is the subject of extensive research as it captures the irregularity of input for the control loop the prediction model uses conditional density estimation based on the exponential distribution we fit this model using a perceptron regressor based on features representing the surrounding communication environment the presented results are based on data collected during a full scale platooning simulations using and sumo we compare different environment abstraction models and show the potential of learning»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d512,n5,w5,mc3,s0.001,t3):\n",
      "\n",
      "MOST (10127, 0.3322412371635437): «cooperative adaptive cruise control cacc is a fundamental connected vehicle application that extends adaptive cruise control by exploiting v2v communication cacc is a crucial ingredient for numerous autonomous vehicle functionalities including platooning distributed route management etc unfortunately malicious v2v communications can subvert cacc leading to string instability and road accidents in this paper we develop a novel resiliency infrastructure raccon for detecting and mitigating v2v attacks on cacc raccon uses machine learning to develop an prediction model that captures anomalous vehicular responses and performs mitigation in real time vehicles can exploit the high efficiency of cacc without compromising safety even under potentially adversarial scenarios we present extensive experimental evaluation to demonstrate the efficacy of raccon»\n",
      "\n",
      "MEDIAN (1722, 0.059344835579395294): «universal filtered multi carrier ufmc waveform has been recommended for 5 th generation 5g cellular networks due to its robustness against synchronization errors and burst support however the ufmc suffers from high power ratio papr problem the high papr degrades the efficiency of high power amplifier hpa and makes the ufmc transmitter inefficient this paper combines slm and generalized gcl precoding to minimize the high papr of ufmc system simulations in matlab have been carried out to analyze the both parameters papr and symbol error rate ser computer simulation results show that the proposed slm based gcl precoded ufmc scheme outperform the gcl precoded ufmc scheme conventional ufmc scheme and conventional ofdm scheme respectively available in the literature»\n",
      "\n",
      "LEAST (47364, -0.1450636386871338): «cloud computing is defined as the management and provision of resources software applications and information as services over the internet numerous organizations are adopting cloud services because of the economy and technology changes over the past year cloud computing has made life easier for other people or organizations by allowing people to have access to information from anywhere in the world through the internet however cloud computing introduces a series of security concerns which data security is a major concern data security is basically linked with any security in the cloud if the network or infrastructure security is compromised the possibility there is a possibility of data being affected data security has three important principles that are confidentiality integrity and availability cia that needs to always be maintained understanding the security concerns in cloud computing is an important requirement for those who are planning to move to the cloud solution thus this paper aims to investigate and develop a hybrid data security framework to mitigate data security challenges in the cloud focusing on legal frameworks such as popia and gdpr a survey was conducted to investigate which techniques are more effective in protecting data and the evaluation ensured that cia triads are covered the limitation on the existing techniques is that they address only one principle or two but not all three at the same time the best technique among the others will be used integrated when designing the proposed framework in order to address cia having more than one security technique to address data security will improve the security in the cloud and will also bring more business to cloud service providers when customers see the security in data enhanced»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(tagged_test_data) - 1)\n",
    "inferred_vector = model.infer_vector(tagged_test_data[doc_id])\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(tagged_test_data[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(tagged_train_data[sims[index][0]].words)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
