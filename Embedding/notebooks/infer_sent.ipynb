{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.12 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/usr/local/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pickle5 as pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "with open('../tokens', 'rb') as pickle_file:\n",
    "    tokenized_sent = pickle.load(pickle_file)\n",
    "\n",
    "random.shuffle(tokenized_sent)\n",
    "\n",
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "test_tokens = tokenized_sent[:10000]\n",
    "train_tokens = tokenized_sent[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: curl: command not found\n",
      "/bin/bash: line 1: curl: command not found\n",
      "/bin/bash: line 1: unzip: command not found\n"
     ]
    }
   ],
   "source": [
    "! mkdir encoder\n",
    "! curl -Lo encoder/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl\n",
    "  \n",
    "! mkdir GloVe\n",
    "! curl -Lo GloVe/glove.840B.300d.zip http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "! unzip GloVe/glove.840B.300d.zip -d GloVe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import InferSent\n",
    "import torch\n",
    "\n",
    "V = 2\n",
    "MODEL_PATH = 'encoder/infersent%s.pkl' % V\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "W2V_PATH = '/content/GloVe/glove.840B.300d.txt'\n",
    "model.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "import random\n",
    "\n",
    "with open('../tokens', 'rb') as pickle_file:\n",
    "    tokenized_sent = pickle.load(pickle_file)\n",
    "\n",
    "random.shuffle(tokenized_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(tokenized_sent, tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I had pizza and pasta\"\n",
    "query_vec = model.encode(query)[0]\n",
    "query_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = []\n",
    "for sent in tokenized_sent:\n",
    "  sim = cosine(query_vec, model.encode([sent])[0])\n",
    "  print(\"Sentence = \", sent, \"; similarity = \", sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = tokenized_sent[0]\n",
    "test_doc_vector = model.infer_vector(test_doc)\n",
    "model.dv.most_similar(positive = [test_doc_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
