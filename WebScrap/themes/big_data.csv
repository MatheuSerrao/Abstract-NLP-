id,title,abstract
9007871,A survey of data partitioning and sampling methods to support big data analysis,"Computer clusters with the shared-nothing architecture are the major computing platforms for big data processing and analysis. In cluster computing, data partitioning and sampling are two fundamental strategies to speed up the computation of big data and increase scalability. In this paper, we present a comprehensive survey of the methods and techniques of data partitioning and sampling with respect to big data processing and analysis. We start with an overview of the mainstream big data frameworks on Hadoop clusters. The basic methods of data partitioning are then discussed including three classical horizontal partitioning schemes: range, hash, and random partitioning. Data partitioning on Hadoop clusters is also discussed with a summary of new strategies for big data partitioning, including the new Random Sample Partition (RSP) distributed model. The classical methods of data sampling are then investigated, including simple random sampling, stratified sampling, and reservoir sampling. Two common methods of big data sampling on computing clusters are also discussed: record-level sampling and block-level sampling. Record-level sampling is not as efficient as block-level sampling on big distributed data. On the other hand, block-level sampling on data blocks generated with the classical data partitioning methods does not necessarily produce good representative samples for approximate computing of big data. In this survey, we also summarize the prevailing strategies and related work on sampling-based approximation on Hadoop clusters. We believe that data partitioning and sampling should be considered together to build approximate cluster computing frameworks that are reliable in both the computational and statistical respects."
9403767,Methods of enterprise electronic file content information mining under big data environment,"As the product of the digital age, big data technology and computer information technology can greatly improve the efficiency and quality of file management and promote the development of enterprises. Based on this, this paper first analyzes the current status of enterprise archives management; Secondly, this paper discusses the countermeasures of information mining of electronic documents of innovative enterprises in the digital age. Text information mining is beneficial to improve the efficiency of text information search and utilization, aiming at the existing problems of traditional methods, the text information mining method is proposed."
9130588,The big data analysis and mining of people's livelihood appeal based on time series modeling and algorithm,"In order to analyze the big data of people's livelihood appeal, this paper proposes a time series modeling and algorithm to decompose the time series {x(t)} of data into long-term change trend L(t), short-term change trend S(t) and occasional change e(t). Then use this method to break down the data of six types of people's livelihood appeal such as unlicensed vendor, industrial noise, sewer cover, academic qualification, out-of-store operation and public transportation, combine other data for correlation analysis, find out the cause of the appeal event and make predictions. The experimental results verify the effectiveness of time series analysis in big data analysis and mining of people's livelihood appeal, and it is an useful attempt in the analysis of e-government big data."
9259196,Multi-attention fusion modeling for sentiment analysis of educational big data,"As an important branch of natural language processing, sentiment analysis has received increasing attention. In teaching evaluation, sentiment analysis can help educators discover the true feelings of students about the course in a timely manner and adjust the teaching plan accurately and timely to improve the quality of education and teaching. Aiming at the inefficiency and heavy workload of college curriculum evaluation methods, a Multi-Attention Fusion Modeling (Multi-AFM) is proposed, which integrates global attention and local attention through gating unit control to generate a reasonable contextual representation and achieve improved classification results. Experimental results show that the Multi-AFM model performs better than the existing methods in the application of education and other fields."
9377876,FDC Cache: Semantics-driven Federated Caching and Querying for Big Data,"To deliver business value, most data-driven enterprises and applications require data to be extracted and merged from otherwise siloed data storage platforms. FDC Cache has been designed and developed to enable the fusion and caching of data drawn from multiple small and/or Big Data stores. This capability executes a sequence of queries, wherein the results from one query may be used to constrain subsequent queries. The results of each query are linked with results from previous queries, incrementally building a cache of semantically linked data that can be used to support multiple independent data requests. FDC Cache uses Semantic Web technologies, and knowledge graphs in particular, to describe the relevant data and relationships in a computable model. This enables applications to reason over the graph, for example to dynamically retrieve targeted subsets of data comprised of previously disparate information. We have successfully applied FDC Cache to two distinct industrial use cases: (i) merging data across multiple sources to assemble information about current parts in a gas turbine, and (ii) dynamically aligning siloed data from electric grid transmission and distribution networks to an industry-standard common model, in which the cache creation time has been shown to scale sub-linearly with the number of data elements. FDC Cache has been open-sourced as part of the GE-developed open source Semantics Toolkit."
9005614,An Effective and Scalable Data Modeling for Enterprise Big Data Platform,"The enormous growth of the internet, enterprise applications, social media, and IoT devices in the current time caused a huge spike in enterprise data growth. Big data platform provided scalable storage to manage enterprise data growth and served easier data access to decision-makers, stakeholders and business users. It is a well-known challenge to classify, organize and store all this data and process it to provide business insights. Due to nature, variety, velocity, volume and value of data make it difficult to effectively process big data. Enterprises face challenges to apply complex business rules, to generate insights and to support data-driven decisions in a timely fashion. As big data lake integrates streams of data from a bunch of business units, stakeholders usually analyze enterprise-wide data from various data models. Data models are a vital component of Big data platform. Users may do complex processing, run queries and perform big table joins to generate required metrics depending on the available data models. It is usually a time consuming and resource-intensive process to find the value from data. It is a no-brainer that big data platform in the enterprise needs high-quality data modeling methods to reach an optimal mix of cost, performance, and quality. This paper addresses these challenges by proposing an effective and scalable way to organize and store data in Big Data Lake. It presents some of the basic principles and methodology to build scalable data models in a distributed environment. It also describes how it overcomes common challenges and presents findings."
9378088,An ER-Flow Diagram for Big Data,"ER diagrams have a proven track record to rep-resent data structure and relationships, in many CS problems, beyond relational databases. The ER diagram strengths are abstraction, generality, flexibility, and intuitive visual representation, with few weaknesses; hence its popularity. The main con is the old box-diamond-ellipse-line notation, which has been subsumed by the more modern and simpler UML box-line notation. Given the broad, varied, and dynamic nature of big data ER diagrams are mostly ignored, except when the data sources are databases. It is common wisdom raw big data needs significant pre-processing before computing any analytics, resulting in a long chain of data transformations computed in SQL, Python, or R languages, for instance. On the other hand, flow diagrams remain the main mechanism to visualize major components of a software system or main processing steps of an algorithm, showing rectangles (verbs) connected by arrows (processing order, dependence). In this work, we propose to combine both diagrams into one. We propose a hybrid diagram, which we call ER-Flow, based on modern UML notation, to assist analysts in data pre-processing and exploration. Aiming to introduce a minimal change to the ER diagram, we extend relationships lines with an arrow, indicating processing flow and we annotate entities coming from pre-processing with numbers and transformation labels. We illustrate how our novel ER-Flow diagram can help the user navigate big data at the metadata level, providing an integrated view of data and source code, with many practical benefits."
9196489,Thoughts On The Ecological Environment Management Innovation Driven By Big Data,"Based on the review of the technical characteristics and development process of big data, combined with the development trend of ecological environment big data, this paper puts forward the thinking of using big data to drive the innovation of ecological environment management and the countermeasures and suggestions for the intelligent application of ecological environment big data."
9006495,Federated Multimodal Big Data Storage & Analytics Platform for Additive Manufacturing,"Additive technologies are expected to revolutionize manufacturing across almost every industry, but there is a sizable gap between the current state of the technology and the maturity required for it to achieve widespread adoption. Advanced analytics are required to improve the reliability and repeatability of additive manufacturing, and those analytics require data. Large volumes of multimodal data are generated and used throughout the additive manufacturing lifecycle, from material design to part design and simulation, part printing to post-processing and inspection. To capture and link that diverse Big Data together, we have designed and developed a federated multimodal Big Data storage and analytics platform comprised of three tiers-a distributed polyglot data storage and analysis tier with different repositories for different data structures, a metadata knowledge graph tier for modeling the data and their relationships across the various repositories, and a user interface tier for visualizing, exploring and invoking analytics on the data. The platform has been used to integrate a collection of previously disparate steps to optimize the process parameters used to build a new additive material, enabling materials scientists and other non-software experts to capture, visualize and analyze the requisite data through a single user interface."
9650117,Data Model and Analysis for Big Data Mapping and Management in the Energy Data Platform,"The energy data scope is very broad including oil and gas, coal, minerals, new energy, renewable and conversion energy, electricity, and others. The different volume, variety, veracity, and velocity of data have challenge to address with the energy data model. The works focus on the development of data model for big data storage implementation schemes in the energy data. The data model has produces by analyzed the national energy big data architecture, develop the data mapping and correlation, big data master data management with energy industry standardization, big data management portal for upstream energy and downstream energy. The research has goal to establishing a foundation for building technology and big data management in the energy sector which includes petroleum, coal, geothermal and renewable energy, and in the future can be the basis for predictive analysis and national energy production."
9671686,"Privacy-Preserving Big Data Exchange: Models, Issues, Future Research Directions","Big data exchange is an emerging problem in the context of big data management and analytics. In big data exchange, multiple entities exchange big datasets beyond the common data integration or data sharing paradigms, mostly in the context of data federation architectures. How to make big data exchange while ensuring privacy preservation constraintsƒ The latter is a critical research challenge that is gaining momentum on the research community, especially due to the wide family of application scenarios where it plays a critical role (e.g., social networks, bio-informatics tools, smart cities systems and applications, and so forth). Inspired by these considerations, in this paper we provide an overview of models and issues in the context of privacy-preserving big data exchange research, along with a selection of future research directions that will play a critical role in next-generation research."
9434443,Research on Innovation of Automobile Marketing Mode Based on Big Data Marketing,"With the rapid development of the Internet, the application of big data is more and more extensive. Compared with traditional marketing, big data marketing has significant advantages in market information acquisition, data processing and analysis, and data application. For the automotive industry, the traditional marketing mode is facing severe challenges due to the development of big data technology. In view of this form, a new marketing mode based on big data marketing, which is called precision marketing, came into being. The new automobile precision marketing mode based on big data can be implemented from the following aspects: precise positioning based on big data analysis, accurate push based on big data mining, and fine management based on big data application."
9378407,Machine Learning and OLAP on Big COVID-19 Data,"In the current technological era, huge amounts of big data are generated and collected from a wide variety of rich data sources. These big data can be of different levels of veracity in the sense that some of them are precise while some others are imprecise and uncertain. Embedded in these big data are useful information and valuable knowledge to be discovered. An example of these big data is healthcare and epidemiological data such as data related to patients who suffered from epidemic diseases like the coronavirus disease 2019 (COVID-19). Knowledge discovered from these epidemiological data-via data science techniques such as machine learning, data mining, and online analytical processing (OLAP)-helps researchers, epidemiologists and policy makers to get a better understanding of the disease, which may inspire them to come up ways to detect, control and combat the disease. In this paper, we present a machine learning and big data analytic tool for processing and analyzing COVID-19 epidemiological data. Specifically, the tool makes good use of taxonomy and OLAP to generalize some specific attributes into some generalized attributes for effective big data analytics. Instead of ignoring unknown or unstated values of some attributes, the tool provides users with flexibility of including or excluding these values, depending on their preference and applications. Moreover, the tool discovers frequent patterns and their related patterns, which help reveal some useful knowledge such as absolute and relative frequency of the patterns. Furthermore, the tool learns from the patterns discovered from historical data and predicts useful information such as clinical outcomes for future data. As such, the tool helps users to get a better understanding of information about the confirmed cases of COVID-19. Although this tool is designed for machine learning and analytics of big epidemiological data, it would be applicable to machine learning and analytics of big data in many other r...
(Show More)"
9671739,Big data analytics in support of the under-rail maintenance management at Vitória – Minas Railway,"This paper describes an ongoing study using data collected by an instrumented ore car on Vitória–Minas Railway, operated by Vale in Brazil. The research uses big data analysis methods over collected data by the instrumented car during its voyages. Railway geometry issues can cause undesirable movements on the wagons that can cause discomfort for passengers or instability for the cargo. In the worst scenario, derailments can occur. Each second, several sensors installed on the instrumented car collect data about velocity, acceleration, and movements on the wagon. The volume of collected data is impressive since the railway has about 2,000 km of extension. That volume compels us to use big data analytics methods. As the result of the research, the team aims to establish some levels of operational conditions, named as severity indexes, which can indicate to the maintenance teams the necessity of intervention on the railway."
9137451,Research on Big Data Reference Architecture Model,"For ISO / / IEC TS 25011:2017 some deficiencies of big data reference system. In this paper, we redesigned the big data reference system structure model, and proposed a goal (big data information service quality), three chains (information value chain, information technology value chain and information assurance value chain) and five roles (big data application provider, big data framework provider and big data information assurance provider) 1-3-5 model of data provider and data consumer, and all the attributes of the model are described. In the part of big data information service quality, the deficiencies in ISO / / IEC TS 25011:2017 are corrected. Then, the basic system of big data is proposed. Under the big data reference architecture model proposed in this paper, compared with some other typical models, the conclusion is that other typical models can be replaced completely."
9434438,Film Big Data Visualization Based on D3.js,"In order to understand and mine the information behind the film more intuitively, D3.js is used to visualize the film big data. After obtaining the film data released in China in 2019 through the crawler, use D3.js to present the data in the form of histogram, doughnut chart, force-directed graph, map, Word Cloud, and add rich interactive functions to enable users to quickly obtain the information they need. The final analysis can provide some decision support for the Chinese film industry, as well as a reference for users to select films. Research shows that D3.js is adaptable and reliable for the visualization goals at high speed with low cost in big data processing activities."
8935096,Mining conditional functional dependency rules on big data,"Current Conditional Functional Dependency (CFD) discovery algorithms always need a well-prepared training dataset. This condition makes them difficult to apply on large and low-quality datasets. To handle the volume issue of big data, we develop the sampling algorithms to obtain a small representative training set. We design the fault-tolerant rule discovery and conflict-resolution algorithms to address the low-quality issue of big data. We also propose parameter selection strategy to ensure the effectiveness of CFD discovery algorithms. Experimental results demonstrate that our method can discover effective CFD rules on billion-tuple data within a reasonable period."
8673585,Cybersecurity in Big Data Era: From Securing Big Data to Data-Driven Security,"‘‘Knowledge is power” is an old adage that has been found to be true in today’s information age. Knowledge is derived from having access to information. The ability to gather information from large volumes of data has become an issue of relative importance. Big Data Analytics (BDA) is the term coined by researchers to describe the art of processing, storing and gathering large amounts of data for future examination. Data is being produced at an alarming rate. The rapid growth of the Internet, Internet of Things (IoT) and other technological advances are the main culprits behind this sustained growth. The data generated is a reflection of the environment it is produced out of, thus we can use the data we get out of systems to figure out the inner workings of that system. This has become an important feature in cybersecurity where the goal is to protect assets. Furthermore, the growing value of data has made big data a high value target. In this paper, we explore recent research works in cybersecurity in relation to big data. We highlight how big data is protected and how big data can also be used as a tool for cybersecurity. We summarize recent works in the form of tables and have presented trends, open research challenges and problems. With this paper, readers can have a more thorough understanding of cybersecurity in the big data era, as well as research trends and open challenges in this active research area."
9545987,Research on Big Data Analysis Data Acquisition and Data Analysis,"Using big data analysis algorithm, this paper discusses the source of data acquisition, points out the technical characteristics of data source, and explains the data acquisition methods and requirements. Clear the purpose of big data analysis, build data analysis system, describe the process of data analysis. There are four steps in big data analysis: data acquisition, data storage, data analysis and data mining. Data acquisition can be divided into two parts: acquisition and preprocessing, which is just narrow data acquisition. The data analysis of the Internet of things is a process of organizing and purposefully collecting data, processing data and analyzing data to form information. The analysis process is the support and execution process of the algorithm. In the data processing cycle, data analysis should be used properly in every link from data acquisition in the field perception layer to data transmission in the communication layer to data processing in the application layer, so as to improve the effectiveness and rationality of data processing."
9289757,A New Approach to Use Big Data Tools to Substitute Unstructured Data Warehouse,"Data warehouse and big data have become the trend to help organise data effectively. Business data are originating in various kinds of sources with different forms from conventional structured data to unstructured data, it is the input for producing useful information essential for business sustainability. This research will navigate through the complicated designs of the common big data and data warehousing technologies to propose an effective approach to use these technologies for designing and building an unstructured textual data warehouse, a crucial and essential tool for most enterprises nowadays for decision making and gaining business competitive advantages. In this research, we utilised the IBM BigInsights Text Analytics, PostgreSQL, and Pentaho tools, an unstructured data warehouse is implemented and worked excellently with the unstructured text from Amazon review datasets, the new proposed approach creates a practical solution for building an unstructured data warehouse."
9006294,QualiBD: A Tool for Modelling Quality Requirements for Big Data Applications,"The development of Big Data applications is not well-explored, to our knowledge. Embracing Big Data in system building, questions arise as to how to elicit, specify, analyse, model, and document Big Data quality requirements. In our ongoing research, we explore a requirements modelling language for Big Data software applications. In this paper, we introduce QualiBD, a modelling tool that implements the proposed goal-oriented requirements language that facilitates the modelling of Big Data quality requirements."
9005530,Federated Query processing for Big Data in Data Science,As the number of databases continues to grow data scientists need to use data from different sources to run machine learning algorithms for analysis. Data science results depend upon the quality of data been extracted. The objective of this research paper is to implement a federated query processing framework which extracts data from different data sources and stores the result datasets in a common in-memory data format. This helps data scientists to perform their analysis and execute machine learning algorithms using different data engines without having to convert the data into their native data format and improve the performance.
9006238,Neural and Quantum Cryptography in Big Data: A Review,"That is a fact that the increasing volume of data brings security problems. Encryption measures taken against these emerging and increasing security problems have been examined, and it has been seen that encryption approaches are performed mainly in the areas of neural and quantum cryptography. According to these two of the advanced cryptography techniques are discussed and analyzed with their advantages and disadvantages. This article is committed to paper to be able to provide solutions for big data privacy and big data security problems with Neural and Quantum Cryptography techniques when questioning their feasibility."
9403759,A Preliminary Study on Data Security Technology in Big Data Cloud Computing Environment,"In the rapid development of Internet technology, the application of various new technologies has become more and more extensive. Among them, the development of big data technology and cloud computing technology is very rapid, and these technologies are of great help to improving the efficiency of data storage and management. However, the data system itself has certain data security problems in the big data cloud computing environment. In order to improve people's information security in the process of data processing and integration, we need to study data security protection technology in the big data cloud computing environment. Only in this way can we solve data and information security issues based on specific conditions and improve the reliability and security of data transmission."
9143040,Big Data based Adaptive Learning and Scope of Automation in Actionable Knowledge,"In general, big data can be treated as a tool to extract knowledge from the larger datasets with different data values. Big-data research is being carried out for a long time to extract the data from larger datasets. Generally, some of the devices, sensors generate a humongous amount of data continuously. Hence performing any computational operation or search operation in that bulk data is remaining as a challenging task. At present, the big data researchers are facing challenges such as duplication of data, and identifying the data from one data set to others and also identifying the multidisciplinary data is also a challenging task. When the data is increasing tremendously day by day as a result the server size, capacity and device storage size, RAM etc., should also be improved for deploying fast and efficient results. In this research work, the Big Data Analytics Problem (BDAP) is proposed for offering many solutions such as data deduplication, security, reliability access control etc., and finally and most important it is used for making analysis and decision making."
9403806,Big data cleaning model of smart grid based on Tensor Tucker decomposition,"The traditional big data cleaning model processes data in the form of template matching, which is limited by the data dimension. It not only needs a large calculation space, but also has poor data cleaning effect. To solve the above problems, a smart grid big data cleaning model based on tensor Tucker decomposition is proposed. KNN algorithm is used to detect abnormal data in power grid big data, and the missing data is filled and removed. The tensor Tucker decomposition is used to compress the data and reduce the data dimension. Based on the neural network structure, the data cleaning model is constructed. Compared with the traditional model, the average effective cleaning rate of the cleaning model after tensor Tucker decomposition is 94.16%, which has good data cleaning effect."
9095568,Operation Framework of the Command Information System Based on Big Data Analysis,"With the development of Internet and information technology, big data analysis brings new opportunities for all industries and fields in the world. This paper expounds the basic concept of big data and data analysis, builds a framework of the command information system based on big data analysis, puts forward the solution of real-time data analysis and data distribution for the command information system, provides theoretical foundation for our army command information system in period of big data."
9378286,An Indexing Scheme for Telerehabilitation Big Data,"Reduced cost and increased proliferation of sensors has resulted in the generation of a large amount of data. To make use of this data effectively, efficient techniques for collecting, storing and managing data are needed. In this paper, we present a health big data indexing technique that allows for the efficient storage, querying and management of tele-rehabilitation related big data collected via health sensors connected to client machines accessing web-based e-Health frameworks. Our novel scheme is based on indexing of rehabilitation data based on the human body joint model. We further index the data based on other parameters that may be of interest to researchers such as ethnicity and geographical location. We have described all components of the system in brief."
8669607,Research on Feasibility Path of Technology Supervision and Technology Protection in Big Data Environment,"Big data will bring revolutionary changes from life to thinking for society as a whole. At the same time, the massive data and potential value of big data are subject to many security risks. Aiming at the above problems, a data privacy protection model for big data platform is proposed. First, the data privacy protection model of big data for data owners is introduced in detail, including protocol design, logic design, complexity analysis and security analysis. Then, the query privacy protection model of big data for ordinary users is introduced in detail, including query protocol design and query mode design. Complexity analysis and safety analysis are performed. Finally, a stand-alone simulation experiment is built for the proposed privacy protection model. Experimental data is obtained and analyzed. The feasibility of the privacy protection model is verified."
8837005,Research on Government Integrity Evaluation Based on Big Data,"By studying the international advanced practices of government integrity evaluation represented by Standard & Poor's, Global Integrity, Transparency International and Korea, this paper found that most of the evaluations are based on perceptual surveys. Although this method of data acquisition is simple and easy to implement, it has inherent defects, such as strong subjectivity, lack of details, prone to cause sample deviation, etc. Based on the goal of improving government capacity in integrity, this paper put forward a new idea of government integrity evaluation based on big data: Firstly, collect the behavior data and complaint reporting data in the government business systems, combine with the public opinion data on the Internet. Then, use the big data technology to get the evaluation indicator data of government integrity. Finally, construct a scientific evaluation model through the credit scorecard method. Compared with the traditional measure of evaluation, the government integrity evaluation based on big data in this paper not only can obtain more accurate evaluation results, but also has great value in its evaluation process. A large amount of objective and quantitative - rather than subjective and perceived data - can better support government decision-making and reform. The scientific evaluation indicator system can also guide the specific work of the government."
9691296,"A mini-review of machine learning in big data analytics: Applications, challenges, and prospects","The availability of digital technology in the hands of every citizenry worldwide makes an available unprecedented massive amount of data. The capability to process these gigantic amounts of data in real-time with Big Data Analytics (BDA) tools and Machine Learning (ML) algorithms carries many paybacks. However, the high number of free BDA tools, platforms, and data mining tools makes it challenging to select the appropriate one for the right task. This paper presents a comprehensive mini-literature review of ML in BDA, using a keyword search; a total of 1512 published articles was identified. The articles were screened to 140 based on the study proposed novel taxonomy. The study outcome shows that deep neural networks (15%), support vector machines (15%), artificial neural networks (14%), decision trees (12%), and ensemble learning techniques (11%) are widely applied in BDA. The related applications fields, challenges, and most importantly the openings for future research, are detailed."
9360971,"Research on Refined Sales Management, Data Analysis and Forecasting under Big Data","This article analyzes the key points of refined sales management under big data. The main points of sales management include how to establish a sales management organization, how to improve the sales management information system, how to improve the evaluation management system, and how to strengthen internal sales control. Combining the key points of data analysis under big data, the author studies the establishment of data warehouse, data cleaning and mining, the establishment of data prediction models, and the arrangement of model analysis results. The purpose of this article is to help people give full play to the advantages of big data technology applications and promote the healthy development of the enterprise economy."
9377953,Quasi-optimal Data Placement for Secure Multi-tenant Data Federation on the Cloud,"As it is difficult to directly share data among different organizations, data federation brings new opportunities to the data-related cooperation among different organizations by providing abstract data interfaces. With the development of Cloud computing, organizations store data on the Cloud to achieve elasticity and scalability for data processing. The existing data placement approaches generally only consider one aspect, which is either communication cost or time cost, and do not consider the features of jobs that process the data. In this paper, we propose an approach to enable secure data processing on the Cloud with the data from different organizations. The approach consists of a data federation platform for secure data processing on the Cloud named FedCube and a greedy data placement algorithm that creates a plan to store data on the Cloud in order to achieve multiple objectives based on a cost model. The cost model is composed of two objectives, i.e., reducing both monetary cost and execution time. We present an experimental evaluation by comparing our data placement algorithm with the existing methods based on the data federation platform. The experiments show that our proposed algorithm significantly reduce the total cost (up to 69.8%)."
9109961,Research on the Application of Big Data Technology in Electronic Commerce Supply Chain,"In order to realize the application of big data technology in e-commerce supply chain, this paper puts forward a novel application method of e-commerce supply chain based on big data technology. This method is based on big data technology, combines the Internet of things technology and cloud computing technology, constructs the big data platform of the e-commerce supply chain, and can mine and analyze the data in the e-commerce supply chain. The research results show that this method can promote the application and development of big data technology in e-commerce supply chain and bring great convenience for businesses and customers."
9378113,A Study on the Causes of Garbage Collection in Java for Big Data Workloads,"Garbage collection in Java is critical to the performance of Big Data applications. Our study brings forth the causes that invoke the 3 Java garbage collectors for Big Data and non Big Data workloads. We conclude that allocation failure occurs for about 31-99 per cent of the total garbage collector execution time and is the most common cause for garbage collection in Big Data workloads. In case of Dacapo workloads, we observe that the prominent cause for garbage collection is system gc calls which occur for about 40-99 per cent of the total garbage collector execution time."
8725723,Intelligent Procuratorate Depends on Big Data Investigation Technology,"With the change of the times and the advent of the era of wisdom, it is urgent for procuratorial organs to apply big data investigation technology to solve difficult problems in their work. Big data can discover deep-seated rules and connections of data through valuable data processing. Big data investigation is different from the traditional reconstructing criminal process by consequence traceability. It is a process of mining effective clues on the basis of analyzing and dealing with the links between various clues. It is an effective investigation model based on a large number of data, which can make certain prediction of the direction of investigation. This is a change for ex post investigation and passive investigation in the past. It will also change the single-thread investigation mode to multi-clue cooperative investigation, which will surely lead the future development direction of investigation."
9010596,Using Big Data for Data Leak Prevention,"The paper present our approach for protecting sensitive data, using the methods of Big Data. To effectively protect the valuable information within the organization, the following steps are needed: Employing a holistic approach for data classification, identifying sensitive data of the organization, Identifying critical exit points - communication channels, applications and connected devices and protecting the sensitive data by controlling the critical exit points. Our approach is based on creating of component-based architecture framework for ISS, conceptual models for data protection and implementation with COTS IT security products as Data Leak Prevention (DLP) solutions. Our approach is data centric, which is holistic by its nature to protect the meaningful data of the organization."
9377734,Requirements Engineering Practices and Challenges in the Context of Big Data Software Development Projects: Early Insights from a Case Study,"This paper reports on the results of an exploratory case study on a large-scale Big Data systems development project in the Oil&Gas domain within a non-profit organisation. The aim of this study was to investigate the RE practices and challenges in such projects, currently bereft in the scientific literature. This investigation was focused on: (a) RE practices; (b) sources and distribution of requirements; (c) the role of Big Data characteristics and technologies in RE and systems design; and (d) RE challenges in engineering Big Data Systems. The main results show that (a) there is a lack of specific project tailored RE practices, tools, and frameworks for elicitation, specification and modelling, analysis, and prioritisation of requirements; (b) 40% of the system's requirements are considered Big Data-related from which 75% are identified from internal sources; (c) Big Data characteristics and technologies play an important role in defining quality requirements and system's architecture; (d) five challenges in eliciting, documenting, and analysing Big Data related requirements were identified and discussed. The findings suggest academics and practitioners opportunities to engage in further research in this area."
9110076,Research on the Risk and Supervision Method of Big Data Application in Financial Field,"In order to solve the possible risks in the application of big data in the financial field, this paper proposes a new supervision method based on big data. This method is based on big data, constructs the application platform of financial big data, and carries on the real-time mining to the massive big data in the financial field. The results show that this method can not only break the problem of data island, improve the security of personal privacy data, but also promote the standardization of big data."
9360991,Design and Implementation of Big Data Visual Statistical Analysis Platform,"With the rapid development of the Internet industry, more and more enterprises begin to realize the importance of data. Big data has gradually become an important reference for enterprises to understand their current situation and determine their future development direction. Big data visual statistical analysis platform refers to the system platform that completes most of the big data statistical analysis and shows the demand through the visual interface operation. The system platform mainly includes several functional modules such as visual ETL, visual construction site, authority management, data subscription and system monitoring. The research and development process is mainly based on the Spring framework. MySQL, Redis and HDFS are taken as data storage tools, and Apache Kylin, Spark and other data computing tools are used to carry out architecture design based on the core principles of high performance and high scalability. Finally, various services are combined with the concept of micro-service architecture to complete the overall construction of the system."
9343361,Big Data Science on COVID-19 Data,"In the current era of big data, high volume of big data can be generated and collected from a wide variety of rich data sources at a rapid rate. Embedded in these big data are useful information and valuable knowledge. Examples include healthcare and epidemiological data such as data related to patients who suffered from viral diseases like the coronavirus disease 2019 (COVID-19). Knowledge discovered from these epidemiological data via data science helps researchers, epidemiologists and policy makers to get a better understanding of the disease, which may inspire them to come up ways to detect, control and combat the disease. In this paper, we present a data science solution for analyzing big COVID-19 epidemiological data. The solution helps users to get a better understanding of information about the confirmed cases of COVID-19. Evaluation results show the benefits of our data science solution in discovering useful knowledge from big COVID-19 data."
9403166,Research on the Core Technology of Education Big Data Based on Data Mining,"In recent years, big data technology has made amazing achievements in the field of education, which has also aroused the attention of scholars on the application of data mining technology in education big data. However, the technology is still in the primary stage, and there are still many deficiencies. Therefore, this paper proposes the core technology research of education big data based on data mining. This paper makes an in-depth investigation and Research on the current management mode of education big data. Through the survey, it is a mainstream trend to adopt data mining technology to manage education big data. However, due to the immature technology, there are still some technical defects in the existing management, such as inaccurate prediction and incomplete data collection. In view of these shortcomings, this paper proposes an optimization and improvement scheme, which adjusts the data normalization processing method, optimizes the data clustering method, improves the prediction accuracy and simplifies the calculation steps. In the related verification experiments, compared with the traditional random recommendation algorithm and collaborative filtering algorithm, the prediction accuracy of the improved scheme has been improved, reaching a high level of 99.2%. This paper analyzes that the education big data management scheme based on data mining will play an important role in the future education management."
9457403,Research on Library Personalized Service Mode Based on Big Data Application,"This paper explores the concept and technology of the big data, analyzes the big data environment in the library, and analyzes the source, classification and characteristics of library big data from the relationship between readers, collections and librarians. On this basis, this article constructs a library personalized information service model based on big data applications, and analyzes the current problems and countermeasures faced by libraries."
8669649,Stocks Analysis and Prediction Using Big Data Analytics,"Big data analytics are used primarily in various sectors for accurate prediction and analysis of the large data sets. They allow the discovery of significant information from large data sets, otherwise, it is hidden. In this paper, an approach of robust Cloudera-Hadoop based data pipeline is proposed to perform analyses for any scale and type of data, in which selected US stocks are analysed to predict daily gains based on real time data from Yahoo Finance. The Apache Hadoop big-data framework is provided to handle large data sets through distributed storage and processing, stocks from the US stock market are picked and their daily gain data are divided into training and test data set to predict the stocks with high daily gains using Machine Learning module of Spark."
9552131,The Framework of Extracting Unstructured Usage for Big Data Platform,"Big Data becomes crucial tools for new era of data analytics. The amount of unstructured data is also increasing. As a result, the number of unstructured data projects are increased. However, several organizations are still lack of knowledge how to determine the unstructured data in the organization and exploit it. Therefore, the tool of extracting unstructured data is needed. This research aims to propose the framework to identify the unstructured usage in the organization. The framework has been derived from the interview of the experts in areas. After that, the framework has been used to verify the results. The success case and failed are also shown. This can be seen that the proposed framework can be used in the organization to help the user extract the unstructured data usage in the organization. It can help to make the decision related to unstructured data project."
9142979,Data Mining Visualization with the Impact of Nature Inspired Algorithms in Big Data,Data mining visualization is an important aspect of big data visualization and analysis. The impact of the nature-inspired algorithm along with the impact of computing traditions for the complete visualization of the storage and data communication needs have been studied. This paper also explores the possibilities of the hybridization of data mining in terms of association of cloud computing. It also explores the data analytical view in the exploration of these approaches in terms of data storage in big data. Based on these aspects the methodological advancement along with the problem statements has been analyzed. This will help in the exploration of computational capability along with the new insights in this domain.
9523499,LotusSQL: SQL engine for high-performance big data systems,"In recent years, Apache Spark has become the de facto standard for big data processing. SparkSQL is a module offering support for relational analysis on Spark with Structured Query Language (SQL). SparkSQL provides convenient data processing interfaces. Despite its efficient optimizer, SparkSQL still suffers from the inefficiency of Spark resulting from Java virtual machine and the unnecessary data serialization and deserialization. Adopting native languages such as C++ could help to avoid such bottlenecks. Benefiting from a bare-metal runtime environment and template usage, systems with C++ interfaces usually achieve superior performance. However, the complexity of native languages also increases the required programming and debugging efforts. In this work, we present LotusSQL, an engine to provide SQL support for dataset abstraction on a native backend Lotus. We employ a convenient SQL processing framework to deal with frontend jobs. Advanced query optimization technologies are added to improve the quality of execution plans. Above the storage design and user interface of the compute engine, LotusSQL implements a set of structured dataset operations with high efficiency and integrates them with the frontend. Evaluation results show that LotusSQL achieves a speedup of up to 9× in certain queries and outperforms Spark SQL in a standard query benchmark by more than 2× on average."
9389892,Research and Application of Big Data Analysis for Oil and Gas Production,"The history of oil and gas development and production is a history of data development. The generation of a large amount of information data has laid the cornerstone for the application of big data analysis. How to effectively mine data resources, use big data analysis to guide oilfield production practices, and provide a theoretical basis for decision-making to improve quality and efficiency is the technology core. In recent years, Huabei Oilfield has explored the application of big data analysis in oil and gas production. According to the types and characteristics of oilfield data, it has proposed and created a closed-loop big data analysis “seven-step method” system from acquisition, processing, tracking, and evaluation, preliminary designed and developed a data mining platform for oil production engineering based on Hadoop/Spark; The platform has been applied in 6 oil and gas production units and achieved remarkable social and economic benefits."
9148352,Implementation of Water Quality Management Platform for Aquaculture Based on Big Data,"In order to ensure the quality and quantity of aquaculture, aquaculture farmers need to grasp the water quality in time. However, most farmers have to collect water quality data manually at present, and cannot store and reuse that information rapidly. This paper aims to use SpringBoot framework and JPA framework to build a big data platform of acquisition automation and visualization, which realizes the data analysis and display of heterogeneous water quality and breeding information. The platform can make the water quality prediction and real-time warning. Meanwhile, it realizes the management of robots, users and breeding experts. The application of this platform will bring better social benefits to aquaculture farmers."
9110106,Research on the Application of Big Data in Industrial Structure Adjustment and Economic Indexes,"In order to improve the utilization efficiency of big data in China's industrial structure adjustment and economic index, this paper puts forward a novel method of industrial structure adjustment and economic index based on big data. Based on big data, this method can mine and utilize industrial structure data and economic index data. The research results show that this method can improve big data's utilization efficiency in China's industrial structure adjustment and economic indicators, and promote the rationalization and upgrading of China's industrial structure."
9434494,Application and research of Big data analysis in commercial Banks,"With the vigorous development of fintech, the market environment of the traditional financial industry has undergone great changes. The operation and management are becoming increasingly digital and intelligent, the marketing is becoming more scenariooriented and precise, and the service mode is becoming more personalized and customized. It is urgent to establish an innovative management and service mechanism that meets the needs of The Times. With the in-depth application of new information technologies such as big data, cloud computing, blockchain and artificial intelligence, big data has brought unprecedented opportunities for the development of the banking industry. How to effectively apply big data to the management and business innovation of commercial Banks is an important issue facing the whole banking industry. Therefore, commercial Banks should focus on the development pattern of the big data industry and conduct in-depth research and exploration on the application status and future scenarios of the big data industry in commercial Banks based on their own business realities. Swot analysis should be carried out on the advantages, disadvantages, opportunities and challenges of big data application in commercial Banks from the perspectives of policy orientation and market environment, and the optimization strategy of big data application in banking business in the future should be discussed in order to provide some references."
8836992,Research on Real-time Analysis and Hybrid Encryption of Big Data,"With the increasing of massive multi-source heterogeneous big data, the higher demand on the speed of data analysis has been raised. Based on the analysis of the existing problems of Hadoop MapReduce and Apache Spark, this paper proposes to use Spark Streaming for real-time processing of massive stream data, and builds a prototype cluster, which proves the real-time analysis of log data (online log and offline log) and the real-time processing of network attack data. At the same time, a hybrid encryption method combining ECC encryption with block data encryption and a secret key generation method combining semiconductor noise source and chaotic sequence are proposed. The simulation results show that the efficiency and security of encryption are effectively guaranteed."
9006039,"Applying SDN based data network on HPC Big Data Computing – Design, Implementation, and Evaluation","Large scale storage data networks are difficult to conFigure and tricky to maintain [1][2][3]. As storage data volumes grow and the pace of change accelerates, it can be a struggle to keep up the integrity of a large scale storage network. Software Defined Networking (SDN) [5][6][7][8][10][11] provides a method to centrally conFigure and manage physical and virtual network devices such as routers, switches, and gateways in HPC datacenter. Current HPC computer cluster and data centers are using homogeneous data network technologies such as the Infiniband network (QDR, FDR, EDR, and HDR). Due to the connector, cable, and bandwidth backward compatibility issues, once an aged HPC computing system was retired, we have to demolish all established computer clusters, data network, and data storage. Eventually we lost all costly investment on the data network and storage. Those current deployment approaches do not provide a feasible and compatible growing path and cannot meet the need for future extreme scale HPC computing systems [4][12][13]."
9564340,Towards Platform-Agnostic and Autonomous Orchestration of Big Data Services,"Big data analytics and business insights are of high importance and demand among today’s services and applications. Traditionally, the entire big data pipeline goes through numerous processing steps. However, the complexity of supporting big data analytic applications is more than its recent reputation would suggest. On top of hybrid big data and high-performance computing resources, this paper presents a comprehensive microservices architecture to ease the management and enactment of end-to-end big data workflow management processes. It is developed along with intuitive graphical user interfaces to abstract and hide to the end user the specificities of the underlying network, storage and compute infrastructure. Entitled as Big Data Apps Composition Environment, it facilitates the design, composition, configuration, orchestration, enactment, and validation of end-to-end big data analytic services actuated into deployment workflows. Our approach differentiates to the current engines, as it adopts a big data-driven methodology which is scalable to multiple executors and has embedded notebooks for on-demand and real-time scripting analytics. Therefore, big data services and analytic applications deployment are being accelerated, while semi-automatic scaling through the definition of multiple executors for improved time performance of demanding tasks is supported."
8706990,Random Sample Partition: A Distributed Data Model for Big Data Analysis,"With the ever-increasing volume of data, alternative strategies are required to divide big data into statistically consistent data blocks that can be used directly as representative samples of the entire data set in big data analysis. In this paper, we propose the Random Sample Partition (RSP) distributed data model to represent a big data set as a set of disjoint data blocks, called RSP blocks. Each RSP block has a probability distribution similar to that of the entire data set. RSP blocks can be used to estimate the statistical properties of the data and build predictive models without computing the entire data set. We demonstrate the implications of the RSP model on sampling from big data and introduce a new RSP-based method for approximate big data analysis which can be applied to different scenarios in the industry. This method significantly reduces the computational burden of big data and increases the productivity of data scientists."
9110059,New Employee Student Repast Big Data Analysis Research Application,"with the continuous improvement of information construction, the vast majority of colleges and universities in China have begun to build digital campus, the construction of all teachers and students and school administrators have brought great convenience. With the construction of digital campus, colleges and universities will produce massive data every day, among which the data generated by students account for a large proportion. The data generated by students include scores, information on borrowing books, credit card information of dormitory access control and consumption data of campus one-card. By analyzing the behavioral data generated by students, some behavioral characteristics of students in school are found, which can provide a more scientific basis for the management of students. This paper makes use of the data such as the achievement information of students in a vocational college and the consumption information of campus one-card. Firstly, the original data is preprocessed so that the processed data can meet the basic requirements of data analysis. Then, the data after preprocessing is discretized with the data discretization technology so that the data can meet the requirements of the Apriori algorithm of association rules. Finally, Apriori algorithm is used to mine the correlation between students' academic performance and campus one-card consumption data."
9109930,Research on Big Data's Prevention Technology of Financial Systemic Risk,"In order to reduce the seriousness and frequency of financial systemic risk in the new era, this paper puts forward a novel big data prevention technology of financial systemic risk. With the combination of big data technology, Internet technology and cloud computing technology, this technology can monitor the financial market in real time and guard against suspicious information. The research results show that this technology realizes the close combination of big data and the financial market, reduces the cross-infection of financial systemic risk, and improves the controllability of financial systemic risk."
9378162,Fast and Effective Object Classification for Big Image Data,"Classification for big image data is an essential field of big data technology. Big image data classification has a wide range of applications, such as face recognition, object detection, and human posture recognition. Traditional methods for big image data classification usually ignore the close connection between different levels of features in neural networks. In this paper, we propose a new way for big image data classification that improves the previous method through the Multi-Level Feature Connection Network (MFC-Net). MFC-Net presents a multi-level feature connection module to mine more useful features for classification. Experiments show that MFC-Net significantly improves its baseline SSD (Single Shot Multibox Detector) and other advanced classification neural networks in the classic datasets Pascal VOC and Microsoft COCO."
9407102,Multi-source Heterogeneous Data Association Technology to Build Public Safety Big Data Integration Research,"This article analyzes the principles of building public safety big data integration. The content of this article includes advancement, stability, security, etc. The author studied the overall function design, background management design, data collection formatting design, mobile terminal function design, data collection system design, data collection design, system interface design, system security design, push service design, document analysis service design, etc. The purpose of this paper is to give full play to the application value of multi-source heterogeneous technology and improve the application effect of the integrated public safety big data system."
9110049,Research on the Communication Mode of Big Data Technology in the Field of Dongba Character Graphic Design,"In order to improve the communication efficiency of big data technology in the field of Dongba character graphic design, this paper puts forward a novel opportunity big data technology communication mode in the field of Dongba character graphic design. This model is based on big data technology and can collect and mine data in the field of Dongba character graphic design. The research results show that this model can effectively improve the communication efficiency of big data technology in the field of Dongba character graphic design, and realize the wide application of Dongba character in the field of graphic design."
9403813,Research on Big Data Intelligent Application Effect Evaluation Overall Technology,"The big data intelligent application effect evaluation is aimed at panoramic, realistic, dynamic and quantitative displaying and analyzing the whole process and effect of big data intelligent application, and the main scene is the application of important points such as simulation deduction, simulation evaluation and situation analysis. By using the mature experience in the field of digital simulation evaluation, integrating the latest research achievements in the field of big data analysis and artificial intelligence, the overall technology route is creatively proposed with data integration scale, application modeling intelligent, process deduction customization, effect evaluation refined, situation display comprehensive. Research results will guide the prototype system construction."
9457419,Research on Gridding Management of Intelligent Society Based on Big Data,"Big data technology is integrated into public management, which provides technical support and practical scheme for democratic participation and democratic decision-making of community grid. To some extent, this provides a risk response plan for gridding service and management. However, when using big data to realize gridding management, there are also many problems, such as the discretization of multiple governance subjects, the separation of data resources, the limitations of data sharing, and the vulnerability of data security. In order to make better use of big data to improve the level of grid management, the government needs to improve the top-level design and system construction from the macro level, the technical system and talent training from the medium level, and the privacy protection and data security from the micro level."
9459026,Analysis of the Security Strategy of Computer Network Data under the Background of Big Data,"The arrival and popularization of the era of big data has brought convenience to mankind. At the same time, data security is also our top priority. This paper analyzes the data security threats in the computer network under the background of big data, and then puts forward how to deal with the data security governance strategy."
9663258,Big data with cloud computing: Discussions and challenges,"With the recent advancements in computer technologies, the amount of data available is increasing day by day. However, excessive amounts of data create great challenges for users. Meanwhile, cloud computing services provide a powerful environment to store large volumes of data. They eliminate various requirements, such as dedicated space and maintenance of expensive computer hardware and software. Handling big data is a time-consuming task that requires large computational clusters to ensure successful data storage and processing. In this work, the definition, classification, and characteristics of big data are discussed, along with various cloud services, such as Microsoft Azure, Google Cloud, Amazon Web Services, International Business Machine cloud, Hortonworks, and MapR. A comparative analysis of various cloud-based big data frameworks is also performed. Various research challenges are defined in terms of distributed database storage, data security, heterogeneity, and data visualization."
9148505,Application Research of Big Data Statistics in the Field of Economic Management,"In the context of continuous social and economic development, the integration of statistics and economic management has been strengthened. Big data statistical technology has found economic development laws from many data, and its effect in macroeconomic analysis is extremely high. This article focuses on the application of big data statistical methods and existing problems in the field of economic management and proposes corresponding countermeasures."
9378310,Approximate Query Processing for Big Data in Heterogeneous Databases,"Big Data analytics is used in decision making. It involves heavy computation to obtain exact answers. To alleviate this problem, approximate query processing (AQP) was adopted, which provides approximate results with error bounds. The AQP models which have been proposed are supported only by a single database. In an organization, big data is stored in multiple databases that have different data models. This research aims to provide AQP as a middleware solution using query optimization for heterogeneous databases."
9680405,RSP-Hist: Approximate Histograms for Big Data Exploration on Hadoop Clusters,"We propose a sampling-based method, called RSP-Hist, to construct approximate equi-width histograms and help data scientists explore the probability distribution of big data on Hadoop clusters. In RSP- Hist, the Random Sample Partition (RSP) model is used to store a big data set as ready-to-use random sample data blocks, called RSP blocks, in the Hadoop Distributed File System (HDFS). An approximate histogram is computed by applying a sequential histogram algorithm in parallel to each block in a block-level sample of RSP blocks. Local histograms from individual RSP blocks are combined to produce an approximate histogram for the entire data. We tested RSP-Hist on four data sets using a small computing cluster. In this paper, we demonstrate the effect of the sampling rate and the number of buckets on the histogram accuracy and show that RSP-based approximate histograms are equivalent to the exact histograms computed from the entire data. RSP- Hist can avoid the data correlation issue in HDFS blocks and significantly reduce both computation and communication costs. It enables iterative and interactive exploration of big data sets on small computing clusters and can be used for multivariate data exploration."
9390052,GIS cloud computing based government Big Data analysis platform,"Transparency, wisdom and responsibility are new requirements for government work in the era of Big Data. Government Big Data is changing the traditional mode of government work, which needs corresponding technical means for auxiliary analysis and application. This paper first analyzes the spatial related government Big Data, then introduces association analysis method of government Big Data, based on GIS cloud computing technology, it proposes the government Big Data platform architecture and main functions, and finally explores the application analysis case based on traffic accident data."
9403054,Big Data Driven Model for New York Taxi Trips Analysis,"Due to the accumulation of large amount of evolution in metropolitan areas, urban data is understood and has become the first-hand prospect of manageable data, the driven analysis which can be recycled to improve life quality in urban areas. In this study, the influential factors on total fare amount charged to passengers are explored and analysed by using the taxi trip data in the year 2015 to provide the insights for people in NYC to plan their trips in a most economically efficient way."
9434476,Research on Emergency Management Information System Model Based on Big Data,"In the era of big data, the thinking of emergency management should be changed from “experience driven” to “data driven”; the traditional analysis technology and method should be changed, and the method of big data analysis should be applied to the process of emergency decision-making management. On the basis of analyzing the current research on emergency management based on big data, starting from the concept and characteristics of big data, this paper analyzes the application requirements of emergency management for big data, improves the existing technical framework of emergency platform, and proposes an emergency management system model based on big data, so as to realize the integration of big data and emergency management information mining, and provide information for emergency management technical solution reference and methodology support."
9148361,Research on Application of Distributed Server Architecture for Virtual Reality Scenarios in Big Data Environment,"As the mainstream big data distributed computing framework cannot meet the requirements of virtual reality applications for high real-time business and data-intensive services, this paper designs a distributed server cluster system, which is deployed on Alibaba Cloud and Tencent Cloud. In the case of high concurrency, it provides users with a variety of high real-time data services to meet the requirements of real-time, high availability, and high scalability, and solves the problems of high-concurrency user interaction and massive data storage and transmission in virtual reality systems. The distributed server cluster system can customize different policies according to specific business and cooperate with cloud computer resources to ensure data security and transmission efficiency. The experimental results show that the modules and algorithms of the system designed in this paper can run correctly, and the distributed server cluster system designed in this paper can meet the needs and goals of large-scale virtual reality scenarios."
9470249,The Construction of a Smart Campus Model Based on Big Data,"With the rapid development of big data technology, big data has penetrated into all walks of life, and its value has become increasingly prominent. However, because schools are affected by geographical and economic factors, the information development of schools in different regions is inconsistent, and data problems limit the height that wisdom can reach. How to better establish big data thinking? This article analyzes the current situation and bottlenecks of education big data governance, Focus on overcoming technical difficulties such as data mining, learning analysis, evaluation and analysis, and propose that a smart campus with large and medium platforms and small platforms should be established to achieve full data compatibility, standardized data asset sets, unified API data services, online data calling systems, and visualization output of computing power and other countermeasures for education big data governance, meet the requirements of education data governance in the current big data era, and finally obtain the huge value of it."
8945787,Multi-Dimensional Visualization Analysis of China's Big Data Research from 2012 to 2019,"Big data is a research hotspot in various fields currently. This paper obtains research literature on big data from 2012 to 2019 based on the CNKI database. It uses Citespace and other software to study topics, grants-in-aid, research authors, subject distribution, journal sources, keyword clustering and other dimensions to draw big data research maps, visually analyze big data literature, and form 7 big data research topics such as ""#0 Big data""."
9457323,Visualization research and analysis of academic articles on big data,"In recent years, big data has become a hot topic of extensive research in academia. The application of big data involves various fields. At present, there is a lack of systematic analysis of the literature in this field, and it is difficult to understand the research focus and trends in the field of big data. This paper obtains data from CNKI, Web of Science, and Google Scholar, and selects articles related to big data published between 2017 and 2020 as the research sample, and uses Python to visualize word frequency, co-word cluster analysis and analysis on the keywords and topics of the paper. This article mainly explains the major countries (regions), core research fields and related research hotspots involved in the research of academic articles of big data in recent years.The visualization results show that the research hotspots of academic articles on big mathematics involve many aspects such as artificial intelligence, economic and financial forecasting, policy management analysis, data information. As current domestic related research is mostly confined to academic papers, we believe that existing academic terms The scope of research needs to be expanded. The big data information industry and other industries should be increased, interdisciplinary cooperation, and focus on strengthening the academic research on medical, psychological, and big data of some algorithm innovation."
9110003,Analysis on the Influence and Countermeasures of Big Data in Military Logistics Support,"In order to realize the application of big data in military logistics support, this paper puts forward a novel military logistics support management method based on big data. This method is based on big data to mine and analyze all kinds of data of military logistics support. The research results show that this method can manage the military logistics support scientifically, improve the efficiency of military logistics support, and realize the modernization and intellectualization of military logistics support in our country."
9006445,Towards a Multi-engine Query Optimizer for Complex SQL Queries on Big Data,"In an era where big data analytics has become a first-class requirement for both the industrial and the academic community, multiple engines are built to execute distributed domain-specific analytics. SQL-based big data analytics is a very popular but also challenging domain due to its complexity that requires multiple runtime query optimizations. Popular frameworks, such as Presto and SparkSQL, commonly retrieve data from multiple sources and process them locally using domain-specific optimizers. However, recent work indicates that no single engine offers the optimal all-in-one solution for all types of SQL queries. Taking this into account, we envision building an optimizer to facilitate faster distributed SQL analytics over multiple engines, which will perform operator-level optimization using Machine Learning techniques and will exploit the sophisticated data-driven local engine optimizations."
9402989,Study on Library Individualized Information Security Under the Background of Big Data,"Under the background of big data, the issue of users' individual needs are increasingly prominent. This paper analyzes the potential information security problems of library users and finds that their individualized information is easy to be leaked, falsified or lost in the process of information collection and mining. To solve these problems, this paper has proposed an improved data encryption/decryption architecture to effectively improve the defense security of the system and shorten the data processing time as much as possible, and discussed the influence of different factors on the time consumption of information camouflage/information extraction to solve the data privacy security problem from the technical level."
8669582,Construction and Application of Big Data Analysis Platform for Ideological and Political Education in Colleges,"To meet the large data analysis needs of ideological and political education in colleges, this paper designs an assistant expert analysis system based on Hadoop. It integrates the functions of data acquisition, data storage, data analysis and data visualization, and provides a friendly human-computer interaction interface to shield the details of large data analysis algorithm, to help teaching staff use large data analysis technology simply and efficiently for high concurrency and rapid query. We classify and design the basic operation model based on MapReduce for users to configure complex data processing logic freely. The system can also add reusable and extensible computing and analysis module to the platform according to the field experience, to expand the data analysis and processing capabilities of the system, which facilitates users to explore iterative and incremental data."
9324632,Geocube: Towards the Multi-Source Geospatial Data Cube in Big Data Era,"The big data is characterized by challenges on variety, volumes, velocity etc. Recent advocate of data cube in the Earth observation (EO) domain has shown great promise to provide analysis ready data for remote sensing applications. It is possible to develop a geospatial big data infrastructure layered on the data cube by incorporating a uniform analysis-ready multidimensional data structure and exploiting its usage in connecting EO data analytics and OLAP (Online Analytical Processing), thus enabling a multi-source geospatial data cube accommodating both EO and location-based social-economic data. The creation of such a geospatial data cube, named GeoCube, needs special attentions from geospatial perspective including the formalization of spatio-temporal dimensions, tiling along these dimensions for high performance geoprocessing, and processing of geospatial/EO queries against these dimensions. This will help develop a new framework for big geospatial data analytics while at the time keeping connections to the data cube in the business intelligence domain. The paper will highlight these issues and identify a research agenda for developing such a geospatial data cube."
9109987,Research on Enterprise Human Resource Management Under the Background of Big Data,"With the development of information technology, the emergence of big data technologies and supporting solutions is helping companies to digitally transform. At the same time, corporate human resources management has also shifted from traditional problem-driven to data-driven in the era of big data, helping managers make more prudent and scientific human resource management decisions from a more dimensional perspective. Enterprise human resource management should actively use big data, keep up with the pace of the big data era, carry out a comprehensive innovation of itself, inject fresh blood into human resource work, and promote the further development of enterprise human resource management. Making full use of the advantages of data information and network platforms for human resource management. I believe that with the help of big data analysis, human resource management will become better and better for enterprises."
9006051,Big Federal Data Centers Implementing FAIR Data Principles: ARM Data Center Example,"Atmospheric Radiation Measurement (ARM) is a multi-laboratory/multi-institutional, US Department of Energy Office of Science National User Facility. ARM's data is currently hosted at the ARM Data Center (ADC) in Oak Ridge, Tennessee. The ADC holds more than 12,000 data products, with a total holding of more than 1.8 PB of data that dates back to 1992. This includes data from instruments, value-added products, model outputs, field campaigns, and principle investigator contributed data. In this paper, we discuss how big federal scientific data centers, such as ARM, that use modern and scalable architecture apply findable, accessible, interoperable, and reusable (FAIR) data principles to improve overall efficiency. These principles mainly emphasize machine-to-machine interactions that are directly applicable to ARM because of its data volume."
8836984,Adaptive Learning Model and Implementation Based on Big Data,"The traditional face-to-face education model can no longer meet the needs of further training outstanding talents. Only through the Big Data learning analysis model, we can explore deeply and study the learner's learning process, discover the learning rules, and then provide them according to the characteristics and needs of each student; personalized adaptive learning and learning methods to give full play to the potential of students. This research starts from the connotation and application of big data, and the comprehensiveness of the data and the potential ""big value"". Based on Big Data analysis, a personalized adaptive online learning analysis model is constructed from four dimensions: Data and Environment (Who), How and Target (Why). Taking C-language programming as an example, this paper analyzes the structure of learning process based on Big Data and adaptive learning, the visualization of learning process and the empirical effect of learning. The research results show the data analysis of students' learning behavior and knowledge mastery. It can recommend a reasonable learning path and appropriate learning resources, and can provide timely and accurate feedback on the learning effect of students, and provide personalized service intervention, which is conducive to the promotion of teaching and learning."
9032921,City Geospatial Dashboard: IoT and Big Data Analytics for Geospatial Solutions Provider in Disaster Management,"Geospatial information generated from satellites, drones, and big data (mobile CDR (call details record), GPS trajectory data, wireless sensor network, and IoT (Internet of Things)) are important to all processes in disaster management such as disaster mitigation, preparedness, response, and mitigation. The emergence of a global navigation system and wireless communication technology changed the way we live and how we collect geospatial data in the field. For example, a large amount of geospatial data streams from the data repository as a base map in the field, and many IoT devices can collect and transmit geospatial data to IoT cloud server or centralised geodatabases. Moreover, collection, sharing and visualisation of all collected geospatial data is a crucial task for effective disaster planning and mitigation. Proper information needs to reach appropriate disaster management teams in minimal time to reduce loss of life and property. In this paper, we discuss establishment of a City Geospatial Dashboard, which can collect, share and visualise geospatial data collected from satellites, IoT devices, and other big data. We also explain geovisualisation of big data analytical results such as near-real-time rainfall profiler, hourly grid population, link population and flow direction estimated from mobile CDR, and hourly link speed computed from bus/taxi GPS trajectory data in order to improve spatial thinking and planning processes in disaster management by providing a set of spatial analysis tools known as geovisualisation."
9245455,Sakdas: A Python Package for Data Profiling and Data Quality Auditing,"Data Profiling and data quality management become a more significant part of data engineering, which an essential part of ensuring that the system delivers quality information to users. In the last decade, data quality was considered to need more managing. Especially in the big data era that the data comes from many sources, many data types, and an enormous amount. Thus it makes the managing of data quality is more difficult and complicated. The traditional system was unable to respond as needed. The data quality managing software for big data was developed but often found in a high-priced, difficult to customize as needed, and mostly provide as GUI, which is challenging to integrate with other systems. From this problem, we have developed an opensource package for data quality managing. By using Python programming language, Which is a programming language that is widely used in the scientific and engineering field today. Because it is a programming language that is easy to read syntax, small, and has many additional packages to integrate. The software developed here is called “Sakdas” this package has been divided into three parts. The first part deals with data profiling provide a set of data analyses to generate a data profile, and this profile will help to define the data quality rules. The second part deals with data quality auditing that users can set their own data quality rules for data quality measurement. The final part deals with data visualizing that provides data profiling and data auditing report to improve the data quality. The results of the profiling and auditing services, the user can specify both the form of a report for self-review. Or in the form of JSON for use in post-process automation."
9403738,Research on big data mining and fault prediction based on elevator life cycle,"With the rapid development of China's economy, the elevator has become a basic tool in daily life, and the potential safety hazards caused by the elevator are also concerned. It is urgent to use big data technology to mine the existing data to obtain the corresponding laws of elevator failure. This paper carries out the information data collection of each link through the elevator design, installation, maintenance and inspection of the whole life cycle, applies the classification model and data mining technology of expert supervised learning, analyzes the impact of elevator related feature information on the elevator equipment failure, and predicts the typical elevator fault based on the elevator information data."
9047330,A Data Fusion and Data Cleaning System for Smart Grids Big Data,"The smart grid is considered as one of the important technical areas of big data applications. Based on the massive data generated by smart grids, this paper proposes a system to provide support services for data mining, which includes data fusion, data cleaning, and other data preparation and pre-processing services. According to the typical application scenarios of the power industry, targeted automatic selection and fusion are carried out on the basis of pre-processed power big data. In terms of data cleaning, a universal and effective cleaning solution based on commonly used data mining requirements is proposed. In order to improve the data cleaning efficiency and accuracy, an algorithm for missing value verification based on machine learning is proposed. The test results show that the performance accuracy of the proposed system is 100%. With a comprehensive comparison of several typical machine learning algorithms, Support Vector Machine (SVM) is considered as the most suitable algorithm for data cleaning verification."
9006124,A Big-Data Approach to Defining Breathing Signatures for Identifying Respiratory Disease,"This project seeks to use wearable sensors to develop a novel method for measuring respiratory activity in human subjects. This is the first stage of an ongoing project under the Arizona Center for Accelerated Biomedical Innovation (ACABI) [1]. The ultimate ambition of this effort is to develop a baseline digital breathing signature for a particular individual, so that medical professionals equipped with big-data analysis tools can use deviations from one's signature to differentiate between conventional breathing and abnormal breathing patterns, such as splinting and Kussmaul respirations."
9591970,Research on Dynamically Configurable Data Acquisition System in the Big Data Era,"Based on big data mining and Java Web development platform, this paper uses Apache POI plug-in to design and develop a dynamically configurable data collection system. The system completes service-oriented dynamic configurable data search and collection on the basis of big data mining and big data processing. It selects dynamic configurable data based on time objective function and comprehensive objective function, and designs a configurable data collection system. The simulation experiment results show that the data collection precision of this system is higher, more accurate and more feasible."
9110089,Research on Smartphone Marketing Method Based on Social Big Data,"In order to realize the application of social big data in the field of smartphone marketing, this paper puts forward a novel smartphone marketing method based on social big data. This method is based on the social big data and makes full use of big data's technology to mine and analyze the data of consumer groups in the society. The research results show that this method can effectively help smartphone enterprises to understand the needs of consumer groups, so as to facilitate smartphone enterprises to make better decision-making plans."
9245461,Big Data Analytics Framework for Digital Government,"Digital transformation has increasingly become a central issue to governments around the world as they seek innovative digital solutions in response to socioeconomic, political, and technological pressures. In this paper, we present a framework that formalizes the government-wide digital transformation process, standardizes infrastructure architecture, cultural and industrial change with human resource development, data management and data governance, and data exchange protocols in a trusted and regulated environment, leading toward effective and sustainable utilization of big data analytics in policymaking and creation of digital innovations. We also discuss specific customizations of the framework in the Thai government's context as well as its adoption progress, providing material evidence of the framework's practicality."
8836997,Application Research of VCR Model Based on AHP in the Design of Government Service Big Data Scenario,"Due to the rise of Internet, ICT, cloud computing, big data and other technologies, combined with the development of government governance theory, more and more governments begin to pay attention to and invest in the construction of online government service applications. However, in more countries and regions, the design and application of big data scenarios for online government services are still limited by the government's limited capital investment, weak technical reserves, and poor data resources. Therefore, how to carry out the construction work of online government services more effectively in terms of the above limited conditions is a problem that many governments need to think carefully. In this paper, according to accumulate experience of design and construction of a local government's online government service platform that building a VCR (Value, Capability, Resource) analysis model based on AHP (Analytic Hierarchy Process) method in this case, which can provide a way to solve such problems."
9626261,Research on Professional Talent Training Mode on Data Science and Big Data Technology in Local Application-oriented Universities*,"As a national basic strategic resource, big data has become the focus of academia and industry. Under the new situation of ""double first-class"" construction of national higher education, how can Local Application-oriented Universities scientifically position the talent training objectives of big data major, reasonably set up talent training programs, accurately grasp the talent demand of the industry, cultivate technical talents to meet the needs of social and economic development, and promote the sustainable development of the major according to their own teaching resources and school running conditions, It is the first problem that must be considered in the specialty construction. Taking Ordos Institute of applied technology as an example, this paper explores the talent training system of data science and big data technology major from six aspects of talent training objectives, curriculum system structure, teaching staff construction, teaching research and reform, practical teaching and school enterprise cooperation, so as to provide reference for the talent training reform and development of big data major in Application-oriented brother colleges."
9110045,Research on the Accurate Identification Method of College Students with Financial Difficulties Based on Big Data,"In order to realize the accurate identification of college students with financial difficulties, this paper puts forward a novel identification method of college students with financial difficulties based on big data. This method is based on big data technology and uses the factor evaluation method to mine the family data, students' personal data and the fluctuation data of students' family economy. The research results show that this method has higher recognition accuracy and can effectively reduce the work intensity of subsidized staff in colleges and universities."
9378040,Preserving Privacy of Temporal Big Data,"In the current technological era, huge amounts of big data are generated and collected from a wide variety of rich data sources. Embedded in these big data are useful information and valuable knowledge to be utilized. With the popularity of initiatives of open data, more big data have been published on open data platforms and made accessible to the public. To preserve privacy while maintaining the utility of data, research on privacy-preserving publishing has focused on preserving privacy of sensitive personal data such as patient data for health related applications. However, there are many other real-life situations, in which personal data of individual citizens and their daily routines need to be preserved when publishing. In this paper, we examine the problem of preserving privacy of temporal big data. Specifically, we present a temporal hierarchy privacy preserving model (THPPM) for some common daily routines-for example, parking. The model adapts and extends temporal hierarchy to generalize temporal data related to timestamp and spatial data related to check-in location. It also makes good use of generalized temporal representative points to preserve privacy of specific temporal data points. Evaluations on two real-life datasets on parking tickets for the US city of Buffalo and the Canadian city of Toronto shows that effectiveness and practicality of our THPPM in preserving privacy of temporal big data. Although this model is demonstrated and evaluated on parking ticket data, it would be applicable to preserving privacy of temporal big data for many other real-life applications and services."
9373107,"Big Data Lakes: Models, Frameworks, and Techniques","Nowadays, big data lakes are prominent components of emerging big data architectures. Basically, big data lakes are the natural evolution of data warehousing systems in the big data context, and deal with several requirements deriving from the well-known 3V nature of big data. Along with the emerging of big data lake research initiative, several issues appeared, such as: (i) big data lake models; (ii) big data lake frameworks; (iii) big data lake techniques. In line with this exciting research perspective, this paper proposes an overview of state-of-the-art approaches that are at the foundations of big data lake research, and innovative open problems and issues, which drive future research directions, on advancing the big data lake research trend."
9361028,Research on E-Commerce Security and Data Analysis Platform in the Era of Big Data,"With the rapid development of e-commerce and mobile communication in China, e-commerce platform has been widely used in various industries. How much e-commerce stores, whether it can guarantee the security of transaction information, whether it can analyze and study structured and unstructured data, and whether it can guarantee the security of stored data are all the key factors we need to consider. In this paper, the data and e-commerce security together, and to analyze the security system of e-commerce and discuss the prevention of hidden security policy. When the emergence of e-commerce big data technology can effectively solve the problems existing in e-commerce security, the Hadoop structure is introduced through Apache Hadoop and the Hadoop product Yarn is analyzed with emphasis. From the perspective of electronic security data, the hidden dangers of e-commerce can be effectively analyzed, and the security system of e-commerce can be effectively improved."
9101202,Visual Analysis of Chinese Education Big Data Research in Recent Five Years,"The big data concepts and technologies have brought tremendous changes in the field of education, making education more individualized and intelligent. The article is based on the CNKI database, using 300 Chinese research papers on the theme of education big data as research samples for visual analysis. The results show that the current Chinese education big data research is in a stage of rapid development. The hot topics include Learning Analysis, Education Informationization, Artificial Intelligence and so on. There is little collaboration among authors and among institutions. However, Hai-Guang Fang, Jing-Min Du, Sai-Sai Tong, Jun-Da Chen and other scholars are forming a research cooperation group on education big data research."
9545940,Research on Analysis and Prediction of Big Data of Chinese Medicinal Materials in R+Hadoop,"This article analyzes the basic content and construction steps of R+Hadoop. The author combines the big data requirements of R+Hadoop Chinese medicinal materials to study big data preprocessing, data visualization processing, data modeling analysis, model evaluation and selection, model predictive analysis, system realization analysis, system test analysis, etc. The purpose of this article is to improve the reliability of big data analysis and prediction results and provide an important guarantee for the economic development of the industry."
9457479,Big data analysis based identification method of low- voltage substation area,"Aiming at the problems of low efficiency, low reliability and difficulty in cross substation identification of traditional identification methods, this paper proposes a low- voltage substation identification method based on big data analysis. Firstly, selecting the daily, weekly, monthly or annual measurement data from the big data database of low-voltage substation area to construct the trend curve of user voltage change. The improved grey correlation analysis is used to analyze the correlation degree of line voltage between the unrecognized or cross substation area meter and the meter with clear substation area ownership. The connection relationship between the transformer in substation area and the unrecognized meter is automatically analyzed, which can realize intelligent substation area identification. Finally, the identification method is used to identity the household transformer relationship of a low-voltage distribution network in Wuhan. The test results show that the results are consistent with the real household transformer relationship, and the identification accuracy is relatively high, which has a certain engineering application value."
8725642,Research of Flexible Load Analysis of Distribution Network Based on Big Data,"Aiming at the problem of insufficient computing power in the analysis of flexible load under the condition of massive user data in distribution network, a flexible load analysis method based on big data is proposed. Firstly, the data fusion and feature extraction of the massive user data in distribution network are carried out to realize the preprocessing of the original data. Then, on the basis of MapReduce parallel computing model, the k-means algorithm is used to cluster the load characteristic data and calculate the industry flexibility coefficient and adjustable load. According to the results of load flexibility analysis based on the historical data of a power supply company in a certain city, this method can make statistics on load flexibility (load adjustable space) from industry dimension and time dimension, judge the current load flexibility level, and combine external data and temperature data to carry out load flexibility analysis. According to historical data, the adjustable load level of a certain area, a certain industry and a certain period in the future is predicted."
9361029,Intelligent Processing Technology of Cross Media Intelligence Based on Deep Cognitive Neural Network and Big Data,"This paper studies the cross-media intelligent processing technology based on deep neural cognitive network and big data technology. This paper uses data processing and DNN training algorithms to explore deep cognitive neural networks to study cross-intelligence intelligent processing. The algorithm is mainly based on the rating of the item and the type of the item, and based on the similarity of the item type to give recommendations. This paper conducts data processing by investigating users' item preference and user item ratings. The DNN training algorithm used in this article needs to build a model and determine the method. The model specifically includes an input layer, two hidden layers and an output layer. The data in the input layer of the model is user project preferences, the output layer of the model is user project ratings, the hidden layer adopts the Dropout strategy, and the activation function is ReLU. First, establish the correspondence between item types and user item scores for DNN training, then build a multi-class deep neural network model with a dropout strategy, and finally get the predicted score of the target item after model training and reverse coding. Compared with the collaborative filtering of neural network, the algorithm adopted in this paper does not need to rely on the scores of neighboring users, and only needs to generate recommendations based on the user's personal scores and item types, which is conducive to accelerating the speed of intelligence processing."
9403833,Research and Application of performance Evaluation Model of Rural Preschool Teachers based on big data Algorithm,"In this paper, based on the research of the existing relevant results of teaching performance evaluation, referring to the information classroom performance evaluation system, the classroom teaching performance evaluation system in line with the characteristics of rural early childhood teaching classroom teaching. In this study, the Apriori analysis is adopted to analyze the data of classroom teaching performance evaluation of rural children teaching by using the big data algorithm method. Valuable knowledge of improving classroom teaching performance of rural children teaching is mined. First performance of education, teaching performance evaluation, rural children teaching classroom teaching and the analysis on the relevant situation do big data algorithm, mainly analyses the rural preschool education present situation of the application of classroom teaching, rural children education problems in classroom teaching, the demand of the rural preschool teaching classroom teaching evaluation, and on the basis of existing teaching performance evaluation research expounds the rural children teaching the basic content of the performance evaluation of classroom teaching, summed up the rural preschool teachers' performance evaluation model."
9005502,BigOptiBase: Big Data Analytics for Base Station Energy Consumption Optimization,"Mobile Network Operators develop new technologies, as the 5G network, to handle the constantly increasing network traffic, while they put less effort on optimizing their operations. However, more energy efficient approaches are essential for cost reduction and compliance with energy footprint principles. Network usage and IoT data produced in the base stations can be used to develop such approaches. Considering the above, the BigOptiBase platform has been designed. Through this platform we will offer a big data analytics subsystem developed to provide elastic energy efficient solutions for the base stations using data analytics and machine learning technologies."
9006153,Big Data Analysis on Social Networking,"Social networking media, such as Twitters, Facebook, and Chinese Weibo, has become a major means for people to deliberately express their ideas, thoughts, and views about everything. A huge amount of posts in these social media are issued and viewed by the general public daily. Evidently the social networking media can directly affect people's perceptions on a specific topic. Those data can be used to valuable information that will help organizations to understand what thetrends or sentiments are. Most of the research efforts in social networking data analytics are conducted in English-based social networking media. Research on Chinese social networking media receives relatively little attention. In this paper, we examine the key problems in this field, focus particularly on the characteristics of new vocabulary, emotion expressions, and hierarchical structures in Chinese “Weibo”. Associated theoretical and technological methods to address these problems are reviewed and discussed."
8713238,Research and Application of Big Data Analysis Platform for Oil Production Engineering in Huabei Oilfield,"Big data analysis technology can be used to transform massive data of oil production engineering into knowledge that can be used to guide oilfield production. Due to the lack of suitable large data analysis tools, a large data analysis software system was developed to simplify the workload of data analysis. This paper illustrates the research and application of large energy consumption data analysis through the development of big data analysis methods, process improvement and software platform, then achieves the goal of reducing costs and improving efficiency."
9109894,Research on the Application of Big Data in the Informatization of Higher Education Management Mode,"In order to realize the wide application of the informationization of higher education management mode, this paper puts forward a novel higher education management model based on big data. This model is based on big data, adopts the methods of information research and comparative experiment, actively constructs the network education management platform based on big data, and deeply excavates the educational data of colleges and universities. The research results show that this model improves the information level of the higher education management model and promotes the wide application of big data in the higher education management model."
8240631,MRMondrian: Scalable Multidimensional Anonymisation for Big Data Privacy Preservation,"Scalable data processing platforms built on cloud computing becomes increasingly attractive as infrastructure for supporting big data applications. But privacy concerns are one of the major obstacles to making use of public cloud platforms. Multidimensional anonymisation, a global-recoding generalisation scheme for privacy-preserving data publishing, has been a recent focus due to its capability of balancing data obfuscation and usability. Existing multidimensional anonymisation methods suffer from scalability problems when handling big data due to the impractical serial I/O cost. Given the recursive feature of multidimensional anonymisation, parallelisation is an ideal solution to scalability issues. However, it is still a challenge to use existing distributed and parallel paradigms directly for recursive computation. In this paper, we propose a scalable approach for big data multidimensional anonymisation based on MapReduce, a state-of-the-art data processing paradigm. Our basic idea is to partition a data set recursively into smaller partitions using MapReduce until all partitions can fit in the memory of a computing node. A tree indexing structure is proposed to achieve recursive computation. Moreover, we show the applicability of our approach to differential privacy. Experimental results on real-life data demonstrate that our approach can significantly improve the scalability of multidimensional anonymisation over existing methods."
9425958,Big Data Processing and Application Research,"Nowadays, big data has become a constantly extended and widely mentioned term. It can excavate, describe and utilize a large amount of structured, unstructured and semi-structured data to obtain more information. With the rapid increase of data, big data has become more and more diverse, and the big data technology has emerged consequently. This paper reviews the literature of big data and the related technologies, such as Hadoop and Map Reduce. And it discusses the life cycle of big data, that is, big data acquisition, preprocessing, storage and analysis. Then it expounds the representative application of big data. Finally, based on the above study, this paper summarizes the development of big data."
8785889,Research on Hotspot and Trend of Online Public Opinion Research in Big Data Environment,"In the era of big data, the features of online public opinion give some serious challenges for existing data analysis methods and it's necessary to give a review on the status and development trend of it. By means of CNKI, this paper collects published papers which involved in online public opinion research in big data Environment from 2010 to 2017.Using bibliometrics analysis and CiteSpace5.0 visualization application software, we get the hot spot and important frontier trend of online public opinion research in big data environment, on this basis, give a review on this research field. Some existing problems are analyzed and the future research direction of this filed are looked ahead. We hope this work can provide references for future related research and innovation."
8669621,Accurate Marking Method of Network Attacking Information Based on Big Data Analysis,"In the open network environment, the network offensive information is implanted in big data environment, so it is necessary to carry out accurate location marking of network offensive information, to realize network attack detection, and to implement the process of accurate location marking of network offensive information. Combined with big data analysis method, the location of network attack nodes is realized, but when network attacks cross in series, the performance of attack information tagging is not good. An accurate marking technique for network attack information is proposed based on big data fusion tracking recognition. The adaptive learning model combined with big data is used to mark and sample the network attack information, and the feature analysis model of attack information chain is designed by extracting the association rules. This paper classifies the data types of the network attack nodes, and improves the network attack detection ability by the task scheduling method of the network attack information nodes, and realizes the accurate marking of the network attacking information. Simulation results show that the proposed algorithm can effectively improve the accuracy of marking offensive information in open network environment, the efficiency of attack detection and the ability of intrusion prevention is improved, and it has good application value in the field of network security defense."
9014354,Securing Big Data in the Age of AI,"Increasingly organizations are collecting ever larger amounts of data to build complex data analytics, machine learning and AI models. Furthermore, the data needed for building such models may be unstructured (e.g., text, image, and video). Hence such data may be stored in different data management systems ranging from relational databases to newer NoSQL databases tailored for storing unstructured data. Furthermore, data scientists are increasingly using programming languages such as Python, R etc. to process data using many existing libraries. In some cases, the developed code will be automatically executed by the NoSQL system on the stored data. These developments indicate the need for a data security and privacy solution that can uniformly protect data stored in many different data management systems and enforce security policies even if sensitive data is processed using a data scientist submitted complex program. In this paper, we introduce our vision for building such a solution for protecting big data. Specifically, our proposed SECUREDL system allows organizations to 1) enforce policies that control access to sensitive data, 2) keep necessary audit logs automatically for data governance and regulatory compliance, 3) sanitize and redact sensitive data on-the-fly based on the data sensitivity and AI model needs, 4) detect potentially unauthorized or anomalous access to sensitive data, 5) automatically create attribute-based access control policies based on data sensitivity and data type."
9457420,Research on System Design of Big Data-driven Teachers' Professional Ability Development,"Big data provides objective data support and services for the development of teachers' professional competence. In another words, it could be an effective way to promote the development of teachers' professional innovation by using the data as the driving force. The article analyzes the characteristics of teachers' professional ability under the big data environment. On this basis, the teacher professional ability development system is designed in detail from the content organization, system construction and implementation process. The design provides a more scientific, objective and comprehensive basis for the realization of dynamic and quantitative analysis of teachers' professional ability, and then provides accurate and personalized services for the development of teachers' professional ability."
9373135,An Intelligent Visual Big Data Analytics Framework for Supporting Interactive Exploration and Visualization of Big OLAP Cubes,"Visual big data analytics aims at supporting big data analytics via visual metaphors, with a plethora of applications in modern settings and scenarios. In all these domains, visual big data analytics paradigms offer several advantages, among which some noticeable ones are: (i) fast knowledge understanding from big data sets; (ii) pattern and trend discovery from big data sets; (iii) entity and model discovery from big data sets; (iv) sharing insights among organizations. Among several proposals, OLAP-based visual big data analytics methodologies and tools represents a successful case of visual big data analytics frameworks, which is entirely based on OLAP analysis. In this context, an OLAP cube is typically explored with multiple aggregations selecting different subsets of cube dimensions to analyze trends or to discover unexpected results. Unfortunately, such analytic process is generally manual and fails to statistically explain results. On the basis of these considerations, in this paper we propose an innovative OLAP-shaped visual big data analytics framework that incorporates a state-of-the-art statistical technique for supporting exploration and visualization of OLAP data cubes. An experimental evaluation with a medical data set presents statistically significant results and interactive visualizations, which link risk factors and degree of disease."
9389909,Research on identification technology of encircled serial tags based on big data and semantic analysis,"In order to further improve the accuracy of tag recognition, this paper proposes a tag recognition technology based on big data and semantic analysis. Firstly, the big data technology is used to establish the analysis model, identify the behavior of the surrounding tags, and collect and classify the characteristics of the surrounding tags. Based on the complex network, the model of circle recognition is established. Secondly, based on the principle of multi-objective and semantic analysis, the intelligent association rule mining model is constructed to optimize the identification steps of encirclement and collusion in big data. Through the data experimental results, the hidden rules behind the transaction data are revealed, and the transaction track and behavior characteristics of surround bidding and collusion are depicted, so as to effectively reflect the internal institutional root of inducing surround bidding and collusion behavior, which can provide reference for the future The next step of the bidding supervision department is to suit the remedy to the case, establish a comprehensive and effective mechanism for the prevention and control of bidding collusion, and provide strong technical support."
9403810,Research on the Teaching Reform of Finance and Accounting Major under the Background of Big Data,"With the development of information and intelligent technology such as Internet, big data and cloud computing, the concept of big data in education and teaching has also been widely concerned by the society and colleges and universities. The application of big data technology broadens educational resources and teaching channels, and provides a new space for teaching reform and talent training of accounting majors. Based on the background of big data and combined with the characteristics of finance and accounting majors, this paper integrates big data thinking into the teaching reform process of finance and accounting majors, integrates the needs of big data information resources and application ability cultivation of finance and accounting majors, improves the training quality of finance and accounting professionals, and promotes the teaching reform of finance and accounting majors."
8669514,An Approach of Russian Online Learning Behavior Analysis and Mining Based on Big Data,"This paper starts from the specific activities of online learning under the background of big data, to perform data mining and analysis on learning trajectory left by different learners in the online learning context. In specific application, the learners' behavior of online foreign language learning platform is analyzed, the massive real-time data generated by the learners in the platform learning are mined, and the immersive personalized online learning environment is constructed from the aspects of learning behavior guidance. Finally, the case of online learning based on big data environment is designed to explore the intensive thinking and behavior of learners, to describe the behavior characteristics of users through learning proximity, frequency and length of the platform, and to complete the classification index system based on user behavior. Cluster analysis, recommendation analysis and correlation analysis are performed for online learning behavior in big data environment, which provides suggestions and enlightenment for the platform users to evaluate and intervene in learning, and for teachers to make and improve teaching decisions."
9196457,Research on Data Encryption of Network Communication Based on Big Data,"Since big data technology is integrated across interdisciplinary fields, where many new technologies are introduced but the risks are also higher. Therefore, in the big data environment, there are higher requirements for the security protection technology of information communication. Besides, the 3DES algorithm is generated after three rounds of polling based on the DES algorithm in the paper, which uses shift, XOR, S-box and other operations. What's more, the plain text is replaced by IP, and after multiple iterations, the sampling data is encrypted. Experiments prove that the research method proposed in the paper has the advantages of high encryption strength, low resource consumption and low encryption and decryption time, which is suitable for application in power systems."
9457456,Publication volume of major databases related to ideological and political education: using big data and Internet technologies,"In the past ten years, big data technology Internet technology has become more and more available in the education market. At the same time, the public and the government are paying more and more attention to ideological and political education, which has led to the explosive growth and massive agglomeration of data such as global education literature. In order to integrate ideological and political education literature data, we used a literature retrieval platform for retrieval and applied data mining and other big data technologies. Data from Clarivate Analytics Web of Science (WOS) and the database called China National Knowledge Infrastructure from the journal, Chinese Social Sciences Citation Index (CNKI CSSCI), which do not index preprints, were assessed. Our estimates indicate that 981 documents from WOS and 1247 documents from CNKI CSSCI. Publications include research articles, early access, abstracts, reviews and editorials. For example, among the 1,247 documents in WOS, research articles accounted for 93.782%, early access accounted for 4.077%, and the rest were abstracts, editorials, comments, etc. This article provides a snapshot that briefly introduces the development of ideological and political education literature in the past 10 years to understand the development of ideological and political education."
9403030,Research on Education Big Data Security Strategy under Network Environment,"In recent years, big data in education has become an important force to promote educational reform. However, the current research at home and abroad mainly focuses on how to use big data in education and pays insufficient attention to the information security problems it faces, which may lead to information security risks. The birth of cloud computing technology provides favorable conditions for the deployment of big data in education, but also brings challenges to the security of big data in education. Based on this, this paper studies the current education big data information security problems, find the existing problems, and targeted puts forward education under the network environment big data security policies, including storage security, access control, security strategies and virtual safety security strategy, and establish a safety technical framework, using standard and safety supervision system as the main content of the guarantee system, ensure the safety of the big data cloud environment education. The research results show that the network is a developing technology, so security problems often occur in the network environment. Only by formulating strict education big data security strategies and effectively ensuring the security of education big data, can education big data be rapidly developed and the legitimate rights and interests of users of education resources and the healthy development of big data be ensured."
8669646,Analysis and Improvement Strategy for Profit Contribution of Bank Customer Under Big Data Background,"Our research takes the bank's data as the object, and performs an intensive analysis model of bank customer profit contribution, under the guidance of big data theory and data mining method. Then, based on the profit contribution of the asset class business, the profit contribution of the liability business and the profit contribution of the intermediate business class, as well as the basic model of the customer profit contribution evaluation are constructed. Finally, certain assets data of a subordinate branch of a state-owned commercial bank are used, and an improved empirical analysis of customer profit contribution model and cluster analysis method is carried out. The strategy proposed in this paper is verified to be in line with the actual needs of enterprises. On one hand, it improves the loyalty of customers to banks; on the other hand, it can further expand the banking customer base and provide effective support for potential value mining of customers."
9110035,Research on the Application of Big Data and Artificial Intelligence Technology in Computer Network Technology,"In order to realize the application of big data and artificial intelligence technology in computer network technology, this paper puts forward a novel application method of computer network technology based on big data technology and artificial intelligence technology. This method is based on big data technology and artificial intelligence technology, and can give full play to the data analysis ability of big data technology and the intelligent thinking of artificial intelligence technology. The research results show that this method can fundamentally realize the application of big data and artificial intelligence technology in computer network technology, and bring great convenience to human production and life."
8862267,Big Data Quality Framework: Pre-Processing Data in Weather Monitoring Application,"Big Data has become an imminent part of all industries and business sectors today. All organizations in any sector like energy, banking, retail, hardware, networking, etc all generate huge quantum of heterogenous data which if mined, processed and analyzed accurately can reveal immensely useful patterns for business heads to apply to generate and grow their businesses. Big Data helps in acquiring, processing and analyzing large amounts of heterogeneous data to derive valuable results. Quality of information is affected by size, speed and format in which data is generated. Hence, Quality of Big Data is of great relevance and importance. We propose addressing various aspects of the raw data to improve its quality in the pre-processing stage, as the raw data may not usable as-is. We are exploring process like Cleansing to fix as much data as feasible, Noise filters to remove bad data, as well sub-processes for Integration and Filtering along with Data Transformation/Normalization. We evaluate and profile the Big Data during acquisition stage, which is adapted to expectations to avoid cost overheads later while also improving and leading to accurate data analysis. Hence, it is imperative to improve Data quality even it is absorbed and utilized in an industry's Big Data system. In this paper, we propose a Pre-Processing Framework to address quality of data in a weather monitoring and forecasting application that also takes into account global warming parameters and raises alerts/notifications to warn users and scientists in advance."
9005597,"Deception, Robustness and Trust in Big Data Fueled Deep Learning Systems","We are entering an exciting era where human intelligence is being enhanced by machine intelligence through big data fueled artificial intelligence (AI) and machine learning (ML). However, recent work shows that DNN models trained privately are vulnerable to adversarial inputs. Such adversarial inputs inject small amount of perturbations to the input data to fool machine learning models to misbehave, turning a deep neural network against itself. As new defense methods are proposed, more sophisticated attack algorithms are surfaced. This arms race has been ongoing since the rise of adversarial machine learning. This keynote provides a comprehensive analysis and characterization of the most representative attacks and their defenses. As more and more mission critical systems are incorporating machine learning and AI as an essential component in their real-world big data applications and their big data service provisioning platforms or products, understanding and ensuring the verifiable robustness of deep learning becomes a pressing challenge in the presence of adversarial attacks. This includes (1) the development of formal metrics to quantitatively evaluate and measure the robustness of a DNN prediction with respect of intentional and unintentional artifacts and deceptions, (2) the comprehensive understanding of the blind spots and the invariants in the DNN trained models and the DNN training process, and (3) the statistical measurement of trust and distrust that we can place on a deep learning algorithm to perform reliably and truthfully. In this keynote talk, I will use empirical analysis and evaluation of our cross-layer strategic teaming defense framework and techniques to illustrate the feasibility of ensuring robust deep learning."
9672082,Big Data Testing Framework for Recommendation Systems in e-Science and e-Commerce Domains,"Software testing is an important process to evaluate whether the developed software applications meet the required specifications. There is an emerging need for testing frameworks for big data software projects to ensure the quality of the big data applications and satisfy the user requirements. In this study, we propose a software testing framework that can be utilized in big data projects both in e-science and e-commerce. In particular, we design the proposed framework to test big data-based recommendation applications. To show the usability of the proposed framework, we provide a reference prototype implementation and use the prototype to test a big data recommendation application. We apply the prototype implementation to test both functional and non-functional methods of the recommendation application. The results indicate that the proposed testing framework is usable and efficient for testing the recommendation systems that use big data processing techniques."
9434439,Analysis on the Application of Deep Learning Technology in the Field of English Education Big Data Mining,"With the convening of the Big Data Summit on artificial Intelligence and Education in the world, scholars from many countries have discussed the new trend of educational reform, confirming that the deep integration of technology and English education will bring more opportunities and challenges. Among them, as a hot issue in the field of AI, in-depth learning will become the key to the development of education. Through the screening and statistical research of related research, this paper analyzes the concept of deep learning in different fields. Finally, it clarifies the significance of introducing deep learning into the field of English educational big data mining. At the same time, in view of the objects and problems to be solved in the field of educational big data mining, this paper puts forward some suggestions on the further development of deep learning technology in the field of English educational big data mining."
9006391,Suspicious Network Event Recognition Using Modified Stacking Ensemble Machine Learning,"This study aims to detect genuine suspicious events and false alarms within a dataset of network traffic alerts. The rapid development of cloud computing and artificial intelligence-oriented automatic services have enabled a large amount of data and information to be transmitted among network nodes. However, the amount of cyber-threats, cyberattacks, and network intrusions have increased in various domains of network environments. Based on the fields of data science and machine learning, this paper proposes a series of solutions involving data preprocessing, exploratory data analysis, new features creation, features selection, ensemble learning, models construction, and verification to identify suspicious network events. This paper proposes a modified form of stacking ensemble machine learning which includes AdaBoost, Neural Networks, Random Forest, LightGBM, and Extremely Randomised Trees (Extra Trees) to realise a high-performance classification. A suspicious network event recognition dataset for a security operations centre, which uses real network log observations from the 2019 IEEE BigData Cup Challenge, is used as an experimental dataset. This paper investigates the possibility of integrating big-data analytics, machine learning, and data science to improve intelligent cybersecurity."
9378016,A differentiation between Image Mining and Computer Vision in the application area of Big Data,"The technological progress in image acquisition, image processing, and improvements in the field of big data in the last decades opens a wide range of possible applications for image processing using analytical methods. The most popular concepts in this field of tension are computer vision and image mining. However, the issue is that there is no clear distinction between these two concepts in the current scientific discussion. To address this need, a structured literature review was carried out. Thereby, the key characteristics as well as the process of image mining could be identified and compared to computer vision. Thus, this research in progress study was a first step towards differentiating these two concepts. In conclusion, a hypothesis could be derived, which will be considered now in our ongoing research."
9391025,Research on Data Security in Big Data Cloud Computing Environment,"In the big data cloud computing environment, data security issues have become a focus of attention. This paper delivers an overview of conceptions, characteristics and advanced technologies for big data cloud computing. Security issues of data quality and privacy control are elaborated pertaining to data access, data isolation, data integrity, data destruction, data transmission and data sharing. Eventually, a virtualization architecture and related strategies are proposed to against threats and enhance the data security in big data cloud environment."
9148155,Marketing Strategy of Modern Enterprise under the Background of Big Data,"With the continuous increase of consumption data and information in the network environment, electric power enterprises start to apply new technology to process the massive information and data, so as to fully exploit the value of data. Under the background of big data, enterprises have both opportunities and challenges in marketing, so they should seize the opportunities and actively meet the challenges, so as to remain invincible in the fierce market competition. In the actual work, the optimization of enterprise's marketing mode needs to realize the effective protection of consumer privacy information, enhance the pertinence of marketing activities, and formulate marketing strategies in a planned way. Corporate marketing is a management activity involving various social relations such as producers, distributors, and consumers. The most fundamental purpose is to build a scientific and reasonable bridge in various social relations so that all parties can achieve a win-win situation. In the traditional marketing model, the company's demand for the market and customers is more based on static research and text descriptions, and its attention to its dynamic changes cannot be quantified in detail because of lack of actual data."
8645613,A New Approach for Scheduling Tasks and/or Jobs in Big Data Cluster,"400 hundred million tweets are sent each day, 4.75 billion multimedia content is shared every day on Facebook, and an estimated of hundreds of hours of video are uploaded to YouTube every minute. Moreover, also IOT devices (RFID and WIFI wearable devices) are generating a huge number of data per seconds. During the last two years, the amount of data that has been created is about 90% of the whole data created so far. All these facts require clusters of computers with high specs in order to treat them. Knowing that the prices of computers are continuously dropping from year to another, almost all companies have started their Big Data projects. The return on investment (ROI) of such a project is beneficial to companies in terms of business. Since the advent of Big Data, a lot improvement is been done in order to optimize the usage of the resources (especially RAM) and to reduce the required amount of time needed for running Big Data projects. Still, effort needs to be done for the scheduler for efficiently scheduling the tasks inside the DataNodes of the Big Data Cluster. In this paper, we propose a new approach for scheduling tasks and/or jobs in Big Data Cluster in which mainly focus on optimizing the assignment of tasks to the data nodes by the NameNode. Prominent obtained results proved that our task scheduler outperforms the traditional task scheduler: FIFO Scheduler and Capacity Scheduler available in Big Data open source distributions such as Cloudera [19] and HortonWorks [20]."
9110235,Research on the Application of Big Data in the Field of Strategic Management of Cultural Industry,"In order to realize the application of big data in the field of strategic management of cultural industry, this paper puts forward a novel strategic management method of cultural industry based on big data technology. This method is based on big data technology and can mine and analyze all kinds of data produced by the cultural industry. The research results show that this method can effectively promote the prosperity and development of China's cultural industry, and contribute to the improvement of China's cultural industry system."
9671997,Big Data Analytics Framework for Predictive Analytics using Public Data with Privacy Preserving,"There are increasingly leveraging public data with cities increasingly interested in driving both responsiveness to citizen demands and cost savings through data analytics. As public managers seek to augment existing data sources, such as 311 complaints, with existing secondary data, such as US Census products, severe challenges exist. This paper considers the problems inherent in data being collected at divergent geographic levels over different time horizons. An inductive analytical methodology is developed to create units of analysis that are both useful and analytically appropriate for public managers and policy leaders in urban areas. A big data analytics framework for public data, called BDAP, was presented predictive analytics for community need considering data the spatial and temporal location while addressing the data issues such as missing values, privacy-preserving, and predictive modeling. The findings illustrate the power of inductive data curation and privacy-preserving leading to benefits to the big data community. An application for the Open Data Platform was developed using KCMO’s 311 data, crime data and census data."
9109884,Design of Urban Intelligent Traffic Congestion Situation Monitoring System Based on Big Data,"In the traditional urban intelligent traffic jam situation monitoring system, there is a problem of long data query time when analyzing and computing the data. Based on this, an urban intelligent traffic congestion situation monitoring system based on big data is designed. Build the overall framework of the system, and design the hardware system and the software system. The hardware system includes distributed storage host, parallel computing host, user terminal, switch, data access host and monitor.; the software system mainly includes data docking, storage, analysis and visualization and other functional modules, realizes distributed storage and parallel computing of data based on Spark technology, and completes the design of urban intelligent traffic congestion situation monitoring system based on big data. The experimental results show that the designed urban intelligent traffic congestion situation monitoring system based on big data needs less query time and can compute and process data more quickly."
9110051,Application of Differential Privacy in Location Trajectory Big Data,"With the development of mobile internet technology, GPS technology and social software have been widely used in people's lives. The problem of big data privacy protection related to location trajectory is becoming more and more serious. The traditional location trajectory privacy protection method requires certain background knowledge and it is difficult to adapt to massive mass. Privacy protection of data. differential privacy protection technology protects privacy by attacking data by randomly perturbing raw data. The method used in this paper is to first sample the position trajectory, form the irregular polygons of the high-frequency access points in the sampling points and position data, calculate the center of gravity of the polygon, and then use the differential privacy protection algorithm to add noise to the center of gravity of the polygon to form a new one. The center of gravity, and the new center of gravity are connected to form a new trajectory. The purpose of protecting the position trajectory is well achieved. It is proved that the differential privacy protection algorithm can effectively protect the position trajectory by adding noise."
9389859,Research on Anti-tampering Simulation Algorithm of Block Chain-based Supply Chain Financial Big Data,"In China, small and medium-sized enterprises are the foundation of overall economic development and are directly related to the employment and livelihood issues of the entire society. However, due to related issues, its financing costs are extremely high. For this reason, supply chain finance came into being. This article summarizes the shortcomings of traditional supply chain finance based on previous work experience. The author discusses the research on block chain-based supply chain financial big data tamper-proof simulation algorithm from four aspects: financial big data feature evaluation criteria, financial big data key feature extraction, supply chain financial big data key feature antitampering methods, simulation experiment and data processing content."
8669638,Evaluation Model of Education Service Quality Satisfaction in Colleges and Universities Dependent on Classification Attribute Big Data Feature Selection Algorithm,"In view of the insufficiency in the education service quality in colleges and universities, a kind of evaluation model of the education service quality satisfaction in the colleges and universities that is dependent on the classification attribute big data feature selection algorithm is put forward in this paper based on the existing work. On the basis of detailed description of the model components, further study on the evaluation method of the proposed model for the education service quality satisfaction in the colleges and universities is carried out. Under the guidance of the evaluation model of the education service quality satisfaction in the colleges and universities, the method for the construction of the evaluation model of the education service quality satisfaction in the colleges and universities is studied with the orientation to the education service resources in the colleges and universities under the open big data environment. In addition, experimental verification is carried out on the basis of the evaluation data in the 360 Encyclopedia on the education service quality satisfaction in the colleges and universities. The experimental results show that the model and method put forward in this paper can effectively evaluate the quality of the education service in the colleges and universities."
9457318,The Applications of Big Data Analysis in Student Management Education,"With the positive effect of big data on promoting education reform and innovation, student management education in universities moves on to the age of information and intelligence. Collecting, integrating and analyzing data from ""Intelligent Student management education Platform"" of University of Electronic Science and Technology of China (UESTC), this paper first figures out the association among students' behaviors, then discusses the applications of big data analysis via four cases in practice. Our paper shows that big data analysis can not only help teachers keep informed about students' daily routine, learning habits and expense records duly and thoroughly, but also promote our work towards operating more dynamically, warning in advance, subsidizing students more accurately, and teaching students more individualizedlly."
9092124,Big Data Pipeline with ML-Based and Crowd Sourced Dynamically Created and Maintained Columnar Data Warehouse for Structured and Unstructured Big Data,"The existing big data platforms take data through distributed processing platforms and store them in a data lake. The architectures such as Lambda and Kappa address the real-time and batch processing of data. Such systems provide real time analytics on the raw data and delayed analytics on the curated data. The data denormalization, creation and maintenance of a columnar dimensional data warehouse is usually time consuming with no or limited support for unstructured data. The system introduced in this paper automatically creates and dynamically maintains its data warehouse as a part of its big data pipeline in addition to its data lake. It creates its data warehouse on structured, semi-structured and unstructured data. It uses Machine Learning to identify and create dimensions. It also establishes relations among data from different data sources and creates the corresponding dimensions. It dynamically optimizes the dimensions based on the crowd sourced data provided by end users and also based on query analysis."
9384569,Research on the Development of Maritime and Air Intelligence Big Data,"With the development of science and technology, maritime and air intelligence data has exploded and maritime and air intelligence analysis has entered the era of big data. This article summarizes the definition of big data, introduces intelligence analysis methods based on big data, U.S. military big data application research and features of maritime and air intelligence. Proposing relevant development strategies from four aspects: the Construction of big data platform for maritime and air intelligence analysis, the maritime and air intelligence big data analysis software, the digitization of mission and exercise, and the cultivation of maritime and air intelligence big data talents. Providing references for the navy to explore and develop maritime and air intelligence analysis work."
9626288,Research Hotspots and Trend Analysis of Big Data in Education,"With the development of information education, more and more digital records are produced in the process of education and teaching in the field of education. Using related technology to provide support for education and teaching is the development trend of education in the future. This paper uses CiteSpace to make a visual analysis of the literature in the field of big data of domestic education, and reveals the research hotspot and development trend of big data in chinese education. This paper combs the literature from the perspective of research hotspot and development direction, and summarizes its practical difficulties, in order to provide reference for the following development of big data of domestic education."
9525843,Design of transmission line safety early warning system based on big data variable analysis,"In order to improve the accuracy and efficiency of transmission line safety early warning, a transmission line safety early warning system based on big data variable analysis is proposed. Firstly, the overall architecture of the system is designed under the B / S architecture. Secondly, in the hardware part of the system, the security data real-time monitoring module, data transmission module and security warning module are designed to meet the functional requirements of the system. Finally, in the system software design part, the big data variable analysis method is used to calculate the hidden danger of transmission line safety, so as to improve the effectiveness of transmission safety early warning. The experimental results show that, compared with the traditional security early warning system, the early warning accuracy and efficiency of the designed system are significantly improved, which can ensure the safe operation of the transmission line."
9457356,Research on the Model of College English Network Learning Platform Based on Education Big Data,"With the development of society and the progress of science, network technology is changing the living state of modern people little by little. It also brings some challenges and opportunities to the field of education in China. Nowadays, the network learning platform of Big Data provides a lot of convenience for English teaching in colleges and universities in China. At present, many colleges and universities do not realize the importance of online teaching mode to learning English. Many teachers still adhere to the traditional idea and adopt the teaching mode of full hall irrigation, which leads to the extremely low quality of English teaching and the low interest of students in learning, so it is difficult to achieve the ideal learning effect. Therefore, under the background of Big Data, it is necessary to construct the model of college English network platform reasonably to help students improve their learning efficiency. This paper briefly summarizes the model of Big Data and network learning platform, and analyzes the application of Big Data in the field of education. The principle of model construction of college English online learning platform based on Big Data is deeply studied. At the same time, the problems of college English education in China are put forward, and the way of constructing English network learning platform model under the background of educational Big Data is analyzed."
9196429,Application of remote sensing big data technology in refined urban management,"As urbanization and economic globalization gather pace, cities are facing a spate of problems in pursuit of sustainable development despite their rapid progress. Against the backdrop of China's initiatives to develop smart cities, introducing remote sensing big data technology into refined urban management can enable coordinated, accurate and timely exchange of information among different units in cities, thereby improving the level of intelligence in urban management and develop a urban management mode that is efficient, precise, continuous and all-covering. This study explored the framework of the big data platform for refined management of cities, analyzed the processing and application of remote sensing big data technology was in refined urban management that involved dynamic monitoring of data on the bare soil, built-up land and water bodies, thus providing a technical basis for construction of smart cities."
9006574,Smart EHR - A Big-Data Approach to Automated Collection and Processing of Multi-Modal Health Signals in a Doctor-patient Encounter,"This work focuses on creating a smart Electronic Health Record (EHR) platform to collect and analyze doctor-patient interactions. It is an often cited fact that doctors are spending less and less time with patients, but two recent surveys have quantified what these numbers really are and the results are disturbing. In one survey [1], it was found that during the office day, physicians spent 27.0% of their total time on direct clinical face time with patients and 49.2% of their time on EHR and deskwork. In another survey [2], results “suggest that the physicians logged an average of 3.08 hours on office visits and 3.17 hours on desktop medicine each day,... Over time, log records from physicians showed a decline in the time allocated to face-to-face visits, accompanied by an increase in time allocated to desktop medicine It is precisely this problem that the University of Arizona's “Wired Room” project seeks to address."
9006290,A Modern Approach to Big Provenance,"Information provenance seeks to model how data evolves and is manipulated within a system, the processes and actions that affect the data, and who or what is responsible for these actions. Systems can generate large amounts of provenance data depending on the granularity and abstractions modeled for that system. Methods developed for managing and performing analytics over provenance data sets were created before the standardization of the ontology and data model. This initial work focuses on revisiting older provenance analytics methods and applying them to the new standard while also bringing them into a introducing big data platforms and infrastructure to tackle the issue of big provenance."
8386682,QuantCloud: Enabling Big Data Complex Event Processing for Quantitative Finance Through a Data-Driven Execution,"Quantitative Finance (QF) utilizes increasingly sophisticated mathematic models and advanced computer techniques to predict the movement of global markets, and price the derivatives and other assets. Being able to react quickly and intelligently to fast-changing markets is a decisive success factor for trading companies. To date, the rise of QF requires an integrated toolchain of enabling technologies to carry out complex event processing on the explosive growth and diversified forms of market metadata, in pursuit of a microsecond latency on an Exabyte-level dataset. Inspired by this, we present a data-driven execution paradigm that untangles the dependencies of complex processing events and integrate the paradigm with a big data infrastructure that streams time series data. This integrated platform is termed as the QuantCloud platform. Essentially, QuantCloud executes the complex event processing in a data-driven mode and manages large amounts of diversified market data in a data-parallel mode. To show its practicability and performance, we develop a prototype and benchmark by applying real-world QF research models on the New York Stock Exchange (NYSE) data. Using this prototype, we demonstrate this platform with an application to: (i) data cleaning and aggregating (including the computing of logarithmic returns from tick data and the finding the medians of grouped data) and (ii) data modeling: the autoregressive-moving average (ARMA) model. The performance results show that (a) this platform obtains a high throughput (usually in the order of millions of tick messages per second) and a sub-microsecond latency; (b) it fully executes data-dependent tasks through a data-driven execution; and (c) it implements a modular design approach for rapidly developing these data-crunching methods and QF research models. This platform resulting from an aggregated effort of the data-driven execution and big data infrastructure, offers the financial engineers with new insights and ...
(Show More)"
9208652,Distributed Data Strategies to Support Large-Scale Data Analysis Across Geo-Distributed Data Centers,"As the volume of data grows rapidly, storing big data in a single data center is no longer feasible. Hence, companies have developed two scenarios to store their big data in multiple data centers. In the first scenario, the company's big data are distributed in multiple data centers without data replication. In the second scenario, data are also stored in multiple data centers but important data are replicated in these data centers to increase data safety and availability. However, in these scenarios, analyzing big data distributed in multiple data centers becomes a challenging task. In this paper, we propose two data distribution strategies to support big data analysis across geo-distributed data centers. In these strategies, we use the recent Random Sample Partition data model to convert big data into sets of random sample data blocks and distribute these data blocks into multiple data centers either without replication or with replication. In analyzing big data in multiple data centers without replication, we randomly select samples of data blocks from multiple data centers and download the sample data blocks to one data center for analysis. In the second strategy with replication of data blocks, we can analyze big data on any data center by randomly selecting a sample of data blocks replicated from other data centers. This strategy avoids data transformation between data centers. We demonstrate the performance of the two strategies in big data analysis by using simulation results produced on one local data center and four AWS data centers in North America, Asia, and Australia."
9525483,Architecture Design of Application Oriented Undergraduate Innovation and Entrepreneurship Guidance Service Platform Based on Big Data Technology,"A large number of homogeneous university innovation and entrepreneurship information platform construction is facing low utilization rate, which cannot support the activities and sustainable development of teachers and students. Therefore, based on the development situation of big data era, this paper establishes an innovation and entrepreneurship guidance service platform based on B/S architecture for the guidance service of innovation and entrepreneurship education system in application-oriented universities. The scheme mainly uses the advanced J2EE environment, and combined with big data to build a new model of innovation and entrepreneurship education system in application-oriented university. We also design and implement the key modules of the system combined with data sharing and Internet technology. The development process involves the storage application of Servlet, JavaBean, JSP, JavaScript and SQL technology. The system operation test results prove the feasibility of the scheme, which can effectively play the role of big data and improve the entrepreneurship rate of college graduates."
9442572,Research on Financial Information Model Construction under the Background of Big Data,"The wide application of big data provides technical support for the transformation of enterprise financial information. Financial information is ushering in new opportunities and challenges. Big data puts forward higher requirements for enterprise financial information. Financial information under the background of big data can integrate the information and data of enterprises to the greatest extent, thereby improving the financial efficiency of enterprises and the core competitiveness of enterprises. Combining the characteristics of big data, this paper proposes the construction of financial information model and provides corresponding optimization strategies, which is conducive to the planning and implementation of enterprise financial information system."
9434508,Analysis of Community Mental Health Services in the Context of Big Data,"Nowadays, big data shows more and more rapid development tendency and presents bright prospects. From the perspective of its technical architecture, the current big data technology has become mature, and made important impacts on the reform and development of many fields. The community is the basic unit of people's social life, so it is effective to start from the community to improve the mental health of the Chinese people. It is necessary for us to introduce the concept of big data into the field of community mental health services, analyze the mental health data of community residents in detail, and establish a feedback system for mental health data, which is helpful to propose the realization path of data feedback and strengthen the mental health of community residents to build a happy China."
9101292,The Construction of Teaching Resource System of Fine Arts Based on Big Data,"In recent years, the number of built in fine arts teaching resource and click-through rates increased rapidly, but many resources database based on the traditional online learning system, teaching paths of a single, one-sided emphasis on “hits”, reduced to “material center” and other issues, and students before that the huge resource repository is difficult to find suitable for their own learning resources and learning route, this study by collecting large amounts of log data, based on the technology of data mining in the fine arts professional learning in the process of learning behavior data, through the study of artificial intelligence algorithm analysis to construct characteristic model, to recommend learning path, the object, Effectively use the established online learning system to improve the learning efficiency of learners."
9101257,Data Mining and Feature Analysis of College Students’ Campus Network Behavior,"The rise and promotion of big data methods enables teachers to understand the behavior patterns of students in a timely and accurate manner, especially to find out the groups of students that need to be focused on in time, and to help promote the student affairs management from empirical qualitative knowledge to scientific quantitative analysis. This paper applies the clustering method of data mining to analyze the campus network behavior of 3,245 students in a certain grade of B university, obtains a total of 23.843 million Internet access data in 4 years. The result shows 4 groups of students with different characteristics of Internet access, finds 350 students with large network usage. Achievements and other aspects of performance of these students are affected. This study carried out data mining of student campus network behavior, which can be used as a practical operation case for student affairs management data mining, providing effective data support for the accurate and scientific development of student affairs management."
9516494,Application of Statistical Sampling Survey in the Context of Big Data Era : ——Based on China’s 1% population sample survey in 2015,"“Data” becomes “Big Data”, which is the beginning of a major era transformation. With the stepping into the era of big data, people’s thinking, cognition, behavior, etc. have undergone tremendous changes. Whether it is high in temples or far away from rivers and lakes, “big data” is undoubtedly a topic that has attracted particularly high attention. On this background, this paper is based on China’s 1% population sample survey in 2015 to empirically explore the application of statistical sample surveys in the context of the big data era. The research results show that in the context of big data, sampling surveys are faced with many opportunities and challenges. Only by organically combining big data technology with sampling surveys can the data obtained be richer and more effective."
9120906,Machine Learning and Big Data Implementation on Health Care data,"Healthcare is the most prominent field suitable for the applications of machine learning and big data on health care data. The implementations of health care with big data and machine learning is increased with the client health requirements. The electronic health record applications are being increased in this current situation, which is needed to be focused on utilizing the data generated by those applications. There is a large volume of data in health care that is related to different health care domains especially neuro and cardiac. These data need a special focus and the architectures currently focusing on these domains has to implement the latest technologies to predict some patterns. In this article, the implementation of different health care architecture is focussed, which uses live data gathered from different sources over the globe. In this article, machine learning approaches and the big data framework are combined to design a prediction model and data handling techniques."
9360988,The Design of University Employment Information Service System Based on Big Data,"At present, there are many problems in the employment information service of colleges and universities, such as students' difficulty in choosing a job, and it is difficult for colleges and universities to obtain feedback from the employment market to guide teaching work. In view of these problems, the university employment information service system based on big data was developed. With the help of big data related technologies, the system recommends personalized work for students to help colleges and universities track the skills needed for employment in time. The system is designed based on the spark technology of the big data parallel computing framework of in-memory computing, it uses Scrapy Web crawler technology to obtain job data from the internet for the system and save it to the MongoDB database. As for the specific system functions, TF-IDF algorithm is used to extract the features of the job data, K-means algorithm is used to cluster the job types, then job recommendation is carried out through text analysis, LDA thematic model algorithm is used to analyze the hot spots of the employment market, and finally achieve job recommendation and analysis of job data."
9516548,Application of Artificial Intelligence in Computer Network Technology in big data era,"In this era of big data network technology, computer and information technology are also making rapid progress. The rapid progress of big data network technology also makes the country and some large enterprises step up the research on artificial intelligence technology. This paper first defines the related concepts of big data and artificial intelligence, and analyzes the characteristics and technical advantages of artificial intelligence on this basis. At the same time, this paper discusses the application of artificial intelligence in computer network from the aspects of computer network security, system evaluation and network security management, so as to put forward a reference strategy for the better application of artificial intelligence in computer network technology. This study can not only greatly promote the application of artificial intelligence in the field of computer network technology, but also further promote the development of artificial intelligence and computer network."
9196293,Research on Big Data Technology and Application in Internet Era,"This paper starts with the analysis of the characteristics of big data technology in the Internet era and its impact on the times, and then makes a thorough analysis of the problems faced by big data in the development process, including the requirements of high-level processing technicians, equipment, security problems in big data, and the problems of composition and governance. Then it elaborates in detail how to solve many problems faced by big data technology in the development in contemporary society. Starting from the needs of the times, China's Internet technology has been developed and improved while improving the rapid development of big data technology."
8669529,Research on Medical Service System Based on Big Data Technology,"The purpose of the medical information sharing system based on big data in this paper is promoting the development of medical informatization, providing technical solutions and supporting conditions for the construction of regional medical informatization in China. The system is bound to promote the quality of medical information service by the application of big data and cloud computing and solve the ""high cost but low efficiency"" problem. This paper designs a service pattern that takes the patients as the center and realizes the reasonable distribution and sharing of medical resources. The system also provides experience and references for the medical service innovation in China. In this paper, a medical service system BDMSP which based on big data technology, is introduced. It describes the design of BDMSP from system architecture, key technologies, its application and etc. It may be a helpful research for application of big data technology."
8689011,A Framework for Big Data Governance to Advance RHINs: A Case Study of China,"The emergence of big data presents a serious challenge to the fast growth of regional health information networks (RHINs) globally. In China, many constructors of RHINs have spontaneously and independently created governance measures, which may be valuable as a point of reference for other countries. This paper aimed to propose a big data governance framework for healthcare data based on the governance activities associated with the processing of RHINs in China. Typical methodology for RHIN case studies in China, including rich personal experience in nationwide consulting, literature review, expert consultation, and interpretative structural modeling methods, was adopted. Based on the analysis of ten typical RHIN case studies, healthcare big data governance practices in China were summarized. A framework with 3 domains and 12 elements was proposed, which include a drive domain (big data strategy planning, laws and regulations, open transaction, and industry support), capability domain (healthcare big data organization, collection, storage, process and analysis, and usage), and support domain (healthcare big data resource planning, standards system, and privacy and security protection). We obtained 12 guidelines for healthcare big data governance. A big data governance framework with 3 domains and 12 elements was presented based on Chinese practice, which might serve as valuable references for the cross-dimensional development of RHINs, provide overall guidance for the sustainable development of regional health informatization, and contribute to realizing the business value of healthcare big data."
8669513,A Dynamic Prediction Model of Real-Time Link Travel Time Based on Traffic Big Data,"In order to improve the dynamic prediction ability of the real-time segment travel time in the traffic information platform, traffic big data can effectively feedback traffic congestion. A real-time link travel time dynamic prediction algorithm based on big data analysis is proposed. The structure model of interactive traffic information platform is constructed by using Small-World model, and the traffic state set of traffic information platform is sampled by using RFID tag reading technology. The real-time traffic condition big data in the sampled traffic information platform is processed by information fusion, and the principal component characteristic quantity of the real-time traffic condition big data in the traffic information platform is extracted, and the travel time and road network state information of the real-time road section are reorganized. According to the main component feature extraction of traffic big data in the traffic information platform, the real-time road condition monitoring and travel time prediction are carried out, and the basis of traffic big data analysis, real-time dynamic prediction of road travel time was carried out on the traffic information platform. The simulation results show that the proposed method is more accurate, and the anti-congestion and traffic capacity of the traffic network is improved by using the method to predict the dynamic travel time of the real-time section of the traffic information platform."
9110043,Innovative Research on the Training Mode of Accounting Professionals Under the Environment of Big Data,"In order to make the training mode of accounting professionals more in line with the environment of big data, this paper puts forward an effective and innovative scheme. The scheme uses scientific and efficient big data technology to build big data information platform, which can provide modern and intelligent technical support for the efficient accounting professional training mode. At the same time, by using the methods of literature analysis and comparative study, this paper further discusses the close relationship between the emergence of big data era and the reform of accounting professionals. The research result of this paper is to realize the reform and innovation of the training mode of accounting professionals in colleges and universities based on big data platform, and then solve the main disadvantages of the traditional training mode of accounting professionals in our country, for example, unclear teaching objectives, unscientific curriculum and so on."
8725744,Analysis of the Application of Military Big Data in Equipment Quality Information Management,"This At present, big data has risen to the national strategy. Big data is fully integrated into the military field, becoming the driving force of military scientific research, the core element of construction management, and an important resource for war success. This paper mainly expounds the basic connotation of big data technology and military big data, and analyzes the application of military big data in equipment quality information management, and proposes information collection, storage, analysis, processing, exchange and feedback on equipment quality information management. The countermeasures provide methods and basis for military big data in equipment information management."
9407169,Application research of Big data in provincial important Product traceability system,"With the rapid development of information technology, big data technology fusion of Internet of Things technology has been better applied in provincial important product traceability. As a provincial important product traceability system connecting all links from planting, breeding, production and processing to logistics, transportation and sales, it generates a huge database of data every day. So big data technology is needed for data analysis and data mining to improve economic efficiency for government decisions, for industries/enterprises, and for social development."
9457414,Big Data Technology Boosts Research on the Modernization of Vocational Education Management in Shandong Province,"Big data technology has flourished in recent years. As a subdivision of big data, education big data has great potential to promote education reform. Big data technology is developing rapidly, which provides new possibilities for the application of big data. In order to deeply analyze the development of big data in education, starting from the latest development of big data technology, the development trend of big data is explained from the aspects of infrastructure, analysis technology and field application. Then through the analysis of the composition and characteristics of big data in the education field, the meaning of big data in education is analyzed. In order to promote the modern management of vocational education, this article analyzes the challenges of vocational education in the era of big data on the basis of analyzing the status quo of vocational education. First, special skills and innovation capabilities will become the subject of talent training. The second is that learning and personalized training will be deeply integrated. The third is that technical education and comprehensive capabilities will achieve multi-subject training. Fourth, information technology and teaching resources will promote the reform of teaching models. Fifth, super skill and good organization will become the basic requirements of teachers. Sixth, management innovation and technology research and development will become important measures for the modern management of vocational colleges. Finally, this article discusses the strategies of modern management of vocational education, including improving the management ability of vocational colleges, building a new vocational education training model, improving the teaching quality evaluation system, and building a ""dual-teacher"" teaching team."
9476492,The Usage of Big Data and Data Analytics in the Study of Climate Change,"In a world more and more connected with digital where the possibility of generating and analyzing big quantities of data is becoming increasingly valuable for society, every day there are new findings on opportunities and strategies in studies that cover a great treatment of data. In the era where Big Data and consequential data analysis are utilized effectively in a variety of topics, how have these behaved towards that which is one of the biggest challenges that human beings face: climate change. This literature review shows how Big Data and data analysis have interacted with the subject-matter and relate the use of these by referring to examples of how it has been implemented in the investigation of climate issues, aiming to reveal how climate change, a subject that has been exhaustively studied, has also been affected with the introduction of Big Data and that with Big Data it was possible to obtain better knowledge about the subject which is extremely important for society's preparation and adjustment."
9355359,Application Scenarios and Practice Essence of Data Science Based on Big Data Analysis,"The synchronous development of urbanization, industrialization and informatization is an important characteristic of China's urbanization. At present, the construction of the major of data science and big data technology in China has become a new hot topic. The major of data science and big data technology has been added by the state in recent years against the background of ""big data"" era. The aim is to train high-level big data talents with big data thinking, big data thinking and analytical application technology. In view of the increasing importance of data science and big data specialty, there are different personnel training programs for data science and big data specialty. The major of data science and big data technology is a combination of software and hardware, based on computing technology and characterized by data science and big data technology. This paper analyzes the current situation and application scenarios of data science, and introduces the challenges and practical methods that big data brings to data analysis tools in data science."
9407207,Research on the Relevance of Big Data Accounting and Financial Information,"This article combines the relevance of big data accounting and financial information, and analyzes the difference between big data accounting and traditional accounting. The research content of this paper includes many aspects such as the change of thinking mode, fragmented or unstructured, data system structure, and the manifestation of information value. The author studied descriptive statistics, correlation testing, regression and analysis, robustness testing, and so on. The purpose of the research is to improve the effect of corporate financial information management and promote the sustainable development of the corporate economy."
8669612,The Application of Big Data Technology in Creative Travel,"With the rapid development of Internet of Things and communication technology and the arrival of the era of big data, the construction of Intelligent Tourism is no longer an unrealistic slogan. The construction of smart tourism destination is in line with the strategic objective of China's tourism development. User behavior interest data are simulated artificially. Then, the features of tourist attractions, tourist routes and user behavior interest are extracted in the tourism field, and the user interest feature model is established. This paper briefly analyzes the application of big data in the tourism industry, promoting the effective application of big data in the tourism industry, further promoting the vigorous development of the tourism industry."
9377830,Visualizing Effects of COVID-19 Social Isolation with Residential Activity Big Data Sensor Data,"The ability to understand and visualize big data sets is of increasing interest to caregivers and clinicians as ambient home sensing can provide massive amounts of data related to the activities of residents. However, this data is only useful if it can be effectively and simply visualized for review and analysis. This paper presents the visualization of longitudinal data sets from ambient well-being sensors deployed in 3 residences that have a spousal pair dyad where 1 resident has been diagnosed with Mild Cognitive Impairment or Dementia and the spousal partner is acting as a caregiver. The paper presents the differences in activity and behaviour that can be observed in the 3 residences by comparing two 30-day periods prior to and one 30-day period during COVID-19 social isolation precautions. The work shows the potential for this circle plot based visualization technique to summarize resident activity and also to convey external factors such as the variation in solar day that can itself influence behaviour."
8713251,Big Data and Safety Management Methods: The Reduction Model of Hot Work Number,"The management of hot work is the key element of petroleum refinery safety management. A large amount of hot-work data has been accumulated, which is underexploited. Driving new insights using big data analytics is the trend. However, there have been few scientific studies on solving a specific problem using big data method in the field of safety management. Hence, the unstructured-data analysis of the hot-work permit-to-work text was investigated. The professional corpus in the hot-work field was constructed using word segmentation, stop list elimination, standardized process, and manual proofreading. All hot-work content collocates were manually grouped into semantic domains in the light of experts' experience. The data-driven reduction models of hot work number were proposed aiming at possible invalid hot work, long-time hot work, repetitive hot work and possible equipment defect. Based on the proposed reduction models, we mined the patterns of hot work and the unnecessary or high-risk hot work could be identified automatically. The result of the reduction model in training set indicated that the reduction models are reasonable. The reduction model 1, reduction model 2, reduction model 3, reduction model 4 could reduce the proportion of hot work number 5%, 3%, 4%, and 2%, respectively. Thus, the targeted measures could be put forward to optimize the safety management of hot work."
8669679,Big Data Based Outdoor Sports Monitor and Analysis System Design of University,"At present, there are few research by domestic and foreign researchers on monitoring and analyzing physical activity of large-scaled students' group, so it is theoretically significant with empirical value to analyze and study outdoor sports data of big data technology. Under such background, a group character-oriented exercise health monitoring solution is put forward. This paper combines with Hadoop cluster to store and analyze mass motion data, and integrates with data processing algorithm and conversion algorithm to quantify various physical activities. We use Hadoop open source framework to design and realize motion information analysis service platform. It respectively processes and analyzes the distributed mass physical activity data from two perspectives of motion individuals and the motion group to obtain analysis results of various data. Finally, the paper designs Android-based query and management of motion information to understand physical activity of students' group intensively."
9457438,An Empirical Study of English Writing Based on Big Data,"English writing can effectively promote the development of learners' basic language knowledge, skills and comprehensive application ability. It is a major and difficult point in college English teaching. Based on the big data behind the correction website, combined with the statistical retrieval of WordSmith Tools and other data, and referring to the online corpus big data resources such as BNC and COCA, this article analyzes the significance of corpus and big data in English writing, correction and teaching, and improves the corpus-based Big data English writing, correction, teaching effect, efficiency and effectiveness."
9212858,Big Data Analytics for Processing Real-time Unstructured Data from CCTV in Traffic Management,"Todays many devices generate data everywhere and anytime. Data grow massively and becomes complex thing that needs to be handled. Unstructured data is one type of big data that is difficult to process and consists of unstable attributes. In traffic management, CCTVs are installed to monitor the specific location in the highway. CCTV generates unstructured data in image and video format. These data are difficult to process due to the complexity of the data. This research proposes to implement big data analytics to process real-time unstructured data from CCTV into knowledge displayed in web dashboard. We implement the YOLO framework with YoloV4 Architecture and COCO dataset for traffic flow counting and detecting illegal parking which is categorized as abnormal situation. Unstructured data from CCTV then transformed into semi-structured format in JSON. Data also can be visualized in real time to facilitate local authority to understand the highway situation. Historical data are stored in the NoSQL database to deep more knowledge such as vehicle traffic pattern. The proposed system requires the ROI drawing line as trigger to count the passing vehicles. These experiments are conducted from open CCTV for traffic online in Bali Tower Public Streaming. The prototype result is able to detect the object with 10 fps."
8945689,Safety Situation and Defects Analysis of Spherical Tanks from Big Data Perspective,"The spherical tank is quite important to the medium storage and exchange of the production process. It is easily eroded by the internal medium, and has defects such as corrosion, cracks, holes in the walls and welds. Inspection is a necessary means to ensure the safe operation of the spherical tank. In this paper, a parser program was designed to collect the large amount of data items in the inspection record files. The thickness data of 16800 measured points, 6325 mm cracks found by magnetic particle testing and 85734 mm length defects found by ultrasonic testing of 91 spherical tanks were collected. From big data perspective, the safety situation and defects analysis of spherical tanks were analyzed. The data safety analysis, combined with mechanism safety analysis, provides richer support for the safe operation of the spherical tanks."
9260067,Big Data Quality Prediction on Banking Applications: Extended Abstract,"Big data has been transformed into knowledge by information systems to add value in businesses. Enterprises relying on it benefit from risk management to a certain extent. The value, however, depends on the quality of data. The quality needs to be verified before any use of the data. Specifically, measuring the quality by simulating the real life situation and even forecast it accurately turns into a hot topic. In recent years, there have been numerous researches on the measurement and assessment of data quality. These are yet to utilize a scientific computational method for the measurement and prediction. Current methods either fail to make an accurate prediction or do not consider the correlation and time sequence factors of the data. To address this, we design a model to extend machine learning technique to business applications predicting this. Firstly, we implement the model to detect data noises from a risk dataset according to an international data quality standard from banking industry and then estimate their impacts with Gaussian and Bayesian methods. Secondly, we direct sequential learning in multiple deep neural networks for the prediction with an attention mechanism. The model is experimented with various network methodologies to show the predictive power of machine learning technique and is evaluated by validation data to confirm the model effectiveness. The model is scalable to apply to any industries utilizing big data other than the banking industry."
9332352,Design and Implementation of Computer Network Information Security Protection Based on Secure Big Data,"In the current development of information technology, big data has become one of its important features. Moreover, with the rapid development of big data related technologies, the threat degree of computer information in China is increasing. Under the background of big data, information data grows rapidly, which makes it easier for people to obtain valuable information. However, people are faced with more and more information security problems, and it is increasingly difficult to maintain information security. In this paper, based on the security big data, the factors affecting the information security of computer network are analyzed, and the specific countermeasures are studied based on the background of big data. The purpose is to provide reference for relevant personnel and improve the stability and security of data information."
9525487,Research on Intelligent Image Scrambling Transform Encryption Algorithm Based on Big Data Analysis,"In order to improve the encryption ability of scrambling transformation of high-resolution knowledge map remote sensing image, a scrambling transformation encryption model of high-resolution knowledge map remote sensing image based on big data analysis and multi feature fusion is proposed. The edge pixel feature analysis model of high-resolution knowledge map remote sensing image is constructed. The edge pixel feature distributed reorganization method is used to realize the pixel structure reorganization. The image is processed by multispectral parameter big data fusion and chaos quantization linear feature analysis. The image encryption key feature analysis is realized by using the combination control method of shallow feature map. The personalized features extracted from image are identified by using intelligent image scrambling transform encryption algorithm, and the multilevel feature analysis model of image scrambling transform encryption is established. The simulation results show that the method has high adaptability and good scrambling performance, and improves the ability of fusion encryption and feature recognition of high-resolution knowledge map remote sensing image."
8945716,Research on College English Teaching Strategies and Applications Based on Big Data,"The era of big data has spawned a new model of college English teaching. How to use big data to support learners and promote the development of English learning is an important topic worthy of further exploration. Based on the characteristics of the era of big data, this paper analyzes the college English teaching in China through the form of empirical analysis, and finally proposes the proposed measures."
9360934,Application Analysis of Big Data in Digital Media,"Up to now, China has entered the era of comprehensive big data, which has also enabled big data technology to be fully applied in various industries. However, it can be seen from its actual development that big data technology still has some unsolvable problems. Based on previous work experience, this article summarizes the specific content of big data changing digital media. The author discusses the specific application of big data in digital media from four aspects. They are the application of big data technology in content production, application in content analysis, application in distributed storage, and application in data operation."
9183863,A Scalable Heterogeneous Big Data Framework for e-Learning Systems,"The adoption of e-learning systems in higher education is a remarkable phenomenon that has redefined teaching and learning. Initially, it was proposed to allow people to learn for personal accomplishment without physically attending any traditional university or academic settings. While these systems continue to provide an efficient and flexible approach for teaching and learning, the rapid integration of ICTs and the expansion of data from these systems remain much concern to the education community. In this study, we propose a smart and secure data flow architectural framework for e-learning that uses a rich set of big data tools within a distributed and parallel analysis platform. Reference Model of Open Distributed Processing (RM-ODP) reference model guided the development of this Big Data framework for e-learning analytics. Using the RM-ODP model as a benchmark, we classify the educational institution's architecture in terms of existing elements, functions and processes to understand stakeholders' views for the development of the framework. Our approach uses an existing distributed computing environment and offers an adaptable standard framework to improve the data acquisition, storage, processing, analysis, security and virtualization for e-learning systems. We implement a scalable and adaptable big data framework for e-learning (BiDeL) and point out how big data concept could integrate into online learning systems to improve teaching and learning in higher education using Apache Spark as a case. The proposed framework was applied to both batch and streaming dataset of students online activities on moodle LMSs. BiDel framework performance shows improved data integration and data governance. This big data framework and the general view of the current state of the art in “big data” technologies will serve as a guide for the creation of e-learning systems, which create new value from existing but underused data. The acquired value will provide decision-makers in ...
(Show More)"
9134140,Design of Network Precision Marketing Based on Big Data Analysis Technology,"In the process of big data processing, big data analysis is the core work content. After obtaining a large amount of data, we use related analysis technology to perform data processing and analysis to obtain knowledge. Its related content includes visual analysis, data mining, predictive analysis, semantic analysis and data quality management. How to obtain big data, classify and store according to data types, mine valuable information from big data, and effectively apply big data in the field of precision marketing are hot topics of research. On the basis of researching the key technologies of big data analysis, this paper uses Hadoop big data to analyze and store the massive online logs generated by users' mobile terminals, and calculates and builds user characteristic databases. We use relevant analysis technology to analyze the user's location information, browsing and usage habits, hobbies, and focus content. At the same time, a precise marketing model is established according to user behavior characteristics and attributes, thereby improving the marketing effect of the enterprise."
9142151,Applying big data based deep learning system to intrusion detection,"With vast amounts of data being generated daily and the ever increasing interconnectivity of the world's internet infrastructures, a machine learning based Intrusion Detection Systems (IDS) has become a vital component to protect our economic and national security. Previous shallow learning and deep learning strategies adopt the single learning model approach for intrusion detection. The single learning model approach may experience problems to understand increasingly complicated data distribution of intrusion patterns. Particularly, the single deep learning model may not be effective to capture unique patterns from intrusive attacks having a small number of samples. In order to further enhance the performance of machine learning based IDS, we propose the Big Data based Hierarchical Deep Learning System (BDHDLS). BDHDLS utilizes behavioral features and content features to understand both network traffic characteristics and information stored in the payload. Each deep learning model in the BDHDLS concentrates its efforts to learn the unique data distribution in one cluster. This strategy can increase the detection rate of intrusive attacks as compared to the previous single learning model approaches. Based on parallel training strategy and big data techniques, the model construction time of BDHDLS is reduced substantially when multiple machines are deployed."
8997532,Practical Data Mid-Platform Design and Implementation for Medical Big Data,"Big Data has attracted much attention in academia and industry fields in the last few years. The trend of utilizing medical big data has increased tremendously as well. The medical big data is generated from medical records, medicine, research, etc. but it is not well connected due to its long-term development in last decades in most hospitals without high-level strategic guide and plan. The information missing, data dispersivity, information isolated island, redundancy problems are key to the failure of the big data platform which is used to manage the medical data asset. We propose a platform called Data Mid-Platform (DMP) to solve the above problems and serve other big data projects as well as scientific assignments. The feasibility of this mid-platform is highly recommended and certified by several domain experts and it is under construction in a real project. It aims to satisfy at least 3 to 5 years big data applications development under the perspective of big data top-level design."
8725711,Online Distance Learning Precision Service Technology Based on Big Data Analysis,"With the rapid growth of online learning resources, users are facing the problems of information overload in the process of online learning. Improving information precision service has become the primary task of distance learning. The paper optimizes the research on the precise service technology and methods of distance learning using the big data analysis technology, and improves the pertinence and individuation of obtaining distance learning services, realizes the individualized teaching under the support of computer and network information technology, enhances the level of distance learning service and knowledge dissemination efficiency, and promote Internet plus education data service industry development."
9095612,The Workload Assessment of National Grid Big Data Projects Based on Content Recommendations and Text Classification,"The evaluation of workload in big data project is an important prerequisite for improving the management of the National Grid big data projects. The lack of relevant models and specifications of the evaluation is caused by the exploratory, uncertainty and characteristics of big data projects. Based on the information of typical projects, this paper proposes to combine with Natural Language Processing (NLP)and machine learning to solve the problem. Firstly, this method obtains the reference value of project workload impact factors through content recommendation, neural network and other algorithms. Then the workload estimation model is built based on the measurement of each impact factor. The results show that the method proposed in this paper can effectively identify and predict the attribute class impact factors of the new project, and can also reasonably complete the workload estimation of the project, which is greatly significant to realize the rational allocation of resources."
9516579,Analysis on the Innovation Mode of Public Management in Big Data Age,"Under the background of the rapid development of computer technology and data technology, public management has also entered the field of vision of many people. There are also some people who study how to innovate public management and connect public management with big data. These researchers will also study how to innovate public management with the help of big data technology. This paper also analyzes the purpose and characteristics of public management in mode innovation, and explains the difficulties encountered by public management in mode innovation. At the same time, this paper also points out the methods and ways of public management innovation in the era of big data, which also enriches the methods of public management innovation."
9150226,Research on Enterprise Economic Risk Forecast Model Based on Big Data Fusion,"In order to improve the capability of enterprise economic risk assessment and prediction, this paper combines panel data analysis method to construct enterprise economic risk prediction model, proposes enterprise economic risk prediction model based on big data fusion, establishes fusion clustering model of enterprise economic risk assessment panel data, and uses fuzzy correlation fusion clustering method to make statistical analysis of enterprise economic risk assessment panel data. Quantitative regression analysis and fuzzy clustering methods are used for panel data mining of enterprise economic risk assessment, adaptive block feature matching in the risk prediction process is carried out according to the mining results of panel data bureau, interference suppression in the enterprise economic risk prediction process is carried out by using correlation feature matching method, large data fusion in the enterprise economic risk prediction process is carried out by combining fuzzy information clustering and statistical analysis methods, and optimization of enterprise economic risk prediction is realized according to the rule distribution relation of recursive entropy. The simulation results show that the method has high accuracy in predicting the economic risks of enterprises, improves the data mining and information fusion capabilities of enterprises' economic risks, and improves the anti-risk capability of enterprises."
9377741,ExNav: An Interactive Big Data Exploration Framework for Big Unstructured Data,"Driven by the increasing gap between the exponential growth of data and the limited human ability to comprehend them, recently, a novel interactive data exploration approach called Explore-by-Examples has generated a lot of attention for its capabilities to bridge this gap and to help the user obtain high-value content from the data that are often hidden using the traditional search methods. However, despite their effectiveness in extracting valuable information, existing Explore-by-Examples systems focus solely on structured data, which represents a small portion of the data available today. In this work, we present a novel data exploration framework, namely ExNav (Exploration Navigator), which enables the user to effortlessly explore the world of unstructured data for insights that are often unreachable from traditional search and exploration methods. In particular, we exploit the space of advanced machine learning, data embedding, and active learning algorithms to design effective exploration and space pruning approaches tailored for unstructured datasets. Our experimental evaluation using multiple real-world unstructured datasets (i.e., text, image, and graph) show that ExNav can reduce users' effort by up to 9x while still achieving the same accuracy as the state-of-the-art alternative. Moreover, ExNav is also able to identify relevant data items that are often undetectable by current techniques, even when a large number of samples are explored."
9360973,Research on How to Strengthen Ideological and Political Education in Colleges and Universities in the Era of Big Data,"Analyzing, judging and sorting out data through big data technology helps us grasp the prospects and laws of the development of things. Especially for the future development direction of things, more accurate calculations can be made, and scientific and reasonable measures can be taken to promote the development of things according to the calculation results. At present, in the process of ideological and political education in my country's colleges and universities, the teaching methods are mainly traditional teaching methods. In classroom teaching, teachers instill the corresponding curriculum theory, the teaching method is relatively simple, and the curriculum content is boring, which seriously affects the teaching efficiency and teaching quality of college ideological and political classrooms. The use of big data technology to build a curriculum network system that is more suitable for students' learning needs. Besides, the use of some simple extracurricular activities to assist students' education and teaching can mobilize students' enthusiasm and enthusiasm for participating in ideological and political education in colleges and universities, which is conducive to giving full play to ideological and political education in colleges and universities positive effect. Therefore, we need to pay attention to the positive role of big data technology in college ideological and political education, and use big data technology to strengthen college ideological and political education."
9516550,Research on Computer Information Processing Technology Based on Big Data,"With the rapid development of modern science and technology and the continuous progress of Internet technology, today’s society has entered a big data era full of opportunities and challenges. At the same time, the increase of computer and Internet information data has brought the same pressure to the traditional computer information processing technology. The continuous improvement of big data technology has created greater profits for enterprises, and various “clouds” have slowly surfaced, which has brought a great test to the progress of computer information processing technology. This paper first analyzes the connotation of big data and computer information processing technology. On this basis, this paper discusses computer information processing technology from the angles of information collection, information storage, information security and information processing. At the same time, combined with the characteristics of computer information processing technology, this paper reveals the development trend of this technology under the background of big data, in order to point out the direction for the development of information technology.This electronic document is a “live” template. The various components of your paper [title, text, heads, etc.] are already defined on the style sheet, as illustrated by the portions given in this document."
9671564,Privacy-Preserving Publishing and Visualization of Spatial-Temporal Information,"Partially due to technological advancements as well as the availability of affordable global positioning system (GPS) and cellular devices, more spatio-temporal data can be generated and collected. The presence of spatial and temporal dimensions uniquely differentiate spatio-temporal data from classical data as spatio-temporal data points are structurally related in the context of space and time. In this paper, we present a solution for privacy-preserving publishing and visualization of spatiotemporal big data information. Specifically, it consists of a spatiotemporal hierarchy model (STHM) for some common big data management tasks such as visualization. Our data visualizer provides actionable insight to enhance data-driven decision making. It also enables the discovery of hidden patterns, clusters of events, and outliers. We design two different metrics to preprocess the spatio-temporal for data visualization. Although we demonstrate the usefulness of our solution in privacy-preserving publishing and visualization of spatio-temporal information by using big real-life parking data from two cities, our solution can be applicable for publishing and visualizing spatio-temporal information from many other big data."
9031432,ATCS: Auto-Tuning Configurations of Big Data Frameworks Based on Generative Adversarial Nets,"Big data processing frameworks (e.g., Spark, Storm) have been extensively used for massive data processing in the industry. To improve the performance and robustness of these frameworks, developers provide users with highly-configurable parameters. Due to the high-dimensional parameter space and complicated interactions of parameters, manual tuning of parameters is time-consuming and ineffective. Building performance-predicting models for big data frameworks is challenging for several reasons: (1) the significant time required to collect training data and (2) the poor accuracy of the prediction model when training data are limited. To meet this challenge, we proposes an auto-tuning configuration parameters system (ATCS), a new auto-tuning approach based on Generative Adversarial Nets (GAN). ATCS can build a performance prediction model with less training data and without sacrificing model accuracy. Moreover, an optimized Genetic Algorithm (GA) is used in ATCS to explore the parameter space for optimum solutions. To prove the effectiveness of ATCS, we select five frequently-used workloads in Spark, each of which runs on five different sized data sets. The results demonstrate that ATCS improves the performance of five frequently-used Spark workloads compared to the default configurations. We achieved a performance increase of 3.5× on average, with a maximum of 6.9×. To obtain similar model accuracy, experiment results also demonstrate that the quantity of ATCS training data is only 6% of Deep Neural Network (DNN) data, 13% of Support Vector Machine (SVM) data, 18% of Decision Tree (DT) data. Moreover, compared to other machine learning models, the average performance increase of ATCS is 1.7× that of DNN, 1.6× that of SVM, 1.7× that of DT on the five typical Spark programs."
9148220,Big Data Analysis of Intelligent Electric Meters' Faults,"At present, there are still some deficiencies in the use of intelligent electricity meters in China, which makes the staff often encounter some problems and faults. This paper will make an in-depth discussion on the big data analysis of intelligent electricity meters' faults, so as to promote the rapid development of intelligent electricity meters in the era of big data in China."
9525875,BIM Based Project Investment Cost Control Strategy in Big Data Environment,"In order to overcome the problems of low efficiency and poor control effect of traditional investment cost control strategies, this paper designs a project investment cost control strategy based on BIM under the environment of big data. We discuss the basic knowledge of dynamic control of investment cost by using data model, and focus on the application of BIM in project cost control. The materials are integrated through standard BIM data interface and 4D model schedule. Then, the project schedule simulation and collision detection collaborative module of BIM are fully used to complete the calculation and distribution of specific workload. The experimental results show that compared with the traditional control strategy, the time consuming of the proposed control scheme is shorter, and the cost waste is less after the application of the proposed strategy, which proves that the proposed strategy effectively promotes the integration of engineering design and engineering cost control, and the control effect is good."
9006000,SecureGBM: Secure Multi-Party Gradient Boosting,"Federated machine learning systems have been widely used to facilitate the joint data analytics across the distributed datasets owned by the different parties that do not trust each others. In this paper, we proposed a novel Gradient Boosting Machines (GBM) framework SecureGBM built-up with a multi-party computation model based on semi-homomorphic encryption, where every involved party can jointly obtain a shared Gradient Boosting machines model while protecting their own data from the potential privacy leakage and inferential identification. More specific, our work focused on a specific “dualparty” secure learning scenario based on two parties — both party own an unique view (i.e., attributes or features) to the sample group of samples while only one party owns the labels. In such scenario, feature and label data are not allowed to share with others.To achieve the above goal, we firstly extent — LightGBM — a well known implementation of tree-based GBM through covering its key operations for training and inference with SEAL homomorphic encryption schemes. However, the performance of such re-implementation is significantly bottle-necked by the explosive inflation of the communication payloads, based on ciphertexts subject to the increasing length of plaintexts. In this way, we then proposed to use stochastic approximation techniques to reduced the communication payloads while accelerating the overall training procedure in a statistical manner. Our experiments using the real-world data showed that SecureGBM can well secure the communication and computation of LightGBM training and inference procedures for the both parties while only losing less than 3% AUC, using the same number of iterations for gradient boosting, on a wide range of benchmark datasets. More specific, compared to LightGBM, the proposed SecureGBM would slowdown with
3x∼64x
time consumption per iteration in the training procedure, while SecureGBM becomes more and more efficient ...
(Show More)"
9403745,The Design of “Smart Party Building” Platform in Colleges and Universities Based on Big Data Environment,"With the continuous development of information technology, the combination of Internet, big data and Party building has become the development direction of informatization and networking of grass-roots party building in Colleges and universities in the new era. Under the requirements of promoting the development of education and cultivating builders and successors of the new era, the grass-roots party construction work in Colleges and universities needs to adapt to the new situation of big data and “Internet +” and go with it. Based on the big data environment, we should use the information network technology to build a “smart party building” platform at the grass-roots level in Colleges and universities. We should make good use of new technology such as big data and cloud computing to comprehensively promote the innovation of the working concept and working mode of strict party governance, and establish a grass-roots “smart party building” platform with university characteristics. This paper expounds the platform from four aspects: working function, information function, learning function and service-oriented function. It is an important method to further improve the construction of grass-roots party organizations and enrich the education and management of Party members."
9457406,Research on the Development of University Innovation and Entrepreneurship Education under the Background of Big Data,"Today, information technologies such as big data, artificial intelligence, mobile Internet, and intelligent integrated networks are gradually changing people's work and life, and technological innovation and technological entrepreneurship will surely become mainstream models. Innovation and entrepreneurship education in colleges and universities closely follows the trend of the era of ""mass entrepreneurship and innovation"", and effectively integrates with big data to promote the development of innovation and entrepreneurship education. This article re-organizes the current problems of innovation and entrepreneurship education in universities, analyzes the existing research, value and role of big data for innovation and entrepreneurship education in universities, and expounds that big data promotes innovation in universities from the three aspects of education philosophy, quality evaluation and education system."
9457433,Research on the Construction of University Informatization Teaching Mode Based on Big Data,"The development of big data has added new vitality to the teaching work of colleges and universities. This article mainly discusses the basic concepts and characteristics of big data. Simultaneously, this article also analyzes the main problems in the construction of college informatization teaching mode under the background of big data. Then, this article studies the main modules and construction methods of college informatization teaching mode. By checking the role of big data technology in college informatization teaching, this article aims to promote the practical construction of college informatization teaching mode. Simultaneously, this article provides some valuable help for college teachers."
8754035,"Making the Pedigree to Your Big Data Repository: Innovative Methods, Solutions, and Algorithms for Supporting Big Data Privacy in Distributed Settings via Data-Driven Paradigms","Starting from our previous research where we in- troduced a general framework for supporting data-driven privacy-preserving big data management in distributed environments, such as emerging Cloud settings, in this paper we further and significantly extend our past research contributions, and provide several novel contributions that complement our previous work in the investigated research field. Our proposed framework can be viewed as an alternative to classical approaches where the privacy of big data is ensured via security-inspired protocols that check several (protocol) layers in order to achieve the desired privacy. Unfortunately, this injects considerable computational overheads in the overall process, thus introducing relevant challenges to be considered. Our approach instead tries to recognize the “pedigree” of suitable summary data representatives computed on top of the target big data repositories, hence avoiding computational overheads due to protocol checking. We also provide a relevant realization of the framework above, the so- called Data-dRIven aggregate-PROvenance privacy-preserving big Multidimensional data (DRIPROM) framework, which specifically considers multidimensional data as the case of interest. Extensions and discussion on main motivations and principles of our proposed research, two relevant case studies that clearly state the need-for and covered (related) properties of supporting privacy- preserving management and analytics of big data in modern distributed systems, and an experimental assessment and analysis of our proposed DRIPROM framework are the major results of this paper."
9443976,An Improved Data Discretization Algorithm based on Rough Sets Theory,"As the key to big data, extracting the potential and core value from a large volume of data is very important. In this study, we propose a discrete data processing algorithm, known as the improved class-attribute contingency coefficient (ICACC) algorithm, based on the rough sets theory and class attribute strain coefficient standard. The proposed ICACC can reduce the data distortion rate effectively by selecting correct discrete points as well as adding the constraint of data inconsistency rate. By testing with the C4.5 algorithm, the proposed ICACC represents a nearly 10 % improvement in terms of the recognition rate and the calculation accuracy, compared with traditional algorithms."
8725665,Big Data Analysis Service Platform Building for Complex Product Manufacturing,"In order to deeply explore the hidden value of big data and promote the process improvement and decision-making level of complex product manufacturing enterprises, the construction of big data analysis service platform for complex product manufacturing was studied. On the basis of the requirement analyzing of complex products, we set up a service-oriented manufacturing big data access platform architecture, and introduced the key technologies of the platform, elaborated the platform function. The platform has implemented the big data access, pre-processing, storage and analysis, especially provided distributed computing engines, algorithmic artifacts, visual artifacts, and visual analysis tools in complex product manufacturing. It supports the rapid construction of complex product big data analysis applications in form of service assembly."
8942297,Towards a multi-agents model for errors detection and correction in big data flows,"The quality of data for decision-making will always be a major factor for companies that want to remain competitors. In addition, the era of Big Data has brought new challenges for the processing, management, storage of data and in particular the challenge represented by the veracity of these data which is one of the 5Vs that characterizes Big Data. This characteristic that defines the quality or reliability of the data and its sources must be verified in the future systems of each company. In this paper, we present an approach that helps to improve the quality of Big Data by the distributed execution of algorithms for detecting and correcting data errors. The idea is to have a multi-agents model for errors detection and correction in big data flow. This model linked to a repository specific to each company. This repository contains the most frequent errors, metadata, error types, error detection algorithms and error correction algorithms. Each agent of this model represents an algorithm and will be deployed in multiple instances when needed. The use of these agents will go through two steps. In the first step, the detection agents and error correction agents manage each flow entering the system in real time. In the second step, all the processed data flows in first step will be a dataset to which the error detection and correction agents are applied in batch in order to process other types of errors. Among architectures who allow this processing type, we have chosen Lambda architecture."
9407187,Research on Public Safety Management under the Application of Big Data and Internet of Things,"In the era of accelerating development of big data and the Internet of Things, the application of the Internet of Things and big data technology in the field of urban public safety management is becoming more and more common. This has had a positive impact on public safety management to a certain extent. However, there are some risks in its actual application. In order to improve the application level of big data and IoT technology, we need to research and analyze the public safety management system under big data and IoT applications, and discuss the risks and advantages brought by big data and IoT technology. At the same time, the author proposes effective countermeasures to try to solve the risks in the field of public safety management under the application of big data and the Internet of Things, which is conducive to improving the level of public safety management."
9671983,Coxswain: Guided Data Analytics,"Data science is driving the next economic revolution, though, it relies on efficient data exploration of data sources, is expensive, and is considered artisanal by data scientists and data analysts. This work introduces Coxswain, a novel data exploration assistant that guides the search of relevant models and provides valuable insights into the data. It mimics the steps of data scientists by selecting and analyzing exploration patterns used to suggest analytical steps in the form of scenarios. Coxswain then captures the customer decisions and adds this feedback for future suggestions. This paper concludes by presenting lessons learned when developing a proof of concept, and interactions with data practitioners."
8725694,A Study on E-commerce Recommender System Based on Big Data,"Recommender system algorithms are widely used in e-commerce to provide personalized and more accurate recommendations to online users and enhance the sales and user stickiness of e-commerce. This paper discusses several recommendation algorithms and the challenge of tradition recommender system in big data situation, and then proposes a framework of distributed and scalable recommender system based on Hadoop. The recommender system based on Hadoop, combining the advantage of computational ability and scalability of MapReduce and hybrid recommendation algorithms, brings a solution to information overload problem in big e-commerce."
9101284,Data Factory: An Efficient Data Analysis Solution in the Era of Big Data,"For each industry in the era of big data, a steady stream of data is generated continually. Due to the enormous information contained in big data, how to maximally extract the value from big data with lower cost to provide decision-making, guide production and resource allocation for the enterprises has attracted more and more attention of most enterprises. This paper proposes a data analysis solution in the era of big data-data factory, and implements a software system to build a data factory for an enterprise promptly and efficiently. By processing, analyzing and modeling the data in a workshop-based production mode similar to the traditional factories using raw materials, our data factory will acquire the analysis results and prediction models and then realize the clustering, classification, evaluation, and prediction data analysis. Moreover, the application of deploying data factory for an enterprise reveals that data factory is an efficient solution for big data analysis, and it improves the efficiency of enterprise data analysis."
8839836,Identity-Based Dynamic Data Auditing for Big Data Storage,"Identity-based remote data auditing schemes can verify data integrity and provide a simple identity authentication and management for multiple users. However, prior works on identity-based remote data auditing lack the support of dynamic operations. In these schemes, tag generation is linked to the index of data block, which is related to update operations such as modification, insertion and deletion. If users perform dynamic operations on a data block, the tags of all subsequent blocks need to be modified. It means that if users want to update data on a big data platform, they have to download the whole file, update the file and send the updated file to the big data platform. Such pattern will bring huge communication overhead. In this paper, we propose an identity-based dynamic data auditing scheme which supports dynamic data operations, including modification, insertion and deletion. As far as we know, there is still no other identity-based data auditing scheme that supports dynamic operations. In particular, to achieve efficient dynamic operations, we use the data structure of Merkle hash tree for block tag authentication, which helps update data with integrity assurance. Analyses of security and performance show that the proposed scheme is efficient and secure."
9355357,Hadoop-Based University Ideological and Political Big Data Platform Design and Behavior Pattern Mining,"The combination of higher education and big data technology is not only the focus of the application of big data technology, but also an emerging field of self-development in the field of higher education. This article is dedicated to building a big data processing platform through Hadoop big data storage architecture, Hive, flume data collection technology, and Sqoop data synchronization technology to achieve efficient processing of big data sets. The traditional data mining algorithm is implemented using Map Reduce programming, and the implementation of the data mining algorithm of the Hadoop platform is studied, mainly to analyze its execution efficiency and scalability. We select the data clustering task in data mining as a representative, and write its Map Reduce version to test and verify its effect on the Hadoop platform. Through comparative experiments of different cluster sizes and different data sizes, it is concluded that the use of Hadoop distributed systems for data mining tasks has a good acceleration ratio and efficiency, and the extended performance analysis of computing power also shows that it has great potential."
9196235,Research on Rural Development Innovation and Development Based on Big Data,"Big data provides brand-new means and tools for comprehensive rural revitalization. It is a powerful support for the comprehensive rural revitalization and an important way to achieve the integrated development of the digital economy and rural revitalization and improve the quality and level of rural revitalization. At present, some places in China have carried out fruitful practical explorations on the promotion of rural revitalization by big data, which has vigorously promoted rural revitalization in depth. However, in the course of practice, there are also imperfect supporting measures, weak infrastructure, lack of applied talents, and data information. There are outstanding problems, such as institutional obstacles, in sharing and integration, and further innovations are needed in platform construction, system improvement, and personnel training to fully play the role of big data in rural revitalization."
9434473,Impact of Business Environment on Industrial Structure Optimization and Upgrading in Liaoning Province through Big Data Analysis,"Based on the data of Liaoning province from 2008 to 2017, this paper studies the impact of business environment on the optimization and upgrading of industrial structure. Through empirical analysis, it is found that the business environment has a significant impact on the optimization and upgrading of industrial structure in a region. Meanwhile, through correlation analysis of big data, this paper finds that liaoning province has improved its environmental factors such as financing, competition fairness, government scale, patent protection, internal government supervision, people's sense of power, social credit and social security. However, local innovation environment, resource access, market intermediary, government intervention and degree of opening to the outside world and other environmental factors need to be further improved."
9196305,Discussion on the Transformation of Computer Remote Network Communication Technology in the Era of Big Data,"With the advent of the big data era, computer network communication technology has brought certain conveniences to the development of people and enterprises, and it has also broken through the traditional time and geographical limitations. However, under the influence of the big data era, China s computers There are still many problems in the development of long-distance network communication technology. The existence of these problems will not only affect the data transmission speed and quality, but also have a certain negative impact on people’s production and life. Therefore, in the context of the era of big data, relevant departments should revolutionize the network communication technology of the Computer College. This article describes the relative advantages and existing problems of computer remote network communication technology in the era of big data, and puts forward reasonable suggestions for computer network remote communication technology."
9109978,Research on Reconstruction of Emergency Decision-Making System Based on Big Data,"In order to realize the application of big data technology in emergency decision-making system reconstruction, a novel emergency decision-making system reconstruction method based on big data technology is proposed in this paper. This method is based on big data technology and can mine all kinds of data generated by the emergency decision-making system. The research results show that this method can fundamentally improve the emergency decision-making system and improve the efficiency of emergency decision-making in our country."
9006255,cPSITRES: A collaborative system for analysis of Big Data on sea ice,"Analysis of sea ice image rasters presents exciting challenges to the computer vision community, and results from such visual analysis can offer novel insights to domain experts studying sea ice. In recent years, there is a surge in the production of geospatial data sets on sea ice along with the methods for their analysis. As numerous providers independently provision geospatial data sets, they are found in varying formats. Also, there is often limited collaboration between the intra-domain and inter-domain experts analyzing these data sets. To tackle these aforementioned challenges, we have developed the cPSITRES system using open-source technologies and libraries to serve cruise-based high-resolution spatiotemporal Big Data on sea ice along with relevant unstructured public data. The system enables its users to perform complex analysis on the provided data sets and also serves as a collaborative platform for the rapid discovery of open-source methods analyzing sea ice. We also showcase a few exemplary traditional and state-of-the-art computer vision methods for the analysis of data provided by cPSITRES."
9407175,Research on the Innovation of China's Pension Insurance Transfer and Succession Model——Based on Big Data Technology,"In the process of rapid economic development, the state must ensure the rationality and scientific nature of the relevant guarantee system, so as to promote stable economic development. However, there are some problems in the current transfer and continuation model of China's pension insurance, which will affect the flow of labor to a certain extent. The transfer and continuation of pension insurance will cause migrant workers to give up corresponding insurance rights and affect the vigorous development of China's labor market. Therefore, we must study and analyze the transfer and continuation model of China's pension insurance. The application of big data technology has a certain significance in the innovation research work of pension insurance transfer and continuation model. Big data technology can not only provide comprehensive data information for the pension insurance transfer and continuation model, but also can effectively improve the pension insurance transfer and continuation model. This requires us to research and analyze the problems of pension insurance transfer and continuation models, and build a new intelligent pension insurance model based on big data. Only in this way can it be ensured that the pension insurance transfer and continuation model meets the mobility needs of the Chinese labor market and promotes the stable development of the Chinese economy."
8713232,Study on the Influence of Organizational Innovation on Organizational Performance under the Circumstances of Big Data : —Intermediary Role of Dynamic Capability,"From the perspective of dynamic capability, we study the mechanism of organizational innovation influence on organizational performance under the circumstances of big data. An intermediary model of the relationship between business practice innovation, workplace organization innovation, external relation innovation, dynamic capability and organizational performance was constructed. An empirical tests through questionnaire survey data of 214 companies affected by big data was conducted. The conclusions show that under the circumstances of big data, business practice innovation, workplace organization innovation and external relation has a positive effect on organizational performance respectively; dynamic capability has a positive effect on organizational performance; dynamic capability play a partial intermediary role in the relationship between business practice innovation and organizational performance, and a full intermediary role in the relationship between workplace organization innovation, external relation innovation and organizational performance."
9403070,Research and Analysis of Student Portrait Based on Campus Big Data,"With the rapid development of smart campuses, college business platforms have gradually accumulated a large amount of student behavior data. Facing the massive campus data, how to extract the hidden and valuable information from it has become an urgent problem for universities to solve. In this project, an user model with five dimensions is proposed, in which include students' basic information, learning ability, consumption level, daily habits and interest preferences. Based on the method of data collection, processing and mining, the students' feature attributes are extracted and student portraits are constructed. Finally, the experimental results show that the student portrait constructed can well describe the digital features of student users, and to a certain extent, provide data basis for decision- making support of teaching management department in universities."
9355375,Adaptive Data Acquisition Technology for Android System Based on Big Data Analysis,"The traditional transportation data had the disadvantage of low acquisition accuracy when performing adaptive acquisition. For this reason, the adaptive data acquisition technology analysis of android system based on big data analysis was proposed. The android system in big data analysis was introduced, the processing framework of the android system for transmitting data was built, and the effective collection of transportation data was achieved; Based on the algorithm of collecting transportation data, the collection of ordinary data, valuable data and invalid data was completed. The test data showed that the proposed adaptive data transmission technology of android system had an analysis accuracy of about 50%, which can effectively collect corresponding transportation data."
9457353,Research on Computer Data Encryption Technology under the Background of Big Data Era,"There are often hidden dangers of theft of information, tampering and destruction of data in life. In this case, data encryption technology as an effective means to effectively enhance the privacy of the network environment has shown its special importance. The article expounds the individual's understanding of data encryption technology and discusses the environment and prospects of data encryption technology in the information age."
9407177,Research on the Influence of Big Data to Audit,"The widespread application of Big data technology has brought a profound impact on the national economic and social operation, and it is gradually affecting the development direction of the audit industry. The application of big data technology has brought a certain influence on the scope of the audit, audit methods, and audit risks. This paper will put forward relevant suggestions and measures in response to a series of impacts brought by Big data to promote the better development of the audit industry."
9403761,Research on an Intelligent Optimization Algorithm for Combinatorial Optimization Problem Based on Big Data,"In this era of rapid development, the development of a multi-level capital market is an urgent social concern. In the new era, new requirements are put forward for the study of portfolio optimization model in China. Under the background of big data era, if we want to further reduce and disperse the risk of financial investment market and increase the universality of portfolio investment optimization field in China, we must correctly deal with the impact and challenge brought by the era, combine with the new requirements of the new era, carry out reform and innovation on portfolio optimization, so as to promote its development. In order to better analyze the development progress of portfolio optimization problem; this paper puts forward a research method of intelligent optimization algorithm which applies big data technology to portfolio optimization problem, so as to put forward a set of new scheme of portfolio optimization problem which fully meets the development requirements of the new era. Through long-term research and analysis, it is found that the research scheme proposed in this paper successfully provides a new idea for the research method of intelligent optimization algorithm based on big data for combinatorial optimization problems."
9101271,Research on the Value of Smarter Education in the Era of Big Data,"With the rapid development of science and technology, the change of “Internet +”, cloud computing, cloud storage and other new generation of information technology makes the information highly circulating, travel and daily life are very convenient, and Big data is the product of the current era. Education as a continuation of thousands of years of behavior, how to comply with the times? How to exploit the intrinsic value of big data? There is also a broader space for thinking and development. The essence of intelligent education lies in the analysis of the current mainstream education model, the combination of specific education behaviors, the analysis of the mutual integration of big data and education, the promotion of the integration and development of education of big data."
9479508,The Copyright Protection and Fair Use of Commercial Data Collections Based on Big Data,"Big data is defined as “data collection” with four “V” - “Volume, Variety, Velocity, Veracity” characteristics. Based on big data, whether the commercial data collection protection under Chinese Copyright Law appropriate and whether the rights of “fair use” under Chinese Copyright Law sufficient to promote the data flow and data sharing, is arguable. Therefore, this article aims to clarify the current disputes about commercial data collections as copyright subject matter and discusses the protection provided to commercial data collections under the framework of Chinese Copyright Law on one hand. And on the other hand, this article aims to explore the improvement of the rights of “fair use” of commercial data collections under the framework of Chinese Copyright Law from perspective of big data sharing and big data flow."
9196238,Data Mining of Popular Science Books Based on Web Crawler,"Big data, artificial intelligence, mobile internet and other information technologies has provided increasingly rich technical means for science popularization, improved the information source of science popularization statistical data, and provided better data support for the research work in the field of science popularization. Using web crawler to grab the data of Taobao, using excel and spss to clean, summarize and structure the data, such as the distribution of sales, the relationship between price and sales, the relationship between price ranking and sales, the relationship between price and comment number, etc., and then carry out data visualization processing and relevant analysis to summarize the public's consumption interest and attention of popular science books."
9523948,AIS Big Data Framework for Maritime Safety Supervision,"Under the pattern of rapid shipping industry development, the extensive application of the AIS data in maritime safety supervision has created gradually increased space-time data of ship. However, although the shipping industry has a massive amount of data, there are obvious shortcomings in data storage and data mining, which make it difficult to effectively use data to guide maritime safety supervision. In view of this, we build an innovation ‘CIPSODAR’ framework, which covers AIS big data technical stack system on Hadoop cluster, including AIS big data processing, AIS big data storage and query, as well as AIS big data mining. Particularly, in the data mining phase, the OD segmentation algorithm, which enables to dispose the typical ship track problems of maritime safety supervision is proposed and realized. Thus, this research result shows that AIS big data is valuable in terms of maritime safety supervision, after systematically combing AIS big data via ‘CIPSODAR’ framework and using OD segmentation algorithm to deal with AIS big data ship track problems."
9526151,Innovation System of University Ideological and Political Education Mode Based on Big Data Technology,"In order to overcome the challenges faced by the ideological and political education mode in colleges and universities in the era of big data, this paper proposes a new innovation system of Ideological and political education mode in colleges and universities based on big data technology. This innovation system is different from other innovation modes of ideological and political education, which gives full play to the characteristics of big data technology and combines ideological and political education with big data. The results show that the innovation system can not only promote the application and development of big data technology in the education industry, but also realize the further development of Ideological and political education mode."
9403834,Network security Mode analysis based on big data environment,"In recent years, driven by the trend of big data and cloud computing, various complex security issues in the traditional security mode have gradually emerged. On the one hand, new, persistent, and advanced attack threats emerge in an endless stream. The use of ransomware, Oday vulnerabilities and even more threatening APT attacks cannot be detected and prevented by traditional security protection equipment. On the other hand, with the explosive growth of Internet traffic, the number of deployed security devices has gradually increased and the network environment has become increasingly complex, resulting in massive amounts of data that cannot be effectively analyzed and utilized. Therefore, how to effectively analyze the network security mode in the big data environment has become an important link facing the current network security problems."
9404710,Hadoop based EMH framework: A Big Data approach,"The terms like Gigabyte and megabyte have become old and outdated now because with the improvement in the field of storage technology, the storage abilities have increased and cost of storage of data has also been reduced. In present times terms like petabyte, terabyte, etc are in vogue as the e-storage capacity has increased worldwide. But at the same time, with improvement in the storage technology, the world now has ever increasing volume of data, so the need for storage is on the rise.Nowadays, huge amount of data is being generated and updated within a short span of time. Therefore, to take care of its storage, access and further advancement, analysis is required. But since the vast amount of data is getting generated in short span of time so the analysis of data as well as management of data has become a tedious, hectic and a challenging job for the data centers and managers.Various issues and challenges are there while tackling data-related issues. For example, the data is available in different types such as structured, unstructured, semi-structured, heterogeneous, or homogeneous, which makes there sorting and storage difficult. Sometimes, the older tools are not sufficient to handle all these or a combination of one or more types in real-time, or in distributed systems such as cloud systems.The creation of data and the aggregation of data is approximately in zettabytes per year. Such, volume of data is not only the problem for data management, but also affects the attributes like variety, velocity, value, and complexity. Then, there are also some technical issues as well related to the data transportation and storage.Thus, we need to think about the issues of storage and management of ever-increasing e-data and develop the novel perspective and innovative ways to address these issues.In this paper, we have analyzed these issues and challenges by studying different methodologies for big data analysis and design for Sensing and omitting medical data, e-Health...
(Show More)"
9539459,Research on Multi-source Data Fusion and Mining Based on Big Data,"To solve the problem of massive multi-source data under the background of multi-sensor big data, a data fusion method which is easy to realize is used to fuse and mine the massive big data, and the difference between the fusion data and the real data is used as the stability judgment method. Compared with the measurement errors of single sensor and average estimation, it is proved that the heterogeneous sensor using weighted least square data fusion has higher measurement accuracy. The numerical examples are consistent with the theoretical derivation, which further verifies the effectiveness of the proposed method and improves the accuracy and mining effect of big data fusion."
9378397,Big Data Architectures for Vehicle Data Analysis,"In this paper, we consider Big Data applications for connected vehicles, where vehicle data is sent several times per second, permitting fine-grained and near real-time analysis of vehicle status and operating behavior. We focus on typical streaming applications and present implementations in Apache Spark and Apache Flink in different architectures and analyze several aspects of Big Data architectures for connected vehicles. First, we aim to show the potential of fine-grained analysis in terms of time resolution and level of detail for vehicular services. For instance, we show how to compute energy efficiency, comparing used energy vs needed energy, on the level of seconds. Secondly, we compare the architecture challenges in vehicular systems, including in-vehicle processing as well as cloud and edge processing. For these, we compare different approaches and architecture solutions. Third, we show that the performance and scalability of our different Big Data processing options differ significantly different for our use case."
9516475,Research on Student Financial Assistance System based on Data Mining and Analysis,"Student funding is of great significance. However, there still exist many imperfections in the process of identification of poor students. The application of big data technology in student funding will provide new support for student funding. First of all, this paper analyzed the functions of all kinds of data systems related to student data information in Colleges and universities. And then, it designed the overall technical scheme of data mining and analysis for Poverty Stricken students. Based on Hadoop data processing platform, a data mining scheme was designed. The application of big data technology to student financial assistance is a feasible way by the above methods."
9110097,Research on the Supervision Method of Big Data Technology in the Systemic Risk of Internet Finance in China,"In order to standardize the supervision process of systemic risk of Internet finance in China, this paper puts forward a novel supervision method of systemic risk of Internet finance in China based on big data technology. This method is based on big data technology, combines computer technology and Internet of things technology, can real-time monitor the systematic data of China's Internet finance, and quickly feedback the information to the relevant staff. The results show that this method can effectively improve the standardization of China's Internet financial systemic risk supervision and reduce the harm caused by China's Internet financial systemic risk."
9407143,Consumption Behavior of Popular Science Books Based on Big Data,"Internet big data provides increasingly rich technical means for science popularization, which has brought about a great change in the consumption mode of popular science books. The consumption scene, payment mode, factors affecting the selection, consumption time period, emotional characteristics of public popular science books have changed greatly. This paper uses big data to get the consumption data of popular science books on e-commerce websites. Based on a comprehensive analysis of each dimension of public popular science books in various dimensions, this paper summarizes the changes of the public's consumption of popular science books, and puts forward research programs in the field of popular science book consumption, as well as related safety issues."
8669577,Customer Classification of Discrete Data Concerning Customer Assets Based on Data Mining,"selecting useful information under the background of big data can help enterprises to classify customers more accurately. Outlier data includes important customer information. In order to study customer classification problem based on customer asset outlier data, a customer classification model based on outlier data analysis concerning customer asset is constructed successfully. The model is based on Variables in 4 dimensions including transaction frequency, types of products or services traded, transaction amount and client age. And using clustering before classification to divide twenty-five types of outlier customer data into four categories and corresponding marketing strategies also are put forward according to different classification of outlier customer data of a company."
9150302,Research on Higher Education Human Resource Department’s Knowledge Management of Teachers in the Era of Big Data,"As human society is entering the era of big data, as the original material of the “data-information-knowledge-wisdom” flow chain, changes in data characteristics affect various processes of knowledge, and they also play a large role Knowledge is the process of knowledge management related to the research object. Based on the connotation of teacher knowledge management, this paper analyzes the problems existing in the current teacher knowledge management model, and proposes corresponding management guarantee measures in the aspects of resources, data, platforms, management systems, and teacher personal development. Knowledge management provides new ideas."
9006196,Industrial track: Architecting railway KPIs data processing with Big Data technologies,"In our conducted research we have built the data processing pipeline for storing railway KPIs data based on Big Data open-source technologies - Apache Hadoop, Kafka, Kafka HDFS Connector, Spark, Airflow and PostgreSQL. Created methodology for data load testing allowed to iteratively perform data load tests with increased data size and evaluate needed cluster software and hardware resources and, finally, detected bottlenecks of solution. As a result of the research we proposed architecture for data processing and storage, gave recommendations on data pipeline optimization. In addition, we calculated approximate cluster machines sizing for current dataset volume for data processing and storage services."
9196362,Big Data Encryption Technology Based on ASCII And Application On Credit Supervision,"Big Data Platform provides business units with data platforms, data products and data services by integrating all data to fully analyze and exploit the intrinsic value of data. Data accessed by big data platforms may include many users' privacy and sensitive information, such as the user's hotel stay history, user payment information, etc., which is at risk of leakage. This paper first analyzes the risks of data leakage, then introduces in detail the theoretical basis and common methods of data desensitization technology, and finally puts forward a set of effective market subject credit supervision application based on asccii, which is committed to solving the problems of insufficient breadth and depth of data utilization for enterprises involved, the problems of lagging regulatory laws and standards, the problems of separating credit construction and market supervision business, and the credit constraints of data governance."
9006149,Autonomic Workload Change Classification and Prediction for Big Data Workloads,"The big data software stack based on Apache Spark and Hadoop has become mission critical in many enterprises. Performance of Spark and Hadoop jobs depends on a large number of configuration settings. The manual tuning procedure is expensive and brittle. There have been efforts to develop online and off-line automatic tuning approaches to make the big data stack more autonomic, but many researchers noted that it is important to tune only when truly necessary because many parameter searches can reduce rather than enhance performance. Autonomic systems need to be able to accurately detect important changes in workload characteristics, predict future workload characteristics, and use this information to pro-actively optimise resource allocation and frequency of parameter searches. This paper presents the first study focusing on workload change detection, change classification and workload forecasting in big data workloads. We demonstrate 99% accuracy for workload change detection, 90% accuracy for workload and workload transition classification, and up to 96% accuracy for future workload type prediction on Spark and Hadoop job flows simulated using popular big data benchmarks. Our method does not rely on past workload history for workload type prediction."
9325674,Big Data Storage using Model Driven Engineering: From Big Data Meta-model to Cloudera PSM meta-model,"The storage and retrieval of large volumes of information, as well as the search for intelligence within a mass of data, is at the heart of the concept of Big Data, and this is why this technology is so important for the IT community and society as a whole. It allows companies to gain valuable insight into their markets and customers so they can offer better-suited products or services. Thus, Big Data Storage plays a key role in decision making. After defining a generic meta-model in previous work for the Storage layer. This paper presents a shift from the generic Big Data Storage layer meta-model (PIM) to a Cloudera Distribution Storage layer meta-model (PSM) using the ATL transformation language. The result of the ATL transformation represents the PSM (Platform-Specific Models) according to the architecture of the MDA."
9377907,Raptor Zonal Statistics: Fully Distributed Zonal Statistics of Big Raster + Vector Data,"Recent advancements in remote sensing technology have resulted in petabytes of data in raster format. This data is often processed in combination with high resolution vector data that represents, for example, city boundaries. One of the common operations that combine big raster and vector data is the zonal statistics which computes some statistics for each polygon in the vector dataset. This paper proposes a novel distributed system to solve the zonal statistics problem which can scale to petabytes of raster and vector data. The proposed method does not require any preprocessing or indexing which makes it perfect for ad-hoc queries that scientists usually want to run. We devise a theoretical cost model that proves the efficiency of our algorithm over the baseline method. Furthermore, we run an extensive experimental evaluation on large scale satellite data with up-to a trillion pixels, and big vector data with up-to hundreds of millions of edges, and we show that our method can perfectly scale to big data with up-to two orders of magnitude performance gain over Rasdaman and Google Earth Engine."
9110032,Research on the Management Mode of Graduate Students in Colleges and Universities Based on Big Data,"In order to improve the efficiency of postgraduate management and realize the modernization and intellectualization of postgraduate management mode, this paper puts forward a postgraduate management mode based on big data. This method is based on big data technology, collects students' personal learning situation, students' personal family situation, students' interests and hobbies, and realizes the optimization of management mode. The research results show that the management model has higher management efficiency, can realize the intellectualization of the management of postgraduates in colleges and universities, and improve the scientificalness and timeliness of the management of postgraduates in colleges and universities."
9407223,Research on the Development of Retail E-commerce in China from the Perspective of Big Data,"After more than 20 years of development, China's retail e-commerce industry shows an explosive growth trend. At the present stage, the over-speed growth of the retail e-commerce industry has gradually leveled off, with many platforms showing a trend of giant standing. The rapid rise of emerging technologies such as big data, artificial intelligence and cloud computing has brought new opportunities and challenges to the development of retail e-commerce, and further exposed the problems of retail e-commerce. In order to satisfy consumers' high-quality and high-demand experience in the future, this paper puts forward countermeasures to improve the development of retail e-commerce in China based on the analysis of big data."
9457320,The British Media’s Opinion on China during COVID-19 Pandemic from the Perspective of Big Data : A Corpus-Based Study on British newspaper the Sun,"Big data offers a new perspective to study international relations. As an analysis method based on big data, a corpus-based study can help analyze international politics. The COVID-19 pandemic causes a tremendous challenge to the international public opinion environment and national image of China, in which the news media played a crucial role. This study selected the British mainstream media-the Sun and outlined China's national image in the UK in the era of the pandemic by collecting the China-related reports during the COVID-19. The paper used corpus as an instrument to study this question. It is clear that the news reported by British media on the topic of China's anti-pandemic action is patently biased with ideological prejudice. The conclusion of this study would be useful in helping China to repair, rebuild and reconstruct the national imagine and be beneficial to the Sino-UK relationship in the post-pandemic era."
8862445,"Cloud, Big Data & IoT: Risk Management","The heart of research pumps for analyzing risks in today's competitive business environment where big, massive computations are performed on interconnected devices pervasively. Advanced computing environments i.e. Cloud, big data and Internet of things are taken under consideration for finding and analyzing business risks developed from evolutionary, interoperable and digital devices communications with massive volume of data generated. Various risks in advanced computational environment have been identified in this research and are provided with risks mitigation strategies. We have also focused on how risk management affects these environments and how that effect can be mitigated for software and business quality improvement."
9361025,The Application of Big Data Analytics in Online Foreign Language Learning among College Students : Empirical Research on Monitoring the Learning Outcomes and Predicting Final Grades,"This paper conducts empirical research on the application of big data to online learning of foreign language with Zhuhai College of Jilin University as the subject. The software EVIEWS is utilized to analyze essential factors affecting online learning process and help learners predict final grades, which affords the benefits of learning supervision and feedback as well as a higher learning efficiency. Recommendations are also provided pertaining to current difficulties in combining big data and online learning."
8669651,Big Data Analysis of E-Commerce Based on the Internet of Things,"In the era of big data, while providing massive information, it also challenges the development of related activities in the overall environment. In the context of the rapid development of e-commerce, the opportunities of the development of the Internet of things technology are analyzed from the aspects of logistics distribution, quality control and facilities promotion. Electronic commerce is a new form of trade under the development of modern information technology, while cloud computing and the Internet of Things provide related services. Under the exertion of their related functions, the revolutionary improvement of e-commerce mode has been realized, and to a certain extent, it has promoted the development and operation of modern market economy. This article analyzes the development strategy of e-commerce based on Internet of things and cloud computing under the overall environment of big data era."
9403770,Research of the Impact of Big Data on Enterprise Import and Export Based on Economic Globalization,"At present, the integration of information technology is an inevitable trend under the background of economic globalization. Big data has a great impact on the import and export of enterprises. The impact on the import and export of enterprises is not only the support of information, but also the support of technology. The article will effectively combine the economic globalization and big data to conduct in-depth research and analysis [1]"
8713243,Analysis on the Development Path of Smart City in the Era of Big Data,"Big data is the key support of smart city. At present, the application of big data technology is more and more mature, which provides a new way for the development of smart city. In this underground, the development of smart city is imminent. Singapore ranks among the best in the world in terms of smart city, and its experience is worth learning. This article makes a theoretical analysis of the construction of smart cities and introduces the development of smart cities in China. Then it analyses the case of Singapore's smart national planning, summarizes Singapore's experience, and finally puts forward some inspiration for the development of China's smart city."
9402956,High Dimensional Complexity of Dynamical System in the Big Data,"Big data technologies are playing an important role in various fields such as biology, finance, economics and engineering. However, the complexity of big data has not been fully understood, especially for the dynamical system in high dimensional space. Here we present a theorem about existence of three-dimensional chaotic behavior for a dynamical system which is widely used in engineering and business. We also give the chaotic behavior at different velocities under initial and fixed values. Simulation results show that our approach can uncover the rich dynamical behaviors of the high dimensional system, e.g. the relationship between the initial value and the chaotic behavior in three- and two-dimensional space."
9516541,Construction of Computer Network Security Defense System Based On Big Data,"The development and popularization of big data technology bring more convenience to users, it also bring a series of computer network security problems. Therefore, this paper will briefly analyze the network security threats faced by users under the background of big data, and then combine the application function of computer network security defense system based on big data to propose an architecture design of computer network security defense system based on big data."
9434504,Genetic Basis of Alzheimer’s Disease and Its Possible Treatments Based on Big Data,"This article is about the genetic basis which causes Alzheimer's disease, and big data which is related to Alzheimer's disease, focusing on which gene and how it can cause Alzheimer's disease and the ways to use big data to try to figure out the treatments for Alzheimer's disease. In addition, the article adopts the general idea about how to use big data to help researchers figure out a better way about the treatment for Alzheimer's disease. The present study shows that the more APOE ε4 exists, the more possibility of getting Alzheimer's disease. The main contribution of the paper is focusing on the genetic basis of Alzheimer's disease as well as giving a general idea of how to use big data to help find the treatment for Alzheimer's disease."
9361012,Influence of Big Data on Modern Risk-oriented Audit and Countermeasures,"The level of economic development determines the actual state of social development. With the advent of the era of fragmentation, science and technology are constantly evolving. Big data and multiple linkage technologies are newly presented in response to the trend of the new era. At the same time, big data can be widely used in various fields. It can also play an effective role in risk-oriented audit. Therefore, this article starts from reality, fully explores the problems of big data in modern risk-oriented audit, and then proposes corresponding solutions."
8713202,Process and Application of Data Mining in the University Library,"In view of characteristics of users' data in the university library and based on big data technology, in this paper we propose a data mining process and discuss some applications of data mining in the university library. Besides, we inveterate the problems in the application of big data mining in the university library and provide some suggestions to solve these problems."
9476385,Big Data Monetization: Platforms and Business Models,"The main goal of our PhD project is to propose a methodology that can be widely applied to determine the monetary value of a Datum in a Big Data environment. In order to define our problem, we started by investigating how monetization in those environments have been suggested in academic literature. By observing the results, it was possible to conclude that little attention has been given to the dimension Value in academic studies related to Big Data when compared to researches directed to the other three classical dimensions (Volume, Velocity and Variety). More specifically, in terms of economic value, studies are even scarcer, and the existing ones do not share a common view on how to measure this value. Bearing that in mind, we have drawn our hypothesis that it would be possible to develop a data-driven methodology (quantitative methods based on artificial intelligence) that could highlight the monetary value of a data asset (value dimension) taking into account the different applications, contexts and scenarios related to those data. We applied a formal process of systematic literature review based on the methodology suggested by Kitchenham to find out what methods have been applied to determine the relevance and value of data in these environments and if these methods are based, in any way, on information theory. The results showed that, in spite of the progress made on the topics of Big Data and the application of analytical methodologies over the last decades, there is no method based on data that is widely used to determine the value of a datum in a Big Data environment. If, on the one hand, monetization in Big Data environments is still a field that needs to be better explored in academic literature, on the other hand, these intangible assets, i.e., data, grow exponentially and are more and more present in the corporate world. It highlights the opportunity to develop studies in search of standards that can be widely accepted and used to this end. We have no...
(Show More)"
9196274,Research on the Current Development of Legacy Media’s WeChat Subscription Accounts in the Big Data Era,"In the era of big data, rapid development of data driven journalism has forced traditional news outlets exploring different way of fast transition. WeChat subscription accounts became a powerful tool to solve their problem. However, inherent problems and limitations have hindered the development of legacy media's WeChat subscription accounts. This paper conducted a thorough analysis on the WeChat subscription account of People's Daily, using it as an example, discussed the current status of legacy media's WeChat subscription accounts and proposed several suggestions for traditional news outlets to develop their WeChat subscription accounts in the future."
9523950,Data Visualization System Based on Big Data Analysis,"In order to improve the user experience in the process of analyzing data information, and improve the intuitiveness of data information, this paper proposes a construction strategy of data visualization system based on big data analysis technology. The construction strategy combines big data analysis technology, relying on the Internet platform, to show the dynamic of data in a variety of ways, providing convenience for users to analyze and study the information behind the data. The results show that the construction strategy can improve the user experience, enhance the intuitiveness of data information, and improve the efficiency of data analysis."
9626217,Study on Design and Application of Device for Secondary Intelligent Ticket Checking of Railway under the Wave of Big Data,"In the course of ""passenger transport histology"", the passenger transport process and ticketing equipment are analyzed in detail, and it is found that the AFC system of the railway can not effectively monitor passenger ticket purchase, the existence of short-distance passengers to buy tickets for long-distance vehicles, ticket evasion, ticket chaos and other phenomena. Through innovative guidance to students, teachers and students jointly designed a second ticket checking device on the train, and successfully applied for a patent for a utility model. The device forms an interactive monitoring system with the station ticket system, interactive fusion of large data of passenger flow in railway station. Through the introduction of the structure and principle of the intelligent secondary ticket checking device, this paper makes use of various identification technologies to carry out secondary ticket checking for passengers, By identifying the passenger information, verifying the identity of the passenger, replacing or otherwise dealing with the passenger who does not get on the train correctly, the accuracy of the passenger ""person-ticket-card"" can be guaranteed, the manpower for checking tickets can be saved, and the quality of checking tickets can be improved, improve the technical level of ticketing system and passenger satisfaction."
8836977,Nautilus: A Precision-Guided Open Data Architecture for Big Omics Data Analysis,To make valuable omics data useful is becoming more urgent in medical research. The need to provide information on what and how data can be useful for a particular research question has presented significant challenges in big data management and analysis. This paper describes a new open data architecture and its architectural components. It also introduces the Nautilus platform following the architecture design. We evaluate the performance of data management with the Nautilus platform and demonstrate that applying smart technologies improves the performance to cost tradeoff achieved in an experimental environment.
9457385,Knowledge Mapping Analysis to Research of Symbiosis Based on Big Data Method,"The research of ""symbiosis"" has made a lot of important achievements in recent years. On the basis of combing and defining the concept of symbiosis, this paper analyzes the knowledge mapping for the text research of symbiosis as a whole with the help of big data method, such as bibliometric analysis by Vosviewer software. The paper holds that the so-called symbiosis mainly refers to the mutual relationship between all things in the world, including the biological reciprocal relationship in nature and the communication relationship in human society. Through collection, cleaning, processing and visualization of the data, the paper believes that the current research of symbiosis has increasingly shown a multi-dimensional, multi-field and multilevel spatial distribution in the discipline field and a more indepth, specific and focused dynamic development trend in the research content."
9675990,Towards various applications of Big Data and related issues and challenges,"A new trend in feature abstraction is Big Data Analysis combined with computational techniques. This includes gathering knowledge from reputable data sources, analyzing information quickly, and forecasting the future. Big data entails vast amounts of data that are challenging to analyze using typical database and software approaches. When using big data applications, a technological hurdle arises when transporting data across several locations, which is quite expensive and necessitates a huge primary memory for storing data for processing. Big data refers to the transaction and interaction of datasets whose size and complexity transcend the usual technical capabilities of acquiring, organizing, and processing data in a cloud environment. This article provides an in depth study of various applications of big data. It also provides a detailed view on various problems and challenges in Big Data."
9516567,Big Data Technology and Prison Management Analysis,"This article analyzes the necessity of big data technology in prison management. The author studied the specific application of big data technology in the prison management system development module, visit registration module, prisoner location query module, book function module, appointment access module, and prison culture module. The author studied how to deepen the integration of big data, how to strengthen the construction of management systems, how to improve data sharing, how to increase capital investment, how to build a smart office system, how to build a talent team, and how to establish optimization measures for a normalized training mechanism. The purpose of this article is to optimize the prison management system and improve the orderliness of supervision and management activities."
9582677,A Visual Data Science Solution for Visualization and Visual Analytics of Big Sequential Data,"In the current era of big data, huge volumes of valuable data have been generated and collected at a rapid velocity from a wide variety of rich data sources. In recent years, the initiates of open data also led to the willingness of many government, researchers, and organizations to share their data and make them publicly accessible. An example of open big data is healthcare, disease and epidemiological data such as privacy-preserving statistics on patients who suffered from epidemic diseases like the coronavirus disease 2019 (COVID-19). Analyzing these open big data can be for social good. For instance, analyzing and mining the disease statistics helps people to get a better understanding of the disease, which may inspire them to take part in preventing, detecting, controlling and combating the disease. As “a picture is worth a thousand words”, having the pictorial representation further enhances people’s understanding of the data and the corresponding results for the analysis and mining. Hence, in this paper, we present a visual data science solution for the visualization and visual analytics of big sequential data. We illustrate the ideas through the visualization and visual analytics of sequences of real-life COVID-19 epidemiological data. Our solution enables people to visualize COVID-19 epidemiological data and their temporal trends. It also allows people to visually analyze the data and discover relationships among popular features associated with the COVID-19 cases. Evaluation of these real-life sequential COVID-19 epidemiological data demonstrates the effectiveness of our visual data science solution in enhancing user experience in the visualization and visual analytics of big sequential data."
9407044,Analysis of Factors Affecting the Sales of Popular Science Books Based on Big Data,"The consumption data of popular science books on Taobao is obtained by using the technology of web crawler, and an empirical study is carried out on the indexes that affect the sales. Through the research, it is found that the sales rank of search engines, the price, the quantity and quality and content of online reviews have a significant impact on the sales of popular science books. Although the basic variable is an important reference index for consumers to make decisions, it has no significant impact on sales. As an important manifestation of the value of popular science books, price has a positive impact on sales, but buyers are usually willing to pay a certain premium for high-quality products. Sales rank is an important function of major e-commerce websites, which has a strong correlation and boosting effect with sales. Different variables have different effects on the sales of popular science books."
9245612,Cluster Validity Index for Big Data Based on Density Discriminant Analysis,"The important factor for clustering unsupervised data is the Cluster Validity Index indicating appropriate number of clusters. The paper proposes the application of the unsupervised density discriminant analysis algorithm for cluster validation in the context of Big Data. In particular, the experiment was conducted to perform clustering tasks on big dataset by using centroid based clustering algorithm and apply unsupervised density discriminant analysis algorithm to find the most appropriate number of clusters. The performance evaluation was performed by means of processing time. The result shows that the time used to perform the clustering task depends on number of features and clusters."
9525854,Big Data Analysis and Optimization Strategy of Tourism Participation Behavior in Ethnic Communities,"To accurately evaluate the current situation of ethnic community tourism participation in China, this paper analyzes the reasons for the low-level operation of ethnic community tourism participation system based on the advanced experience of big data embedded in tourism public service supply. We use system dynamics as a theoretical tool to summarize the influencing factors and main indicators of community tourism decision-making behavior. Combining with the information entropy model and AHP model, this paper finds out the important factors that cause the dilemma of ethnic community tourism participation through quantitative form. Finally, the paper analyzes the potential of ethnic community tourism participation through a specific case, and proves the effectiveness of the model through the experimental results, and puts forward the system optimization strategy from the perspective of new institutional economics, so as to provide a scientific path for the optimization of tourism participation behavior."
8885114,Secure Pattern-Based Data Sensitivity Framework for Big Data in Healthcare,"With the exponential growth in the usage of electronic medical records (EMR), the amount of data generated by the healthcare industry has too increased exponentially. These large amounts of data, known as “Big Data” is mostly unstructured. Special big data analytics methods are required to process the information and retrieve information which is meaningful. As patient information in hospitals and other healthcare facilities become increasingly electronic, Big Data technologies are needed now more than ever to manage and understand this data. In addition, this information tends to be quite sensitive and needs a highly secure environment. However, current security algorithms are hard to be implemented because it would take a huge amount of time and resources. Security protocols in Big data are also not adequate in protecting sensitive information in the healthcare. As a result, the healthcare data is both heterogeneous and insecure. As a solution we propose the Secure Pattern-Based Data Sensitivity Framework (PBDSF), that uses machine learning mechanisms to identify the common set of attributes of patient data, data frequency, various patterns of codes used to identify specific conditions to secure sensitive information. The framework uses Hadoop and is built on Hadoop Distributed File System (HDFS) as a basis for our clusters of machines to process Big Data, and perform tasks such as identifying sensitive information in a huge amount of data and encrypting data that are identified to be sensitive."
9434447,Research on the Development Trend of Aquaculture Based on Big Data Analysis,"Aquaculture economy plays an important role in guaranteeing the food supply and quality protein output of our residents. By cleaning, aggregating and analyzing the big data of China, Japan and the United States from 2010 to 2017, published by the fisheries and aquaculture department of FAO, we study the development trend of aquaculture production and value in the three countries and make a prediction in 5 years by linear regression fitting. Finally, suggestions were put forward for the aquaculture development. This paper found that China's aquaculture production and value have been developing steadily, and would continue to stay progression in five years, but the growth rate would decline. The variety of aquaculture species is diversified, the production and value of aquaculture farming species are relatively balanced. China should strengthen aquaculture resources and environmental conservation and vigorously develop high technology in aquaculture. As for Japan, development prospects are not bright in the near future. Due to the combined effects of tsunami and aging fishery communities, the aquaculture is generally showing a declining trend. Japan should take measures to restore and strengthen fishery resources and revitalize fishing communities. In the United States, aquaculture production declined gradually after 2004 due mainly to the shrinking scale of channel catfish farming. Since then, it has remained quite stable. Besides, the aquaculture species are relatively poor, the production and value of the farming species are extremely uneven. At present, the United States should expand aquaculture species, substantially increase aquaculture production and maintain a growing trend."
9150269,Research on Library Knowledge Service Innovation in Big Data Environment,"With the development of information technology, digital technology and the advent of the era of big data, the research of library knowledge services is gradually deepening. Through the research and analysis of existing knowledge service models and existing problems, the innovative development of library knowledge service models is proposed direction."
9457362,Research on the Competence Literacy Model Construction of National Scholarship Winners in the Context of Big Data,"The Internet can break through the limitations of time and space, and provide more possibilities for education in the context of the world's popular situation. In this article, the author uses big data to analyze the national scholarship evaluation criteria and the experience of ESE scholarship winners in recent years, combined with the core development literacy of Chinese students proposed in 2014, the author build on the basis of independent development and social participation Get up, take independent study, participate in management, practice, and undertake the four major achievements as the framework to realize the establishment of the theoretical model of the ability and literacy of the national scholarship recipients of the ""double first-class"" university. Through the construction of the model, it can provide corresponding practical ways for the cultivation of university talents."
9103893,Research on Data Center Operation and Maintenance Management Based on Big Data,"In the era of big data, data has become a new factor of production. During the operation and maintenance of the data center, rich operation data have been accumulated. How to effectively manage, analyze and mine the massive data accumulated in the operation and maintenance process, solve the problems that cannot be solved by automatic operation and maintenance, improve the fine management level of data center, and enable data center to better provide services for oilfield enterprises and users will become the challenge faced by oilfield data center in the era of big data. Taking “design and implementation of operation and maintenance log analysis system” as an example, this paper introduces the use of big data technology for further analysis and mining of operation and maintenance data, which is helpful to discover new value points, improve operation and maintenance initiative, and provide reference for fine operation and maintenance management of data center."
9434497,Research on Multidimensional Teaching Mode of College English Based on Data Mining,"The rapid development of computer technology and Internet technology has promoted the development of the era of big data. The acquisition and application of data information is an important foundation for improving the level of data application in the era of big data. In the current college English teaching process, the multi-dimensional English teaching model based on data mining has a positive effect on improving college English teaching efficiency and ensuring teaching quality. In the context of big data, teachers not only need to understand the problems in college English teaching, but also teachers must analyze the way of multi-dimensional college English teaching mode based on data mining, so as to effectively improve the quality of English teaching."
9390675,The Optimization of Privacy Data Management Model In Big Data Era,"The management of privacy data in big data era involves data collecting, data storage and data use. Current privacy data management studies focus on concrete techniques and seldom investigate various processes and subjects of privacy data management. In this paper, the basic structure and analytic models of privacy data management is analyzed based on the realization of big data analysis, and problems of imperfect management mechanism, increasing information disclosure risk and deficiencies of current models are analyzed. Based on the problems of privacy data management, the optimized schemes are proposed from perspectives of perfecing privacy data management mechanism, building secure data platform and optimizing data use structure."
9390029,Digital Communication of Chinese Classical Literature in the Era of Big Data,"Chinese classical literature is an important part of Chinese culture, and its inheritance and development is an important content of contemporary. With the development of science and technology, the era of big data has come. In the era of big data, the transmission mode of Chinese classical literature has changed. The wide application of digital communication provides a new way for the dissemination of Chinese classical literature. On this basis, this paper studies the digital communication of Chinese classical literature in the era of big data. This paper establishes the theoretical basis for this study by collecting relevant information, and makes a comparative analysis of the traditional and digital transmission modes of Chinese classical literature. In addition, this paper combines the tag propagation algorithm and scores the traditional and digital communication methods of Chinese classical literature from three aspects of communication efficiency, speed and scope. The results show that, in the digital communication mode of Chinese classical literature, the communication efficiency score is 86 points, the transmission speed score is 92 points, and the dissemination range is 91 points. It can be seen that the digital communication of Chinese classical literature is not only highly efficient and fast, but also has a wide range of dissemination."
9403757,Evaluation of Livable and Resilient Urban Design based on big data,"In the background of the information age, modern information technology is constantly updated and improved, especially the rapid development of mobile information technology, which provides great convenience for the use of big data. In the context of big data, the livability of cities has attracted more and more attention. The construction of livable city is not only the best interpretation of the construction of resource-saving and environment-friendly social policies, but also the most urgent desire of urban residents for high-level economic development and high-quality living environment. This paper analyzes the ideas and methods of urban planning evaluation under the background of big data, which can further strengthen the function of urban space urban planning and promote the construction and development of urban modernization."
9360993,Probe into the Subject Service Innovation of University Library under the Background of Big Data,"In the era of big data, the construction and development of university libraries also need to keep pace with the times. University library managers need to change the traditional service methods, give full play to the role of big data technology, and strengthen the construction and development of library disciplinary services with service objects as the main body. This can provide targeted and specialized subject information services for all levels of school personnel to meet the needs of different users, thereby effectively promoting the sustainable development of university libraries and university education. Based on this, this article will analyze the status quo of academic libraries' subject services in the big data environment and the problems encountered in innovative practical work on the basis of an overview of related concepts. The author proposes corresponding improvement and optimization measures, hoping to provide a reference for the innovation and development of discipline services in university libraries."
9150161,Research on the Construction and Innovation of Lifelong Education System Under the Background of Big Data,"The development of information technology provides technical support for the construction of lifelong education think tanks. It is an urgent need for lifelong education development to create a new type of life think tanks in combination with regional development. The advent of the era of big data has profoundly changed the social structure, social relations, social production and lifestyle, and people's way of thinking. The entire education ecosystem has been reshaped, information and knowledge are constantly changing, and continuous learning has become the basic needs of society members. In addition, China is in a period of social transformation, the quality of the population needs to be improved, the issue of equity in education needs to be solved, and the vitality of social innovation needs to be activated. The unique advantages of big data will help solve the above problems. Therefore, building a learning society for the whole people, lifelong and comprehensive learning is not only an effective way to promote China's sustainable development, but also an inevitable choice in the era of big data."
9360986,Thinking of Equipment Support Capacity Building based on Big Data,"The Big Data is the most popular concept in the field of science and technology after cloud computing. The whole world has entered the era of Big Data, as well as the military field. Based on the analysis of the characteristics of equipment support dada and the requirements of equipment support capacity building under the background of Big Data, this paper proposes the ways of equipment support capacity building, providing references for the construction of our army's equipment support capacity in the new era."
9148364,Analysis on the Strategies of Cultivating Students' Pronunciation and Intonation Awareness in English Teaching in Higher Vocational Colleges in the Era of Big Data,"With the continuous development of modern information technology, the world has entered the era of Internet + big data. Big data is profoundly changing people's thinking, production and lifestyle. English teaching in vocational colleges has also been affected by big data and changed. Especially in today's growing international exchanges, college students' English listening and speaking skills must keep pace with the times. Improving the pronunciation and intonation awareness of college students is an effective way to solve this problem. The typical problems of college students in pronunciation and intonation are poor pronunciation, incorrect intonation, and insufficient pronunciation and intonation. The formation of these problems is multifaceted, including the lack of students' awareness of pronunciation and intonation, and the lack of awareness of teachers' pronunciation and intonation. Teachers can adopt the following methods to improve students' pronunciation and intonation awareness: First, train a group of teachers with pronunciation and intonation awareness. Secondly, teachers must infiltrate the training of pronunciation and intonation in classroom teaching. Thirdly, teachers should combine pronunciation and intonation teaching with traditional English teaching methods. The author believes that by implementing these strategies, students can quickly improve their understanding of English pronunciation and intonation, and then help them master English faster and better."
9601711,Big Data Sampling Algorithm Based on Peak Detection,"Domestic mass data processing system in aerospace field uses big data simple sampling algorithm for data specification in the data preprocessing stage. This paper analyzes the data curve distortion caused by this algorithm, and proposes an optimization method for that. Finally, a big data sampling algorithm based on peak detection is adopted to achieve the purpose of quickly viewing the fidelity and complete picture of massive historical data, while ensuring the correctness of the data interpretation after data preprocessing at the same time. Through the using of real test data for verification, in the data preprocessing stage of the domestic mass data processing system, the large data sampling algorithm based on peak detection is adopted to achieve the high fidelity of the data curve after sampling."
9430223,In Big Data Era: Analysis of Hadoop Cluster Performance,"In recent decades, the dependence on digital tools to assist our daily lives has been growing in almost all sectors and fields. A huge amount of data has been generated and as a result, a new era has emerged: the era of big data. To benefit from this data, several big data analysis tools have emerged, Hadoop being one of them. In this paper, we analyzed Hadoop cluster performance and investigated the effect of the cluster and dataset sizes on its performance. Furthermore, the MapReduce model was used to study and justify its benefits in the big data analysis field. The results showed that the Hadoop cluster and the MapReduce model are powerful in processing and analyzing big data. More benefits can be achieved from the analyzing time perspective when larger data sizes are used. Interestingly, we found that increasing the cluster size beyond a certain point resulted in communication issues, thereby yielding an increase in the CPU time."
9587665,Early Childhood Education Based on Big Data,"The progress of science and technology and the development of the Internet make preschool education constantly reform and advance. In particular, the development of big data has brought new opportunities to preschool education. The thinking of big data will change the whole model of preschool education. This paper mainly studies the early childhood education based on big data. In this paper, 24 science education activities in 2 kindergartens in the city were selected as the research samples with the CLASS classroom evaluation and scoring system as the research tool. Data processing is carried out through data mining algorithm, and the interaction behavior of teachers and children in current kindergarten education activities is analyzed. Big data technology has just entered a beginning stage. As the technology continues to mature, it will bring tremendous changes to preschool education that we cannot imagine at present. This paper has certain reference value for the use, influence and development direction of big data in preschool education."
9533081,"Analysis of monitoring data of Higher Vocational Students' physical health data based on ""big data"" technology","""big data"" technology, as a proper term of the Internet industry, has played a huge role in making the right choice in the development of things, and it is also one of the indispensable technical means in the process of people seeking sustainable, good and rapid development. Based on this, the effective use of ""big data"" should also be regarded as the top priority for the effective development of Higher Vocational Students' physical health data monitoring, and the students' physical health monitoring data should be analyzed objectively and accurately. Based on the analysis of the establishment of the monitoring data analysis system of Higher Vocational Students' physical health data and the building of the monitoring data analysis module of Higher Vocational Students' physical health data, this paper focuses on the application of user login and authority control module, the effective operation of monitoring data management module and the use of monitoring data analysis module, so as to provide a practical reference for the development of Higher Vocational Students' physical health data According to the monitoring data analysis system application path to make a clear discussion."
8787394,Semantic Data Integration Techniques for Transforming Big Biomedical Data into Actionable Knowledge,"FAIR principles and the Open Data initiatives have motivated the publication of large volumes of data. Specifically, in the biomedical domain, the size of the data has increased exponentially in the last decade, and with the advances in the technologies to collect and generate data, a faster growth rate is expected for the next years. The available collections of data are characterized by the dominant dimensions of big data, i.e., they are not only large in volume, but they can be also heterogeneous and present quality issues. These data complexity problems impact on the typical tasks of data management, and particularly, in the task of integrating big biomedical data sources. We tackle the problem of big data integration and present a knowledge-driven framework able to extract and integrate data collected from structured and unstructured data sources. The proposed framework resorts to Natural Language Processing techniques to extract knowledge from unstructured data and short text. Furthermore, ontologies and controlled vocabularies, e.g., UMLS, are utilized to annotate the extracted entities and relations with terms from the ontology or controlled vocabulary. The annotated data is integrated into a knowledge graph. A unified schema is used to describe the meaning of the integrated data as well as the main properties and relations. As proof of concept, we show the results of applying the proposed framework to integrate clinical records from lung cancer patients with data extracted from open data sources like Drugbank and PubMed. The created knowledge graph enables the discovery of interactions between drugs in the treatments prescribed to lung cancer patients."
9582913,BIG DATA SERVICE CAPABILITY OF ENTERPRISE SCALE DATA MIDDLE PLATFORM,"With the rapid development of technologies such as big data, cloud computing, Internet of things and artificial intelligence, electric power enterprises are faced with the strategic deployment of digital transformation. By upgrading IT architecture, power grid companies build the data middle platform, and separate the data operation and product technology from its front platform. Through service reusing and data sharing, the business capability can be shared, which providing technical support for power enterprises to serve a variety of complex business scenarios. This paper focuses on the architecture design of data middle platform in power grid companies, and analyzes its service capability. In addition, this paper sorts out the capability output framework of big data middle platform, and analyzes the data service requirements and application modellings for data middle platform in different business scenarios."
9150243,Research on equipment maintenance Information Management based on big data,"In the process of equipment maintenance, a large amount of maintenance information will be produced. Big data technology will be used to manage, analyze and mine the collected massive equipment maintenance information data, explore the relationship and law between equipment maintenance information, scientifically analyze the equipment use status, predict and guide the equipment maintenance problems, and improve the equipment maintenance efficiency."
9060133,Telecom Big Data Based Precise User Classification Scheme,"With the development of information technology, we are living in a society of data explosion. In precise marketing field, how to classify the population and identify the target users has attracted much concern. Based on telecom big data, this paper has proposed a precise user classification scheme using decision tree. According to the classification result, potential users can be identified and focused on, which can dramatically improve the marketing efficiency and effectiveness with limited marketing expense."
9389984,Big Data Knowledge Map Based on Entity Recognition,"In order to directly and succinctly reflect the composition, dosage, processing and other information between traditional Chinese medicine, as well as the common relationship between traditional Chinese medicine and traditional Chinese medicine, this project collected and processed a large number of traditional Chinese medicine data, through the construction of knowledge map of traditional Chinese medicine, Chinese medicine workers intuitively display the composition of traditional Chinese medicine information, Chinese medicine between direct or indirect related information, so as to facilitate a deep understanding of the hidden knowledge of traditional Chinese medicine information; The project takes the prescription in the information of traditional Chinese medicine as the main research body, studies the composition of the prescription of traditional Chinese medicine and other relevant information, and shows the correlation between the prescription itself, the composition of traditional Chinese medicine, the prescription and the prescription, the prescription and the medicine in this intuitive and concise way, so that more people can understand the prescription and understand the traditional Chinese medicine. The public can easily obtain relevant knowledge of traditional Chinese medicine according to their own situation. The above two aspects have played an important role in human health and promoted the inheritance and promotion of traditional Chinese medicine."
9526156,Intelligent Evaluation of College Students’ Ideological and Political Education Effect Based on Big Data Technology,"In the current ideological and political teaching evaluation, due to many comprehensive evaluation standards, complex process, resource consumption and other reasons, the evaluation is insufficient or mere formality. Thus, this paper proposes a classroom evaluation assistant strategy based on big data technology. The scheme mainly uses a new multi class classification algorithm which takes the similarity direction between classes as the IBTSVM generation algorithm, reads the data from the web system, and trains it by SVM train. Through the method of cross validation, the parameter setting of SVM is obtained. Finally, the algorithm is applied to the evaluation of teachers’ teaching quality, and the samples are trained and verified by case analysis, which proves that the application of intelligent teaching evaluation method based on big data in teaching evaluation classification is feasible and effective."
9434475,Spatial Research on Cultural and Creative Industrial Parks in Jilin Province based on Big Data Technology,"This paper mainly expounds on social science enabled by big data technology to handle the crisis of industrial parks in Jilin Province. To deal with the sustainable renewal of creative industrial park and park space problem under the context of social organization competition in Jilin Province, after analyzing and comparing the data, as well as utilizing the fragmented space in the industrial park, we examined the parking space in three dimensions: urban, social, and physical based on big data technology, and put forward with permeable, community reengineering. We propose a new way of thinking to solve the survival crisis of creative enterprises in the backward region with typical characteristics of Jilin Province."
9006460,An “On The Fly” Framework for Efficiently Generating Synthetic Big Data Sets,"Collecting, analyzing and gaining insight from large volumes of data is now the norm in an ever increasing number of industries. Data analytics techniques, such as machine learning, are powerful tools used to analyze these large volumes of data. Synthetic data sets are routinely relied upon to train and develop such data analytics methods for several reasons: to generate larger data sets than are available, to generate diverse data sets, to preserve anonymity in data sets with sensitive information, etc. Processing, transmitting and storing data is a key issue faced when handling large data sets. This paper presents an “On the fly” framework for generating big synthetic data sets, suitable for these data analytics methods, that is both computationally efficient and applicable to a diverse set of problems. An example application of the proposed framework is presented along with a mathematical analysis of its computational efficiency, demonstrating its effectiveness. Empirical results indicate that the proposed data generation framework provides a reduction in computational time of ≈ 33% when compared to the alternative approach of generating the data set in full."
8444740,A Study on Big Knowledge and Its Engineering Issues,"After entering the big data era, a new term of `big knowledge' has been coined to deal with challenges in mining a mass of knowledge from big data. While researchers used to explore the basic characteristics of big data, we have not seen any studies on the general and essential properties of big knowledge. To fill this gap, this paper studies the concepts of big knowledge, big-knowledge system, and big-knowledge engineering. Ten massiveness characteristics for big knowledge and big-knowledge systems, including massive concepts, connectedness, clean data resources, cases, confidence, capabilities, cumulativeness, concerns, consistency, and completeness, are defined and explored. Based on these characteristics, a comprehensive investigation is conducted on some large-scale knowledge engineering projects, including the Fifth Comprehensive Traffic Survey in Shanghai, the China's Xia-Shang-Zhou Chronology Project, the Troy and Trojan War Project, and the International Human Genome Project, as well as the online free encyclopedia Wikipedia. We also investigate the recent research efforts on knowledge graphs, where they are analyzed to determine which ones can be considered as big knowledge and big-knowledge systems. Further, a definition of big-knowledge engineering and its life cycle paradigm is presented. All of these projects are accordingly checked to determine whether they belong to big-knowledge engineering projects. Finally, the perspectives of big knowledge research are discussed."
9196257,Identification of the Residential Areas for Urban Renewal Based on Big Data : Take Guangzhou as an example,"Urban renewal is an important direction for urban development in China. Affected by urban diseases and lack of land resources, megacities urgently need to carry out urban renewal. The residential areas in Guangzhou also face problems such as low efficiency, poor quality, and insufficient vitality. This paper uses big data to identify the urban residential areas that is in urgent need of transformation and provides a reference for the planning and decision-making of Guangzhou urban renewal."
8923233,Checking the Plausibility of Nutrient Data in Food Datasets Using KNIME and Big Data,"As there is no standardized food database with all products available in Europe, many developers of health apps fall back on databases of communities whose quality is often insufficient. In health apps, the quality of the data sets is critical, as poor quality lowers the user's confidence. This paper examines the plausibility of nutrient data from such data sources using similarity analysis, decision support methods and Big Data technology. During a special developed process, the plausibility of the data is to be increased. Finally, the methods used will be evaluated on the basis of test data."
9005493,Achieving Agile Big Data Science: The Evolution of a Team’s Agile Process Methodology,"While there has been a rapid increase in the use of data science and the related field of big data, there has been minimal discussion on how teams using these techniques should best plan, coordinate and communicate their activities. To help address this gap, this paper reports on a mixed method qualitative study exploring how a big data science team within a Fortune 500 organization used two different agile process methodologies. The study helps clarify the concept of agility within a big data science project, as well as the key process challenges teams encounter when executing a big data science project. Specifically, three key issues were identified: (a) the challenge in task duration estimation, (b) how to account for team members that might be pulled onto other tasks for short bursts and (c) coordination challenges across the different groups within the big data science team. Our findings help explain how different process methodologies might mitigate or exacerbate these challenges and supports previous research showing that big data science teams would benefit from an increased focus on their process methodology and that adopting an Agile Kanban methodology, which focuses on minimizing work-in-progress, could prove beneficial for many big data science teams."
9360940,College English Teaching Reform Driven by Big Data,"At present, the level of China's economic development is constantly improving, and the demand for foreign languages in the process of social development is also increasing. Modern foreign language teaching is developing oriented to be ecological and personalized. In the new era, social development has an increasing demand for excellent English talents. Therefore, when carrying out English education, we need to use effective strategies to promote the reform of college English teaching. This requires us to research and analyze the current problems in college English education in China, and to understand the new characteristics of college English teaching and learning in the context of Big Data and the new challenges we face. At the same time, this article also discusses the reform and practical strategies of college English teaching mode under the influence of big data. Only in this way can the innovation and development of college English talent-training programs be improved and the English proficiency of Chinese college students be improved."
9407158,Exploration of the Digital Transformation of Traditional Enterprise Financial Management under the Background of Big Data,"This article mainly briefly describes some related concepts of the digital transformation of financial management of traditional enterprises under the background of big data. The author analyzes some opportunities and challenges that companies need to face in the process of digital transformation. Moreover, the author also discusses and explains how companies can transform and upgrade, hoping to effectively help companies realize the importance of completing financial digital transformation in the era of big data. Enterprises should actively change their internal financial management methods and gradually improve their own capabilities and competitiveness in the market."
9407151,Research on Fresh Agricultural Product Inventory Management under Big Data,"Based on the analysis of the characteristics of fresh agricultural products, the functions of inventory control and the components of the model, according to the characteristics of the deterioration and demand of fresh agricultural products, this article uses an improved method of economic ordering and batching, focusing on time affecting demand and Deterioration rate, price affects demand, customer waiting time affects the shortage and part of the lagging supply rate and other factors, focusing on the fresh agricultural product inventory control model. At the same time, a fresh agricultural product inventory management system based on a big data platform is constructed, and a strategy for constructing an e-commerce platform for fresh agricultural products based on big data under the Internet environment is proposed."
9213765,Big Data Analytics: Challenges and Opportunities,"Information and Communication Technology (ICT) has revolutionized the society. Unlike in the past, private sector, government agencies, and Non-Governmental Organizations (NGOs) rely on ICT to perform nearly all activities. Decision-making process is one area that has become dependent on ICT, thanks to the concept of big data. Today, the entities rely on ICT to collect a large volume, variety, and velocity of data. Despite the significant contributions of big data, its usage has been crippled mainly because of the problems encountered during the analytics process. This paper studied the challenges that hinder effective analytics of the big data. It used the systematic review to collect and analyze secondary data. The research established that big data analytics has not been perfectly done because of the problem of lack of enough skilled experts, technological drawbacks, and the legal and ethical constraints."
9525921,Visualization Digital System of Digital Museum Based on Big Data Technology,"In order to overcome the difficulties faced by traditional museums in the era of big data, this paper proposes a novel visualization digital system of digital museum based on big data technology. The system fully combines the advantages of big data technology, according to the characteristics of Museum big data to the museum data perception, collection, processing, analysis and storage process. Based on this, the system also makes full use of advanced visualization technology, and can present the processing results and analysis results of Museum big data to users in various forms. The results show that the system can accelerate the transformation and upgrading of traditional museums, and improve the economic and social benefits of museums."
7974765,A New Methodology for Storing Consistent Fuzzy Geospatial Data in Big Data Environment,"In this era of big data, as relational databases are inefficient, NoSQL databases are a workable solution for data storage. In this context, one of the key issues is the veracity and therefore the data quality. Indeed, as with classic data, geospatial big data are generally fuzzy even though they are stored as crisp data (perfect data). Hence, if data are geospatial and fuzzy, additional complexities appear because of the complex syntax and semantic features of such data. The NoSQL databases do not offer strict data consistency. Therefore, new challenges are needed to be overcome to develop efficient methods that simultaneously ensure the performance and the consistency in storing fuzzy geospatial big data. This paper presents a new methodology that tackles the storage issues and validates the fuzzy spatial entities' consistency in a document-based NoSQL system. Consequently, first, to better express the structure of fuzzy geospatial data in such a system, we present a logical model called Fuzzy GeoJSON schema. Second, for consistent storage, we implement a schema-driven pipeline based on the Fuzzy GeoJSON schema and semantic constraints."
9150230,Research on University New Media Student Management Innovation Based on Big Data Environment,"Under the new media environment, the information communication presents the characteristics of timeliness, convenience and interactivity, which changes the working environment of university student management. The new media communication mode represented by big digital technology improves the immediacy and interactivity of university student management. The management of college students under new media not only urges teachers to make changes in knowledge education, but also makes education and daily management follow the pace of The Times. Through the new media platform, colleges and universities can establish more efficient, open and smooth channels for information dissemination of colleges and universities, and do a good job in guiding college students' public opinions."
9068154,A Proposed Framework for Improving Analysis of Big Unstructured Data in Social Media,"With the rapid development of Big Data and the necessity for analyzing their huge volumes, the issue of Unstructured Data analysis in social media was appeared. The Data analysis process is very important in all fields as to make decisions at the right time and over certain facts. The usage of social media has become the latest trend in today's world in which users send, read posts known as `message' and communicate with various groups. Users are sharing their regular life, posting their views on everything like products and locations. This data is extremely unstructured, making it hard to analyze. Machine learning technology offers important data preparation techniques for processing large-scale data to extract knowledge, e.g., classifying data. Extract useful information from social media data is essential to success in the big data age. Therefore, fresh strategies are needed for handling huge quantities of unstructured data and finding the hidden information in these data and achieving better data analysis outcomes, In this paper, the proposed framework recommends the construction of a machine-learning model capable of analyzing unstructured text data with highly accuracy compared to other machine learning algorithms."
9006268,Virtual Big Data for GAN Based Data Augmentation,"Researchers deal with the class imbalanced problem in many real-world applications and GAN based data augmentation is considered as an efficient approach to address this problem. GANs need a huge training data to generate efficient augmented data. However, the required sufficient training data is not available in many research areas. In this paper, we introduce a new concept called virtual big data to address this problem. We prove that, virtual big data can provide the GANs sufficient training data to generate efficient augmented data with less mode collapse and vanishing generator gradients problems. We show that, the curse of dimensionality which is considered as a negative factor in machine learning can play a positive role to solve vanishing generator gradients via making discriminator less perfect. First, we transform the training data from n dimensional space into m dimensional space where, m = c * n and c is concatenation factor. To do so, c different training instances are selected and concatenated to each other to form a c * n dimensional instance. Increasing the dimension of training data from n to c * n is key to increase the number of training instances from N to C(N, c). Transformed training data are called virtual big data since they differ original training instances in terms of size and dimension. Our experiments show that, V-GAN, a GAN trained by virtual big data can outperform standard GANs when it comes to deal with extremely scarce training data. Furthermore, V-GAN can outperform traditional oversampling techniques in terms of precision, F1 score and Area Under Curve (AUC) score."
9006572,Fast Computation of Persistent Homology with Data Reduction and Data Partitioning,"Persistent homology is a method of data analysis that is based in the mathematical field of topology. Unfortunately, the run-time and memory complexities associated with computing persistent homology inhibit general use for the analysis of big data. For example, the best tools currently available to compute persistent homology can process only a few thousand data points in ℝ 3 . Several studies have proposed using sampling or data reduction methods to attack this limit. While these approaches enable the computation of persistent homology on much larger data sets, the methods are approximate. Furthermore, while they largely preserve the results of large topological features, they generally miss reporting information about the small topological features that are present in the data set. While this abstraction is useful in many cases, there are data analysis needs where the smaller features are also significant (e.g., brain artery analysis). This paper explores a combination of data reduction and data partitioning to compute persistent homology on big data that enables the identification of both large and small topological features from the input data set. To reduce the approximation errors that typically accompany data reduction for persistent homology, the described method also includes a mechanism of “upscaling” the data circumscribing the large topological features that are computed from the sampled data. The designed experimental method provides significant results for improving the scale at which persistent homology can be performed."
8817160,Towards Specification of a Software Architecture for Cross-Sectoral Big Data Applications,"The proliferation of Big Data applications puts pressure on improving and optimizing the handling of diverse datasets across different domains. Among several challenges, major difficulties arise in data-sensitive domains like banking, telecommunications, etc., where strict regulations make very difficult to upload and experiment with real data on external cloud resources. In addition, most Big Data research and development efforts aim to address the needs of IT experts, while Big Data analytics tools remain unavailable to non-expert users to a large extent. In this paper, we report on the work-in-progress carried out in the context of the H2020 project I-BiDaaS (Industrial-Driven Big Data as a Self-service Solution) which aims to address the above challenges. The project will design and develop a novel architecture stack that can be easily configured and adjusted to address cross-sectoral needs, helping to resolve data privacy barriers in sensitive domains, and at the same time being usable by non-experts. This paper discusses and motivates the need for Big Data as a self-service, reviews the relevant literature, and identifies gaps with respect to the challenges described above. We then present the I-BiDaaS paradigm for Big Data as a self-service, position it in the context of existing references, and report on initial work towards the conceptual specification of the I-BiDaaS software architecture."
9516495,Big Data Nearest Neighbor Similar Data Retrieval Algorithm based on Improved Random Forest,"In the process of big data nearest neighbor similar data retrieval, affected by the way of data feature extraction, the retrieval accuracy is low. Therefore, this paper proposes the design of big data nearest neighbor similar data retrieval algorithm based on improved random forest. Through the improvement of random forest model and the construction of random decision tree, the characteristics of current nearest neighbor big data are clarified. Based on the improved random forest, the hash code is generated. Finally, combined with the Hamming distance calculation method, the nearest neighbor similar data retrieval of big data is realized. The experimental results show that: in the multi label environment, the retrieval accuracy is improved by 9% and 10%. In the single label environment, the similar data retrieval accuracy of the algorithm is improved by 12% and 28% respectively."
9457333,Intervention Mechanism of Internet addiction among College Students based on big data,"With the rapid development of Internet, the Internet addiction among college students is getting increasingly prominent and has become a significant problem for today's college education work. In this paper, several effective modes of intervention for Internet addiction among college students, from the aspects of society, school and family, are discussed on the basis of big data. The data comes from the massive investigation took among the students in University of Electronic Science and Technology of China(UESTC). By combing the questionnaire survey with case interview, the main factors affecting Internet addiction can be judged based on the Chi-Square test."
9101310,"The Online Attention of Class 5A Scenic Spots in Jiangsu Province, China: A Big Data Analysis of Based on Baidu Index","The online attention is a direct representation of the demand and behavior habits of tourist on the Internet. The daily Baidu Index during a certain period of time with the names of scenic spots as search keywords can indicate the distribution characteristics of the online attention of these scenic spots. The online attention of class 5Ascenic spots in Jiangsu Province shows a precursor effect (having a peak before the holiday starts) during Public Holidays, including the May Day holiday(3days usually beginning from 1st May). While it has a peak during the first three days of National Day holiday(one week usually from 1st to 7th Oct.), consistent with the actual tourist flow. During the whole year, the online attention shows obvious seasonality with 3 peak times."
9378124,"A Fast, Scalable, Universal Approach For Distributed Data Aggregations","In the current era of Big Data, data engineering has transformed into an essential field of study across many branches of science. Advancements in Artificial Intelligence (AI) have broadened the scope of data engineering and opened up new applications in both enterprise and research communities. Aggregations (also termed reduce in functional programming) are an integral functionality in these applications. They are traditionally aimed at generating meaningful information on large data-sets, and today, they are being used for engineering more effective features for complex AI models. Aggregations are usually carried out on top of data abstractions such as tables/ arrays and are combined with other operations such as grouping of values. There are frameworks that excel in the said domains individually. But, we believe that there is an essential requirement for a data analytics tool that can universally integrate with existing frameworks, and thereby increase the productivity and efficiency of the entire data analytics pipeline. Cylon endeavors to fulfill this void. In this paper, we present Cylon's fast and scalable aggregation operations implemented on top of a distributed in-memory table structure that universally integrates with existing frameworks."
9552096,IoT Data Acquisition Node For Deep Learning Time Series Prediction,"With the rapid development of Artificial Intelligence (AI) technology, its applications in the big data analytics and practices have become more and more extensive. Time series prediction based on deep learning, such as LSTM, GRU, and BiLSTM, is an important direction for future big data analytics and practices. In order to obtain the data needed for deep learning time series prediction more accurately and efficiently, Internet of Thing (IoT) technology is needed. In this paper, we propose a flexible, reliable and low-cost IoT data acquisition node. The node can collect the data required for deep learning time series data prediction efficiently for long time. The test results show that the node can effectively meet the design requirements and has the promise to provide a corresponding reference for future related designs."
9201894,Exploration on the construction of big data basic course for non computer major,"Big data courses are widely offered in Colleges and universities at home and abroad, but most of the courses are set up for computer majors or students with computer and mathematics related background. The course content mainly focuses on data analysis algorithm itself or big data infrastructure architecture, and is not suitable for teaching non-computer major students. This paper aims to build a big data basic course for non computer majors from the front technology, analysis process, application scenarios and other aspects of the real world big data, aiming at cultivating students' data thinking and correctly judging big data technology to solve problems in the face of real cases."
9377918,Edge Computing with Big Data Cloud Architecture: A Case Study in Smart Building,"The growth of buildings embedded with technologies that can monitor the internal building environment with respect to energy consumption such as heating, ventilation, air conditioning, wind, motion as well occupancy have an immense potential. From energy management, occupancy administration, security maintenance as well as improving the health and quality of life for humans in indoor or outdoor spaces. These potentials can be realized by a clear understanding of the interplay between vast environmental conditions, humans and their health as well as the many smart products they interact with in their lives. This is a complex process that requires thorough testing and evaluation within smart buildings simulation environments where multiple buildings data can be generated and then effectively analyzed. This can be facilitated by a robust data management process that utilizes big data computing technologies to harness large volumes, variety and velocity of data that can be captured within smart buildings while maintain the security and privacy of data sources.In this paper we describe a smart building architecture that has been designed and developed for management of data from a smart building. In particular the architecture enables acquisition, processing and distribution of simulated environmental building data to multiple consumers and workflows for further processing and analysis locally and in a high performance cloud computing platform. The research premise is that such an architecture enables effective management of multiple data sources within climatic based simulated testing in smart buildings to further research."
8725674,Duplication Detection in News Articles Based on Big Data,"Electronic media has been developing rapidly nowadays, resulting in a large number of news articles produced online, and thus duplication detection is needed. Besides, articles duplication is directly related to articles plagiarism. Existing studies on news articles duplication detection mainly focus on newspaper articles, and we further explore the duplication detection in news articles from the newest online We Media data. In this paper, we propose a tool, NDFinder, using fingerprinting technique with hash index to detect articles duplication. To validate our proposed approach, we crawled a total number of 33,244 news articles data for detection. The results show that our tool accurately detects 2,150 duplicate articles, and the overall precision reaches 97%. Moreover, we apply our approach to detect plagiarism articles based on our duplication results, and we successfully identify 64 pairs of plagiarism articles in our collected data. We further conduct an empirical study and summarize 8 most commonly used plagiarism patterns in plagiarism articles."
9526143,Fragmented Learning Mode for College Students in Big Data Environment,"Nowadays, information technology has greatly changed the way people learn. Fragmented learning, as an informal way of learning, has become an important approach to learn new technologies and knowledge. By analyzing the connotation, characteristics, advantages and disadvantages of fragmented learning, this paper proposes a fragmented learning solution for college students in a data environment, which can recommend personalized learning plans for students and also provide decision making for teachers by collecting and analyzing student’s learning data. In this thesis, a mobile application is developed to collect learner-related data, such as time, location, content, and frequency, etc. What’s more, this proposed method is expected to play an important role in guiding the construction of a lifelong learning society."
9150202,China’s Tourism Industrial Upgrading and Transformation Strategies and Countermeasures in the Background of Big Data,"A relatively systematic analysis on development status of China's tourism industry in the era of big data was carried out based on analytic hierarchy process (AHP) with considerations to the structural characteristics of the industry. Moreover, some upgrading and transformation strategies were proposed for China's tourism industry based on analysis results."
9403816,A Research on the Improvement of the College English Classroom Study in the Context of New Media and Big Data,"As a basic subject, college English is of great significance to the all-around development of college students. But traditionally, there exist certain problems, such as undiversified teaching methods, boredom in classroom teaching, lack of learning interests and ineffective classroom learning among students, facing college English teaching. With the develop of science and technology, the technology of new media has become an important part of people's life and work. In the age of new media and big data, the new media technology with its openness, diversity, plurality, and interactivity, can be combined with and facilitate classroom teaching. Such a combination not only provides abundance of learning materials, but also promotes students' learning interest as well as motivation. What's more, it could stimulate students' full development. Under this background, this paper will probe into the college English teaching status quo and the existing problems first, and then give advices regarding the improvement of students' classroom learning efficiency and quality by utilizing the new media technology."
9137473,Forecast of Wartime Clothing Support Demand Based on Big Data,"Based on the in-depth analysis of the current situation of wartime clothing support, this paper puts forward the research of wartime clothing support prediction based on big data. The main purpose is to realize the real-time perception of wartime clothing support needs, visual control of resources, timely and correct determination, and accurate distribution orientation."
9434470,Research on development of a “VR + elderly care” system based on big data,"The aging population in China is revealing the problems of the traditional elderly care system, including demand-supply imbalance, excessive burden of elderly care, and an immature elderly-care system. In this context, artificial intelligence (AI) finds its way into the elderly care industry, ushering a new era of elderly care, building a technical foundation for an AI-based smart elderly care mode that will combine emerging technologies including Internet, big data and virtual reality (VR). However, AI-based smart elderly care is still in the exploration stage. This study intends to use emerging technologies including VR to make up the defects of traditional elderly care systems, alleviate the burden of elderly care, and boost the development of a home-bound smart elderly care mode that is intelligent and economy-efficient."
9526104,A Method For Comprehensive Ability Assessment of Smart City Construction From The Perspective of Big Data,"In order to overcome the problems of incomprehensive and objective evaluation of the comprehensive ability of smart city construction under the background of big data, a method of coupling coordination degree model of the comprehensive ability of smart city construction based on entropy method and coupling coordination theory was proposed. This method constructs the coupling coordination degree model of the comprehensive ability of smart city construction from three aspects of smart government, smart transportation and smart education and nine indicators. The results show that this method can effectively evaluate the comprehensive ability of smart city construction, and the results are more comprehensive and objective. The maximum coupling degree is 1."
9403805,Application research of Sports Place System based on big data classification technology,"With the rapid development of China's economic construction and the promotion of advocating comprehensive fitness, sports venues and supporting facilities will be built in succession, the construction of high-level sports venues is imperative. At present, intelligent construction has begun to take shape, and the construction of intelligent system has entered the implementation stage. Under such social conditions, the intelligent system construction of sports venues has also entered a new stage. Based on big data classification technology, sports venues are developing towards system integration and comprehensive management. This paper introduces the definition of sports venues of intelligent system, development present situation, the system characteristics and system composition, introduced the intelligent system design process of the sports venues, sports venues are summarized based on the practice of intelligent system of the problems in such aspects as planning, design, find out the solution, summarizes the relevant experience. It is hoped that it can play a certain reference and guiding role in the construction of intelligent system of sports venues in the future and provide reference for the government to formulate norms and standards."
9516581,Design of Social Media User Satisfaction Evaluation System from the Perspective of Big Data Services,"In the era of big data, an important way for country to develop digital economy and improve information management capabilities is to develop service-oriented social media. Based on this background, this article studies the significant impact of service methods, information content, problem-solving quality, and infrastructure facilities of new social media platform on the social media services maturity and user satisfaction. According to the functional characteristics of the social media platform, the user satisfaction evaluation model of social media is constructed."
9150207,Aesthetic Trend of Folk Vocal Music Under the Influence of Big Data Thinking,"Chinese folk vocal music is a fruit of the long history and established culture of China. It is a mixture of diverse Chinese cultural elements, reflecting the Chinese history and cultural heritages. There are many key time nodes in China's history, which have had tremendous impact on development of folk vocal music. In the history of folk vocal music, vocal musicians like Song Zuying, with their beautiful voices and singing expertise, promoted the maturity of folk vocal music. Among the conflicts between Chinese and western culture, western elements were introduced into Chinese folk vocal music. To address the obstacles in development, this study analyzes the Chinese folk vocal music from the angle of big data to explore its development trend."
8725804,"A Framework for Automatic Collection and Updating of ""Honor & Black"" List Based on Big Data","In this paper, we present a framework for automatic collection and update of ""Honor & Black"" list. Based on natural language processing, crawler and big data technology, we firstly collect the ""Honor & Black"" list drawn up by the member units of the joint inter-ministerial conference on the construction of social credit system in China or the competent authorities of other industries. Then we build the ""Honor & Black"" list database, and automatically update the ""Honor & Black"" list database according to the laws and regulations of joint rewards, punishments and the credit repair situation of credit subjects. This paper lays a foundation for improving the joint reward and punishment system and promoting the sharing of social credit information."
8768367,Big Data Analytics and Mining for Effective Visualization and Trends Forecasting of Crime Data,"Big data analytics (BDA) is a systematic approach for analyzing and identifying different patterns, relations, and trends within a large volume of data. In this paper, we apply BDA to criminal data where exploratory data analysis is conducted for visualization and trends prediction. Several the state-of-the-art data mining and deep learning techniques are used. Following statistical analysis and visualization, some interesting facts and patterns are discovered from criminal data in San Francisco, Chicago, and Philadelphia. The predictive results show that the Prophet model and Keras stateful LSTM perform better than neural network models, where the optimal size of the training data is found to be three years. These promising outcomes will benefit for police departments and law enforcement organizations to better understand crime issues and provide insights that will enable them to track activities, predict the likelihood of incidents, effectively deploy resources and optimize the decision making process."
9410109,Analysis and Application: Sports Education Information Management under the Background of Big data,"The new environment of education created by big data has brought a great impact on college physical education. To accelerate the modernization of physical education in colleges and universities, this paper points out the great value and application characteristics of big data in sports education information management. Combined with the characteristics of education big data, the application of data mining technology in education field is analyzed, and an Apriori algorithm based on MapReduce model is proposed. The scheme makes full use of the high-performance characteristics of the distributed computing framework, and improves the management data calculation and storage capacity. The system also provides various data API interfaces, which can effectively integrate all kinds of sports resources in colleges and universities, so as to improve the accuracy of association rule mining. The improvement strategy can then be used to build sports big data environment and improve the decision-making ability and intelligent level of sports management information system."
9457339,Research on the Influencing Factors of Teaching Ability of Textile University Professional Teachers under the Combination of Teaching and Big Data Information--Taking Dalian Polytechnic University as an Example,"Nowadays, textile professionals in the era of big data do not just meet a skill requirement. Because the business operation model brought about by big data is very different from the past, different positions are not independent of each other, but are interconnected and interdependent, and jointly serve the enterprise information operation system. In this respect, the professionalism and diversification of teachers' teaching abilities are the core and key to the development of higher education institutions. With the progress of the times, the rapid development of higher education in China, among the many factors that affect the teaching quality of colleges and universities, the teaching ability of professional teachers is an important factor. The teaching ability of college teachers is of great significance to the development of china's education and the growth of students[1]. This research combines the analysis of big data informatization with textile professional teachers as the research object. Through the sorting and analysis of teaching combined big data, the current situation of the teaching ability of textile teachers in my country is found, and the form of data analysis is used to find out the influence of textiles[2]. Influencing factors of professional teachers' teaching ability, scientifically and effectively find effective strategies for the development of professional teachers' teaching ability in my country's colleges and universities."
9378148,Towards Automatic Data Cleansing and Classification of Valid Historical Data An Incremental Approach Based on MDD,"The project Death and Burial Data: Ireland 1864-1922 (DBDIrl) examines the relationship between historical death registration data and burial data to explore the history of power in Ireland from 1864 to 1922. Its core Big Data arises from historical records from a variety of heterogeneous sources, some aspects are pre-digitized and machine readable. A huge data set (over 4 million records in each source) and its slow manual enrichment (ca 7,000 records processed so far) pose issues of quality, scalability, and creates the need for a quality assurance technology that is accessible to non-programmers. An important goal for the researcher community is to produce a reusable, high-level quality assurance tool for the ingested data that is domain specific (historic data), highly portable across data sources, thus independent of storage technology.This paper outlines the step-wise design of the finer granular digital format, aimed for storage and digital archiving, and the design and test of two generations of the techniques, used in the first two data ingestion and cleaning phases.The first small scale phase was exploratory, based on metadata enrichment transcription to Excel, and conducted in parallel with the design of the final digital format and the discovery of all the domain-specific rules and constraints for the syntax and semantic validity of individual entries. Excel embedded quality checks or database-specific techniques are not adequate due to the technology independence requirement. This first phase produced a Java parser with an embedded data cleaning and evaluation classifier, continuously improved and refined as insights grew. The next, larger scale phase uses a bespoke Historian Web Application that embeds the Java validator from the parser, as well as a new Boolean classifier for valid and complete data assurance built using a Model-Driven Development technique that we also describe. This solution enforces property constraints directly at data capture tim...
(Show More)"
9006339,Agent-based modeling to simulate road travel using Big Data from smartphone GPS: An application to the continental United States,"Growing concerns about urban sustainability, economic and public health vitality, and climate change are common features across the world. Transportation is often inextricably linked to these concerns and this necessitates the development of robust and scalable tools that can assist in timely understanding of the agent-system interactions. Such expedient but accurate analyses are critical for policymaking, especially in the current environment where urban mobility is witnessing a rapid transformation. To support such analyses, we demonstrate a novel methodology that implements a top-down large-scale agent-based simulation of urban travel using Global Positioning System (GPS) derived raw sightings. Specifically, we constructed the daily activity and travel patterns of devices (i.e. agents) using GPS data for a single day (Wednesday, March 6, 2019) for the entire continental United States. Data filtering techniques were applied to identify approximately 2.7 million smart devices (out of a daily total of 30.5 million) that were highly visible and mobile. We sourced roadway network data for the entire North America from Open Street Maps (OSM). We then fed the daily activity and travel records of agents along with the roadway network data into MATSim, an agent-based travel simulator, to produce highly spatiotemporally resolved agent activities along with their estimated travel trajectories. We processed these travel trajectories (1.5 billion records) to estimate vehicle miles traveled (VMT) for each U.S. state and modeled vehicle volumes per roadway link in the continental U.S. Overall, we found strong rank correlations between our results and Federal Highway Administration's VMT estimates, although absolute measures displayed a higher variability. We observed similar trends (i.e. low rank correlation errors but higher absolute errors) at the disaggregate roadway link level when comparing our extrapolated traffic volumes against roadway count station data from a select s...
(Show More)"
9005593,Big Data Analytic for Cascading Failure Analysis,"With the challenges of increased grid dynamics and more variability of power generation from renewable energy sources, rapidly increasing complexity in the grid model, and abundant data from measurements and simulations, the requirements for computational analysis have also increased dramatically. This paper proposes a novel big data analysis approach for power system cascading analysis, prevention, and remediation. The developed techniques will be capable of cascading analysis, better assessment of the systems vulnerability level, as well as proposing potential remediation. Case studies using IEEE 118- bus system and a 563-bus system, with comparisons against a commercial tool, validate the advantages of the developed big data approach: accurate prediction, and more importantly, faster and effective correction actions. The developed techniques could be further used for other power system applications."
9168920,Establishment of corrosion big data standard acquisition platform for refining process,"The advent of the internet of things and big data era has brought new ideas for corrosion analysis and prediction of refining units. With the establishment and application of all kinds of information systems, refining enterprises have accumulated a large number of structured, unstructured, corrosion influencing factors and corrosion result data sources, but all kinds of system data are independent, and the traditional storage methods are limited in calculation, processing and analysis and mining ability, which do not have the conditions of big data analysis and utilization, so it is urgent to study the standardized collection method of corrosion data and establish a unified data center. Based on the whole life process of equipment, this paper studies the data content, data characteristics and current main data acquisition and management forms of corrosion related data in each link of the equipment through-life. In addition, this paper puts forward the overall structure of corrosion big data standard acquisition system for refining process in the enterprise as a whole. The big data acquisition system, which is suitable for corrosion big data comprehensive collection, efficient storage and open interface, is established to carry on the data acquisition step by step, and lays a foundation for the acquisition and analysis and utilization of corrosion big data from refining process."
9262304,Big Data Analytics for Healthcare Recommendation Systems,"Healthcare industry is an indispensable entity in the real world where large volumes of data is accumulated from time to time. Such data assumes characteristics of big data and it is desirable to analyze it and bring about latent relationships among variables in the healthcare data. Data in healthcare industry is rich in useful information. However, a comprehensive big data approach is essential to mine the data and acquire business intelligence. There are many use cases of big data analytics. However, in healthcare industry it is imperative to have knowledge-driven recommendations that help all stakeholders. With the emergence of cloud computing, big data analytics has become a reality. Distributed programming frameworks like Hadoop and Spark, to mention few, are available with associated Distributed File System (DFS) to manage big data. Many researchers contributed towards developing algorithms based on machine learning which is part of Artificial Intelligence (AI). Since healthcare industry is one of the sources of big data, it needs distributed environments for processing. Big data analytics is essential to analyze healthcare data in a comprehensive manner. The cloud computing and big data ecosystem is playing favorable role in realizing big data analytics for healthcare recommendations. A typical recommender system in healthcare industry is supposed to produce recommendations in various aspects of the domain. This paper throws light into different recommenders in healthcare domain that use big data analytics to generate recommendations. It not only provides useful insights but also discussed research gaps that can be used to investigate further to improve the state of the art."
9675894,Hierarchical Structure of E-commerce Big Data Clustering Based on Hadoop Platform,"With the rapid development of portable network access equipment and the iterative update of Internet technology, the network ecosystem has gradually grown and become active, which has also led to the rapid development of e-commerce relying on Internet technology. Compared with traditional offline shopping methods, online e-commerce is undoubtedly a fast, efficient and convenient shopping method. The e-commerce shopping platform that has blown out in recent years has also pro ved this point. Based on Hadoop technology, this paper studies the hierarchical structure of e-commerce big data clustering. Based on the construction of Hadoop e-commerce big data analysis model, relying on association rule analysis, classification and clustering analysis, change and deviation analysis, the realization of Hadoop technology-based E-commerce big data analysis."
9574431,Synthetic Aperture Radar for SDGs in Big Data Era,"To well keep track of progress towards the 17 Sustainable Development Goals and the corresponding 169 targets of the 2030 Agenda for Sustainable Development signed in 2015, the UN Statistical Commission proposed a Global Indicator Framework (GIF) of 232 SDG indicators to help countries to implement development strategies and monitor the progress toward the SDG Targets. In the past years, the contributions of EO-based data to the GIF are recognized and regarded as it will play more important role in the next 10 years of action to realize the SDGs of 2030. In this paper the contributions of Synthetic aperture radar (SAR) to the 232 SDG Indicators are assessed, which can monitor our planet day and night as an important part of EO. And in order to better support the SDGs in the future, the specifications of the SAR-based dataset (products) and the corresponding requirements for the new generation SAR are discussed, which is helpful for the proposed SAR mission designated to SDGs."
9489191,Big Data Technology Assists the Application of Proportional Liability: From Data Understanding Perspective,"This research study analyzes the big data technology that assists the application of proportional liability from the data understanding perspective. 3D model segmentation is the fine-grained 3D recognition task. Given a 3D model, each point or surface of the point cloud model or grid model is assigned a partial category label. To overcome the challenges of the traditional approaches, the data understanding model is optimized to fit for the novel scenarios. The data structure is optimized and the fuzzy analysis pattern is revised. Furthermore, the proposed model is applied into the analysis of the proportional liability scenario. Also, a test has been conducted on the public database. The experimental results prove the comprehensive performance."
9434486,Analysis of Temporal and Spatial Evolution of Urban Brownfield in Changchun City based on Big Data,"Urban brownfield reuse plays an important role in urban economic, social and ecological development. The generation of brownfields in cities is affected by many factors. Based on the urban brownfield data in the downtown area of Changchun, this paper uses the spatial distribution center of gravity method and the analysis of economic and technical indicators to conclude that the urban brownfield renovation of Changchun is mainly affected by political, economic, land and demographic factors. The evolution mechanism mainly includes three aspects: urban planning guidance mechanism, economic transformation promotion mechanism and land policy incentive mechanism."
9443779,Temporal Data Analytics on COVID-19 Data with Ubiquitous Computing,"With technological advancements in computing and communications, huge amounts of big data are generated and collected at a very rapid rate from a wide variety of rich data sources. Embedded in these big data are useful information and valuable knowledge. An example is healthcare and epidemiological data such as data related to patients who suffered from viral diseases like the coronavirus disease 2019 (COVID-19). Knowledge discovered from these epidemiological data via data science helps researchers, epidemiologists and policy makers to get a better understanding of the disease, which may inspire them to come up ways to detect, control and combat the disease. In this paper, we present a temporal data science algorithm for analyzing big COVID-19 epidemiological data, with focus on the temporal data analytics with ubiquitous computing. The algorithm helps users to get a better understanding of information about the confirmed cases of COVID-19. Evaluation results show the benefits of our system in temporal data analytics of big COVID-19 data with ubiquitous computing. Although the algorithm is designed for temporal data analytics of big epidemiological data, it would be applicable to other temporal data analytics of big data in many real-life applications and services."
9140831,The privacy paradigm : An overview of privacy in Business Analytics and Big Data,"In this New Age where information has an indispensable value for companies and data mining technologies are growing in the area of Information Technology, privacy remains a sensitive issue in the approach to the exploitation of the large volume of data generated and processed by companies. The way data is collected, handled and destined is not yet clearly defined and has been the subject of constant debate by several areas of activity. This literature review gives an overview of privacy in the era of Business Analytics and Big Data in different timelines, the opportunities and challenges faced, aiming to broaden discussions on a subject that deserves extreme attention and aims to show that, despite measures for data protection have been created, there is still a need to discuss the subject among the different parties involved in the process to achieve a positive ideal for both users and companies."
9005503,"A Methodology for Cross-Platform, Event-Driven Big Data Analytics-as-a-Service","The advent of Big Data has revolutionized the way in which data are collected, analyzed, and processed, becoming a pre-requisite for each enterprise that competes in the global market. In this respect, the commodization of Big Data analytics is an essential goal to be faced in the near future. Recently, some preliminary approaches have been presented mostly focusing on distributing Big Data platforms as a service, while less has been done on cross-platform Big Data analytics. In this paper, we propose a model-based methodology for Big Data Analytics-as-a-Service that extends existing techniques by supporting cross-communication between batch and stream processing, deployment on multiple platforms, and end-to-end verification against users' requirements."
9315192,Exploration of Big Data Analytics in Healthcare Analytics,"The data is increasing in every field of business finance etc. But the health sector field is not yet fully explored and there is a lot of scope of advancement there. In the past few years, the health sector had gone through a lot of changes, there is a high increase in the number of doctors, patients and diseases. The data that once was in the size of terabytes now reached zettabytes and still growing exponentially. As the data is collected from various sources, therefore, it can be both structured and unstructured. So a lot of time and money is wasted on storing and analyzing it. That's why it is very difficult and complex to analyze it using traditional approaches. So as the time is passing by it is clear that the use of big data tools and techniques will become a necessity in every field. Various scientist and organizations are trying to use these techniques for their financial advantage. Big data analytics will help us to analyze and find the pattern between the data sets by the help of which we can improve the state of the current healthcare system."
9482113,Research on Personalized Education Data Processing in the Era of Big Data,"The development of education is continuously achieving transformation in the era of big data. At present, the application of big data in education is mostly concentrated in the field of data visualization like data collection processing but it is less involved in the requirements and customization of human-oriented personalized education platform. Education is not a top-down mechanical operation process, it should be more appropriate to the subjectivity of educational objects in education. This paper proposes solutions in the aspects of data classification, data governance and personalization education data system construction, it also innovates the design of personalized education program."
9434485,Research on Urban Landscape Image Enhancement under the Background ofBig Data Visualization,"At present, the lack of urban landscape image is common in most cities in China. This article uses the principle of big data visualization and the combination of urban landscape image to discuss the application of urban landscape image enhancement research in China. Starting from multiple dimensions such as Internet questionnaire data, big data software visualization, and urban landscape image enhancement steps, we explores how big data visualization can promote urban landscape image, and draws up countermeasures."
9236929,Research on the Model of Command and Decision System for Big Data,"With the continuous application of high technology in command and operation, the era of big data in military field has come. Traditional data processing can't satisfy the deep analysis of massive heterogeneous data. Cloud computing provides necessary storage, management and computing solutions for big data analysis. Based on the characteristics of big data, using cloud computing and data mining technology, this paper proposes a command and decision system model based on Hadoop to provide efficient and reliable ad hoc analysis, and finally establishes a big data analysis ecosystem for battle command and decision-making."
9060084,A Multi-database Hybrid Storage Method for Big Data of Power Dispatching and Control,"At present, the service scale of the power grid dispatching and control system is rapidly expanding and the multi-level power grid dispatching and control services possess features, including a wide variety of data and scattered storage. In order to manage the data of power grid more efficiently and meet the more efficient, flexible and accurate information acquisition requirements of multi-type users, we apply intelligent search technology to multi-level power grid dispatching and control system.. Facing with the drawbacks of single database in storage and search of massive data, including model data historical data and real-time data, a multi database hybrid storage based intelligent search method and service has been proposed to unified management and application service for multiple types of power dispatching and control big data. On this basis, performance of collection, storage, search, utilization and display of dispatching and control big data for different services has been able to be enhanced."
9064475,The Implementation of a Practical Agricultural Big Data System,"Agricultural big data is growing rapidly and it faces many known and unknown obstacles. This paper focuses on the need for managing farms effectively and making decisions accurately. Using agricultural IoT technology, big data technology and machine learning algorithms, the big data application system is established. Including data collection, data storage, data analysis and visualization management, we present a complete scheme. Through the agricultural big data system, the production cost is reduced and the production efficiency is improved."
8686099,Big Data Quality Challenges,"Big Data, is a growing technique these days. There are many uses of Big Data; Artificial Intelligence, Health Care, Business, and many more. For that reason, it becomes necessary to deal with this massive volume of data with caution and care in a term to make sure that the data used and produced is in high quality. Therefore, the Big Data quality is must, and its rules have to be satisfied. In this paper, the main Big Data Quality Factors, which need to be measured, is presented in the perspective of the data itself, the data management, data processing, and data users. This research highlights the quality factors that may be used later to create different Big Data quality models."
9430205,Big Data Analytics Tools: Twitter API and Spark,"Nowadays, Big Data is become more popular. With increasing the daily social media used, the increase of Data. Twitter is one of most popular social media for most users. However, Twitter provides an API framework that makes it easy for developers to access Twitter data. Using Spark, one can pick out a tweet that contains a specific keyword [1]. One can also do a text analysis about any subject of interest. In this article, Big Data analytics tools were explored, then Twitter data was collected and analyzed by Spark on EMR Amazon public cloud. This experiment can be applied for more complex applications to discover information from Data of interest."
9032565,An analysis of Crime data under Apache Pig on Big Data,"The most important social problem that occurs all around the world is crime. Crime arousing affects children's development, security of public and socio-economic condition of an adult. Discernment about crime rate factors is demanding for government and policy makers in their try to minimize the crime and boost the civilian's life essence. We analyzing big data related to the crimes and crime rate in our paper. In this paper, we familiarize with social problem of crime using apache pig with hadoop, which implicate discovery of verisimilar vicious crime incident selective with the incident-level crime data which is provided by past identical crime incidents. The incident-level crime data stored as a dataset of crime which add type of crime, ID of the criminal, incident date and location are crime limitation or parameters used in this paper. In this paper a big data analysis based analyzing large scale crime data under Apache Pig used various commands in the grunt shell with hadoop distributed file system. Big data analysis gathering problem-solving data set of crime is a burdensome process due to secretiveness principle. So, it's a state-of-the-art method used crime dataset as an input for analyzing large scale crime data that will definitely help out for decision makers, policy makers and government to minimize the crime."
9297009,A Qualitative Assessment of Machine Learning Support for Detecting Data Completeness and Accuracy Issues to Improve Data Analytics in Big Data for the Healthcare Industry,"Tackling Data Quality issues as part of Big Data can be challenging. For data cleansing activities, manual methods are not efficient due to the potentially very large amount of data.. This paper aims to qualitatively assess the possibilities for using machine learning in the process of detecting data incompleteness and inaccuracy, since these two data quality dimensions were found to be the most significant by a previous research study conducted by the authors. A review of existing literature concludes that there is no unique machine learning algorithm most suitable to deal with both incompleteness and inaccuracy of data. Various algorithms are selected from existing studies and applied against a representative big (healthcare) dataset. Following experiments, it was also discovered that the implementation of machine learning algorithms in this context encounters several challenges for Big Data quality activities. These challenges are related to the amount of data particualar machine learning algorithms can scale to and also to certain data type restrictions imposed by some machine learning algorithms. The study concludes that 1) data imputation works better with linear regression models, 2) clustering models are more efficient to detect outliers but fully automated systems may not be realistic in this context. Therefore, a certain level of human judgement is still needed."
9378045,Automotive Big Data Pipeline: Disaggregated Hyper-Converged Infrastructure vs Hyper-Converged Infrastructure,"Big data disrupts everything it touches, but automotive is probably one of the top industries that enjoy and leverage the benefits. The Automotive Big Data Pipeline (ABDP) is a Big Data pipeline base on the automotive use case and is required to scale up agile and high performance in real-time or in batch. Nonetheless, there're many alternative infrastructure designs but lack of knowledge, which fits the best for the automotive domain. It leads this paper into a question: What kinds of infrastructure design could provide better performance for the ABDP?In this paper, we introduce two well-known infrastructure designs called Hyper-Converged infrastructure (HCI) and Disaggregated Hyper-Converged infrastructure (DHCI). HCI combines standard data center hardware using locally attached storage resources to create fast, common building blocks. However, does single standard hardware fit all the requirements? DHCI scale independently from compute and storage provides an option. It provides a more cost-efficient and flexible solution; however, there is no comparison from the performance point of view. Therefore, to address it, our objective is to conduct an empirical performance comparison to see which one performs better.The experiment result shows that DHCI performs almost the same as HCI on CPU utilization, memory, and network consumption. However, regarding storage and running time metrics, DHCI performs slightly higher storage throughput, IOPs, and less running time than HCI."
9524003,Cotton Textile Equipment Data Management System Based on Big Data Technology,"In order to improve the efficiency of data management of cotton textile equipment, this paper proposes a novel data management system of cotton textile equipment based on big data technology. The data management system constructs the basic architecture of cotton textile enterprise data management system based on big data technology, which can improve the efficiency of data collection through terminal data acquisition equipment, and transmit the collected data to the cloud, so as to facilitate users' query and retrieval. The research results show that the data management system can improve the information management level of cotton textile enterprises, ensure the security of data storage and improve the production efficiency."
8806235,Design of Big Data Intelligent Sharing System for the Creative Achievement of College Students in Internet+ Age,"Aiming to improve the ability of big data to share the creative achievements of college students in the Internet+ age, and to build a big data intelligent sharing system for college students' creative achievements in the Internet+ age, a design method of big data intelligent sharing system is proposed based on multi-layer architecture for college students' creative achievements in the Internet+ age. The multi-level big data fusion method is used to design the algorithm of big data intelligent sharing of the creative achievements of college students in the Internet+ age, and the statistical characteristics of big data of the creative achievements of college students in the Internet+ age are extracted. The multi-layer template feature matching method is used to combine big data's creative achievements in the Internet+ age with fuzzy clustering, and the intelligent sharing multi-layer architecture model of big data, the creative achievements of college students in the Internet+ age, is established. Under the structure system of BES, we construct the bottom database of big data intelligent sharing system, which is the creative achievement of college students in the Internet+ age. The program loading and automatic control of big data intelligent sharing system for university students' creative achievements is carried out by cross-compiling method. Under the embedded multi-level architecture, the software development and design of big data intelligent sharing system for college students' creative achievements are realized. The test results show that the system can effectively realize the intelligent sharing of the creative achievements of college students in the Internet+ age big data, the information fusion degree is higher."
9142913,Integrative Approach Of Big Data And Network Attacks Analysis In Cloud Environment,"Lately mining of information from online life is pulling in more consideration because of the blast in the development of Big Data. In security, Big Data manages an assortment of immense advanced data for investigating, envisioning and to draw the bits of knowledge for the expectation and anticipation of digital assaults. Big Data Analytics (BDA) is the term composed by experts to portray the art of dealing with, taking care of and gathering a great deal of data for future evaluation. Data is being made at an upsetting rate. The quick improvement of the Internet, Internet of Things (IoT) and other creative advances are the rule liable gatherings behind this proceeded with advancement. The data made is an impression of the earth, it is conveyed out of, along these lines can use the data got away from structures to understand the internal exercises of that system. This has become a significant element in cyber security where the objective is to secure resources. Moreover, the developing estimation of information has made large information a high worth objective. Right now, investigate ongoing exploration works in cyber security comparable to huge information and feature how Big information is secured and how huge information can likewise be utilized as a device for cyber security. Simultaneously, a Big Data based concentrated log investigation framework is actualized to distinguish the system traffic happened with assailants through DDOS, SQL Injection and Bruce Force assault. The log record is naturally transmitted to the brought together cloud server and big information is started in the investigation process."
9736538,Optimizing performance of Real-Time Big Data stateful streaming applications on Cloud,"Exponential growth in the volume of data generated over the last decade has triggered massive research and adoption of distributed big data analytics platforms. In real-time streaming analytics, data is received as a continuous event stream. These events are iteratively correlated and analyzed in micro-batches till the processing reaches a logical conclusive stage. For every iteration, data received as part of the new batch is correlated with the results of the previous iteration and cached as interim results. This real-time stateful analysis of streaming data has been made possible by distributed data-intensive computing frameworks like Apache Spark. Though the spark state storage is highly optimized, its access is limited within the context of the Spark job. Since, these interim results may need to be consumed by applications running external to Spark context, saving these results in external memory involves a significant overhead due to the high volume of I/O. Similar challenges are observed when the spark job needs to consume from an external data store. These challenges get compounded in cloud-based deployment. This paper presents the optimized data storage and retrieval pattern from the spark job to/from the independent storage using the standard off the shelf tools. Our focus on standard off the shelf storage is to ensure that the design patterns presented as part of this paper could be adopted for production deployment."
9317510,Implanting Big Data Technology into the Construction of “Smart Parking”,"As my country attaches more and more importance to the construction of smart cities, the construction of smart parking is gradually becoming more mature. With the advent of the big data era, data analysis is becoming more and more important in the construction of smart parking. Big data analysis can not only effectively use idle data, but also provide government managers with effective, accurate, and real-time data support, thereby improving the efficiency of managers' planning and management of parking lots. This paper mainly studies the current complex parking situation in Tongliang District of Chongqing City, and uses big data technology to replace traditional data management methods to solve the current problems of parking business in Tongliang District, Chongqing City."
9378367,Metadata-Driven Industrial-Grade ETL System,"Digital transformation of a railway system based on big data technologies relies on integrating large volumes of streaming data into digitally enabled enterprise systems to form a comprehensive and efficient intelligent transportation system. Data requirements of the smart railway transportation involve a large number of unstructured data and semi-structured data including railway KPI data. Traditional ETL technology cannot cope with fast growing demands of processing large volumes of real-time data collected from heterogeneous sources both inside the system and in the environment. According to the characteristics of the railway KPI data, this paper proposes the designs of an automated ETL system with higher versatility and efficiency of data processing. To reach the goals, we optimize the workflow of the ETL using a proprietary designed metadata management framework. Making ETL suitable for big data-driven railway transportation environment, requires redesigning the ETL processing rules by using metadata model and then optimizing the extracting, transforming and loading processes of the ETL system. Our experimental results with actual railway KPI data show that the proposed metadata supported automated ETL system can effectively serve the railway KPI data processing using open source distributed big data technologies. The proposed metadata framework proved to be efficient in processing complex data structures and large data capacity of big data."
9255244,Overview of Big Data Applications in Remote Sensing,"In this paper, a survey of big data applications in remote sensing was conducted. Within the scope of this study, the studies in the literature were evaluated in terms of different big data sources and types in remote sensing, big data technologies and software architectures utilized to manage big data. This paper is intended to guide researchers who will work on big data applications in remote sensing."
9457427,Green Wave Zone Evaluation Method Based on Electronic Police Data,"In the urban intelligent transportation system, green wave coordination has always been the mainstream in the field of traffic coordination control, but the method, result, and degree of green wave optimization for green wave optimization have always been a problem in academic research. This paper uses big data analysis methods to propose the concept of filtering optimization index, which integrates travel time, number of stops, and intersections and other information, and can objectively and accurately evaluate the traffic coordination status. In the article, the electronic police big data from the actual city is used as the experimental data set for the first time. Compared with the traditional geomagnetic coil, the electronic police obtains more data dimensions and more accurate data. Processing the electronic police data set through data analysis and machine learning methods can quickly and effectively find the problem of unreasonable traffic signal timing signal configuration, which has guiding significance for the traffic control department to optimize the filtered signal."
9201859,Cloud Computing-based Big Data mining Connotation and Solution,"According to the contrastive perspective between traditional data mining and big data mining, this article discusses the connotation of big data mining and proposes the system frame of big data mining about cloud computing and mining service. Taking the multifunctional Hadoop big data mining platform as an example, this article analyses the internal workflow of big data mining and its advantages as well as challenges, which can provide a reference for users to cognize and apply the big data mining."
9450991,Research on Artificial Intelligence Industrial Big Data Platform for Industrial Internet Applications,"With the development of industry, enterprises have put forward higher requirements for real-time data collection and analysis. According to this, a distributed industrial big data platform for Industrial Internet applications is designed, which can effectively support the industrial field big data collection and storage. The system contains a distributed database, real-time database and offline big data platform to implement the collection and storage of all data in the system. Thus, the industrial big data platform architecture and related data hierarchical processing flow are proposed, which can effectively meet the requirements of the multi-source data and real-time processing of smart factory. The proposed data platform technical architecture will have important reference value for the realization of smart manufacturing and smart factory."
9006397,Exploiting Anti-Monotonic Constraints in Mining Palindromic Motifs from Big Genomic Data,"The advent of high-throughput technologies such as Illumina HiSeq X, mass spectrometry, and microarray heralds a new era of big biological datasets in computational biology. This digital revolution in bioinformatics has generated unprecedented volumes of omics data (e.g., transcriptomes, genomes, proteomes, metabolomes) with various degrees of veracities and values. These deluge of omics data are awash with a wealth of information in the form of frequently repeated contiguous patterns-namely, sequence motifs. Sequence motifs are short repeated contiguous subsequences located in the promoter region of a genome sequence. On some occasions, users are interested in mining only a particular type of sequence motifs (e.g., palindromic motifs). In genomics, palindromes are sequences from the nucleotide bases from deoxyribonucleic acid (DNA) or ribonucleic acid (RNA) strands that are symmetrical in the sense that they read exactly the same as their complementary sequences in the reverse direction. The use of classical constraints (e.g., anti-monotonic, succinct, and/or convertible constraints) allows users to specify their interest in the universal search space, and thus enhancing distinct and effective pruning of the search space- leading to a reduction in the computational time required for the mining process. Despite several attempts made by existing algorithms for mining palindromic motifs from DNA sequences, a major drawback stems from the high volumes of the DNA sequences leading to high complexities and turnaround time of the algorithms. To this end, we propose a parallel scalable sequential mining algorithm that exploits some features of anti-monotonic constraints-using the in-memory computing model of the Apache Spark framework deployed on a cluster of a homogeneous distributed-memory system-for mining palindromic motifs from high volumes of DNA sequences. To evaluate our algorithm, we obtained the human genome (Homo sapiens) assemblies GRCh37 patch 13 (hg19), which...
(Show More)"
8283808,A Secure High-Order Lanczos-Based Orthogonal Tensor SVD for Big Data Reduction in Cloud Environment,"Singular value decomposition (SVD) has been applied to cyber security and cyber forensics since it can reduce data. However, SVD is hard to reduce high-order big data because it is designed for only matrix data initially. Reducing high-order big data is desired for cyber security applications, and is a very challenging issue. In this paper, we propose a novel orthogonal tensor SVD method using big data techniques for high-order big data (naturally represented as tensors) reduction, which can be extensively used in big data applications of cyber security and cyber forensics. More specifically, we first present a high-order lanczos-based orthogonal tensor SVD algorithm to reduce high-order data. Then, for utilizing the incomparable benefits of cloud, we develop a secure orthogonal tensor SVD method to outsource the computation task of the orthogonal tensor SVD algorithm to cloud. The secure orthogonal tensor SVD method can protect data security from untrusted cloud by applying garbled circuits to the orthogonal tensor SVD algorithm. This is, to our best knowledge, the first work to address high-order big data reduction by employing cloud computing. Finally, we analyze the security and efficiency of our proposed orthogonal tensor SVD on synthetic dataset and real network intrusion detection dataset, and the results demonstrate that our proposed method is very promising for big data reduction."
9378386,A Simple Low Cost Parallel Architecture for Big Data Analytics,"Big Data Systems (Hadoop, DBMSs) require a complicated setup and tuning to store and process big data on a parallel cluster. This is mainly due to static partitioning when data sets are loaded or copied into the file system. Parallel processing thereafter works in a distributed manner, aiming for balanced parallel execution across nodes. Node synchronization, data redistribution and distributed caching in main memory are difficult to tune in the system. On the other hand, there exist analytical problems and algorithms, which can be computed in parallel, with minimal synchronization and fully independent computation. Moreover, some problems can be solved in one pass or few passes. In this paper, we introduce a low cost, yet useful, processing architecture in which data sets are dynamically partitioned at run-time and storage is transient. Each node processes one partition independently and partial results are gathered at the master processing node. Surprisingly, we show this architecture works well for some popular machine learning models as well as some graph algorithms. We attempt to identify which problem characteristics enable such efficient processing, and we also show the main bottleneck is the initial data set partitioning and distribution across nodes. We anticipate our architecture can benefit parallel processing in the cloud, where a dynamic number of virtual processors is decided at runtime or when the data set is analyzed for a short time."
8645583,"Big data acquisition, preprocessing and analysis to Develop and Implement Effective Database System with High Security Standards","This paper provides a guideline to develop and implement the strategy to acquire big data, preprocessing and analyse to develop and implement an effective database system with high security system DBMS with efficient and effective performance. The paper discusses the main steps that help organization to develop effective database management system. Then how the developed system be ready for any threats when the data is accessed for the data analysis. The paper apply the theory concept for the banking industry where the personal data is critical and need maintain the high confidentiality and described the each steps to better database system implementation."
9005952,Federated Recommendation Systems,"Despite its great progress so far, artificial intelligence (AI) is facing a serious challenge in the availability of high-quality Big Data. In many practical applications, data are in the form of isolated islands. Efforts to integrate the data are increasingly difficult partly due to serious concerns over user privacy and data security. The problem is exacerbated by strict government regulations such as Europe's General Data Privacy Regulations (GDPR). In this talk, I will review these challenges and describe efforts to address them in recommendation systems area. In particular, I will give an overview of recent advances in federated learning and then focus on developments of “federated recommendation systems”, which aims to build high-performance recommendation systems by bridging data repositories without compromising data security and privacy."
8679267,Diagnosis of Corporate Insolvency Using Massive News Articles for Credit Management,"In the aftermath of the 4th Industrial Revolution, AI and Big data technology have been used in various fields in South Korea, and the techniques are being applied to and complemented in various service fields which were implemented without them before. Especially, in order to secure credit stability for borrowed companies from financial institutions and to preemptively respond to the risks about-by means of online news articles and SNS data-the attempts to forecast the possibility of insolvency and adopt them into actual business are actively conducted by major domestic banks. In this study, we describe several analytical methods, outputs, and problems that are encountered during the processes of developing the unstructured text-based prediction system to detect the possibility of corporate insolvency-which ordered by a national government bank and discuss related issues with a real case. As a result, we have implemented an automatic tagger program for labeling largely unlabeled articles, and newly devised a prediction algorithm of the possibility of corporate insolvency. We achieved the accuracy of 92% (AUC 0.96) in aspect of performance and the hit ratio of 50% among the number of predicted 26 candidates that have the possibility of insolvency. Thus, the result of our study is revealed to be complementary to the financial data analysis sufficiently in performance, but yet have several limitations such as data coverage, reliability, and the characteristics of Korean language."
8787655,Research on Academic Evaluation of College Students Based on Big Data,"Big data has a revolutionary impact on the whole society, especially on the development of higher education. By investigating the current situation of academic evaluation of university students at home and abroad, this paper sorts out the relevant contents between big data and academic evaluation of university students, innovatively combines big data with academic evaluation of university students, aiming at promoting students' individualized development, making them grasp the principles of comprehensiveness, orientation, pluralism as well as difference, and exploring key connecting links and data sources in the process of developing academic evaluation. In order to bring the big data in students' academic evaluation into full play, this paper includes process design, data mining and realistic challenges."
9006357,Real-Time Machine Learning Competition on Data Streams at the IEEE Big Data 2019,"In this paper, we present the competition “Real-time Machine Learning Competition on Data Streams a BigData Cup Challenge of the IEEE Big Data 2019 conference. Data streams, such as data originated from sensors, have increasingly gained the interest of researchers and companies and are currently widely studied in data science. Companies in the telecommunication and energy industries are trying to exploit these data and get real-time insights on their services and equipment. In order to extract valuable knowledge from data streams, one must be able to analyze the data as they arrive and make meaningful predictions. For this purpose, we use fast incremental learners. There already exists a great community that is organizing various competitions on machine learning tasks for batch learners. Our goal was to introduce the same approach to engage the whole community in solving essential problems in data stream mining. We performed a new kind of data science competition based on a real-time prediction setting, using a novel competition platform on data streams. The examples to predict were released in real-time, and the predictions had also to be submitted in real-time. To the best of our knowledge, this was the first data science competition conducted in real-time. The task of the competition was to predict network activity, and the data has been provided by one of our partner companies."
9006234,bench4gis: Benchmarking Privacy-aware Geocoding with Open Big Data,"Geocoding, the process of translating addresses to geographic coordinates, is a relatively straight-forward and well-studied process, but limitations due to privacy concerns may restrict usage of geographic data. The impact of these limitations are further compounded by the scale of the data, and in turn, also limits viable geocoding strategies. For example, healthcare data is protected by patient privacy laws in addition to possible institutional regulations that restrict external transmission and sharing of data. This results in the implementation of “in-house” geocoding solutions where data is processed behind an organization's firewall; quality assurance for these implementations is problematic because sensitive data cannot be used to externally validate results. In this paper, we present our software framework called bench4gis which benchmarks privacy-aware geocoding solutions by leveraging open big data as surrogate data for quality assurance; the scale of open big data sets for address data can ensure that results are geographically meaningful for the locale of the implementing institution."
9558902,Big Data Based Archiving Management System,"The size of data in institutions such as banks is increasing rapidly due to the fact that the number of new products is put into service, the number of customers is increasing rapidly, the number of new applications is put into use due to regulations, and the data that must be kept compulsory such as audit trail records are excessive. When these data remain in existing systems for years, systems and applications become heavy, and the costs of operational processes such as backup and system maintenance increase. For all these problems, the data should be classified and categorized according to the frequency of access, those that do not need instant access to the categorized data should be archived by moving them to secondary and less costly systems and deleted from the source system. The large data-based archiving management system will be developed as a software product, providing more effective access to structural or unstructured data to be archived in the Hadoop ecosystem and bringing cheaper storage costs."
8727699,Security Measures Assessment for Big Data Management Systems,"There is a trend in the use of big data today, and subsequently, increased requirements for systems able to store and manipulate these huge quantities of data. However, the adoption of these Big Data management systems can have positive as well as negative effects on the data security of service consumers.This paper aims to highlight the Big Data security problems, as well as the recent statistics showing the number of vulnerabilities that attack these systems, which prevent them to work safely. It allows analyzing a set of statistics in order to shed light on the importance of big data security. For finally present a proposal solution that can improve the security level of Hadoop Big Data management system, while justifying its feasibility."
9378026,"Self-Service, On-Demand Creation of OLAP Cubes over Big Data: a Metadata-Driven Approach","Nowadays, huge amounts of data are continuously created from different sources in different formats, and stored into data lakes for further use. A typical use case is to conduct online analyses in order to gain business insights and make better decisions. However, there are many obstacles to overcome when it comes on analysing Big Data online, such as dealing with schema-free data, conciliating different data formats, managing different locations, and allowing BI professionals and analysts to create their analytical data by themselves. In this paper, we propose some solutions to overcome these obstacles. We propose a data lake metadata model as well as a metadata-driven approach to create OLAP cubes from data lakes on-demand and in a self-service manner. We apply our work to Twitter social network and we present a proof-of-concept dedicated application."
9516532,Analysis of Credit Strategy of Small and Medium Enterprises Based on Big Data,"At present, big data has the characteristics of “high-dimensional, massive, and real-time.” The analysis based on big data can make people have a better interpretation of data, while the analysis with predictive significance can make some predictive inference based on the results of visual analysis and big data analysis. Therefore, this article mainly studies the bank’s credit strategy for small, medium and micro enterprises based on big data, and conducts quantitative analysis based on publicly available index data. It establishes a credit strategy evaluation system for credit strategies such as whether to lend, loan interest rate, and loan limit. The comprehensive evaluation method is used to analyze the bank’s credit strategy to the enterprise."
9065276,Effective Garbage Data Filtering Algorithm for SNS Big Data Processing by Machine Learning,"Recently, as the use of social network services (SNS) increases in daily modern life, the amount of SNS data generated has become very large. In addition, increasing efforts are being directed to extracting various pieces of information by collecting, processing and analyzing large amounts of SNS data. While various pieces of information can be extracted from SNS data through big data processing, this is a highly resource-intensive task. Therefore, in order to obtain information from SNS data, a lot of time and material resources are required. In this paper, we propose a data filtering algorithm that filters out garbage data that has no meaning as data among SNS data. The proposed algorithm improves the filtering accuracy by recursive learning based on the initial learning data. Experimental results show that the proposed algorithm has a filtering effect of over 70% on the experimental keywords."
8725673,Innovative Practice of Line Loss Management Model Based on Big Data,"In order to adapt to the new situation of energy supply side reform, relying on the promotion and application of synchronization line loss management system, improving the organizational system of line loss management, setting up a closed-loop management mechanism of ""clear objectives, process control and result control"", reconstructing the standardization process of line loss, strengthening the four major leading professions of development, operation inspection, marketing and control, and establishing a coordinated guarantee system of multiple units and departments. The working mechanism of ""Four Guarantees, One Evaluation, One Summary"" forms the normal operation system from the company headquarters to the grass-roots power supply stations and teams, and realizes the double improvement of the company's basic management and operation efficiency."
9144893,A novel approach for high-velocity big geo-data handling using iterative and feature learning algorithms,"Geospatial data were exclusively generated by official agencies. However, following the technological revolution in data collection and production, various sources have emerged for the massive production of geospatial data, resulting the phenomenon of big geo-data. Therefore, dealing with large amounts of these data sets, results in a high velocity as they change very quickly, is a challenging task. Hence, analysis become more complex and computation become prohibitively expensive. As a result, spatial computing technologies become limited in front of these complex data and operations. Accordingly, we aimed to refine complexity with simplicity by replacing traditional geospatial models with referring to the simplest intelligent and minimum resource requirement algorithms that can be applied against these constraints, while ensuring the criteria of performance and scalability. In this work, we focus on the high-velocity of this big geo-data through the use of an iterative approach applied to a feature learning algorithms to decrease the memory consumption and the time complexity of traditional machine learning algorithms. According to our knowledge, although they were widely applied in the 19th century as a solution to overcome the problems of limitation of memory and computing resources. Iterative methods were still not used for the big geo-data analytics and generally for the big data domain. Thus, this approach could be beneficial especially for real time applications such as the anomaly monitoring and detection."
9288550,Basic Knowledge Construction Technique to Reduce The Volume of Low-Dimensional Big Data,"Big-data has the characteristics of high volume, velocity, and variety (3v) and continues to grow exponentially following the development of the use of world information and communication technology. The main problem in the use of big data is data deluge. The need for technology and big-data storage and processing methods to offset the exponential data growth rate is potentially unlimited, giving rise to the problem of increasing exponential technology requirements as well. In this paper, we propose a new approach in the realm of big-data analysis, through separating the basic-knowledge construction process from the original data into knowledge with much smaller velocity and volume. There are three problems to be solved, such as formulating basic-knowledge, developing a method for constructing basic-knowledge from initial data, and developing a technique for analyzing basic-knowledge into final knowledge. In this study, the technique used to build basic-knowledge is clustering-based. Analysis of basic-knowledge into final-knowledge is limited to the clustering-based analysis process. The main contributions in this paper are basic-knowledge formulation, new big-data analytic architecture, basic-knowledge construction algorithms (DSC4BKC), and analysis algorithms from basic-knowledge (BDAfBK) to final-knowledge. To test our proposed method, we use the BIRCH clustering algorithm with O(n) complexity as the baseline. We also used the artificial test-data generated from WEKA, and the IRIS4D and Diabetes data from the UCI Machine Learning Data Set for validation. Our test shows that the proposed method much more efficient in using data storage (84.69% up to 99.80%), faster in processing (20.84% up to 86.91%, and produces final-knowledge that is similar to the baseline."
8319508,Model-Based Big Data Analytics-as-a-Service: Take Big Data to the Next Level,"The Big Data revolution promises to build a data-driven ecosystem where better decisions are supported by enhanced analytics and data management. However, major hurdles still need to be overcome on the road that leads to commoditization and wide adoption of Big Data Analytics (BDA). Big Data complexity is the first factor hampering the full potential of BDA. The opacity and variety of Big Data technologies and computations, in fact, make BDA a failure prone and resource-intensive process, which requires a trial-and-error approach. This problem is even exacerbated by the fact that current solutions to Big Data application development take a bottom-up approach, where the last technology release drives application development. Selection of the best Big Data platform, as well as of the best pipeline to execute analytics, represents then a deal breaker. In this paper, we propose a return to roots by defining a Model-Driven Engineering (MDE) methodology that supports automation of BDA based on model specification. Our approach lets customers declare requirements to be achieved by an abstract Big Data platform and smart engines deploy the Big Data pipeline carrying out the analytics on a specific instance of such platform. Driven by customers' requirements, our methodology is based on an OWL-S ontology of Big Data services and on a compiler transforming OWL-S service compositions in workflows that can be directly executed on the selected platform. The proposal is experimentally evaluated in a real-world scenario focusing on the threat detection system of SAP."
9137476,Research on Lucene Based Full-Text Query Search Service for Smart Distribution System,"Big data is one of the newest and biggest technological changes in the IT industry. Data search, data association and analysis are the essential needs by big data utilities. There are all kinds of literary data in distribution network which are not utilized and analyzed. Full-text query can incorporate straight words and return mass data set according to the search which provides the convenience for data management and decision support. In this paper, a full-text retrieval system based on Lucene architecture integrated with Hadoop architecture for distribution network big data center is established which could provide literary and full-text query across all distribution network management systems such as Distribution management system(DMS), Intelligent system for integrated grid operation (OS2), Customer service system etc. The proposed application could assist system operators to fasten the information retrieval and provide the convenience and efficiency of data analysis by the big data technology."
9050159,Big Data Oriented Mining and Implementation Analysis for Online Education Information,"With the advent of the big data, the amount of data generated during the development of online education is also amazing. Therefore, online education based on big data guidance has become a hot research trend. Focusing on educational mining of big data and learning analysis techniques, this paper uses Apriori algorithm running on Hadoop to improve the efficiency of parallel computing, by studying the data set segmentation idea and optimization from the key value reduction. Then, we analyze and study the characteristics of educational big data, and perform data set processing for user-course access frequency data, which improves the accuracy of association rule mining and provides instructive information for school education decision-making and teaching management."
9378421,SELIS BDA: Big Data Analytics for the Logistics Domain,"In this paper we present the SELIS Big Data Analytics and Machine Learning System (BDA), an open-source cloud-enabled elastic system that has been designed and implemented in order to address data related issues from the logistics domain. By taking into consideration real-life data analytics needs from more than 40 EU logistics providers we present the detailed SELIS BDA architecture along with the generic data and execution model devised to accommodate their diverse needs. We describe the main technologies we have utilized to realize the respective offering and justify our choices from the wider open-source Big Data systems community. We experimentally test our offering under various workloads where we prove that it can scale to serve a large number of concurrent requests while its abstraction/orchestration poses a very small overhead compared to the stand-alone Big Data systems. We believe that the SELIS BDA can be an easy-to-use entry point for the big data analytics world for any logistics company especially from the SME domain."
9410061,Information Fusion and Intelligent Management of Industrial Internet of Things under the Background of Big Data,"This paper summarizes the types and contents of enterprise big data information, analyzes the demand and characteristics of enterprise shared data information based on the Internet of things, and analyzes the current situation of enterprise big data fusion at home and abroad. Firstly, using the idea of the Internet of things for reference, the intelligent sensor is used as the key component of data acquisition, and the multi energy data acquisition technology is discussed. Then the data information of entity enterprises is taken as the research object and a low energy consumption transmission method based on data fusion mechanism for industrial ubiquitous Internet of things is proposed. Finally, a network monitoring and data fusion platform for the industrial Internet of things is implemented. The monitoring node networking and platform usability test are also performed. It is proved that the scheme can achieve multi parameter, real-time, high reliable network intelligent management."
8920802,Construction of Big Data Hyperchaotic Mixed Encryption Model for Mobile Network Privacy,"Big data of mobile network privacy is vulnerable to clear text attack in the process of storage and mixed network information sharing, which leads to information leakage. Through the mixed encryption of data of mobile network privacy big data to improve the confidentiality and security of mobile network privacy big data, a mobile network privacy big data hybrid encryption algorithm based on hyperchaos theory is proposed. The hybrid encryption key of mobile network privacy big data is constructed by using hyperchaotic nonlinear mapping hybrid encryption technology. Combined with the feature distribution of mobile network privacy big data, the mixed encrypted public key is designed by using Logistic hyperchaotic arrangement method, and a hyperchaotic analytic cipher and block cipher are constructed by using Rossle chaotic mapping. The random piecewise linear combination method is used to design the coding and key of mobile network privacy big data. According to the two-dimensional coding characteristics of mobile network privacy big data in the key authorization protocol, the hybrid encryption and decryption key of mobile network privacy big data is designed, and the mixed encryption and decryption key of mobile network privacy big data is constructed, Realize the privacy of mobile network big data mixed encryption output and key design. The simulation results show that this method has good confidentiality and strong steganography performance, which improves the anti-attack ability of big data, which is used to encrypt the privacy of mobile network."
9262724,"The Trend, Hotspots, Frontier and Path of Big Data Visualization Research in China——Based on the Knowledge Graph Analysis of Citespace5.5.R2","In 2016, China has adopted big data visualization technology as its national development strategy, however relevant literature review research is deficient at present. In view of this, this study uses Citespace5.5.R2 to elaborately analyze 2875 documents in CNKI database from 1994 to 2020 by adopting the methods of keyword co-occurrence analysis, document co-citation analysis and high-cited document analysis, which reasonably draw a conclusion on the research trend, research hotspots distribution, research frontier and research path of big data visualization research field in China. In general, research on big data visualization in China keeps a steady growing trend; Research hotspots are divided into four major themes: journalism is the main application industry, big data visualization technology and platform research, the representation of big data visualization and big data visualization algorithm research. From the perspective of research frontier, research based on Knowledge Graph has become the latest research method and Echart has become the latest technology implementation method in this field. In view of the research path, Chinese big data visualization research has gone through three stages: 1994-2003 is in the embryonic stage, 2004-2011 is in the stage of stable development and 2012- 2020 is in the rapid development stage."
8862739,Empirical Investigation of Big Data Analytical Tools: Comparative Analysis,"In this paper, we carry out an empirical investigation of the Big Data Analytical tools, Google BigQuery, Datameer Big Data Analytics, Alteryx Designer and Pentaho Big Data Analytics. Further, this paper provides for a comparative analysis among the most popular Big Data Analytical tools. The results of the undertaken industrial survey reveal higher adoption of Pentaho Big Data Analytics in present-day software industry as compared to other Big Data Analytical tools."
9162295,A Big Data Platform For Spatio-Temporal Social Event Discovery,"The tremendous rise of location-enriched microblogging has made it possible to discover social events from social media, as well as their evolution over space and time. Over the last decade, multiple studies on event detection from social media have been proposed, with the aim of extracting specific types of events, such as, social gatherings, natural disasters, and emergency situations, among others. However, existing works do not consider the incremental and continuous processing of events over the large amounts of social streams, and therefore, cannot determine the spatial and temporal evolution of such events. This work presents a big data mining platform for the incremental discovery of geo-social events based on a scalable and efficient architecture that can manage and mine a huge data flow of unstructured streams. We demonstrate our early results over twitter datasets and discuss its main advantage by incorporating advanced features for event extraction, thus allowing for great opportunities from application perspectives."
9006521,The Internet of Responsibilities - Connecting Human Responsibilities using Big Data and Blockchain,"Accountability in the workplace is critically important and remains a challenging problem, especially with respect to workplace safety management. In this paper, we introduce a novel notion, the Internet of Responsibilities, for accountability management. Our method sorts through the list of responsibilities with respect to hazardous positions. The positions are interconnected using directed acyclic graphs (DAGs) indicating the hierarchy of responsibilities in the organization. In addition, the system detects and collects responsibilities, and represents risk areas in terms of the positions of the responsibility nodes. Finally, an automatic reminder and assignment system is used to enforce a strict responsibility control without human intervention. Using blockchain technology, we further extend our system with the capability to store, recover and encrypt responsibility data. We show that through the application of the Internet of Responsibility network model driven by Big Data, enterprise and government agencies can attain a highly secured and safe workplace. Therefore, our model offers a combination of interconnected responsibilities, accountability, monitoring, and safety which is crucial for the protection of employees and the success of organizations."
9373613,A Discretization Method for Industrial Data Based on Big Data Technology,"A parallel improvement of the traditional K-Means clustering algorithm is achieved based on the Mapreduce architecture, and the new parallelized clustering algorithm is used to realize the discretization of industrial big data in this paper. The new algorithm streamlines the calculation process, meanwhile, saves the computational overhead caused by data analysis and communication consumption caused by information transfer."
9202379,Selection of Optimal Packaging Methods for Different Food Based on Big Data Analysis,"In order to improve the ability of food packaging optimization and selection, combined with big data analysis method, different food best packaging methods are selected, and a large data classification technology for different food packaging methods based on fuzzy directivity classification is proposed. Big data parametric model which reflects the best packaging characteristics of different foods is extracted, and the extracted packaging parameters are matched by adaptive fuzzy matching. Then, the directional clustering method is used to classify and identify big data, which is combined with the food packaging. The shelf life and food characteristics are processed by big data information fusion to realize the best match between food packaging and food characteristics. The retrieval node graph model grouping method is used to classify different food packaging data to optimize the selection of different food packaging methods. The simulation results show that, the method used to select the best packaging methods for different foods has better intelligence, improving the ability of classification and recognition of food packaging, and promoting the intelligent development of food packaging."
9610223,Design and Realization of College Student Management System Based on Information Technology under Big Data Technology,"With the popularization of education informatization, colleges and universities generally have information management systems, which can manage school information, teacher information, student information, and performance information, and are equipped with special databases or data clusters to store this information. How to effectively use these data to extract and mine valuable information from these data, so as to provide schools and teachers with auxiliary decision-making, and truly improve the level and quality of school running has become an issue worthy of attention. The purpose of this paper is to design and implement the university management system based on big data technology. This paper firstly summarizes the basic theory of big data and derives the core technology of big data data mining and other core technologies, combined with the current university student management system in our country. The status quo, analysis of its problems and shortcomings, on this basis, combined with big data technology to design and analyze the college student management system. This article systematically expounds the design and use of the database, function modules and related technologies of the management system. And conduct research through research methods such as comparison and field investigation. Experimental research shows that compared with the traditional college student management system, the college student management system based on big data technology is more practical and more powerful."
9442544,Research and Application of Big Earth Data Distribution and Sharing System,"In recent years, the rapid development of earth observation system and intelligent computing technology provides a rare opportunity for the progress and even change of remote sensing technology. Remote sensing information technology is gradually entering a big earth data era characterized by data model driven and big data analysis. However, in the construction of earth observation system, the “island phenomenon” is ubiquitous. Thus, to develop the data distribution and sharing system for big earth data is among the most advanced international application areas. Firstly, from the view of big earth data, this paper discusses the construction of improved data distribution and sharing system and corresponding system workflow. Then the system key technologies are introduced. Consequently, the application system is shown and discussed."
9006058,Bagging Using Instance-Level Difficulty for Multi-Class Imbalanced Big Data Classification on Spark,"Most machine learning methods work under the assumption that classes have a roughly balanced number of instances. However, in many real-life problems we may have some types of instances appearing predominantly more frequently than the others which causes a bias towards the majority class during classifier training. This becomes even more challenging when dealing with multiple classes, where relationships between them are not easily defined. Learning from multi-class imbalanced data has not been widely considered in the context of big data mining, despite the fact that this is a learning difficulty frequently appearing in this domain. In this paper, we address this challenge by proposing a comprehensive ensemble-based framework. We propose to analyze each class to extract instance-level characteristics describing their difficulty levels. We embed this information into the existing UnderBagging framework. Our ensemble samples instances with probabilities proportional to their difficulty levels. This allows us to focus the learning process on the most difficult instances, better capturing the properties of multi-class imbalanced problems. We implemented our framework on Apache Spark to allow for high-performance computing over big data sets. This experimental study shows that taking into account the instance-level difficulty leads to training of significantly more accurate ensembles."
9344686,Research on the Impact of Big Data Capabilities on Government’s Smart Service Performance: Empirical Evidence From China,"The government of China seeks to improve e-government service quality and build a service-oriented government that citizens find satisfactory. To this end, big data is being used as a new tool of government service innovation. However, there is a lack of research on how big data affects the performance of government smart services. This article explores the influence mechanisms of government big data capabilities on the performance of smart service provision, utilizing the carding analysis of relevant literature, published both in China and abroad. To this end, a structural equation model was constructed. Using data from 289 valid questionnaires in Jiangsu, Shandong, Zhejiang, and other provinces and cities in China, the study tests internal mechanisms of big data capabilities and its effect on smart service performance. Following a new definition of government big data capability, the paper divides the capability into three dimensions: big data system capability, big data human capability and big data management capability. The main conclusions are as follows: (1) Big data management capability has a significant positive impact on big data human capability and big data system capability. (2) Big data system capability has a significant positive impact on big data human capability. (3) Big data system capability and big data management capability have a significant positive effect on smart service performance. (4) The impact of big data human capability on smart service performance is not however significant enough to bring about the improvements which the government seeks."
9005714,Data Services with Bindaas: RESTful Interfaces for Diverse Data Sources,"The diversity of data management systems affords developers the luxury of building heterogeneous architectures to address the unique needs of big data. It allows one to mix-nmatch systems that can store, query, update, and process data based on specific use cases. However, this heterogeneity brings with it the burden of developing custom interfaces for each data management system. Existing big data frameworks fall short in mitigating these challenges imposed. In this paper, we present Bindaas, a secure and extensible big data middleware that offers uniform access to diverse data sources. By providing a RESTful web service interface to the data sources, Bindaas exposes query, update, store, and delete functionality of the data sources as data service APIs, while providing turn-key support for standard operations involving access control and audit-trails. The research community has deployed Bindaas in various production environments in healthcare. Our evaluations highlight the efficiency of Bindaas in serving concurrent requests to data source instances with minimal overheads."
9534596,Big Data Analysis Capability Demand Analysis and Training Measures for Smart Supply Chain Management Talents,"According to the data-based smart supply chain analysis methods and the application of various analytical methods in smart supply chain applications, this paper summarizes the big data analysis capability system for smart supply chain management talents, which includes problem identification, data feasibility demonstration, data visualization, model construction and result evaluation. In addition, the capability indexes are refined. At last the training measures of big data analysis ability of talents based on the cooperation of universities and enterprises are put forward, which provide reference for the training of applied undergraduate talents."
9533072,The development and research of Chinese Artistic Swimming under the background of big data--compared with the world's top three teams,"With the advent of the 5G era, the data information age has gradually entered people's work and life, the rapid development of our lives has changed dramatically. The big data that comes with it not only brings convenience to people's life, but also brings important opportunities for the development of sports industry. Using big data analysis to understand the development of Artistic swimming in China. At the same time, through data comparison, to understand the development of the world's top three countries. Using data mining and analysis technology, it is designed for the free routines difficulty of the artistic swimming group in china, analysis the design trends for the project's difficulty to provide a strong reference basis for Chinese artistic swimming team in the future."
8776764,Enhancing Big Data Security using Elliptic Curve Cryptography,"Withgrowing times and technology, and the data related to it is increasing on daily basis and so is the daunting task to manage it. The present solution to this problem i.e our present databases, are not the long-term solutions. These data volumes need to be stored safely and retrieved safely to use. This paper presents an overview of security issues for big data. Big Data encompasses data configuration, distribution and analysis of the data that overcome the drawbacks of traditional data processing technology. Big data manages, stores and acquires data in a speedy and cost-effective manner with the help of tools, technologies and frameworks."
9457476,Research on Educational Reform of Administrative Law Based on Big Data,"The administrative law curriculum occupies an important position in the legal education system of China, but due to its separate theoretical system and complicated knowledge construction, it is difficult for administrative law teaching to take on the important task of cultivating research and applied talents. With the advent of the big data era, not only the research field of administrative law teaching has been opened up, but also the teaching content and teaching methods of administrative law have been enriched. It should start with three aspects: optimizing teaching content, increasing the application of case teaching, innovating teaching methods, establishing a network interactive teaching model, improving teaching methods, and advancing the situational teaching model, and vigorously increase students' enthusiasm for learning administrative law, and then master the essence and essence of administrative law."
9095678,Design and Research of Analog Data Pool of Intelligent Manufacturing Oriented to Impeller,"Impeller data is investigated and understood including the data information content, data type and characteristics in the process of intelligent manufacturing of enterprises. The data information of the whole life cycle of impeller is the research object. The characteristics and functions of data pool are analyzed based on the analysis of data Lake structure. It is analyzed and designed of the big data analog data pool of intelligent manufacturing for impeller. And the framework of the data pool is constructed for impeller. It is achieved of the design requirements of big data analog data pool processing system by Hadoop, Java, MapReduce and other components. They are processed for data merging, data sorting, data extraction and other functions. A lot of data is analyzed and extracted more clearly in the process of impeller intelligent manufacturing, which achieve the purpose of data processing. The establishment of analog data pool not only plays an important role in the research of data storage and processing, but also plays an important role in improving the efficiency of intelligent manufacturing industry."
9671277,Bench-Ranking: A First Step Towards Prescriptive Performance Analyses For Big Data Frameworks,"Leveraging Big Data (BD) processing frameworks to process large-scale Resource Description Framework (RDF) datasets holds a great interest in optimizing query performance. Modern BD services are complicated data systems, where tuning the configurations notably affects the performance. Benchmarking different frameworks and configurations provides the community with best practices towards selecting the most suitable configurations. However, most of these benchmarking efforts are classified as descriptive or diagnostic analytics. Moreover, there is no standardization for comparing and contrasting these benchmarks based on quantitative ranking techniques. This paper aims to fill this timely research gap by proposing ranking criteria (called Bench-ranking) that provide prescriptive analytics via ranking functions. In particular, Bench-ranking starts by describing the current state-of-the-art single-dimensional ranking limitations. Next, we discuss the recent benchmarking requirements for sophisticated approaches over multi-dimensional ranking. Finally, we discuss the ranking criteria goodness by reviewing its conformance and coherence metrics. We validate Bench-ranking by conducting an empirical study using large RDF datasets under a relational BD engine, i.e., Apache Spark-SQL. The proposed ranking techniques provide the practitioners with clear insights to make an informed decision, especially with experimental trade-offs for such complex solution space."
8645577,Evolvement of Big Data Challenges in Computational Intelligence and Soft computing,"This research Paper will go through a deep dive discussion and explanation evolvement of Big Data Challenges, there are many complexities involved in Big data mainly format and unstructured nature. These have to be organised and extracted using computational intelligence and soft computing. Various theories and tools are used to to extract meaningful data from the big data. Still there many more challenges like volume, velocity and veracity. The modern world using the smart devices and millions of bytes of data generated every millsecond. This paper discusses the evelovement of big data in the insurance sector as case."
9179553,Predicting the Performance of Tunnel Boring Machines using Big Operational Data,"Accurate prediction of the performance of tunnel boring machines (TBMs) is important to safe and efficient tunneling. Traditional prediction method of TBM performance is restricted by the lack of sufficient rock mass data and the prediction accuracy is low. A comprehensive management and preprocessing framework of TBM big operational data is proposed in this paper, after which a new prediction method of TBM performance is proposed. The effectiveness of the proposed method is tested on 4 different tunnels. Prediction results show that the big operational data based method can predict TBM performance with high accuracy, and in most cases, the random forest algorithm generates better prediction results than the long-short term memory (LSTM) neural network. The data imbalance phenomenon leads to the emergence of big prediction errors on certain operational segments, highlighting the necessity of adopting new sampling methods to create a more balanced dataset, and incremental learning methods to update the prediction model timely."
9358758,Visualized Analysis of Tourism Big Data based on Real-Time Analysis and Complexity Measurement,"Visualized analysis of tourism big data based on real-time analysis and complexity measurement is studied in this paper. The development trend of the information visualization technology has to be closely integrated with analytical science, from the structure-centric visualization to the dynamic attribute visualization of potential phenomena and from “task-centric” to “user-centric”. This paper proposes two major novelties. (1) Through a detailed analysis of the existing organizational conditions and collaborative processes, it focuses on analyzing the scope of the system, where the data is pre-processed based on the core complexity estimation. (2) The proposed research work use the initiative of the agent to hand over the tasks of data extraction, data processing, data query and so on in the data warehouse system to the corresponding agent. The results have proven the effectiveness."
9002837,A Spark Based Big Data Analytics Framework for Competitive Intelligence,"In the era of Big Data, an ever-growing stream of information is available online in different formats structured, semi-structured and unstructured, more and more companies and organizations are trying to take advantage of this phenomena and make data-based decisions through the use of automatic processes and software which gave birth to competitive intelligence systems. Though traditional techniques of data mining and statistics used in these systems do not respond to the main challenges of big data such as volume, variety, and velocity, which makes it a must for enterprises to harness the power of new technologies in big data analytics and create value out of its advantages. In this paper, we propose a framework based on Apache Spark for competitive intelligence strategy implementation in all its steps from data collection, data analysis, data visualization to results and findings communication in order to assist the decision-making process of an organization."
8938936,Research on the Construction of Big Data Platform for College Education,"With the accumulation of data on mass education resources in colleges and universities, building a complete educational big data analysis platform will have a positive impact on the school's education management model. In this paper, Yunnan Normal University is an example. Based on the analysis of the functional requirements of the educational big data platform, a complete big data analysis platform architecture scheme is proposed, which can provide reference for the planning and construction of the university education big data platform."
9005479,Application of big data analytics to support power networks and their transition towards smart grids,"Power systems are becoming more complex, which increases instability issues and outage risks. The development of smart grids could help manage such complex systems. One important pillar in smart grids is big data analytics. In this poster paper, we discuss where and how machine learning could contribute to more efficient asset management. We also identify challenges that stand in the way of the widespread use of big data analytics in smart grids. While the nature of data, as well as data and asset management systems themselves make the use of big data challenging, data analytics could improve the reliability of power supply by providing the functions of detection, prediction, and selection."
8681030,Big Data-Based Improved Data Acquisition and Storage System for Designing Industrial Data Platform,"Big data-based acquisition and storage system (ASS) plays an important role in the design of industrial data platform. Many big data frameworks have been integrated compression and serialization method. These methods cannot meet the needs of industrial production information management for requiring time-consuming and mass storage. Based on the existing big data frameworks, we propose an enhanced industrial big data platform in order to reduce the data processing time while requiring fewer data storage space. Specifically, this paper focuses on evaluating the impact of multiple compression and serialization methods on big data platform performance and tries to choose optimal compression and serialization methods for the industrial data platform. Compared to the methods integrated in Hadoop and Spark, the experimental results showed the data compression time of the platform has been reduced by 73.9% with a less than 96% the size of data compressed, furthermore, the data serialization time has been reduced by 80.8%. With the increasing amount of data, it takes less time to compare with benchmark methods."
9546382,Research on the Application of Big Data in Smart Food Safety,"Food safety is not only related to the vital interests of the public, but also related to the long-term stability of the country. First, the source and characteristics of big data in the food industry are combed, in this paper. Then, the pretreatment process of big data for smart food safety is described, and its parallel computing model is introduced. At last, the application contexts of smart food safety are provided."
9378158,Uncovering Performance Interference of Multi-Tenants in Big Data Environments,"In big data environments, measuring performance interference while sharing resources is complex and not well covered by current benchmarks and tools. Different applications can compete for the same resources (e.g., persistent storage) until they become overloaded without notice either by the benchmark or the big data system. We unveil the case when RocksDB (a big data management system) shares disk flashes among multiple tenants and how YCSB and db_bench (two state-of-the-art big data benchmarks) fail to catch performance interference. In this paper, we define a methodology to measure the problem of performance interference over time and show how RocksDB quickly degrades throughput until it turns almost inoperative while sharing the persistent storage with other tenants."
9626300,Research on Curriculum Construction of Big Data and Accounting under the Background of Big Data,"In the era of big data and artificial intelligence, society has put forward new requirements for the quality structure, ability structure, knowledge structure, skill structure and learning ability of accounting talents. In response to the new needs of the society for the skills, structure and learning ability of accounting professionals in the big data era, this article analyzes the reconstruction of the accounting professional curriculum system from the perspective of big data technology and management accounting, and analyzes the accounting professional curriculum system in the big data era Based on the core courses of engineering and management, it puts forward suggestions and countermeasures for the cross-border integration of big data and accounting curriculum system, hoping to help the accounting professional teaching in colleges and universities to achieve better development."
8862773,The Different Tools and Technique to Handle Challenges in Big Data,"The big data are data in large size and which cannot be maintained in terms of bytes. Know a day's big data is so popular that almost every business is depends on data. The data can arise in various forms such as structured, unstructured and semi structured. The different sources of big data generations are through social media such as face book, Google forums, and search engines. These data will be used by different enterprises to make their decision making. Hence big data analysis is a big challenge because data is time variant. This paper presents different techniques used to process big data and various challenges faced by analysts while making decision making. This paper also gives description of various frameworks available to process a big data. The scope of this paper is to find best possible technique to process big data."
9201913,"Advanced, Privacy-Preserving and Approximate Big Data Management and Analytics in Distributed Environments: What is Now and What is Next","Nowadays, big data management and analytics are gaining momentum within the research community, stirred-up by both sophisticated theoretical models and pragmatic achievements mainly appearing in the target Cloud-based applications and systems. In this so-delineated context, three top-class topics have emerged in the literature: (i) advanced big data management and analytics in distributed environments; (ii) privacy-preserving big data management and analytics in distributed environments; (iii) approximate big-data-management-and-analytics techniques and algorithms over uncertain and imprecise big data repositories in distributed environments. These critical topics are now heavily influencing the research community, and will play more and more a first-class role in actual and future research experiences. Following this clear evidence, in this paper we provide the current state-of-the-art on the reference topics, along with considerations for driving future research efforts in the field."
8851053,Probabilistic Programming and Big Data,"The advent of the Internet in the late 1990s led to the increased flood of data termed Big Data. To derive meaningful value from big data, specialized tools and techniques are required. These tools and techniques are categorized under data management and data analysis. Under data analysis, predictive tools and techniques exists. These predictive tools and techniques use statistical models and machine learning algorithms to predict future events. Models are developed using probability theories such as Bayesian networks. However, development of probabilistic models require extreme technical expertise and it is a difficult task to model complex real-life situations. Thus, the emergence of probabilistic programming. The idea of probabilistic programming is new and its potential in AI and big data processing is important. This paper presents discussions on probabilistic reasoning and probabilistic programming with respect to big data. An investigation of the potential of probabilistic programming in big data is also presented by conducting a search through literature to find available big data solutions that use probabilistic programming. This search found one solution called InferSpark built on top of Apache Spark to process big data. This is an indication that more big data applications that uses the concept of probabilistic programming needs to be done."
9358722,Computer Data Processing Mode in the era of Big Data: from Feature Analysis to Comprehensive Mining,"Computer data processing mode in the era of big data from feature analysis to comprehensive mining is discussed in this paper. The integrated detection framework divides the structure of the system operation mode when a large amount of data intrusion attacks the computer in the network environment, and each functional structure is then directly connected to a corresponding system component module. The primary novelty of the paper is through the core effective use of the dynamic reconfigurable features of FPGA, the matching characteristics and matching speed of regular expressions are improved. The feature extraction algorithm is optimized and enhanced for the complexity testing. The experiment results shows that the rate of accuracy has been improved."
9152919,"Paper Review On Data Mining, components, And Big Data","Recent progress in software and hardware has allowed different data measurements in a variety of fields to be captured. These measures are produced continuously at very fluctuating data rates. For example, network sensors, web logs and computer network traffic. Computer-intensive activities are the collection, query and removal of these data sets. Mining data sources include the recovery of knowledge systems incorporated into templates and trends on streams of non-stop information. Because of the importance of its applications and the increasing generation of data stream research, information. Information. Information. Analysis applications for data streams can range from critical scientific and astronomical applications to major business and financial applications. Algorithms, processes and structures Streaming challenges have been developed over the last three years. We present the newest in this increasingly important field in this review paper."
8787479,"Big Data Against Childhood Obesity, the BigO Project","BigO (bigoprogram.eu) is an EU-funded project that collects objective evidence on the causes of obesity in local communities and helps public health authorities design effective counter obesity interventions. A novel technological platform is being built relying on mobile devices and sensors for data acquisition combined with big data analytics and visualization. During the 4 year project duration the BigO platform will be used by 9000 school and age-matched obese children and adolescents as sources for community data. Led by Aristotle University of Thessaloniki, the project brings together schools, health and clinical scientists, technology providers, personal health solutions businesses and mobile communication providers in Greece, Sweden, Ireland, Spain and the Netherlands."
9453048,Network information inheritance of traditional and migrant craftsmanship based on the background of big data,"Network information inheritance of traditional and migrant craftsmanship based on the background of big data is studied. The data structure has not yet achieved uniformity in scope, and it is still difficult to achieve data integration on one platform; in addition, the increasing business volume makes the development direction of data present a trend of fragmentation, and the user's business model Is also gradually changing. To face with this challenge, this paper studies the novel data structure for the efficient analysis. We apply the model on the scenario of the traditional and migrant craftsmanship, the test results reflect that the model is efficient."
8920732,Big Data Security and Privacy Protection,"In view of the wide application and popularization of large data, more and more data security and privacy issues have brought great challenges to the development of large data. Starting from the characteristics of big data, this paper analyses various risks of information security, and puts forward the corresponding development strategy of big data security. The results show that the combination of technology and relevant policies and regulations can better solve the problem of big data security and privacy protection."
8963377,The Social Mentality of Netizens in the Guangdong-Hong Kong-Macao Greater Bay Area: Big Data Monitoring of Social Media,"In 2019, the development plan for the Guangdong-Hong Kong-Macao Greater Bay Area (GBA) was officially announced. This will be a useful boost to cooperation among Hong Kong, Macao, and the Pan-Pearl River Delta, and requires positive social mentality as a driving force. Analyzing the netizens' expression on social media has become the most important method to comprehend social mentality. Therefore, this study explores the social mentality of GBA netizens through social cognition, social perception, and social development efficiency. Specifically, this study utilizes big data methods to analyze how netizens in the GBA describe their social mentality."
8890526,Data Mining and Machine Learning Applications for Educational Big Data in the University,In this paper data mining and machine learning applications for educational big data in the university are examined. We proposed prediction models in learning analytics using the student teaching data and show the effectiveness of machine learning methods. Some examples of practical applications will be shown to verify practical effectiveness.
9621151,Introduction to Building and Service of the Fire Safety Big Data Platform in Korea,"In the past 10 years, about 40,000 fires have occurred annually in Korea, and human and material damages due to these fires are increasing. In order to reduce these damages due to fire, it is necessary to collect and analyze data on the causes of fire. The Korea Fire Agency is currently carrying out the national project to build a fire safety big data platform and centers from 2020 with the support of the Ministry of Science and ICT. This paper introduces the fire safety big data platform and centers that supply big data to provide various analysis and services of disaster-related data. Users can obtain predictions and advanced information on fire and disaster situations by using the data and analysis services provided by the platform."
9459049,Technical Architecture of Big Data Cloud Platform for Intelligent Washing Factory,"In response to the needs of intelligent washing, a set of intelligent washing factory technical architecture based on cloud computing services is proposed based on the comprehensive application of technologies including the Internet of Things(IOT), mobile internet, big data, and cloud computing. Through the construction of a big data cloud platform for intelligent washing factory management, functions such as intelligent polyester production management and washing big data applications have been realized. This technical architecture integrates the three-tier structure of cloud computing IaaS, PaaS, and SaaS, and the technical route of each layer is described in the article."
9264179,An Iterative Methodology for Defining Big Data Analytics Architectures,"Thanks to the advances achieved in the last decade, the lack of adequate technologies to deal with Big Data characteristics such as Data Volume is no longer an issue. Instead, recent studies highlight that one of the main Big Data issues is the lack of expertise to select adequate technologies and build the correct Big Data architecture for the problem at hand. In order to tackle this problem, we present our methodology for the generation of Big Data pipelines based on several requirements derived from Big Data features that are critical for the selection of the most appropriate tools and techniques. Thus, thanks to our approach we reduce the required know-how to select and build Big Data architectures by providing a step-by-step methodology that leads Big Data architects into creating their Big Data Pipelines for the case at hand. Our methodology has been tested in two use cases."
9237484,Research on Coordinated Processing Scheme of Intelligent Transportation under Big Data Structure,"Intelligent traffic management system is the general trend of traffic system development. It integrates various advanced technologies such as information technology, wireless communication technology, computer technology and sensor technology to form a comprehensive and efficient traffic management system. Data is the core of intelligent transportation, and in-depth processing and analysis of traffic data is the key. Through data analysis and mining of big data of intelligent transportation, the aim of optimizing the organization of intelligent transportation can be realized, and the scientific decision-making and intelligent travel can be realized. The essence of intelligent transportation system (ITS) is to comprehensively solve the transportation problems by using modern high and new technology. The purpose is to establish a comprehensive transportation system that can play a role in a wide range, all-round, real-time, accurate, efficient, safe, convenient and comfortable way. This paper systematically discusses the theory, method and technology involved in the construction of its platform and framework based on big data."
9457335,Research on the path of precise guidance system for student development in universities based on big data analysis,"With the rapid development of information technology, big data has brought new development opportunities for the accurate construction of development guidance system for students in colleges and universities. Big data analysis is the use of all data for analysis and processing, with the characteristics of quantification, diversification, rapidness and value. Through the analysis and processing of school data such as the student's educational administration system and daily activities, and the analysis of the needs of students in questionnaires, a full grasp of student performance, a comprehensive understanding of habits and performance needs can be achieved. Accurately locate student needs, accurately customize guidance resources, accurately analyze student conditions, accurately push resource information, and create a self-motivating environment for students from four precise aspects, so as to enhance students' internal motivation and promote students' all-round development, and running the concept of precise ideological and political through the whole process of student development guidance."
9422064,A New Method for information security risk management in big data environment,"In recent years, the social security problems are becoming more and more complex, and the public security work is arduous. The traditional governance mode needs more transformation and bigger upgrading. At present, the police information processing work lacks of effective information data support. By using advanced technologies such as big data and artificial intelligence, the police information big data application platform is constructed to more effectively gather information related to the police situation, dig deeply into the police information data resources, and expand the application according to police information business. In order to achieve a more comprehensive source of police information, more efficient business processing, and more positive service to the grassroots, we need accurate prediction and decision support. So as to promote the transformation of public security policing mode from extensive manpower type to intelligent fine type, this paper propose a new method based private matching protocol for information security risk management in big data environment, and provide security analysis at the last."
9006358,Provenance–aware workflow for data quality management and improvement for large continuous scientific data streams,"Data quality assessment, management and improvement is an integral part of any big data intensive scientific research to ensure accurate, reliable, and reproducible scientific discoveries. The task of maintaining the quality of data, however, is non-trivial and poses a challenge for a program like the Department of Energy's Atmospheric Radiation Measurement (ARM) that collects data from hundreds of instruments across the world, and distributes thousands of streaming data products that are continuously produced in near-real-time for an archive 1.7 Petabyte in size and growing. In this paper, we present a computational data processing workflow to address the data quality issues via an easy and intuitive web-based portal that allows reporting of any quality issues for any site, facility or instruments at a granularity down to individual variables in the data files. This portal allows instrument specialists and scientists to provide corrective actions in the form of symbolic equations. A parallel processing framework applies the data improvement to a large volume of data in an efficient, parallel environment, while optimizing data transfer and file I/O operations; corrected files are then systematically versioned and archived. A provenance tracking module tracks and records any change made to the data during its entire life cycle which are communicated transparently to the scientific users. Developed in Python using open source technologies, this software architecture enables fast and efficient management and improvement of data in an operational data center environment."
9668793,Research on Intelligent Acceleration Algorithm for Big Data Mining in Communication Network Based on Support Vector Machine,"As a budding technology, big data’s technical implementation and commercial application are in the exploratory stage. With the increasing development of network and communication technology, a large amount of information is pouring in. How to effectively select the required information has become a more and more prominent problem. Data mining is a data processing technology developed to meet this need. Support vector machine is a new technology in data mining. It is a new tool to solve machine learning problems with the help of optimization methods. Among them, it focuses on the support vector machine, including the development history and present situation of support vector machine, the main basic concepts and research contents. On this basis, it studies various training algorithms of support vector machine which are relatively common at present, and compares their advantages and disadvantages. Big data has various data types, forming a data stream with various attributes. As we all know, data source classification based on batch processing can improve the query speed, but it still can’t meet the demand of real-time query. Therefore, feature selection mechanism is usually introduced in the process of data mining modeling to reduce its load. However, when faced with the query of high-dimensional data, the query space grows exponentially, which is difficult to realize. Therefore, this paper proposes the efficiency of an intelligent acceleration algorithm for big data mining based on vector machine communication network."
8875358,Robustness of Basal Heart Rate against Declining Physical Activity Analysis of Physiological Big Data,"To examine the influences of reduced physical activity on the circadian architecture of heart rate, we performed big data analysis on the effect of relative time spent in the lying position on the timing and level of basal heart rate (BHR, 24-h minimum heart rate). In the big data of simultaneously recorded 24-h electrocardiogram and triaxial acceleration in 12,530 men and 17,529 women, BHR was found to occur at the median [IQR] of 04:07 [01:35- 05:35] in men and 03:50 [01:35-05:53] in women. The clock time when BHR occurred was slightly accelerated by advancing age (-11 and -8 min per 10-y increment of age for men and women) and was slightly delayed by increasing lying time (only +6 and +9 min per 10% increment of lying ratio in the day). This study indicates that BHR is a robust biological property that is not easily lost by declining physical activity."
9498860,Application of Big Data Technology in Financial Management Teaching,"The application of big data in financial management is a compulsory professional development course for finance and economics related majors, which is highly theoretical, practical and technical, and belongs to interdisciplinary integration course. The course focuses on the whole process of big data processing such as data collection, processing, analysis and mining, and visualization. Relying on the professional skills training system of big data financial analysis, the course focuses on cultivating students' big data thinking and mastering the comprehensive application of big data technology in the field of financial analysis."
9075686,Application and Research of Computer Big Data in Internet Learning and Information Processing,"With the continuous progress and development of information technology, a large number of data need to be stored and processed. With the arrival of the era of big data, people's demand for data information is not only limited to simple acquisition, but also tends to gradually accumulate data and actively seek analysis. However, when the amount of data is too large, large data related information storage and processing technology will be widely studied and applied. How to help people acquire data better and faster and analyze data reasonably and efficiently is a problem that needs to be faced in the era of big data. In this paper, three basic models of data structure are analyzed and a new sequential data structure - curve data structure is proposed based on these three data models. At the same time, this paper will focus on the task-level separated data visualization structure model and realize the efficiency of large data information search based on it. Finally, based on the large data of climate and human activities, the structure proposed in this paper will be validated and analyzed from a hierarchical level."
8725728,Full Consideration of Big Data Characteristics in Sentiment Analysis Context,"We live in a digital world where every interaction with Internet generates digital traces that reveal a lot of details about our thinking. The volume of these daily-generated traces increases exponentially creating massive loads of information, which represents a big part of a new world called Big Data. This big data is used by different type of projects to extract valuable information either to take marketing decisions, track specific behaviors or detect threat attacks. Sentiment analysis (SA) is one of the most active research areas relying on big data, even if their involvement would be of great added value. However, most of its applications, like other big data projects, consider only the volume, sometimes also the veracity, and completely ignore the rest of big data characteristics (Variety, Velocity, Value, Variability, and Visualization). In this paper, we focus on projecting big data characteristics in a sentiment context to get out the most of big data. Our main contribution consists of presenting and analyzing the most known sentiment analysis approaches and contributions that rely on big data by showing their main characteristics. Furthermore, we explain how SA applications should consider big data characteristics to be fully aligned with big data contexts."
9591940,Research on Blockchain Privacy Protection of Enterprise Internal Control Evaluation in the Big Data Era,"Privacy protection and information security are two key issues facing the advanced big data era in the future, especially for the internal control evaluation system of enterprises with rich core data exchange, and blockchain technology provides a variety of privacy protection algorithms. This paper mainly studies the privacy protection of internal control evaluation of enterprises based on blockchain technology and big data, and provides an effective system and platform framework for enterprise managers to carry out internal control work."
9070434,Interactive Analytics of Massive Spatial Vector Data via Display-Driven Computing,"In the big data era, real-time analysis of large-scale spatial data remains a challenging problem since the computational scales of conventional data-driven methods expand rapidly with data volumes. This paper presents display-driven computing (DisDC), a new computing model for interactive analysis of large-scale spatial vector data. The computing units in DisDC are screen pixels for display rather than spatial objects in traditional data-driven methods, and the core task of DisDC is to judge the spatial relationships between pixels and spatial objects. As the number of pixels for display is stable, DisDC is less sensitive to data volumes and can be used to provide real-time data analysis of large-scale spatial vector data. Experiments show that DisDC is capable of handling billion-scale spatial vector data, and an online demonstration is provided (https://github.com/MemoryMmy/DisDC)."
9403819,The Research Process and Prospect of Chinese Bel Canto Theory in the 21st Century—Visual Big Data Analysis Based on CNKI Periodical Literature,"This paper analyzes bel canto theory research literature in China from 2000 to 2020 using big data, image data visualization analysis method, and drawing on the CNKI database. The keywords focused on co word analysis, clustering analysis, time zone map analysis and mutation analysis. By basing research on big data and employing visualization analysis, this paper analyzes the research's academic influence and objectively reflects the current state of the theoretical research on bel canto in China from a particular angle."
9309975,Monitoring and Control of Unstructured Manufacturing Big Data,"Unstructured manufacturing big data silos are challenging for enabling various data-driven applications such as digital threads and digital twins in manufacturing. The management of big data silos requires to address the issues of large volume, data inconsistency, data redundancy, information silos and data security. This research developed a systematic approach to managing data silos using the state of art big data software. Applying this approach in the product life cycle can control data silos, data consistency, redundancy, timely update and enable the automatic workflow of each system."
9574054,Big Data Fusion Challenge: Unmanned Aerial System Based Precision Agriculture,"The International Conference of Computational Intelligence 2021 organized multi Remote Sensing Data Competitions, and a Big Data Fusion Challenge using UAS based precision Agriculture is coordinated by North Carolina A&T State University and Mississippi State University. The Big Data Challenge focused on Multi-sensor and Multitemporal datasets including the hyper spectral imagery with 251 bands. A multi-class problem is given to classify three different crops and at three yield levels. The challenge received multiple submissions and the winning approach is based on inference learning using residual neural networks with 150 layers with a performance of Kappa accuracy as 0.86."
9671506,Communication efficient distributed learning of neural networks in Big Data environments using Spark,"Distributed (or federated) training of neural networks is an important approach to reduce the training time significantly. Previous experiments on communication efficient distributed learning have shown that model averaging, even if provably correct only in case of convex loss functions, is also working for the training of neural networks in some cases, however restricted to simple examples with relatively small standard data sets. In this paper, we investigate to what extent distributed communication efficient learning scales to huge data sets and complex, deep neural networks. We show how to integrate communication efficient distributed learning into the big data environment Spark and apply it to a complex real-world scenario, namely image segmentation on a large automotive data set (A2D2). We present evidence based results that the distributed approach scales successfully with increasing number of computing nodes in the case of fully convolutional networks."
9539353,A Scalable Data Processing Model for Big Data Analysis of Enterprise Technology Innovation,"In many areas such as enterprise technology innovation, the volume of data to be analyzed grows rapidly. In order to analyze and use these huge data resources, we must rely on effective data analysis technology. However, the traditional data processing technology has encountered certain obstacles in scalability. A Scalable Data Processing Model (SDPM) was proposed in this study to solve problems concerning innovative services of enterprises. The model performed formal analysis and description of SDPM, and through this model, it implemented the clustering analysis and incremental computing algorithm of enterprise technology innovation application data. Research results demonstrate the potential of the proposed model can effectively analyze enterprise technology innovation data, and have similar performance in incremental computing for different sizes of data sets. The query response time is less than 1 second on average. The research results of this study show that the SDPM can adapt to the service needs of enterprise technology innovation data and improve the efficiency of data processing. This proposed model provided technical and theoretical support for big data processing."
9197859,Role of Bloom Filter in Analysis of Big Data,"Big data is a collection of large amount of data which increases in volume, velocity and variety very rapidly. As a researcher, deriving values of importance from this large repository of data is utmost important and challenging. This paper discusses the methods for using Probabilistic Data Structure in Big Data Analysis. The application is primarily focused on Bloom Filters as processing of big data is a major challenge because big data is a continuous stream of rapidly increasing data. To have maximum benefit from data, a bloom Filter can be used so that usability of big data can be achieved while decreasing space or time."
9470384,Application Research of Personalized Recommendation Technology in College English Teaching Reform under The Background of Big Data,"To study the impact of big data on education activities and English teaching activities, this paper proposes an improvement scheme of online teaching by personalized recommendation technology, integrated with big data cloud storage platform. First, through reading and sorting a large number of literature such as education big data and personalized teaching, this paper analyzes the current situation and existing problems. Then Hadoop is adopted as the key analysis and processing technology, and K-means clustering and association rules algorithm are used to establish the user learning preference model. Finally, according to the model, a big data recommendation live platform is implemented and tested. The results show that our scheme not only effectively solves the problem of massive resource storage, but also meets the personalized needs of learners in the learning process, which has a wide range of practical value in the field of teaching research."
7921576,SEEN: A Selective Encryption Method to Ensure Confidentiality for Big Sensing Data Streams,"Resource constrained sensing devices are being used widely to build and deploy self-organizing wireless sensor networks for a variety of critical applications such as smart cities, smart health, precision agriculture and industrial control systems. Many such devices sense the deployed environment and generate a variety of data and send them to the server for analysis as data streams. A Data Stream Manager (DSM) at the server collects the data streams (often called big data) to perform real time analysis and decision-making for these critical applications. A malicious adversary may access or tamper with the data in transit. One of the challenging tasks in such applications is to assure the trustworthiness of the collected data so that any decisions are made on the processing of correct data. Assuring high data trustworthiness requires that the system satisfies two key security properties: confidentiality and integrity. To ensure the confidentiality of collected data, we need to prevent sensitive information from reaching the wrong people by ensuring that the right people are getting it. Sensed data are always associated with different sensitivity levels based on the sensitivity of emerging applications or the sensed data types or the sensing devices. For example, a temperature in a precision agriculture application may not be as sensitive as monitored data in smart health. Providing multilevel data confidentiality along with data integrity for big sensing data streams in the context of near real time analytics is a challenging problem. In this paper, we propose a Selective Encryption (SEEN) method to secure big sensing data streams that satisfies the desired multiple levels of confidentiality and data integrity. Our method is based on two key concepts: common shared keys that are initialized and updated by DSM without requiring retransmission, and a seamless key refreshment process without interrupting the data stream encryption/decryption. Theoretical analyses and e...
(Show More)"
8669507,Study on Big Data Based Land Use Performance in Yunnan Province,"Based on large data, this paper takes sixteen prefectures in Yunnan Province as the object of study to establish the evaluation system with land use performance as the destination layer and land input level, land use degree, land use efficiency and sustainability of land use as the criterion layer for elevating the land use performance by collecting land use and social & economic development data in the study area from 2005 to 2014 by the method of TOPSIS. And it gets conclusions as follows: (1) The overall level of land use performance in Yunnan Province is not high. Most areas experienced a low to intermediate transition in land use performance, and thus the level of land use is low; (2) From 2005 to 2014, the land use performance in Kunming, Qujing, Baoshan and Honghe was on the rise, while that in the other twelve regions, including Lijiang and Dali, was fluctuating upward; (3) There is a big gap in land use performance within Yunnan Province."
9095244,Innovative Approach for PMM Data Processing and Analytics,"ALTEC defined and developed a framework with the main aim to process a big amount of data allowing a seamless connection between the collected information and the analyses performed by end users. This is the ASDP environment, that allows to organize data in the most adapt domain data store in order to have data ready for complex analyses. In particular, the PMM module of the ISS is a reference case for the survey on framework capabilities for telemetry data management. The main objective is to demonstrate the advantages achievable through the application of new data analysis methodologies and tools after data organization through ASDP capabilities."
9526145,Research on the optimization of rural e-commerce human resources based on big data,"In order to improve the accuracy and rationality of rural e-commerce human resource data mining, this paper puts forward the research of rural e-commerce human resource optimization based on big data. This paper analyzes the demand structure of rural e-commerce human resources, and mines the relevant data of human resources personnel of a rural e-commerce enterprise in Heilongjiang Province. Based on the principle of e-commerce information, human resource gain is calculated. This paper analyzes the constraints of rural e-commerce human resource allocation, constructs the objective function of rural e-commerce human resource allocation, and completes the rural e-commerce human resource allocation. The experimental results show that the proposed human resource allocation method has high data mining accuracy and optimization rationality, and can meet the needs of rural e-commerce human resource allocation."
9434477,Research on Innovation of Enterprise Business Model Based on Big Data Analysis,"As the big data era, the development of big data catalyzed a large number of related industries, also brought the business model innovation opportunities. Big data problems rising rapidly from the technical level to the highest level of national strategy. This paper from the business management in big data is facing under the background of the times of the analysis of the challenges, enterprises are facing in the application and research problems, new changes and new research brings big data environment for business opportunities, thinking and exploring how to let China quickly adapt to big data environment in the business model innovation, and the effective use of new opportunities and challenges. At last, the paper makes a prospect for the development of big data."
8940574,Software Engineering for Big Data Application Development: Systematic Literature Survey Using Snowballing,The Big Data Analytics is revolutionizing the Information and Technology sector. Researchers and corporate giants are investing their resources into developing big data application softwares that can provide them useful insight about collected data efficiently and help them to make strategic decisions. But failure rates for big data applications is rather high than anticipated. Hence there is a need to revisit software engineering methodologies and software processes and make them more adaptable for Big Data Applications. Objective: In this paper we are doing systematic literature review of research papers that focuses on software engineering methodologies and software processes for big data applications. Method: Total of 695 papers were reviewed and 22 papers were found relevant according to research question/s using snowballing method. Result: The research papers helped in finding the methodologies and requirements for developing big data applications.
9524250,Research on Big Data Compression Algorithm Based on BIM,"With the wide application of BIM, the mass BIM data generated has brought severe challenges to the storage, processing, and transmission on the limited bandwidth network of the model. In order to achieve smooth browsing and query of BIM data on the shared platform, this paper built a BIM big data storage framework based on the IFC standard, analyzed the inefficiency of the Huffman compression algorithm when constructing a binary tree, and proposed a construction process based on heap sorting. The proposed new algorithm was tested through experiments, and the results show that the efficiency of Huffman compression algorithm was improved when the amount of data was relatively large. In order to realize fast query based on compressed data, the idea of ElasticSearch+Hadoop server cluster is proposed."
9377839,Learning Minimum Bounding Rectangles for Efficient Trajectory Similarity Search,"Early pruning of dissimilar trajectories is important in similar trajectory search on a big mobility data. R-trees can perform the pruning effectively, but the search and index size become inefficient due to numerous overlapping of minimum bounding regions in a dense and big dataset. Thus, we introduce the extended usage of learned index to learn the minimum bounding rectangles for trajectory similarity search. Our approach is designed to provide an effective pruning for trajectory similarity search with less storage size."
9160174,Big Data in Climate Change Research: opportunities and Challenges,"The advent of fourth industrial revolution has come at a cost; our planet earth is enduring concurrent changes in population, increase in urban infrastructure, depleting natural resources, depleting forest covers, increase in pollution etc., and its cumulative ill effects on global climate. These changes coupled with advancements in technology viz. Sensors and Data Mining techniques have led to a growth in study of Climate Data as a method to thwart Climate Change. Climate change study is a data intensive subject which has seen numerous innovations in the data collection methods, and study of that data using Big Data Analytics. There has been a considerable shift from traditional study methods like random sampling of climate data to data intensive methods where complete datasets are analyzed by means of Big Data Analytics. The study of climate change and its effects has been one of the top priorities in Big Climate Data Analytics implementations and detailed research has been done covering a plethora of topics. However, the study of climate data by recent methods has revealed several challenges previously unrecorded in data mining literature, unless these challenges are addressed, big data analytics will not have the same meaningful impact that it has on other fields. The purpose of this paper is to provide an overview of use of Big Data in Climate Change research and the opportunities and challenges pertaining to it, by studying and summarizing the current state of applications of Big Data in Climate Science."
9378008,Data Reduction and Deep-Learning Based Recovery for Geospatial Visualization and Satellite Imagery,"The storage, retrieval, and distribution of data are some critical aspects of big data management. Data scientists and decision-makers often need to share large datasets and make decisions on archiving or deleting historical data to cope with resource constraints. A potential approach to mitigate such problems is to reduce big datasets into smaller ones, which will not only lower storage requirements but also allow light load transfer over the network. Carefully prepared data by removing redundancies, along with a machine learning model capable of reconstructing the whole dataset from its reduced version, can improve the storage scalability, data transfer, and speed up the overall data management pipeline. In this paper, we explore some data reduction strategies for big datasets, while ensuring that the data can be transferred and used ubiquitously by all stakeholders, i.e., the entire dataset can be reconstructed with high quality whenever necessary. Our approach guarantees a minimum of 75% data size reduction, where the reconstruction accuracy observed is as high as 98.75% on an average for geospatial meteorological data (e.g., soil moisture and albedo), and 99.09% for satellite imagery. We propose a novel variance based reduction technique that can further reduce the data size without losing the accuracy significantly, and adopt various deep learning approaches for high-quality reconstruction."
9476628,Platform for real-time data analysis and visualization based on Big Data methods,"Data is one of the most important and essential sciences for visualizing graphs. Analysis and visualization techniques are widely used to create metrics and predictions about the context. The present work is part of an engineering design of surfaces project, which proposes a model of analysis and visualization of data using temperature and pressure sensors at plastic injection machines. The objective is to monitor the data collected from the manufacture process of plastic molds. The result was achieved by developing a model for analyzing and visualizing data in real time, with sensors that collect temperature and pressure data, and the possibility of viewing the application's data history. It is also possible to monitor the alerts that the model can trigger based on the collected data. Through the developed dashboards, it is possible for production managers to have at their disposal a decision support system that aggregates information of productivity and the need for preventive maintenance of equipment's."
9007438,A Big Data Provenance Model for Data Security Supervision Based on PROV-DM Model,"Nowadays, big data has become a hot research topic. It gives fresh impetus to the economic and social development. However, the huge value of big data also makes it the focus of attacks. Big data security incidents occur frequently in recent years. The security supervision capacities for big data do not match its important role. Data provenance which describes the origins of data and the process by which it arrived the current state, is an effective approach for data supervision. For the full use of provenance in big data supervision, a provenance model which defines the concepts used to represent the provenance types and relations is required to be built in advance, but current provenance models do not adapt to big data scenarios well. In this paper, we comprehensively consider the characteristics of big data and the requirements of data security supervision, extend the widely used provenance model PROV-DM by subtyping and new relation definition, and propose a big data provenance model (BDPM) for data supervision. BDPM model supports the provenance representation of various data types and diverse data processing modes to represent the entire data transformation process through different components in the big data system, and defines new relations to enrich provenance analysis functions. Based on BDPM model, we introduce the constraints that should be satisfied in the construction of valid provenance graph and present the data security supervision methods via provenance graph analysis. Finally, we evaluated the satisfiability of BDPM model through a case study."
9202383,Study on the Impact of Big Data Technology on the Audit and its Application,"Data is most precious resource for the world in the era of big data. Now most of the information and data needed for audit is in electronic form. The technology and resources related to big data will have a far-reaching impact on audit, and inspire auditing institutions to make technological, business and management innovations oriented from big data, and drive the reform of audit management by constructing the audit management and operation platforms."
8958046,Problems and Prospectives of Big Data Storage and Processing Standartization,"In the paper, we analyze the problem of standardization in the domain of storage and processing of big data in the application to the Internet of things. We highlight the underlying problems of big data; analyze the scientific, technological and economic barriers to the development of big data. We offer perspective research directions in the domain of development of standards of data representation."
9276827,Study on the Mode and Mechanism of the Big Data Opening about China's Government,"In the era of big data, on the one hand, the opening of government big data can bring development opportunities for government governance, scientific research, social development, on the other hand, it also makes the protection of state secrets and personal privacy face great challenges. This paper first defines the scope of China's government's big data opening, then studies the current situation of foreign government's big data opening, then analyzes the current situation and challenges of China's government's big data opening, and finally proposes a method of mode and mechanism of China's government's big data opening, providing a reference for the implementation of China's big data opening policy."
9390007,Design of verification and verification system for electric metering pipeline meters based on big data analysis,"Based on the big data analysis method, the verification and verification system of electric metering pipeline meters is designed. This paper expounds the working principle of electric energy metering device and intelligent electric energy meter in the automatic verification system of electric power metering pipeline meters. Combined with the principle of big data analysis, it collects the operation data of electric metering pipeline meters. By optimizing the hardware structure of the system, such as mobile terminal and sensor, it can improve the safety and stability of the system operation, and in the structure of the Internet of things, the power metering flow. The design of knowledge base and rule base is carried out in the verification and verification system of water line electric meter, and the operation flow of system software is improved, so as to assist the verification and verification system of electric metering pipeline meters, so as to quickly complete the operation and maintenance processing, and achieve the research effect of improving the production capacity and qualification rate of electric metering pipeline meters. Finally, according to the requirements of 596-2012 verification regulation, the performance of the verification and verification system of electric metering pipeline meters is tested, and the error value of electric energy in the system is detected to judge the operation safety set stability of the verification and verification system of electric metering pipeline meters. The research proves that the system can effectively meet the requirements of automatic verification of electric energy meters in the practical application process, effectively improve the application level of electric energy measurement technology, and improve the management effect of electric power enterprises."
9391008,Hybrid Collaborative Filtering Recommendation Algorithm for ALS Model Based on a Big Data Platform,"Aiming at the advantages of parallel computing on a big data platform, an improved algorithm for the ALS model under a big data platform is proposed. According to the number of users' visits, the hybrid recommendation is carried out, and a similar user reconstruction matrix model is used for optimization. Experiments show that: the ALS model hybrid collaborative filtering recommendation algorithm based on big data platform can improve the recommendation accuracy compared with the traditional K-means clustering recommendation algorithm, the article based recommendation algorithm, and the tag-based recommendation algorithm, and the acceleration ratio increases significantly with the increase of nodes when the big data set are running."
9403793,Big data analysis and server applications for Unmanned Aerial Vehicle/Drones,"This thesis mainly proposed a novel way to solve the analysis of big data of the unmanned aerial vehicle (UAV) platform in the operation process with the corresponding software, for developing the efficiency of the traditional measurement of survey-mapping and solving flight safety problems. Using a large database server of UAV with the related industries processing applications and network applications, applications of UAV with automate, autonomous, and intelligent are truly executed. Meanwhile, making its applications become easier, more accurate, safer and faster in some field, such as the survey-mapping of UAV, several times or more efficiency are achieved."
9407872,Spatial Data Science of COVID-19 Data,"Huge amounts of big data can be generated and collected from a wide variety of rich data sources. Embedded in these big data are useful information and valuable knowledge. An example is healthcare and epidemiological data such as data related to patients who suffered from viral diseases like the coronavirus disease 2019 (COVID-19). Knowledge discovered from these epidemiological data via data science helps researchers, epidemiologists and policy makers to get a better understanding of the disease, which may inspire them to come up ways to detect, control and combat the disease. In this paper, we present a spatial data science system for analyzing big COVID-19 epidemiological data, with focus on the spatial data analytics among different geographic locations. The system helps users to get a better understanding of information about the confirmed cases of COVID-19. Evaluation results show the benefits of our system in spatial data analytics of big COVID-19 data."
9148213,Research on Network Information Security Protection Technology Based on Big Data,"The growth of massive data information in the era of big data has brought huge challenges to computer network information security. The establishment of a computer network information security system and the application of information technology such as big data technology and computer network technology can ensure the security of data information. The necessity of computer network information security protection under the background of big data is analyzed. The principles of network information security protection are studied. Combined with the characteristics of the big data era, a variety of computer advanced technologies are used to construct a computer network information security protection system and carried out research."
9529590,Toward a Novel Measurement Framework for Big Data (MEGA),"Big Data is quickly becoming a chief part of the decision-making process in both industry and academia. As more and more institutions begin relying on Big Data to make strategic decisions, the quality of the underlying data comes into question. The quality of Big Data isn’t always transparent and large-scale systems may even lack its visibility, which adversely affects the credibility of the Big Data systems. Continuous monitoring and measurement of data quality is therefore paramount in assessing whether the information can serve its purpose in a particular context (such as Big Data analytics, for example). This research addresses the need for Big Data quality measurement modeling and automation by proposing a novel conceptual quality measurement framework for Big Data (MEGA) with the purpose of assessing the underlying quality characteristics of Big Data (also known as the V’s of Big Data) at each step of the Big Data Pipelines. The theoretical quality measurement models for four of the Big Data V’s (Volume, Variety, Velocity, Veracity) are currently automated; the remaining 6 V’s (Vincularity, Validity, Value, Volatility, Valence and Vitality) will be tackled in our future work. The approach is illustrated on a case study."
9173440,Method for generating infrared big data for deep learning algorithm training by using small sample data,"With regard to precision guided weapon, a large amount of feature data is required for the training of non-cooperative target deep learning recognition models. In this paper, based on the remote sensing data and target temperature information, the variable parameters of big data generation are proposed by analyzing the formation mechanism of infrared radiation characteristics. And then, the 3D temperature field of the target is constructed based on small sample information. Finally, based on the 3D temperature field, multiple sets of infrared characteristic data are generated with different observation angles and sun positions. By analyzing the data results, it can be seen that when the observation angle is changed, the variation of the tank barrel radiation characteristics are up to 80%, and when the position of the sun is changed, the variation of the tank hatch radiation characteristics is up to 100%. The big data generation method proposed in this paper has the characteristics of diverse characteristics, high data scalability and high feature continuity, and can be used as training data for deep learning models."
9006283,Privacy and Security of Big Data in AI Systems: A Research and Standards Perspective,"The huge volume, variety, and velocity of big data have empowered Machine Learning (ML) techniques and Artificial Intelligence (AI) systems. However, the vast portion of data used to train AI systems is sensitive information. Hence, any vulnerability has a potentially disastrous impact on privacy aspects and security issues. Nevertheless, the increased demands for high-quality AI from governments and companies require the utilization of big data in the systems. Several studies have highlighted the threats of big data on different platforms and the countermeasures to reduce the risks caused by attacks. In this paper, we provide an overview of the existing threats which violate privacy aspects and security issues inflicted by big data as a primary driving force within the AI/ML workflow. We define an adversarial model to investigate the attacks. Additionally, we analyze and summarize the defense strategies and countermeasures of these attacks. Furthermore, due to the impact of AI systems in the market and the vast majority of business sectors, we also investigate Standards Developing Organizations (SDOs) that are actively involved in providing guidelines to protect the privacy and ensure the security of big data and AI systems. Our far-reaching goal is to bridge the research and standardization frame to increase the consistency and efficiency of AI systems developments guaranteeing customer satisfaction while transferring a high degree of trustworthiness."
9202758,"Experimenting and Assessing a Distributed Privacy-Preserving OLAP over Big Data Framework: Principles, Practice, and Experiences","OLAP is an authoritative analytical tool in the emerging big data analytics context, with particular regards to the target distributed environments (e.g., Clouds). Here, privacy-preserving OLAP-based big data analytics is a critical topic, with several amenities in the context of innovative big data application scenarios like smart cities, social networks, bio-informatics, and so forth. The goal is that of providing privacy preservation during OLAP analysis tasks, with particular emphasis on the privacy of OLAP aggregates. Following this line of research, in this paper we provide a deep contribution on experimenting and assessing a state-of-the-art distributed privacy-preserving OLAP framework, named as SPPOLAP, whose main benefit is that of introducing a completely-novel privacy notion for OLAP data cubes."
8921390,Research on Financial Information Integration of Agricultural Supply-Side Structural Reform in Heilongjiang Province Under the Framework of Big Data,"Aiming at the low efficiency of financial information integration in agricultural supply-side structural reform caused by existing technologies, this paper studies the financial information integration of agricultural supply-side structural reform in Heilongjiang province under the framework of big data. The web extraction model is used to extract financial information of agricultural supply-side structural reform in Heilongjiang province from various web pages, and the extracted XML data files are sorted to remove the repetitive financial information. The sorted financial information is mapped to the database according to the set mapping rules. Clustering algorithm is used to integrate financial information data in database. In order to verify the research effect of financial information data integration under big data architecture, a comparative experiment is conducted with traditional information integration. The experimental results show that the proposed financial information integration efficiency of agricultural supply-side structural reform in Heilongjiang province under the big data framework is nearly 30% higher than the traditional integration efficiency, which is more advantageous."
9016588,The Impact of Big Data In Healthcare Analytics,"No doubt that we are living in the era of Big Data, where we are noticing the expansion of smart healthcare devices. The main obstacles for the Healthcare platform researchers in choosing the right Big Data tool to process unstructured data. Therefore, the current area of research is shifted from massive storage to efficiently analyze the data. This paper aims to present state-of-the-art Big Data analytics tools and presented the Intelligent Medical Platform (IMP) as a case study in dealing with the multimodal data. The result shows that the proposed platform is scalable in dealing with health care data."
9378406,Towards a Multi-Perspective Methodology for Big Data Requirements,"This poster describes work in progress that is concerned with requirements engineering in the context of big data. Drawing experience from a H2020 project, this poster argues for a classification of requirements from different perspectives that can be used to guide the requirements elicitation process and form the basis of a common methodology for requirements engineering in big data applications."
9006167,Anonymous Privacy-Preserving Scheme for Big Data Over the Cloud,"This paper introduces an anonymous privacy-preserving scheme for big data over the cloud. The proposed design helps to enhance the encryption/decryption time of big data by utilizing the MapReduce framework. The Hadoop distributed file system and the secure hash algorithm are employed to provide the anonymity, security and efficiency requirements for the proposed scheme. The experimental results show a significant enhancement in the computational time of data encryption and decryption."
9671862,Finding Your Way Through the Jungle of Big Data Architectures,"This paper presents a systematic review of common analytical data architectures based on DAMA-DMBOK and ArchiMate. The paper is work in progress and provides a first view on Gartner’s Logical Data Warehouse paradigm, Data Fabric and Dehghani’s Data Mesh proposal as well as their interdependencies. It furthermore sketches the way forward how this work can be extended by covering more architecture paradigms (incl. classic Data Warehouse, Data Vault, Data Lake, Lambda and Kappa architectures) and introducing a template with among others ""context"", ""problem"" and ""solution"" descriptions, leading ultimately to a pattern system providing guidance for choosing the right architecture paradigm for the right situation"
9403835,Analysis of Computer Science Based on Big-Data Mining,"The scientific construction of a first-class discipline construction evaluation system is of great significance to the promotion of discipline construction. As an important evaluation reference system, the third-party evaluation system must pay attention to its underlying data sources and calculation methods. Using the massive underlying data of the Scopus database, through the analysis of the computer disciplines of four Chinese universities, the development trend is discussed from the aspects of overall academic output, scientific research quality, and hot topics."
9110013,Research on the Entrepreneurship Practice of College Huizhou Merchants Based on Big Data,"In order to improve the entrepreneurial practice ability of college students' Huizhou merchants under the environment of big data, this paper puts forward a novel research method of college students' Huizhou merchants' entrepreneurial practice based on big data. Based on big data, this method constructs big data network sharing platform, which can retrieve and mine all kinds of information related to college students' Huizhou merchants' entrepreneurship. The research results show that this method is helpful to improve the practical ability and success rate of college students' Huizhou merchants' entrepreneurship, and realize the cross-regional exchange of Huizhou merchants' entrepreneurial practical experience."
9093748,Data Anonymization for Big Crowdsourcing Data,"In traditional database systems, data anonymization has been extensively studied, it provides an effective solution for data privacy preservation, and multidimensional anonymization scheme among them is widely used. However, without delicate parameter settings, these technologies may cause uncontrollable information loss and decrease the accuracy of data analytic tasks. Furthermore, crowdsourcing data is usually huge in amount and must be distributed stored in clouds, which makes the conventional data anonymization technologies not applicable. In this paper, we propose a framework that uses MapReduce to anonymize large-scale data before disseminating them to human workers. In order to guarantee the number and distribution of data records to be similar in all nodes, our framework first redistributes the original data to all participating nodes. Then a heuristic two-phase anonymization schema, which can be seamlessly integrated into the framework, is proposed. Experimental results show that with the same objective of privacy, our approach is scalable for large-scale data and can improve the average accuracy of human worker's analytic tasks."
8727423,A New Approach of Exploiting Self-Adjoint Matrix Polynomials of Large Random Matrices for Anomaly Detection and Fault Location,"Synchronized measurements of a large power grid enable an unprecedented opportunity to study the spatial-temporal correlations. Statistical analytics for those massive datasets start with high-dimensional data matrices. Uncertainty is ubiquitous in a future's power grid. These data matrices are recognized as random matrices. This new point of view is fundamental in our theoretical analysis since true covariance matrices cannot be estimated accurately in a high-dimensional regime. As an alternative, we consider large-dimensional sample covariance matrices in the asymptotic regime to replace the true covariance matrices. The self-adjoint polynomials of large-dimensional random matrices are studied as statistics for big data analytics. The calculation of the asymptotic spectrum distribution (ASD) for such a matrix polynomial is understandably challenging. This task is made possible by a recent breakthrough in free probability, an active research branch in random matrix theory. This is the very reason why the work of this paper is inspired initially. The new approach is interesting in many aspects. The mathematical reason may be most critical. The real-world problems can be solved using this approach, however."
9314391,Big Data Value Chain: A Unified Approach for Integrated Data Quality and Security,"Big Data has grown significantly in recent years. This growth has led organizations to adopt Big Data Value Chains (BDVC) as the appropriate framework for unlocking the value to make suitable decisions. Despite its promising opportunities, Big Data raises new concerns such as data quality and security that could radically impact the effectiveness of the BDVC. These two essential aspects have become an urgent need for any Big Data project to provide meaningful datasets and reliable insights. In this contribution, we highlight the importance of considering data quality and security requirements. Then, we propose a coherent, unified framework that extends BDVC with security and quality aspects. Through quality and security reports, the model can self-evaluate and arrange tasks according to orchestration and monitoring process, allowing the BDVC to evolve at the organization pace and to align strategically with its objectives as well as to federate a sustainable ecosystem."
8884176,Analysis and Visualization Implementation of Medical Big Data Resource Sharing Mechanism Based on Deep Learning,"With the development of information technology, the informationization of the medical industry is also constantly developing rapidly, and medical data is growing exponentially. In the context of “Big Data +”, people began to study the application of data visualization to medical data. Data visualization can make full use of the human sensory vision system to guide users through data analysis and present information hidden behind the data in an intuitive and easy-to-use manner. This paper first introduces the workflow of DBN, a deep learning algorithm, and summarizes the computational characteristics of the algorithm. The classification function is translated into an assembler using an instruction set-based assembly language, and the program is evaluated for performance. Secondly, based on the Hadoop ecosystem, this paper analyzes the BDMISS system for big data medical information resource sharing. Based on the system's requirements and functional positioning, from the medical information collection and sharing, data mining and knowledge management level, the big data medical service system is constructed. Based on the semantic network and ontology theory, big data mining technology and the design of “medical cloud”, the resource sharing mechanism is analyzed. Based on the Spring MVC framework, using Echarts, HCharts and other data visualization technology, according to the design of specific modules, the visualization and display of medical data is realized, which has certain promotion effect on the research and development of medical big data visualization analysis."
9150286,Research on the Model of “data-based governance” in Colleges and Universities,"The development of big data technology has provided rich data resources for higher education governance, making the construction of the “data-based governance” model in colleges a reality. On this basis, this paper analyzes the future development of colleges and universities from the connotation and realization of the “data-based governance” model. Operational management mechanisms and other aspects have proposed feasible ways to strive to provide a theoretical reference for enhancing the modernization of educational governance capabilities of colleges and universities."
8542956,Predicting Completion Risk in PPP Projects Using Big Data Analytics,"Accurate prediction of potential delays in public private partnerships (PPP) projects could provide valuable information relevant for planning and mitigating completion risk in future PPP projects. However, existing techniques for evaluating completion risk remain incapable of identifying hidden patterns in risk behavior within large samples of projects, which are increasingly relevant for accurate prediction. To effectively tackle this problem in PPP projects, this study proposes a Big Data Analytics predictive modeling technique for completion risk prediction. With data from 4294 PPP project samples delivered across Europe between 1992 and 2015, a series of predictive models have been devised and evaluated using linear regression, regression trees, random forest, support vector machine, and deep neural network for completion risk prediction. Results and findings from this study reveal that random forest is an effective technique for predicting delays in PPP projects, with lower average test predicting error than other legacy regression techniques. Research issues relating to model selection, training, and validation are also presented in the study."
9421778,Research on Personalized Recommendation System Based on Big Data Mining Technology,"The rapid popularization of the Internet has promoted the transformation of the Internet industry, and a large number of new businesses have emerged. It has ushered in new development opportunities and challenges in all walks of life. Information technology is deeply integrated with human production and life, global data is showing explosive growth, and the problem of information explosion is getting worse. With the increasing volume of data, people's ability to understand and process data is limited. How to help individuals effectively manage these data and help them obtain the information they need is extremely important. Researchers try to use information filtering technology to solve the problem of information overload. Big data mining technology represented by personalized recommendation has become an important tool. This article discusses related theories such as big data and big data mining technology, and uses it as a guide basis, combined with related recommendation algorithms, to build a personalized recommendation system based on big data mining technology. The article analyzes the application cases of personalized information recommendation systems in some industries, discusses the processing methods and basic processes of massive data mining, analyzes the basic framework of personalized recommendation systems, and provides references for data mining and application researchers and related workers."
8929756,Advanced Technologies of Big Data Research in Distributed Information Systems,"The big data tendency prospects as well as timeliness of the problem are studied in this paper. The principles of work with them are addressed. Big data processing technologies are provided. The analysis of each one is performed. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database is provided."
8729522,Research and Practice of Big Data Analysis Process Based on Hadoop Framework,"With the rapid development of Internet, Internet of Things (IOT) and cloud computing technology, human society has entered the era of big data. How to mine effective information from massive data, assist decision-making, and realize the value of large data? Big data analysis plays a key role. Based on the analysis of Hadoop's ecological architecture, the basic process of large data analysis based on Hadoop was presented in this study, and the technical recommendation for off-line and real-time typical application scenarios was proposed. Finally, Hadoop was used to build the application environment, and WordCount case was combined to analyze Map and Reduce calculation process, in order to provide some reference value for the construction of big data platform and big data analysis and processing."
8594554,An Integrated Methodology for Big Data Classification and Security for Improving Cloud Systems Data Mobility,"The expand trend of cloud data mobility led to malicious data threats that necessitate using data protection techniques. Most cloud system applications contain valuable and confidential data, such as personal, trade, or health information. Threats on such data may put the cloud systems that hold these data at high risk. However, traditional security solutions are not capable of handling the security of big data mobility. The current security mechanisms are insufficient for big data due to their shortage of determining the data that should be protected or due to their intractable time complexity. Therefore, the demand for securing mobile big data has been increasing rapidly to avoid any potential risks. This paper proposes an integrated methodology to classify and secure big data before executing data mobility, duplication, and analysis. The necessity of securing big data mobility is determined by classifying the data according to the risk impact level of their contents into two categories; confidential and public. Based on the classification category, the impact of data security is studied and substantiated on the confidential data in the scope of Hadoop Distributed File System. It is revealed that the proposed approach can significantly improve the cloud systems data mobility."
9148236,Application of Group Cognitive Kansei Information Acquisition Based on Big Data,"For the group's cognitive-kansei information, that is, the user's kansei expression of products, the existing research, and practical application are relatively limited. This paper combines big data with cognitive-kansei information acquisition in kansei engineering and extracts cognitive-kansei information from a large number of texts. This method can improve the efficiency of collecting cognitive-kansei information, can truly reflect the group's cognition, and has objectivity. Taking UAV as an example, the effectiveness of the method of group cognitive-kansei information acquisition based on big data is verified."
9155049,Hybrid security analysis based on intelligent adaptive learning in Big Data,"Big data provides a way to handle and analyze large amount of data or complex set. It provides a systematic extraction also. In this paper a hybrid security analysis based on intelligent adaptive learning in big data has been discussed with the current trends. This paper also explores the possibility of cloud computing collaboration with big data. The advantages along with the impact for the overall platform evaluation has been discussed with the traditional trends. It has been useful in the analysis and the exploration of future research. This discussion also covers the computational variability and the connotation in terms of data reliability, availability and management in big data with data security aspects."
8892618,Data-Enabled Digestive Medicine: A New Big Data Analytics Platform,"This paper presents a big data analystics platform for clinical research and practice in the Gastroenterology Department of Xiangya Hospital at Central South University in China. This platform features a comprehensive and systematic support of big data in digestive medicine including geneneral health management, clinical gastroenterology practice, and related genomics research, which is proven to be helpful in real world clinical practices. A typical use case of integrated analysis based on electronic medical records and colonoscopy data was presented and discussed, the analaystic report on risk factors of colorectal diseases shows a reasonable recommendation about the age when people should start to screen the colorectal cancer, which could be very useful to individual and group health management for the general population in China."
9117504,Pruning Deficiency of Big Data Analytics using Cognitive Computing,"Since past few years the size of the data is growing extremely at fast rates 10 times faster in growth. This will include all the responsibilities to make smart decisions streaming from the browsing patterns and produce extra supplements which aids in the decision-making progress. As the size of the data is recorded from a variety of devices like mobile sensors, remote sensing and data is recorded from everywhere; huge amount of data gets stored which is sometimes even never analysed. Big data is a very “big” thing which is getting stored and increasing the volume of raw data sometimes 90% of the raw data sets are never analysed and are just discarded from the memory. Out of it just 10% gets analysed sometimes and are converted into information from those raw data sets. So, analysis of data by human beings could be time consuming but processing enormous amount of data at a large scale using cognitive can be done. In this paper, we tried to focus on the areas where the cognitive computing can be used in order to lessen the shortcomings of the big data analytics, principles from which cognitive computing came. We also focused on the urgent need on how the language processing of data is done to understand the meaning of the rough data and process it to useful information."
9378023,Zero-Shot Machine Learning Technique for Classification of Multi-User Big Data Workloads,"During the last decade machine learning has revolutionized computer science applications. Supervised machine learning algorithms have become especially successful in many industries including health, legal, security, finance, travel, and others. Training supervised learning algorithms, however, is expensive because the real world contains a very large number of different classes that need to be covered by the training set. This is especially true for the highly variable, multi-user workload data produced by the strategically vital big data and cloud software stacks. It is very important, however, to be able to accurately classify these complex workloads in order to enable autonomic management and optimization. Zero-Shot Learning (ZSL) is an advanced machine learning approach that enables classification of objects without having to explicitly train on examples of those objects. In this paper we present a new ZSL technique intended to reduce the expense of assembling workload training sets for big data analytic workloads. We demonstrate that multi-user big data workloads can be treated as hybrids of simpler, single-user workload classes, and classified accurately without having to explicitly train on example instances of multi-user workloads. Our technique is able to accurately classify both unseen multi-user workloads, and seen single-user workloads using the same classifier. We demonstrate 83% classification accuracy for the unseen multi-user workloads, and 92% classification accuracy for the seen, single-user workload classes."
9332207,Big Data Adaptive Encryption Technology for Remote Network Storage,"The traditional network storage big data encryption method had the problem of taking a long time to encrypt. The adaptive encryption technology of big data storage with remote network in the context of big data was proposed. The adaptive encryption principle to shorten the encryption program, selected based on the principles of the selected encryption designed adaptive encryption operation structure, through the calculation of chaos in the structure to realize remote network adaptive storing big data encryption. Through the calculation of the chaotic encryption process of big data in the model, the encryption of adaptive storage big data with remote network was realized. Simulation test was carried out in the simulated environment. The structure showed that the design remote network storage big data adaptive encryption technology taked 14% less time than the traditional encryption technology, the adaptive encryption method of big data showed good performance with the short time consumed of 2186s, and had high operating efficiency."
9162602,Research on Improving Intelligent Inspection Efficiency of Substation Based on Big Data Analysis,"The integration of big data analysis technology into the state monitoring of substation equipment can improve the utilization rate of state monitoring data, information sharing and data analysis ability. In this paper, three distributed data analysis schemes, namely Hive relational online analysis (ROLAP), Impala relational online analysis (ROLAP) and HBase multidimensional online analysis (MOLAP), were proposed based on the business development requirements of power system and the storage performance and analysis efficiency of traditional state monitoring platform. The experimental results show that the data loading speed is slower than the conventional model, but the roll-up performance and storage overhead are better than the conventional mathematical model. The load time is approximately 1.7 to 1.9 times that of the regular data model. The validity and feasibility of the model are verified by experiments."
9109990,Research on Tax Collection and Administration Based on Big Data Analysis,"Utilizing big data is the main trend in tax collection and administration. In the era of big data, to enhance application effect of big data in tax collection and administration, we must try our best to excavate big data. First, the work mode of tax collection and administration needs to be changed, and management force of taxation work process should be strengthened. Then, according to the current status of enterprise development, a comprehensive big data application system should be formulated, to allow enterprise personnel to grasp various tax-related information fully. Constructing a set of tax management systems that are compatible with the development of the enterprise, and paying attention to the use and research, quality and efficiency of tax administration can be steadily improved."
9002676,Big Data Dependability Opportunities & Challenges,"Big Data is a very large data set, its analysis exceeds the capabilities of traditional database management systems. Big Data is linked to the need for large computing and storage capacity.Big Data dependability is one of the major concerns of organizations. It reflects the confidence that can be placed in these data. Nowadays, companies find a major interest in Big Data, but dependability challenge remains a major obstacle.In this article, we present different works that have addressed Big Data dependability aspects. This study highlights new opportunities in this field as well as different challenges."
9525857,Design and Function of Teaching Incentive Mechanism of University Teachers Under the Background of Big Data,"Data analysis and application have greatly changed the teaching management and evaluation system and provided an opportunity for scientific management. This paper takes the way of teaching incentive of university teachers as the breakthrough point, expounds the improvement path of the teaching incentive mechanism of university teachers under the background of big data. The paper introduces key technology of big data in education, such as educational data mining and learning analysis technology, and at the same time designs a whole-process teaching incentive system for university teachers based on big data. The system is built on the Hadoop big data platform, using the column-oriented distributed open source database HBase as the database system. It carries on the distributed computation to the teacher's scientific research, the teaching administration, the personnel information, the examination reward and punishment, and provides the decision basis for the teacher, s teaching incentive. In the context of big data, positive incentives, such as teaching awards and salary incentives, and negative incentives, such as supervision and assessment, can effectively improve the teaching quality, further improve the teaching level, promote the education and teaching management in colleges and universities, and lay a solid foundation for the implementation of the fundamental task of cultivating people by virtue."
9470406,Big Data Assisted Online Teaching Platform for Ideological and Political Theory Course in Universities,"To accurately grasp the characteristics and needs of the object, and enhance the pertinence and effectiveness of evening teaching of Ideological and political theory course, this paper designs an online teaching platform assisted by big data technology. According to the actual needs of the network teaching model, we make the overall planning and design of the functional modules of the platform. Then, in the key module of user classification and location, feature sets related to learning behavior are extracted from learners' behavior data, and a personalized model of user portrait based on improved K-means algorithm is constructed. Through the big data platform based on Hadoop distributed cluster, combined with data analysis algorithm, the data set is cleaned, standardized, analyzed and processed, and the user interests and preferences are analyzed. Finally, the function of the system is tested through web development, and the results show that our scheme can depict the different characteristics of learners, which provides a scientific basis for personalized recommendation and auxiliary learning of Ideological and political education."
9676162,Korean Grammar Error Recognition Algorithm Based on Big Data Corpus and Semantic Analysis,"Korean grammar error recognition algorithm based on big data corpus and semantic analysis is studied in this paper. Data mining directly faces massive data, and there are also some various complex relationships between these data, which leads to the surge of search space and search dimension in the mining process. Based on the traditional methods, the semantic analysis and the big data framework are combined to construct framework for the recognition algorithm. The component analysis method is mainly used in the field of word meaning research, and its use premise is to divide the word meaning into different semantic components, this model is applied into the grammar error recognition. The performance of the model is efficient, and the application scenarios are discussed."
9006086,Identifying Implicit Requirements in SRS Big Data,"Over the past few years, we have worked on pioneering an approach that employs Commonsense Knowledge (CSK) to automate the identification of Implicit Requirements (IMRs) from text in large Software Requirements Specifications (SRS) documents. This paper builds on our IMR-identification approach by adding CNN-based deep learning to detect IMRs from complex SRS big data such as images and tables."
8725750,An Open Sharing Pattern Design of Massive Power Big Data,"Starting from the description of big data value, this article firstly introduced the main sources and the chief characteristics of power big data, secondly elicited the background, present status and primary requirements of open sharing for power big data, and thirdly elaborated the key technologies which were involved in the open sharing pattern of power big data. Then, based on the analysis of open sharing and the technologies, the overall framework and technical route for the open sharing pattern of massive power big data were designed. Then, the open sharing pattern of power big data were designed in detail from the following three aspects: the way of metadata management, the mode of user access control for data open sharing, and the route of sharing service gateway generation, and then, this article gave the complete process which describes the steps of an open sharing service building, and all of these can help to achieve open sharing of massive power big data. Finally this article analyzed the effectiveness of open sharing for power big data in data mining and data transaction, summarized the open sharing pattern of massive power big data, and gave the prospects for the next step of data open sharing work."
9396813,Effective use of Big Data in Precision Agriculture,"Precision Agriculture is the key terminology in agriculture Engineering. Precision agriculture can make the use of legacy data of agriculture to make the farming better in terms of quantity and quality. To enhance the production of the agriculture, technologies such as big data analytics along with data mining tool can use the legacy agricultural data to make the future prediction. This prediction can help to enhance the Agro-Economy."
8449102,An Incremental Tensor-Train Decomposition for Cyber-Physical-Social Big Data,"Cyber-physical-social big data generated from ubiquitous devices and diverse spaces generally are multi-source, heterogeneous, and deeply intertwined. To efficiently analyze and handle the ubiquitous cyber-physical-social big data, tensor is considered as an effective tool, but the curse of dimensionality is still the main bottleneck of tensor-based big data analysis. Tensor networks can considerably alleviate or overcome it through the tensor approximate theory. Therefore, this paper focuses on developing an efficient big data processing framework based on tensor networks and providing an incremental tensor train decomposition approach for the streaming big data. Concretely, this paper first presents a hierarchical cyber-physical-social big data processing framework composed of three planes, namely, data representation and decomposition, data storage and processing, and data analysis and service, in which tensor train (TT) and quantized TT decompositions are particularly introduced to remarkably overcome the curse of dimensionality. Besides, to efficiently handle the continuous streaming big data and avoid the repeated decomposition for the history data, an incremental tensor train decomposition (ITTD) approach is proposed and the complexities are further analyzed in detail. Experimental results demonstrate that ITTD demonstrably outperforms the nonincremental TT decomposition in execution time on the precise of guaranteeing the nearly equal approximation error."
9265118,Using Big Data Analytics to Detect Fraud in Healthcare Provision,"Big Data technologies can contribute to medical fraud detection. The aim of this paper is to present by an example, the methodological approach of the Hellenic National Organization for the Provision of Health Services (EOPYY) in data analysis to detect financial or medical fraud in claims. To analyze the data for fraud detection, a selection of prescription data from the year 2018 were examined. The Local Correlation Integral algorithm was applied to detect any outliers on the dataset. The results revealed that 7 out of 879 products could be characterized as outliers. These outliers must be further investigated to determine if they represent fraud cases. According to the results of this study, this outliers detection approach can support and help the fraud detection process conducted by the auditing services in Healthcare sector."
8767322,Constructing National Geospatial Big Data Platform: Current Status and Future Direction,"With the increasing predominance of Internet of Things (IoT) applications, a considerable amount of geospatial information has been accumulating from various sources. In addition to the common features of big data, the unique characteristics of spatial data make the treatment of big spatial data even more complicated. To facilitate developers creating big spatial data applications, it is imperative to develop new technologies to efficiently handle the massive amount of big spatial data. Given this impetus, the Korean government launched a five-year national project involving businesses, government, and the research community. The goal is to develop a platform for efficiently storing, extracting, processing, and analyzing geospatial big data. This paper explains the expected outcome from the project including the overall architecture of the platform, along with its current status and future direction."
9519373,Big Data Driven Decision Making Guidelines for South African Banking Institutions,"This study developed guidelines to support the incorporation of big data analytics into the decision-making process. This study was conducted within the banking sector of South Africa, with participants from three leading South African banking institutions. The conducted research followed the design science research process. A proof of concept was undertaken where the developed guidelines were tested using a test questionnaire. The criteria the guidelines were tested against was that they are supported with evidence; supported with a discussion of the benefits; easy to follow; effects of the guideline will be seen quickly and compatible with existing norms and values in practice. The result was a list of guidelines that received an agreeable response. The guidelines were developed to provide support to banking organizations that have middle level big data maturity. The adoption of the guidelines can assist banking institutions to achieve a high-level of big data maturity."
9498924,Research on Marketing System Construction of Internet Platform Based on Big Data Technology,"With the rapid change in the media environment and the development of data technology, big data has increasingly become a core role and concept in the field of marketing operation. For the Internet platform, marketing is its core profit model, and the use of data to improve marketing effectiveness is an issue that Internet platforms always pay attention to. The path to obtain big data, mine the value of big data, and support marketing operations based on big data is becoming critical in the development of Internet platforms. This paper takes Google as a research case, and deeply analyzes the data source, data mining technology, user labeling system of Google platform, and the marketing ecology built on this basis. Through the analysis of Google, we finally came to the conclusion: for the Internet platform, big data technology is an important factor in the marketing system construction, but the integration of technology and marketing ecology is more important, and the Internet platform must realize the depth integration of data and marketing system ecology to effectively improve the efficiency of marketing operations."
8996527,Overview of Big Data in Smart Grid,"The integration of Electrical power with advanced information and communication technologies has led to an intelligent electricity grid known as the Smart Grid. The Smart Grid has also led to the improvement of the entire energy flow system through a bidirectional flow of power and information between utility and consumer, hence making the system safe, efficient and reliable. Big data in smart grid are very significant and visible due to the accumulation of the increasing volumes of data. This data is accessed by the electrical utilities as well as customers from smart meters, power management units (PMUs), supervisory control and data acquisition (SCADA) systems, frequency disturbance recorders (FDRs), outage management systems, wide-area monitoring system (WAMS), field devices, customer billing software, customers' data, sensors, computers and communication networks all integrated into the power network. Therefore, big data has a great significance in the establishment of a better Smart Grid. This paper introduces smart grid and its concepts, the role of big data in smart grid; challenges faced by big data in smart grid and the prospect of the big data in smart grids."
8303780,Nonparametric Distributed Learning Architecture for Big Data: Algorithm and Applications,"Dramatic increases in the size and complexity of modern datasets have made traditional “centralized” statistical inference prohibitive. In addition to computational challenges associated with big data learning, the presence of numerous data types (e.g., discrete, continuous, categorical, etc.) makes automation and scalability difficult. A question of immediate concern is how to design a data-intensive statistical inference architecture without changing the basic statistical modeling principles developed for “small” data over the last century. To address this problem, we present MetaLP, a flexible, distributed statistical modeling framework suitable for large-scale data analysis, where statistical inference meets big data computing. This framework consists of three key components that work together to provide a holistic solution for big data learning: (i) partitioning massive data into smaller datasets for parallel processing and efficient computation, (ii) modern nonparametric learning based on a specially designed, orthonormal data transformation leading to mixed data algorithms, and finally (iii) combining heterogeneous “local” inferences from partitioned data using meta-analysis techniques to arrive at the “global” inference for the original big data. We present an application of this general theory in the context of a nonparametric two-sample inference algorithm for Expedia personalized hotel recommendations based on 10 million search result records."
8669546,Network Intrusion Risk Assessment Based on Big Data,"The accurate evaluation of network intrusion risk big data, improve the evaluation probability is the basis to ensure the network security, the traditional evaluation method is difficult to realize the efficient location and evaluation of the network intrusion data under the strong intrusion interference. It cannot effectively evaluate the global feature points of the regular data of network intrusion association, which leads to high probability of resampling, false alarm and missed detection. A network intrusion risk assessment algorithm based on big data association rule mining is proposed to construct a network intrusion risk big data model under strong intrusion interference. The fuzzy search method of network intrusion correlation dimension feature is used to search the regular data of network intrusion association adaptively, and the global feature evaluation and intrusion intensity evaluation value of network intrusion association regularization data are obtained. In order to make intrusion evaluation suitable for linear real-time processing process and improve the performance of evaluation under strong intrusion interference, a stochastic linear fitting model is used to adjust the results. Big data association rules mining is used to judge the joint characteristics of network intrusion association regularization data and realize the mining and risk assessment of network intrusion big data association rules. The simulation results show that the algorithm has better performance in intrusion risk assessment, and the evaluation probability is better than the traditional algorithm, which ensures the network security."
8713257,Big Data Analytics for Higher Education in The Cloud Era,"Universities today possess large volumes of structured and unstructured data, generated from several educational and administrative processes and systems. This data forms what is known today as big data. The common challenge many universities face today is to find the most effective way to harness this data, visualize it and then optimize it for its purposes of continuously delivering enhanced education. While big data technologies require costly infrastructure and expertise for its life cycle management, there has been overwhelming success using Big Data Analytics (BDA) in the business sector for cost reduction and effectiveness. This provides the motivation to explore the use of BDA in the education sector to understand the opportunities it might provide to higher education. In this paper, we explore how data and analytics have been used so far in the higher education sector for enhanced learning or to support decisions, what opportunities and challenges surround BDA in this sector."
9671414,Retrieving of Data Similarity using Metadata on a Data Analysis Competition Platform,"In recent years, instead of closing data and analysis skills in-house, there has been much interest in widely releasing data analysis knowledge on the web. A data exchange platform is a type of digital platform that exchanges data between stakeholders, e.g., data owners, users, and analysts. However, the datasets handled on such platforms are independently acquired and stored by the data providers for their own purposes. These datasets are not based on the premise of coordination and combination, and there is currently little information available to discuss the systematic organization and combination of these datasets. In this study, we focus on a metadata, summary information of data, and examine the similarity of data on a data exchange platform using natural language processing. In our experiments, we use the metadata from the data exchange platform Kaggle. To compare the similarity of the data, our method employs word2vec and BERT as vectorize methods and converts data descriptions to vectors. Then, our method measures the distances of each vector by calculating cosine similarities between each vector. From experimental results, we found that Kaggle has the same character as other data exchange platforms. Additionally, the results indicated the usability of the natural language processing-based method for extracting similar data pairs."
8627988,A Scalable Multi-Data Sources Based Recursive Approximation Approach for Fast Error Recovery in Big Sensing Data on Cloud,"Big sensing data is commonly encountered from various surveillance or sensing systems. Sampling and transferring errors are commonly encountered during each stage of sensing data processing. How to recover from these errors with accuracy and efficiency is quite challenging because of high sensing data volume and unrepeatable wireless communication environment. While Cloud provides a promising platform for processing big sensing data, however scalable and accurate error recovery solutions are still need. In this paper, we propose a novel approach to achieve fast error recovery in a scalable manner on cloud. This approach is based on the prediction of a recovery replacement data by making multiple data sources based approximation. The approximation process will use coverage information carried by data units to limit the algorithm in a small cluster of sensing data instead of a whole data spectrum. Specifically, in each sensing data cluster, a Euclidean distance based approximation is proposed to calculate a time series prediction. With the calculated time series, a detected error can be recovered with a predicted data value. Through the experiment with real world meteorological data sets on cloud, we demonstrate that the proposed error recovery approach can achieve high accuracy in data approximation to replace the original data error. At the same time, with MapReduce based implementation for scalability, the experimental results also show significant efficiency on time saving."
8669086,Framework of Big data Analysis about IoT-Home-device for supporting a decision making an effective strategy about new product design,"This paper introduces a framework of big data analysis about IoT home devices which are delivered to the consumer through several distribution channels, are used by a home user in the smart home, and are repaired in A/S center (repair shop). We collect big data and make an analysis at three major stages that are distribution stage, customer-usage stage, and A/S stage. The ultimate purpose of the presented framework is to help the small/medium companies to make an elastic strategy for the new product. Therefore they can make a more effective decision at three major stages. For example, they can reduce redundancy about a distribution channel, they can adjust a quantity of warehousing, release, stock. They can make a decision on what to upgrade the new next device, how to increase durability, and so on. For these purposes, this framework consists of three subsystems. 1) A data crawler that collects and stores big data about IoT-home devices at three major stages, 2) A big data analyzer about IoT-home device with an appreciate analytic model, 3) A visualization of insights, which help a user to understand the analytic output."
9498875,Internet User Behavior Analysis Based on Big Data,"Today's world has entered the simultaneous development of big data technology and mobile Internet technology, and has acquired a large amount of Internet user behavior data. Through the analysis of Internet user behavior data, it is possible to obtain Internet user behaviors such as the location distribution of Internet users, Internet trends, consumption behaviors, etc., which can help Internet users' preferences, meet user needs, and target users for targeted promotion. It is absolutely necessary for any organization to produce better services. The purpose of the research in this article is to conduct data analysis on Internet user behavior in the era of big data, and to make innovative development of traditional user behavior patterns. From the perspective of big data analysis, in the field of Internet user behavior, through the scientific application of big data technology and theoretical derivation, this paper can reveal the internal laws of Internet user behavior relatively completely. The experimental results show that the use of big data for Internet users needs to process multiple data rationally to provide decision-making reference value to analysis and decision-makers in a correct way, or directly provide decision-making data to the senior management."
9298378,A Hybrid Approach to Data Pre-processing Methods,"This is an era of big data, as data is growing exponentially and resources are running out of infrastructure, so it is required to accommodate all the data that gets generated. We collect data in enormous amounts to derive meaningful conclusions, perform effective data analytics and improve decision making. As we don't have enough infrastructures to support data storage for huge volumes, it is needed to clean the data in compulsion. It is a mandatory to carry out a step before doing anything with the data. We call it pre-processing of data and this is carried out in various steps. Pre-processing includes data cleaning, data integration, data filtering, and data transformation and so on. As such preprocessing is not limited to the number of steps or a number of methods or definitive methods. We must innovatively preprocess the data before it is being consumed for data analytics. It has become a responsibility for every data analyst or big data researcher to handpick data for his or her analytics. Considering all these techniques in mind we are proposing a hybrid technique to leverage various algorithms available to pre-process our data along with minor modifications such as at the run time, choosing an algorithm or technique wisely based on the data that we have."
9377864,Measuring Semantic Similarity across EU GDPR Regulation and Cloud Privacy Policies,"Data protection authorities formulate policies and rules which the service providers have to comply with to ensure security and privacy when they perform Big Data analytics using users Personally Identifiable Information (PII). The knowledge contained in the data regulations and organizational privacy policies are typically maintained as short unstructured text in HTML or PDF formats. Hence it is an open challenge to determine the specific regulation rules that are being addressed by a provider's privacy policies. We have developed a semantically rich framework, using techniques from Semantic Web and Natural Language Processing, to extract and compare the context of a short text in real-time. This framework allows automated incremental text comparison and identifying context from short text policy documents by determining the semantic similarity score and extracting semantically similar key terms. Additionally, we also created a knowledge graph to store the semantically similar comparison results while evaluating our framework across EU GDPR and privacy policies of 20 organizations complying with this regulation associated with various categories apply to Big Data stored in the cloud. Our approach can be utilized by Big Data practitioners to update their referential documents regularly based on the authority documents."
9409014,The Design of Cross-border E-commerce Recommendation System Based on Big Data Technology,"With the outbreak of the new technological revolution cross-border e-commerce came into being, building a new way for enterprises to export goods, a trade method that binds commodity trade with Internet information technology to form a convenient and open trade system and achieve trade interconnection of global economies. Many Chinese enterprises participate in cross-border e-commerce exports, but their export marketing strategies have drawbacks, and their marketing targeting and precision are not high, which hinder Chinese cross-border e-commerce enterprises from carrying out international marketing. In the context of big data, cross-border e-merchants can use collected data to establish a customer database, build a customer portrait model through machine learning technology, and use personalized recommendation systems to realize accurate marketing with two-way customer interaction. To address the problems in cross-border e-commerce marketing in the context of big data, this paper studies the user behavior data generated by cross-border e-commerce. Based on a large amount of low-value density behavioral data of cross-border e-commerce consumers, this paper designs a cross-border e-commerce precision marketing system applicable to processing user behavioral data, and provides a reference for those who are engaged in cross-border e-commerce."
9563604,Optimization of User Feature Extraction Algorithm Comprehensive Innovation System for Students in the Era of Computer Internet Big Data,"Ideological and political courses, as the main channel for cultivating students' world outlook, values, outlook on life and socialist core values, occupy an important position in the ideological and political education of colleges and universities. Aiming at the problems of traditional multimedia teaching methods, such as emphasizing skills and neglecting teaching, rigid use and lack of selectivity, this paper designs and implements an ideological and political teaching system based on big data analysis. The system consists of two parts: multimedia teaching software and computer big data recommendation. The multimedia teaching software realizes online teaching and resource management functions based on the B/S architecture. The big data recommendation subsystem recommends more suitable learning resources to users by collecting and analyzing user behaviors and extracting user characteristics. The function realization and performance test results show that the system has realized the teaching mode with students as the main body. It can not only effectively enhance the learning experience of students, but also support multiple people to learn online at the same time, which can effectively enhance students' learning initiative."
8666626,The Big potential of Big Data towards universities outcome based funding,"Government contribution for public higher education institution remains a significant source of funding a major contributing factor for operational success. Globally governments funding for higher education institutions is moving towards outcome based assessments and targets. Failure to meet the funding targets could have negative impacts to the institutions financial ability to run the university operations, and such failures may rise from many factors among them is poor analysis of the available data. The advent realization of Big Data analytics for any organization has the potential to support decision making hence improving efficiency and effectiveness, Thus Big data analytics could improve the institutions of higher education's performance including students' success rates due to its prescriptive and predictive nature. This study investigated how Big Data could be leveraged to improve public higher learning institutions students' performance to attain Outcome-based Funding (OBF)."
9421402,Exploration on Big Data Education for Computer majors in Applied Colleges and Universities,"In the teaching process of computer major in applied colleges and universities, the full application of big data education can improve the overall education level of computer major. In the teaching process of computer major, big data thinking and big data application ability should be listed as the key teaching content. Therefore, it is necessary to study and analyze the big data education of computer major in applied colleges and universities, to discuss the main components and main points of learning of big data ability education, and to promote the innovation of teaching methods and teaching schemes of computer major in applied colleges and universities. Only in this way can we cultivate students' big data thinking and improve students' big data application ability."
9526681,Research on Abnormal Detection Method of Network Big Data Flow Based on Track Information,"In order to solve this problem, a new anomaly detection method based on trajectory information is proposed. The method of sliding window is used to deal with network big data flow, and the data flow is divided into data blocks. The correlation degree of track information is analyzed to extract data flow features. According to the extracted data flow characteristics, the candidate outliers in the sliding window are verified and the detection method is designed. The experimental results show that the anomaly detection method based on trajectory information has high detection rate and low error detection rate, and its performance is superior."
9539221,Data Encryption of Big Data Redundancy Elimination Algorithm Combining Bloom Filter Technology,"With the continuous expansion of various businesses, data have presented explosive growth. The previous data redundancy elimination algorithm had high storage consumption, prolonged time consumption, and unsatisfactory detection effect of repetition rate. This paper introduced the Bloom filter data structure to reduce the dimension of big data and proposed a new data redundancy elimination algorithm. Firstly, the complete file detection algorithm is used in this algorithm to test and match the data. For the data blocks passing the test, the CDC block detection algorithm is used for further testing and matching. The cosine similarity equation and Hamming distance value are used to calculate the data similarity, complete the final redundancy elimination of data, and perform data encryption on this basis equation. The simulation experiment results suggest that the data redundancy elimination algorithm proposed in this paper has excellent comprehensive performance, which has not only ensured the detection accuracy of data repetition rate but also improved the data detection speed, while reducing the storage overhead and protecting the data security at the same time."
9415189,Big Data Platform for Intelligence Industrial IoT Sensor Monitoring System Based on Edge Computing and AI,"The cutting edge of Industry 4.0 has driven everything to be converted to disruptive innovation and digitalized. This digital revolution is imprinted by modern and advanced technology that takes advantage of Big Data and Artificial Intelligence (AI) to nurture from automatic learning systems, smart city, smart energy, smart factory to the edge computing technology, and so on. To harness an appealing, noteworthy, and leading development in smart manufacturing industry, the modern industrial sciences and technologies such as Big Data, Artificial Intelligence, Internet of things, and Edge Computing have to be integrated cooperatively. Accordingly, a suggestion on the integration is presented in this paper. This proposed paper describes the design and implementation of big data platform for intelligence industrial internet of things sensor monitoring system and conveys a prediction of any upcoming errors beforehand. The architecture design is based on edge computing and artificial intelligence. To extend more precisely, industrial internet of things sensor here is about the condition monitoring sensor data - vibration, temperature, related humidity, and barometric pressure inside facility manufacturing factory."
9261799,Semantic Layer Construction for Big Data Integration,"Heterogeneity problem (data model, schema and semantics) is the one of the challenges of data integration from different big data stores. In order to overcome that problem in big data integration, semantic conceptual layer is constructed as an intermediate layer between different data stores by using ontology. To achieve this goal, there are two steps involved: generate local ontologies from different data systems and merge extracted local ontologies to build a global ontology. The main focus of the paper is merging ontologies which matches local ontologies by syntactic and semantic similarity measures. The two concepts are syntactically compared by Jaccard similarity measure and semantically compared by using WordNet. The matching approach takes into account the class name, internal structure (attributes) of the class, relationship (objectProperty relation, is-part-of relation) of the compared concepts. The performance of proposed algorithm will be compared other merging algorithms such as PROMPT."
9533159,The Big Data Analysis of Current Situation and Development for High-risk Sports Events in Jiangxi Province,"In the era of big data, fundamental changes have taken place in sports communication. The application of new media promotes the resource acquisition and information mining of big data. This paper expounds the main characteristics of high-risk sport events in Jiangxi province under the background of big data, the application and existing problems of big data in the operation and management of high-risk sport events in Jiangxi province, and prospects the development of high-risk sport events in Jiangxi province under the background of big data. How to standardize the operation of high-risk sports scientifically and manage and deal with the risk in time has become the bottleneck of restricting the development of high-risk sports in Jiangxi province in China. This paper takes the development status and risk management strategies of high-risk sports (swimming, diving, rock climbing) in Jiangxi province as the research object, and makes an investigation and big data analysis by using the methods of literature, square talks, field visits, questionnaires, logical analysis and mathematical statistics. Finally, under the base of the big data analysis, the paper puts forward the countermeasures and suggestions for the development of high-risk sports in Jiangxi province."
8951368,Enhanced Map Reduce Techniques for Big Data Analytics based on K-Means Clustering,"The Clustering methods have been greatly adopted in various real world data analysis applications, such as customer behavior analysis, medical data analysis, digital forensics, etc. In existing system, MR-mafia subspace clustering algorithm becomes inefficient as well as ineffective because the data size are continuously increasing, and data blocks are overlaying. Big Data environment inherits several knowledge and we extracts the necessary knowledge and K-means clustering algorithm is being designed. This paper focused on K - mean clustering algorithm based on improved map reduce techniques. The algorithm takes advantages to avoid unnecessary input and output data and also used to optimize data storage and also to achieve the out sourcing of data privacy. We have using a medical datasets of this project, and Enhanced map reduce based K - means clustering algorithm have been proposed which work effectively done and that can be outsourced to cloud server."
9389981,Research on The Analysis of Users’ Behavior Based on Big Data,"In order to deal with the problems of massiveness, feature sparsity and irregularity of web logs, the Word2Vec model and K-Means clustering analysis method are adopted to propose a method to analysis the users' behavior based on big data. First of all, combined with web crawler analysis technology, the users' behavior information is expanded to enrich their behavioral characteristics. Second, Word2Vec is used to build a word vector model to represent users in the form of vectors. Finally, the K-Means are improved to optimize the user behavior analysis strategy. Experimental analysis results show that the method proposed in this paper is superior to the classic K-Means algorithm and SKHC algorithm in terms of user behavior clustering analysis."
9568727,Tensor Train-Based Multiple Clusterings for Big Data in Cyber-Physical-Social Systems and Its Efficient Implementations,"Multiple clusterings are conducive to discovering different data patterns hidden in data from different perspectives, so it has tremendous value in applications like community detection, resource recommendation, and gene expression, etc. To solve the problem that the existing multiple clustering approaches are mainly oriented to low-dimensional single-domain data and are not suitable for big data in Cyber-Physical-Social Systems (CPSS), a tensor-based multiple clustering (TMC) was proposed. However, as the scale of data continues to increase, data storage, computing load, and memory overhead will increase exponentially, leading to dimensional disasters and greatly affecting the efficiency of TMC. Therefore, a tensor train-based multiple clustering (TTMC) and its parallel computing method are studied in this paper. First, a tensor train (TT)-based multiple clustering parallel analytic and service framework is present. Then, a TT-based multi-linear attribute combination weight learning algorithm, a selective weighted tensor train distance and the TTMC algorithm are put forward to improve the accuracy and efficiency of TMC. Furthermore, an efficient distributed parallel computing strategy of TTMC is designed by using TT core parallelism. Experimental results demonstrate that TTMC and its parallelization can significantly improve computation efficiency and clustering accuracy while reducing the running memory compared to the original TMC algorithm."
9463554,Research on Big Data Value Creation System Applied to CPS,"Big data technology is positively affecting and changing various important fields such as science, industry, agriculture, and commerce. As intelligent manufacturing has gradually become a new battlefield for competition among countries in the world, countries have successively released a new generation of industrial development strategies centered on CPS (Cyber-Physical System). How to develop big data technology, tap the value of big data and effectively use big data technology to promote industrial development, has become a hot spot for competing research in various countries. Based on the above background, this paper studies the application of big data technology in CPS. First, it introduces the development overview of big data technology, and elaborates the architecture system and key technologies of CPS. On this basis, the key role of big data technology in the application of CPS and the differentiated characteristics of industrial big data are further studied, and the progress of the application of big data technology in CPS is summarized, and the application of big data technology to CPS is proposed. Value creation system. Finally, it analyzes the shortcomings in the current research, and looks forward to the future research direction."
8900159,Perspectives for VHR Big Data Image Processing and Analytics Toward a Dedicated Framework for Major Disaster and Environment Monitoring from Space,"Through various initiatives, CNES, the French space agency, has been involved in major disaster and environment monitoring from Space for many years and in particular in the International Charter which delivers satellite data to nations affected by major disasters and in the THEIA organization which promotes the use of satellite data to monitor human and climate impacts on environment.Thus, CNES developed in 2014 a reference framework to generate value-added products from satellite data. Since 2017, considering the increase of data and processing requests, CNES has decided to move to a new framework based on big data and cloud technologies and extended to data analytics.This paper will first introduce THEIA and Charter initiatives. It will present the current framework in operation and its limitations. It will then focus on the innovative approach to handle big data and analytics needs and finally presents the first results and perspectives."
9409983,Research on Logistics Management Information System Based on Big Data,"To transform data into wealth more efficiently in a variety of databases, to realize the intelligent real-time monitoring of logistics data, this paper discusses the application of data mining in logistics information system by describing the development status of logistics industry in the era of big data. Firstly, the basic components, construction modules and working mechanism of Hadoop ecosystem are deeply analyzed and studied; the standard process of big data mining process is analyzed and the design idea and process of traditional K-means algorithm are deeply studied and improved. Through the construction of Hadoop cloud computing platform and the analysis of customer transaction volume, profit, order quantity and credit degree and other data and characteristics, the feasibility and effectiveness of the improved algorithm applied to Hadoop cloud computing platform is verified, combined with other industry data evaluation and analysis experience. The results show that the improved scheme has obvious advantages in big data processing, which provides a new technical means for optimizing logistics management and improving statistical efficiency."
7931658,Privacy-Preserving Data Encryption Strategy for Big Data in Mobile Cloud Computing,"Privacy has become a considerable issue when the applications of big data are dramatically growing in cloud computing. The benefits of the implementation for these emerging technologies have improved or changed service models and improve application performances in various perspectives. However, the remarkably growing volume of data sizes has also resulted in many challenges in practice. The execution time of the data encryption is one of the serious issues during the data processing and transmissions. Many current applications abandon data encryptions in order to reach an adoptive performance level companioning with privacy concerns. In this paper, we concentrate on privacy and propose a novel data encryption approach, which is called Dynamic Data Encryption Strategy (D2ES). Our proposed approach aims to selectively encrypt data and use privacy classification methods under timing constraints. This approach is designed to maximize the privacy protection scope by using a selective encryption strategy within the required execution time requirements. The performance of D2ES has been evaluated in our experiments, which provides the proof of the privacy enhancement."
9406986,Research on E-commerce Precision Marketing Strategy Based on Big Data Technology,"In recent years, the development of e-commerce platforms has been gaining momentum, which has made the mining and marketing of e-commerce data more and more critical. Major e-commerce platforms and companies are starting to analyse basic information about their customers, extracting useful information from it, accurately screening customer needs and finally developing targeted marketing programmes that can reduce advertising costs while also generating revenue for the company. Based on the background of big data, this paper firstly composes and integrates the theoretical research on big data and precision marketing, analyses the current marketing status of e-commerce, develops a precision marketing plan that meets the characteristics of e-commerce, and combines the big data platform of e-commerce and personalised precision marketing system to adopt a variety of marketing methods in order to facilitate enterprises to optimise and innovate their existing precision marketing strategies and improve their business performance."
9006303,AFrame: Extending DataFrames for Large-Scale Modern Data Analysis,"Analyzing the increasingly large volumes of data that are available today, possibly including the application of custom machine learning models, requires the utilization of distributed frameworks. This can result in serious productivity issues for “normal” data scientists. This paper introduces AFrame, a new scalable data analysis package powered by a Big Data management system that extends the data scientists' familiar DataFrame operations to efficiently operate on managed data at scale. AFrame is implemented as a layer on top of Apache AsterixDB, transparently scaling out the execution of DataFrame operations and machine learning model invocation through a parallel, shared-nothing big data management system. AFrame incrementally constructs SQL++ queries and leverages AsterixDB's semistructured data management facilities, user-defined function support, and live data ingestion support. In order to evaluate the proposed approach, this paper also introduces an extensible micro-benchmark for use in evaluating DataFrame performance in both single-node and distributed settings via a collection of representative analytic operations. This paper presents the architecture of AFrame, describes the underlying capabilities of AsterixDB that efficiently support modern data analytic operations, and utilizes the proposed benchmark to evaluate and compare the performance and support for largescale data analyses provided by alternative DataFrame libraries."
8770562,Challenges of Big Data Implementation in a Public Hospital,"The digitalization of the healthcare system has resulted in a huge amount of data in medicine. These data help healthcare organizations improve health-process efficiency, enhance healthcare quality, and reduce healthcare cost. In Thailand, several private hospitals obtain numerous benefits by utilizing big data analytics. However, public hospitals might encounter with some difficulties for implementing big data technology. This paper presents challenges of big data implementation in a case study public hospital. According to the analysis, challenges are discussed in aspects of technology, data, human, and organization. The recommendation for implementing big data is proposed as a guideline for big data implementation in the public hospital."
9377736,HotKey-LSM: A Hotness-Aware LSM-Tree for Big Data Storage,"In this paper, to improve the read performance of LSM-tree, we propose an enhanced LSM-tree called HotKey-LSM. The key idea of HotKey-LSM is to put hot keys and cold keys in two separated column families. Thus, when a hot key is not in the block cache, LSM-tree only needs to access a small hot-key LSM-tree to read the key. With this mechanism, most hot-key requests will be answered with low latency: if the hot key is in the block cache, we can return the memory address of the key; if it is not in the cache, we search the small hot-key LSM-tree. This differs from the traditional LSM-tree in that a hot-key request may traverse a large LSM-tree, which causes a high read latency. We implement HotKey-LSM on RocksDB and compare HotKey-LSM with the original RocksDB. The result in terms of QPS suggests the efficiency of our proposal."
9418939,The Core Competencies of Chinese College Students Based on Big Data Analysis,"The core competencies of Chinese college students draw attention from Chinese academic circles in recent years. At present, how to use big data to search, organize, analyze and visualize the massive literature on the core competencies of college students, and how to draw the research context and trend of the core competencies of college students are the key problems to be solved. Under the premise of defining the basic concepts, using information technology, data analysis and literature research methods to sort out the research results of core competencies in China, and analyze the track and main results of the core competencies research of college students in China through CiteSpace software and make a comprehensive evaluation. Aims at affirming academic contribution, and then forming a new academic growth point."
9127414,Critical Success Factors for Big Data: A Systematic Literature Review,"During the last few decades, many organizations have started recognizing the benefits of Big Data (BD) to drive their digital transformation and to gain faster insights from faster data. Making smart data-driven decisions will help the organizations to ride the waves toward invaluable investments. The successful implementation of Big Data projects depends on their alignment with the current organizational, technological, and analytical aspects. Identifying the Critical Success Factors (CSFs) for Big Data is fundamental to overcome the challenges surrounding Big Data Analytics (BDA) and implementation. In recent years, the investigations related to identifying the CSFs of Big Data and Big Data Analytics expanded on a large scale trying to address the limitations in existing publications and contribute to the body of knowledge. This paper aims to provide more understanding about the existing CSFs for Big Data Analytics and implementation and contributes to the body of knowledge by answering three research questions: 1) How many studies have investigated on Big Data CSFs for analytics and implementation?, 2) What are the existing CSFs for Big Data Analytics, and 3) What are the categories of Big Data Analytics CSFs?. By conducting a Systematic Literature Review (SLR) for the available studies related to Big Data CSFs in the last twelve years (2007-2019), a final list of sixteen (16) related articles was extracted and analyzed to identify the Big Data Analytics CSFs and their categories. Based on the descriptive qualitative content analysis method for the selected literature, this SLR paper identifies 74 CSFs for Big Data and proposes a classification schema and framework in terms of 5 categories, namely Organization, Technology, People, Data Management, and Governance. The findings of this paper could be used as a referential framework for a successful strategy and implementation of Big Data by formulating more effective data-driven decisions. Future work will investig...
(Show More)"
9373180,Conceptual Modeling and Smart Computing for Big Transportation Data,"Technical advancements in recent decades have led to generation and collection of much more data at a rapid rate from a wide variety of rich data sources. The popularity of initiates of open data has also encouraged the sharing of these big data so that they have become publicly accessible. Examples of these big data include transportation data. Analyzing and mining these big transportation data help users (e.g., commuters, city planners) to take appropriate actions (e.g., making wise decisions), which in turn help building a smarter city. This leads to smart computing. Moreover, contents of available big transportation data may vary among cities, which lead to the conceptual modeling to describe- at a high level of abstraction-the semantics of data analytic and mining software applications on big transportation data. In this paper, we present conceptual modeling and smart computing for big transportation data. We illustrate our idea with real-life big transportation data from the Canadian city of Winnipeg and to show its practicality in real-life data."
9110091,A Real-Time Computer Network Trend Analysis Algorithm Based on Dynamic Data Stream in the Context of Big Data,"The extraction of effective trends can provide early warning, status assessment and decision support for monitoring objects. Traditional curve trend analysis algorithms include sliding window (SW) algorithm and extrapolation online data segmentation (OSO) algorithm. Compared with conventional least squares method, the overall least-squares method has a higher accuracy of straight line fitting. In addition, there is no limit to the maximum length of the sliding window for the SW algorithm. When the threshold of the detection point is relatively large, the length of the window may be long. The OSD algorithm defines the minimum sliding window length, so that the mutation point within the minimum sliding window cannot be detected. Aiming at the shortcomings of the SW algorithm and the OSD algorithm, a new data stream trend analysis method is proposed. This method adopts the overall least squares method to fit the data stream segmentally to improve the precision of the trend analysis. In addition, it also proposes a variable sliding window. The algorithm solves the fixed window problem of the SW algorithm and the OSD algorithm to achieve a reasonable segmentation of the data stream."
8536475,An Improved Secure High-Order-Lanczos Based Orthogonal Tensor SVD for Outsourced Cyber-Physical-Social Big Data Reduction,"Cyber-physical-social big data concern heterogeneous, multiaspect, large-volume data generated in cyber-physical-social systems (CPSS). Orthogonal tensor SVD (OTSVD) has emerged as a powerful tool to reduce cyber-physical-social big data. In this work, we propose an improved secure high-order-Lanczos based OTSVD for cyber-physical-social big data reduction in clouds. Specifically, to take advantage of the parallel processing capability of cloud computing, the improved secure high-order Lanczos algorithm is derived by restructuring the original high-order Lanczos algorithm such that only one synchronization point per iteration is required. To protect data privacy, the improved secure high-order-Lanczos based OTSVD employs homomorphic encryption integrated with batching technique, and garbled circuits, and makes all computations of the OTSVD algorithm in clouds come true. To our knowledge, this is the first study to efficiently tackle big data reduction in clouds in a privacy-preserving manner. Finally, we prove that our improved approach is secure in semi-trusted model. And we evaluate the proposed improved secure OTSVD on real datasets. The results show that our proposed improved secure approach is efficient and scalable for cyber-physical-social big data reduction."
9362939,Survey on Big Data Analytics:Domain Areas and Features,"The primary objective of this paper is to provide an insight into Big Data Analytics Tools to address business use cases across a broad range of Domains. The paper provides a systematic review and a survey of the open-source and other Big Data Analytics System. The research data used in this paper act as a reference, to provide a summary of these tools that are available and their usefulness in the Business Domains."
9591923,Research on Mobile Reading Weak Communication Promotion System of University Library Based on Mobile Big Data Decision-making Analysis,"With the rapid development of information and communication technologies such as mobile Internet, cloud computing, Internet of Things, edge technology, and data mining, the library industry has entered the era of mobile big data. This paper studies the weak dissemination promotion system of mobile readers in university libraries based on mobile big data decision analysis, points out the main problems existing in the mobile reading promotion of libraries in the mobile big data era, and puts forward the mobile big data decision analysis library mobile Read the specific strategies for promoting the problem."
9422032,Multi dimensional data distribution monitoring based on OLAP,"With the rapid development of the Internet, society is gradually entering the information age, and various data in enterprises have become the most important strategic core resources of all enterprises. The operation and decision-making of enterprises all require a large amount of data analysis. Nowadays, many companies do not pay enough attention to the monitoring of data asset distribution. In addition, various internal systems such as financial management and ERP systems are relatively independent. Each system has its own data organization standard, which makes it difficult to conduct a unified management of data. This also directly leads to the one-sided and subjective problem of enterprise managers' distribution of data assets. With the construction of the data center of each enterprise, the data of each system is aggregated to the center through data integration technology. Therefore, all enterprises need to build a multi-dimensional data distribution monitoring model around data links to comprehensively monitor the status of various data distributions across the company's entire network, and improve data service capabilities and sharing capabilities as well as the company's operational capabilities. This article uses OLAP technology to construct a multi-dimensional data distribution monitoring model for the data link in the process of power enterprise data integration. This article first selects the dimensions and metrics that need to be monitored in the multidimensional data, and then constructs the conceptual model, logical model and physical model of the multidimensional data using on line analytical processing technology. Finally, an example analysis of OLAP system architecture based on B/S structure is realized. The overall data distribution of the enterprise can be grasped by analyzing the various dimensions of the data link, such as System type, location distribution, and time."
9586867,Construction of A Product Design Model Based on Big Data,"Objective: In the background of the rapid arrival of the big data era, a product design model based on big data is proposed, which can greatly improve the design ability and efficiency of enterprises, and bring greater profits and market core competitiveness to enterprises. Methods: Based on the study of the changes brought to design by traditional design methods and the era of big data, the paper establishes the information base based on user data and product data by means of literature research and interdisciplinary method, and establishes the mapping relationship between databanks. Results: According to the design process, the information base and mapping relationship are integrated, a complete design model is formed, iteration is continuously perfected and the method is proposed for effectiveness testing. Conclusion: The method model proposed in this study has some theoretical significance in the fields of big data application and product design, and brings real and effective practical significance to designers and enterprises."
9202292,The Model of Big Data Cloud Computing Based on Extended Subjective Logic,"This paper has firstly introduced big data services and cloud computing model based on different process forms, and analyzed the authentication technology and security services of the existing big data to understand their processing characteristics. Operation principles and complexity of the big data services and cloud computing have also been studied, and summary about their suitable environment and pros and cons have been made. Based on the Cloud Computing, the author has put forward the Model of Big Data Cloud Computing based on Extended Subjective Logic (MBDCC-ESL), which has introduced Jφsang's subjective logic to test the data credibility and expanded it to solve the problem of the trustworthiness of big data in the cloud computing environment. Simulation results show that the model works pretty well."
8701389,Demonetization-Twitter Data Analysis using Big Data & Hadoop,"In today's fast track online and globalised world analysing data and managing it is a major consent. Majority of people use online tools to share their data and views through twitter, Facebook. It has become extremely important to analyse and detect the positive and negative response a particular topic or issue in daily lives. To make data analysis easier and more conceptual Big Data and Hadoop along with various other tools like Hive, Pig, Sqoop have been used to analyse the review of people regarding Demonetization on Twitter platform. These excel at describing data analysis problems as data flows."
8814579,Improving Big Data Application Performance in Edge-Cloud Systems,"Data analysis is widely used in all domains of the economy. While the amount of data to process grows, the time criteria and the resource consumption constraints get stricter. These phenomena call for advanced resource orchestration for the big data applications. The challenge is actually even greater at the advent of edge computing: orchestration of big data resources in a hybrid edge-cloud infrastructure is challenging. The difficulty stems from the fact that wide-area networking and all its well-known issues come into play and affect the performance of the application. In this paper we present the steps we made towards network-aware big data application design over such distributed systems. We propose a HDFS block placement algorithm for the network reliability problem we identify in geographically distributed topologies. The heuristic algorithm we propose provides better big data application performance compared to the default block placement method. We implement our solution in our simulation environment and show the improved quality of big data applications."
8964827,On Transformation of Educational Management at the Time of Big Data,"One of the major questions of educational management is the need of advanced and professional tools and technology for educational management. It is critical for the improvement and enhance of educational management to utilize state-of-the-art information technology, building a platform for highly efficient and professional educational management. First of all, theoretical conception of Instrumental Reason should be clarified, so that basic properties of big-data as well as their deep impact on educational management could be explored. Based on this, a model of management with educational big-data is being prototype, concentrating on the four basic elements-subjective, objective, resource, target. Further on, the road-map is drawn to explain its implementation in accordance with big-data characteristics. The author suggests, in conclusion, that educational management should be wholly transformed and renewed with data processing technology and big-data orientation, so as to realize a success to promote new theory, new technology and new culture of educational management."
9727068,Research on Big Data Security and Privacy Risk Governance,"In the era of Big Data, opportunities and challenges are mixed. The data transfer is increasingly frequent and speedy, and the data lifecycle is also extended, bringing more challenges to security and privacy risk governance. Currently, the common measures of risk governance covering the entire data life cycle are the data-related staff management, equipment security management, data encryption codes, data content identification and de-identification processing, etc. With the trend of data globalization, regulations fragmentation and governance technologization, “International standards”, a measure of governance combining technology and regulation, has the potential to become the best practice. However, “voluntary compliance” of international standards derogates the effectiveness of risk governance through this measure. In order to strengthen the enforcement of the international standards, the paper proposes a governance approach which is “the framework regulated by international standards, and regulations and technologies specifically implemented by national legislation.” It aims to implement the security and privacy risk governance of Big Data effectively."
9378153,On the Large-scale Graph Data Processing for User Interface Testing in Big Data Science Projects,"In functional User Interface testing, test scenarios are written with respect to the requirements that are specified by test analysts. Usually, a test analyst focuses on base URLs and HTML components while collecting requirements of User Interface test scenarios. A base URL is essentially a unit segment of large scale graph data. It has mostly dynamic shape and is used to navigate pages amongst application's pages. We argue that even though dynamic URLs have additional important information about the content of the page, they are not being utilized in generating User Interface test scenarios. In this study, we address this lack of capability and focus on the development of a methodology that can support the usage of large-scale dynamic URL datasets in UI test script generation. Our proposed methodology is designed as an add-on tool that can be used on the top of the existing UI test automation tools to improve testing quality. We introduce a higher quality testing methodology to make the results more accurate, and we discuss the proposed methodology and give an overview of the implementation details followed by the evaluation results. We perform various performance evaluations to investigate how well the proposed algorithms scale under increasing data sizes. The results are promising and show the usability of the proposed methodology."
9378269,Impact of Map-Reduce framework on Hadoop and Spark MR Application Performance,"Hadoop and Spark are popular Map Reduce frameworks, and are under active maintenance. Various benchmark suites and micro-benchmarks have been developed in order to measure and understand the performance and behaviour of the framework. The performance and behaviour of the micro-benchmarks (such as data motifs) are derived from core computations of Big Data applications can also be better understood by such an analysis. Data motifs have been previously studied and each data motif has been shown to behave differently due to changes in two external factors: its input size or input pattern. However, what is not considered by these studies or by any other Hadoop/Spark micro-benchmark distribution, is how the underlying framework can impact the behaviour of the benchmark, in terms of system resource usage and in terms of micro-architectural behaviour. The framework is the third external factor which impacts the behaviour of a big data application. In this work, we analyse the various Hadoop and Spark micro-benchmarks with different input sizes, and differing Hadoop/Spark versions and demonstrate through our results that the behaviour of the motif must also include the underlying framework as a third influencing factor."
9006121,The OTree: Multidimensional Indexing with efficient data Sampling for HPC,"Spatial big data is considered an essential trend in future scientific and business applications. Indeed, research instruments, medical devices, and social networks generate hundreds of petabytes of spatial data per year. However, many authors have pointed out that the lack of specialized frameworks for multidimensional Big Data is limiting possible applications and precluding many scientific breakthroughs. Paramount in achieving High-Performance Data Analytics is to optimize and reduce the I/O operations required to analyze large data sets. To do so, we need to organize and index the data according to its multidimensional attributes. At the same time, to enable fast and interactive exploratory analysis, it is vital to generate approximate representations of large datasets efficiently. In this paper, we propose the Outlook Tree (or OTree), a novel Multidimensional Indexing with efficient data Sampling (MIS) algorithm. The OTree enables exploratory analysis of large multidimensional datasets with arbitrary precision, a vital missing feature in current distributed data management solutions. Our algorithm reduces the indexing overhead and achieves high performance even for write-intensive HPC applications. Indeed, we use the OTree to store the scientific results of a study on the efficiency of drug inhalers. Then we compare the OTree implementation on Apache Cassandra, named Qbeast, with PostgreSQL and plain storage. Lastly, we demonstrate that our proposal delivers better performance and scalability."
8805897,The Application of Big Data in Cyberspace: A Survey,"With the widespread use of network devices, all kinds of isolated sensors can transmit data through the network, and then generate hundreds of billions of data, making big data technology widely applicated in cyberspace. This paper uses a third-party database to search the papers on the topic ""the application of big data in cyberspace"". Then, based on Citespace and other bibliometric tools, these papers searched is analyzed by co-words analysis and articles co-citation analysis. The analysis shows that big data technology is widely used in cyberspace, and the degree and depth of application are deepening year by year. Through the analysis of its time axis of the co-word, we can find that the frontier research areas of ""cyberspace big data applications"" are ""edge computing"", ""energy management"" and ""big data analysis""."
9732646,Social Media Driven Big Data Analysis for Disaster Situation Awareness: A Tutorial,"Situational awareness tries to grasp the situations in the physical world through sensing, communication, and reasoning. Tracking the evolution of changing situations is an essential part of this awareness. Tracking of situation during disasters allows dispatching of aid and rescue resources according to the evolving needs. In recent years, these sensing and communications are shifting more and more towards social media postings, particularly using the Twitter platform. However, extracting intelligence from the available data involves several challenges, including (a) filtering out irrelevant data, (b) fusion of heterogeneous data generated by the social media and other sources, and (c) working with partially geo-tagged social media data in order to deduce the needs of the affected people. Bigdata techniques are essential to accomplish this because of large volume of data, much of which is not very relevant. Spatial analytics of the data plays a key role in understanding the situation but is available only sparsely because many users do not want to be tracked. In this paper, we provide a comprehensive survey on data analytics to assess situational awareness from social medial big data. We also discuss the role of edge computing for handling this analytics in a scalable manner."
8935863,Genomic Anomaly Searching with BLAST Algorithm using MapReduce Framework in Big Data Platform,"Biofarma Corp should adopt big data on vaccine and serum development by analyze genomic sequencing using searching any anomaly. As the root problem, it the anomaly searching requires about 1.62 Terabytes data transient as primary data and 301 Gigabytes as secondary data to get analysis from genomic variance. Moreover Biofarma Corp spent 16 hours for one anomaly searching from 3 Terabytes vaccines. This study proposed big data implementation to handle anomaly searching processes by prioritize less time complexity and less spending storage. It was signalized by a research question, “How big data technology is applied in searching anomalies on genomic data”. It aimed to implement big data system to facilitate large volume and complex data in order to fulfill business process on Biofarma Corp. It adopted framework architecture as brought by Demchenko, Ngo, and Membrey. This study has designed data flow from FASTA and FATQ as sources for anomalies searching processes. This data flow is facilitated in big data system as designed in this research. As main contribution, this research adopted MapReduce framework to run BLAST algorithm with less spending time. As comparison, MapReduce framework can handle 21, 33, and 55 K-Mer in four minutes respectively while 50 minutes were spent without MapReduce."
9134221,Application of Big Data Technology in Industrial Economic Statistics and Forecasting,"Since 2003, big data has received extensive attention. The application of big data not only provides a lot of data foundation for industrial economic analysis, but also greatly enriches the methods of industrial economic data analysis, which greatly improves its precision and timeliness. While enjoying the convenience of using big data, it has also brought us major opportunities and challenges in many aspects, such as data purification, platform development, and personnel training. Big data technologies, such as college collections and multiple storage methods, can make good use of data in industrial economic statistics and forecasting. It enables related enterprises to build a set of real-time monitoring and energy-saving industrial big data management systems to provide more reliable data support."
9655927,Integration of Big Data Analytics and the Cloud Environment in Harnessing Valuable Business Insights,"The integration of big data analytics and the cloud computing environment has become the focus area of many businesses and organizations. The growth that is being observed in big data requires more resources to perform analytics. In the business environment, it is important to be able to generate useful insights from the data that is collected. When integrating the cloud environment, the selection made for the chosen cloud service providers as well as the cloud services would highly impact the success of a business in bringing value to the data that is collected. The medical sector, development of smart cities as well as the entertainment industries are all examples of sectors with huge generation of big data. These are also some fields that have moved into the big data cloud computing environment. The main objective of businesses and organizations is to take the data that is being generated in its final form which can bring value to their decision-making capabilities. Being able to understand the impact of migrating to cloud services, the security challenges, and the wide spectrum of cloud services to choose from would be crucial for businesses. In this paper, the integration of big data technology in the cloud computing environment is discussed critically where different cloud services and tools suitable for generating business insights and the security and privacy challenges are evaluated."
9093774,Detection of Distributed Cyber Attacks Based on Weighted Ensembles of Classifiers and Big Data Processing Architecture,"Distributed cyber attacks represent a special class of attacks on computer networks and systems which is rather difficult to detect. In many respects it is explained by the complexity of such detection demanding joint implementation of procedures of data analysis and technologies of Big Data processing. For this reason the development of new methods for detection of distributed cyber attacks is of great interest to specialists in the field of cyber security. The paper offers a new approach to detection of such cyber attacks. The approach is based on sharing of the weighted ensembles of different classifiers (Decision trees, Logistic regression, Support vector machines) and the Big Data processing architecture. Results of comparative analysis of three different types of the weighted ensembles (weighted voting, soft voting, and adaboost) integrating basic classifiers are evaluated. Experiments, made with use of the CICIDS2017 data set, demonstrated a rather high effectiveness of cyber attack detection and the acceptable level of consumption of the system and time resources. The approach suggested can be used for other related information assurance tasks, for example, detection and counteraction of inappropriate, dubious and harmful information."
9587765,Privacy Preserving Big Data mining using Pseudonymization and Homomorphic Encryption,"Today’s data is so huge so it’s referred to as “Big data.” Such data now exceeds petabytes, and hence businesses have begun to store it in the cloud. Because the cloud is a third party, data must be secured before being uploaded to the cloud in such a way that cloud mining may be performed on protected data, as desired by the organization. Homomorphic encryption permits mining and analysis of encrypted data, hence it is used in the proposed work to encrypt original data on the data owner’s site. Since, homomorphic encryption is a complicated encryption, it takes a long time to encrypt, causing performance to suffer. So, in this paper, we used Hadoop to implement homomorphic encryption, which splits data across nodes in a Hadoop cluster to execute parallel algorithm and provides greater privacy and performance than previous approaches. It also enables for data mining in encrypted form, ensuring that the cloud never sees the original data during mining."
9006106,High Value Customer Acquisition & Retention Modelling – A Scalable Data Mashup Approach,"Identifying valuable customers as well as retaining them has become key component for any business to succeed in this competitive market. Businesses have also realized that relying solely on its own transactional data, might not be sufficient any longer, to meet the required objectives. There is a need to partner and leverage the power of big data available from the external data sources to add more value. In this paper, we are detailing the methodology of mashing up Mobilewalla's high scale mobile consumer data with one of the world's largest online food delivery company in order to revamp their retention and acquisition strategy. In this deployment, Mobilewalla has helped the client, a) to identify the new potential high impact customers from Mobilewalla ecosystem, and b) to predict the unfavorable transitions such as high impact customers getting churned or falling into low impact category. We observed that correctly identified high impact customers by Mobilewalla' customer acquisition model had 21.41% higher average revenue per user (ARPU) than the expected ARPU from high impact customers. Further, the customer retention model can help the client to spend 80% of their retention budget dollars optimally."
9442605,Business Model Innovation in Big Data: A Blue Ocean Shift for Businesses,"Trying to exploit the strategic business potential embedded in big data and build a new value proposition in a brand new blue ocean, many organizations have started to renovate their business models or develop new big-data business models. This paper, based on multiple cases at home and abroad, aims to explore how businesses innovatively use big data to deliver new products or to achieve large efficiency gains. It begins with an account of the current landscape of big data, followed by distinctions between the ways organisations use data. We observe a variety of different business models, for instance, data users, data suppliers and data facilitators as well as main opportunities and challenges presented by big data with hopes to shed light on how businesses renew their Blue Ocean."
9545944,Research on instance-level data cleaning technology,"Effectivedata analysis and data mining are based on data availability and data quality. Data cleaning is a commonly used technique to improve data quality. Instance-level data cleaning is an important part of data cleaning. The focus is on the comparison and analysis of the detection and cleaning methods of attributes and recorded values in the instance-level data cleaning technology, and the experimental analysis of the repeated record cleaning methods. This paper introduces the application field of data cleaning technology represented by the electrical engineering field combined with the application situation, and provides valuable selection suggestions for the characteristics of different data sets and the applicable instancelevel data cleaning technology. Summarizing and analyzing the existing detection and cleaning technology methods, it is concluded that instance-level data cleaning has a lot of research and development space in long text, unstructured data and specific fields. Finally, the challenges and development directions of the instance-level data cleaning technology are prospected."
9533046,Research On the Application of Big Data in Physical Fitness Test and Health Promotion of College Students,"With the in-depth development of information technology in our country, big data applications are becoming the future trend. This article is mainly based on the perspective of big data theory, exploring the related issues of college students' physical fitness test. Firstly, through the integration of college students' physical fitness test indicators and big data, integrating physical fitness test data for classified analysis, proofreading, and making relevant programs to promote physical and mental health. Secondly, SPSS19.0 statistical software was used to accurately measure the physical fitness data, and then a series of scientific and reasonable exercises were carried out accordingly. Finally, the long-term healthy development of college students can be promoted by comparing the results of the physical fitness test."
9407773,The Challenges and Responses of Government Emergency Management in the Era of Big Data,"In the Internet age, big data technology is becoming more and more popular, profoundly affecting all aspects of social life, bringing opportunities for government emergency management work, but also posing new challenges. Under the current big data background, emergency management is facing challenges such as the lack of big data talents, the lack of data early warning and prediction capabilities, the insufficient degree of departmental linkage and cooperation, and the lack of big data security and privacy protection. To solve these problems, governments need to rely on the joint efforts of multiple parties to build an emergency management guarantee system through strengthening personnel training, building a data government, building a data platform, and improving laws and regulations."
9378128,~PB&J~ - Easy Automation of Data Science/Machine Learning Workflows,"The ability to process large amounts of data efficiently is a must in modern Big Data, Data Science and Machine Learning (ML). Easy and succinct workflow expression with highly efficient scaling is key. Existing systems such as Apache Spark and Beam were created for this type of work but have steep learning curve and tremendous operating complexity. Having a simpler tool with less overhead that is well-matched to the typical workflow definition and execution requirements of data science/ML projects will be beneficial.We propose a new framework PB&J that enables succinct definition and data-parallel scale-out execution of workflows with ease. PB&J is easy to learn as it builds on the native Unix shell, with the addition of just a few operators. PB&J supports Maximal Parallelism with its ability to do true pipelining, and fault recovery with Minimal Redo. It is well-matched to the typical data science/ML processing requirements by leveraging the existing command line executables and Python modules. We illustrate the features and strengths of PB&J with real-life Deep Learning data processing workflows. We compare it to existing frameworks such as Apache Spark, Apache Beam, Swift/T and Apache Airflow in terms of ease of authoring, efficiency, scalability and fault recovery."
9529772,Distributed Big Data Computing for Supporting Predictive Analytics of Service Requests,"In the current era of big data, huge volumes of valuable data can be easily generated and collected at a rapid velocity from a wide variety of rich data sources. In recent years, the initiates of open data also led to the willingness of many government, researchers, and organizations to share their data and make them publicly accessible. An example of open big data is service request data. Analyzing these open big data can be for social good. For instance, by analyzing and mining data on non-emergency city service requests, the city could get an insight about its residents’ demand for services. By taking appropriate actions (e.g., adding more staff and/or services, providing more information regarding city services) could enhance the living condition of city residents. In this paper, we present a distributed big data mining system to analyze and mine big data on these non-emergency city service requests. Evaluation on an open big data from a North American city shows the effectiveness and practicality of our distributed big data system in mining these requests for city services and in supporting predictive analytics."
9361816,Design of state Grid shopping mall heating technology application assistant decision system based on big data analysis,"In view of the problem that the decision-making system currently in use takes a long time to respond and causes energy waste due to its low data processing capacity, the state Grid mall heating technology application assistant decision-making system based on big data analysis was designed. The data acquisition and processing part of the original hardware is optimized, and the collected data is reduced and discretized in the software part of the system. Big data analysis technology is used to realize the function of assistant decision system after data analysis. The experimental results show that it is verified that the designed system has short decision response time, high efficiency and can effectively reduce energy waste."
9406932,Research on the Precise Marketing Method of Goods Based on Big Data Technology,"The rise of self-media, the widespread use of Internet of Things (IoT), and the speed of information dissemination has been greatly increased. The rapid development of the scale and quantity of e-commerce in China, the marketing requirements of e-commerce are constantly innovative. Now, we are able to access rich data conveniently. How to extract the relevant data needed by the e-commerce industry from the massive data and multi-dimensional data has become the direction of big data technology development. Based on the analysis of theories and methods related to big data and precision marketing, this paper composes and studies the application of precision marketing in e-commerce in the era of big data. This paper discusses the method of realizing accurate marketing of goods based on big data technology in the mobile Internet environment, establishes the research architecture of accurate marketing in the context of big data, constructs customer portrait model through neural network, and uses it to apply personalized recommendation system to realize accurate marketing of goods."
9373704,Environmental Art Design Teaching Based on Big Data Analysis,"With the deepening of environmental art design teaching reform, big data-driven environmental art design teaching model is also constantly developing. The teaching of environmental art design is a specialty with outstanding characteristics in various disciplines of colleges and universities. Big data can provide rich teaching resources and teaching cases for environmental art design teaching. Promote the transformation of environmental art design teaching from the traditional teaching model to the new teaching model. This article uses big data analysis as the key word, searches the special reports published by core journals in the past five years, and surveys the teaching situation of 100 teachers. This article combines the application of big data in the field of education. From the perspective of big data analysis technology, explore and analyze new models and methods that are beneficial to the teaching of environmental art design. It can be seen from the survey data that 39.7% of the teaching method defects are single. Therefore, in order to improve teaching strategies and improve the educational evaluation system, we can truly meet the individualized learning needs of students. This article proposes that big data improves single teaching and turns to a mixed teaching model of environmental art design."
9315861,Computer Data Processing Mode in the era of Big Data: from Pattern Recognition to Intelligent Sensing,"Computer data processing mode in the era of big data from pattern recognition to intelligent sensing is discussed in this paper. Intelligence refers to the interconnection between things and things and people through the Internet of Things and mobile Internet, combined with the general big data computing, communication, artificial intelligence and other technologies. Neighborhood dependence reflects the proportion of approximate samples to all samples under decision class in mixed information system, and it is also a measure to describe the degree of relationship between conditional attribute set and decision attribute, so it can be used as a heuristic function to reduce the attribute of mixed information system. This paper designed the model from the collection to processing, from pattern analysis to the intelligent sensing. The experimental results have proven that the proposed model can sense the data effectively."
9320472,Review on Integrating Geospatial Big Datasets and Open Research Issues,"Big data and geographic information systems (GIS) are two technologies that have increasingly influenced many areas in the last 10 years and will continue to improve and help solve serious global problems, such as consequences of climate change or global pandemics. A wide spectrum of GIS applications interacts with the continuous growth of geospatial big data sources to drive precise and informed decisions. Geospatial big data integration is designed to accomplish the compatibility of distinct geospatial datasets regardless of their spatial coverage. The large number of geospatial big data sources demand effective data integration for storing and handling such datasets, which will be used for geospatial data analysis and visualization. For instance, risk management datasets related to healthcare and the environment are heterogeneous and disparate. Obtaining a unified view of such geospatial big datasets is complicated and challenging, especially if we consider problems related to healthcare pandemics and environmental disasters. Hence, before we can attempt to predict and mitigate processes occurring in these domains, we must realize that geospatial big data integration is crucial in consolidating datasets. We explore and discuss issues involved in integrating geospatial big datasets in this study. We then classify big data integration processes into three categories, namely, data warehousing, data transformation and integration methods. Furthermore, several research challenges focused on geospatial big data, big earth data, data warehousing, data transformation and linked data are presented. Lastly, open research issues and emerging trends that require in-depth investigations in the near future are highlighted in this study."
9410145,Big data Analysis on The Management Content of College Students' Mental Health Education,"To solve the problems of big data demand and data awareness low, data storage demand and storage technology backward in health education in Colleges and universities, this paper integrates modern information technology into the field of mental health education of college students. Based on the detailed analysis and comparison of various classification algorithms, combined with the characteristics of psychological problem data, C4.5 decision tree algorithm is selected to construct a decision tree model for the psychological problem of symptoms, and uses it to predict the psychological problems of college students. Then the structure model of negative psychology is established by decision tree, and the potential groups with anxiety and depression are found by using clustering technology. The cause analysis based on actual data can provide reliable basis for psychological educators, to improve the efficiency and effectiveness of school psychological consultation."
9640811,Big-Data Based English-Chinese Corpus Collection and Mining and Machine Translation Framework,"This paper adopts web big data mining method to collect and mine the English and Chinese corpus, and designs an English-Chinese machine translation framework. First, create an English-Chinese parallel corpus based on big data, and use data mining to collect and mine the English-Chinese corpus. Then, based on the web big data method, a real-time English-Chinese machine translation framework was designed to realize vocabulary alignment, phrase alignment and syntactic knot alignment. Finally, the validity of the translation framework is verified through experimental data."
8901253,Network Precision Marketing Strategy of Agricultural Products Based on Big Data Analysis,"To improve the network marketing performance of agricultural products under the mode of big data analysis, and using the framework of Business Intelligence (BI), this paper studies the network marketing based on big data. Through the analysis of current situation of network marketing and the characteristics of big data, it is concluded that big data network marketing has the inevitable development trend of network marketing, and the network marketing model based on big data is designed. Apache open source of Hadoop framework is used to collect and analyze large data, and HDFS is used to accurately analyze massive data after data storage. Through the system the enterprise can realize the data analysis and optimization work for each customer, which greatly saves manpower and improves work efficiency."
9130564,M-IDAs: A Scalable and Droppable Big Data Intelligent Platform Based on Modular Design,"More and more companies and individuals aware of the potential value in the accumulating data. With the development of data analysis technology and the application of machine learning methods, it becomes possible to mine the value in data and maximize it. However, there are problems such as low data utilization and insufficient depth and breadth of data mining. And the main reasons are: (1) The development cost of the data analysis application platform is high. (2) Business personnel lack knowledge in the field of data analysis and have high learning costs, or the data processing efficiency is low. Therefore, this paper proposes a Scalable and Droppable Big Data Intelligent Platform base on Modular Design called M-IDAs to provide intelligent data analysis support. Which adopts modular design technology to decompose and package the data processing and analyzing functions to form various visual modules that can be easily used and operated independently. It can effectively reduce costs, improve efficiency, and promote data utilization and value maximization."
8805946,Research on the Management Model of University Students Academic Early Warning Based on Big Data Analysis,"The advancement of technology has greatly promoted education. And with the popularization of information technology construction in higher education institutions, the concept of ""Big Data"" has been paid more and more attention in the management of higher education. Data mining is used to analyze students learning situation. The design of the academic early warning management system can effectively prevent some students from being at risk of dropping out of school due to academic difficulties, improve the quality of higher education operations, and provide higher education managers with the idea of carrying out targeted risk prevention."
9378106,Big Data Processing for Power Grid Event Detection,"In this paper we present the application of big data processing for the development of machine learning (ML) models to detect relevant events in power grid operations. This is based on almost 20TB of phasor measurement unit data corresponding to up to two years of operation of three grid interconnections which provide power to most of the United States. A significant aspect of the work consists in having all data processing performed on a single standard GPU server, from pre-processing to ML model training and testing. We describe the data and computational infrastructure, challenges faced and methods used in data processing, main findings and results. The ML approach employed for best utilization of the big data is also discussed, including sample results."
8848542,Distributed Data Platform for Automotive Industry: A Robust Solution for Tackling Big Challenges of Big Data in Transportation Science,"Nowadays, large amounts of data are being generated from numerous sources. Such a trend is evident in many research fields where the number of data producers is constantly increasing. For example, fields of transportation science and automotive industry may consider each vehicle on the road as a separate data producer which can generate large amounts of data. In the literature, the big data is commonly used as an umbrella term when discussing research related to the following data challenges: volume, variety, velocity, veracity and value. Furthermore, it is a common approach to use a variety of programming tools and methods for different data processing phases, i.e., data collection, data storage, and data analysis. In this paper, we present a distributed data platform that addresses the aforementioned challenges by relying on a specific design choices for each of data processing phases. We argument how such the data platform supports robustness, scalability, fault tolerance, and reliability by showcasing the two real-world use-cases from the transportation/automotive domain: (i) collection, storage, and analysis of the data generated by electric cleaners fleet, and (ii) collection, storage, and analysis of transaction data from EV charging stations, which is further used to develop the EV charging infrastructure."
8807847,Towards a New Architecture for Data Multilevels Interactive Visualization in Big Data Domains,"The progress of the Big Data technology in the different domains continues to reveal, day after day, so many issues affecting this field. The data presentation is a part of these issues, because it is directly related to the user that requires visualization to facilitate the data collection as well as the analysis and the utilization of results as needed. However, implementing visualization requires a low latency. Therefore, many problems regarding the Big Data major characteristics, namely volume, variety and velocity arise and should be addressed. Knowing that each Big Data domain has specific peculiarities, it remains far from thinking of a generic solution to the visualization problem. This latter is manifested in different kinds. One of these kinds that is prevalent in Big Data domains is hierarchical visualization, which is based on presenting data by levels, while respecting the relations between them. In this paper, we propose an architecture composed of modules that cover the Big Data visualization process, taking into account the hierarchical relations between data. In order to valorise our proposal, we implement a prototype that supports the modules composing our architecture which are developed using different tools such as Scrapy and D3js libraries. The experimentation, which was carried out in the educational domain, showed its applicability to real systems."
9073586,Data Quality Management for Big Data Applications,"Currently, as a result of the continuous increase of data, one of the key issues is the development of systems and applications to deal with storage, management and processing of big numbers of data. These data are found in unstructured ways. Data management with traditional approaches is inappropriate because of the large and complex data sizes. Hadoop is a suitable solution for the continuous increase in data sizes. The important characteristics of the Hadoop are distributed processing, high storage space, and easy administration. Hadoop is better known for distributed file systems. In this paper, we have proposed techniques and algorithms that deal with big data including data collecting, data preprocessing, algorithms for data cleaning, A Technique for Converting Unstructured Data to Structured Data using metadata, distributed data file system (fragmentation algorithm) and Quality assurance algorithms by using the model is the statistical model to evaluate the highest educational institutions. We concluded that Metadata accelerates query response required and facilitates query execution, metadata will be content for reports, fields and descriptions. Total time access for three complex queries in distributed processing it is 00: 03: 00 per second while in nondistributed processing it is at 00: 15: 77 per second, average is approximately five minutes per second. Quality assurance note values (T-test) is 0.239 and values (T-dis) is 1.96, as a result of dealing with scientific sets and humanities sets. In the comparison law, it can be deduced that if the t-test is smaller than the t-dis; so there is no difference between the mean of the scientific and humanities samples, the values of C.V for both scientific is (8.585) and humanities sets is (7.427), using the law of homogeneity know whether any sets are more homogeneous whenever the value of a small C.V was more homogeneous however the humanity set is more homogeneity."
9095732,Big Data Oriented Light-Load Embedded Performance Modeling,"With increasing development of big data, the performance assessment and optimization face with a big challenge. The traditional methods widely use delivery-testing-analysis-solving (DTAS) ring. In big data area, big data environment is necessary for the testing phase in DTAS, which results in the big cost in both time and hardware. This paper proposes the big data oriented light-load embedded performance modeling. It ascertains the performance criteria to set the Capacity and Performance (C&P) factors. These factors will be embedded into the software with an on-off switch during the architecture, design and developing phases before DTAS phase. After the software coding done with embedded C&P factors, a small traffic load is run to collect the C&P data. The collected data will be used for the performance bottleneck finding, performance optimization, and forecasting the capacity and performance for various customers' scenarios. Since the data easily help locate the issue, the required running traffic is small, and the problem solving is done before the traditional DTAS, this study is more suitable for the big data application. It can save more than 50% of time, decrease the software development efforts, and reduce the lab resources occupation. Finally, the proposed method is employed in the real prototype of an Internet of Things application, obtains the better capacity and performance, and the experiment data verify its effectiveness."
9050303,Improvement Strategy of Sports Product Network Marketing Strategy Based on Big Data Analysis,"A sports goods company with big data resources is taken as an example in this paper, to be investigated and analyzed intensively using real-life cases of network marketing strategies and means. According to the monitoring indicators of network marketing effects carried out by the company during network marketing, the system of network marketing effect monitoring of sports goods company is simply established. The problem of establishing a large company from is discussed in four aspects: marketing environment, strategy and planning, organizational structure and marketing process The data marketing system proposes recommendations and transition plans for the big data marketing platform. Through empirical analysis, it draws opinions and suggestions on the improvement of online marketing, website promotion, online advertising, online sales and microblog marketing."
9587175,Data Transaction Pricing Model for Energy Big Data Centers,"This paper studies and proposes an energy data transaction method based on the combination of multi-layer hierarchical fusion fuzzy feature mapping method (MLHFFFM) and long short-term memory neural network (LSTM). First, analyze the big data collected to determine the type of missing data. On this basis, MLHFFFM and fuzzy C-means algorithm (FCM) are used to cluster electricity big data, and the LSTM neural network is trained based on the characteristic values of different users and historical data, and different pricing strategies are designed for different data types. Finally, the feasibility and reliability of the improved method proposed in this paper are verified through the data analysis and comparison experiment of the public data set."
9181320,Analyzing and Exploring the Impact of Big Data Analytics in Sports Science,"Big data is the first-ever use of data and statistics enabling to make effective decisions in professional sports. The primary focus of the research paper is to evaluate how the use of big data has benefited sports. The research work conducted in the paper focuses on extracting information from the constructed database as per user requirements. Two different databases have been constructed by gathering data from espncricinfo.com. The first database consists of the records of batsmen comprising 15 attributes relevant to the international career of the batsmen. The second database contains records of bowlers involving 16 attributes relevant to the international career of the bowlers. The research paper encompasses a detailed flowchart and an algorithm detailing the systematic approach followed to mine required data from the database. The research work conducted would enable any cricket fan or a layman to mine the information in which he/she is interested. The proper utilization of the data gathered from different sources like wearable devices enables coaches and team management to get the best out of the players. The research paper elaborates on the use of the Hortonworks Hue 2.2.0 framework in analyzing the gathered data and extracting information via appropriate tools of the framework as per need. The constructed database is uploaded into the framework and the queries and scripts are formatted to get results in tabular and graphical form. The research work would enable coaches and instructors to select best batsmen and outstanding bowlers to construct a strong team via mining the relevant databases and come out with the best outcome. The research work would even enable general masses to built their own teams after analyzing the past performance of different batsmen and bowlers and construct their own teams and participate in fantasy gaming platforms like Dream11, MyTeam11, Howzat, etc."
9603577,Construction and path of innovative information management platform for flow of high-level talents in local universities in the era of big data,"Using big data technology to build talent flow information management platform, with its powerful data capture, data analysis, data storage, data calls and a series data visualization technology, innovative flow by the high-level visitors guide, salary welfare treatment, process specification, control service, education, training and regulatory constraints problem overall planning. And it gives quantitative decision support to the management of high-level talent flow in local colleges and universities, so as to promotes the formation of a talent system and development environment in regional colleges and universities."
9139118,Research on Data Security Protection Method Based on Big Data Technology,"The construction of power Internet of things is an important development direction of power grid enterprises in the future. Big data not only brings economic and social benefits to the power system industry, but also brings many information security problems. Therefore, in the case of accelerating the construction of ubiquitous electric Internet of things, it is urgent to standardize the data security protection in the ubiquitous electric Internet of things environment. By analyzing the characteristics of big data in power system, this paper discusses the security risks faced by big data in power system. Finally, we propose some methods of data security protection based on the defects of big data security in current power system. By building a data security intelligent management and control platform, it can automatically discover and identify the types and levels of data assets, and build a classification and grading information base of dynamic data assets. And through the detection and identification of data labels and data content characteristics, tracking the use of data flow process. So as to realize the monitoring of data security state. By protecting sensitive data against leakage based on the whole life cycle of data, the big data security of power grid informatization can be effectively guaranteed and the safety immunity of power information system can be improved."
9378470,Benchmarking performance of RaySGD and Horovod for big data applications,"With the advent of big data, training deep learning models quickly has gained prime significance. The faster a model is trained, the more relevant are its predictions in a given context. Deep learning is used for non structured data such as images, videos, sounds, text corpus, all of which represent a huge volume of data and also use complex models. Training these workloads can often take days or even weeks, because of various factors such as size of data, complexity of model, network and the underlying hardware infrastructure. The recognized divide and conquer solution to expedite the training process is to distribute either data or the model. Alas, the challenges of a distributed training setup are well known - creating and maintaining a cluster, enabling data or model parallelism along with uninterrupted communication across the cluster nodes.In this paper, we focus on two lightweight libraries for distributed deep learning, RaySGD and Horovod, which aim to alleviate these challenges by providing support for seamless parallellization. We conduct an in-depth benchmarking exercise to evaluate the performance of both libraries for training time(latency) incurred. Our experiments are conducted on a combination of various parameters such as hardware setup (CPU or GPU based), standard and manually coded models, real world and synthetic datasets. We also vary batch sizes of large workloads and number of worker nodes in a distributed setting. The insights obtained from our experiments act as guidelines for data scientists, facilitating the decision making process when conducting distributed training of big data applications on RaySGD or Horovod."
9260639,A New Algorithm for Maximizing Total Big Data Flow in a Cloud Radio Access Network,"In this paper, we propose a new algorithm to maximize the total down link Big Data flow in terms of total number of transmitted packets per millisecond for cloud radio access networks (C-RANs). We formulate the above problem using the C-RAN graph. The fairness is the implicit objective of this problem. The proposed algorithm solves this problem by selecting paths of the Big Data transmission. Simulation results show that the proposed algorithm achieves better total Big Data flows, as well as better fairness."
9434479,Scientometric Analysis of Research on Network Public Opinion in A Context of Big Data,"Big data, as both a scientific tool and a new thinking pattern to analyze the data sets, has brought a profound influence on the research of network public opinion. To propose a reference for further study based on the application of big data in network public opinion, this paper aims to analyze the annual trends, main countries, institutions, publications, and topics of the relevant papers collected from the Web of Science (WoS) database. The findings show that there are several institutions from China, the U.S., Spain, and South Korea have made an outstanding contribution to it. The bibliographic coupling network of publications shows the capacity of the research in enabling interdisciplinary collaboration in the context of big data. Based on the co-occurrence network generated from the author's keywords data, a concise keywords map is produced and there are five clusters on it, including (a) big data and social media, (b) public sentiment and opinion mining,(c) sentiment analysis and machine learning, (d) elections and political communication, and (e) research methods."
9017182,Turbine Load Control Instability Fault and Its Diagnosis Method with Big Data Fusion Model,"Turbine load control instability fault has a great impact on the thermal power unit's primary and secondary frequency modulation performance. A new type of load instability fault was found by checking the actual operation condition of a 660 MW supercritical steam turbine, that is, the actual load rejection amount of the regulating valve is as high as 200 MW under the condition of small action. Through comprehensive analysis, the physical mechanism of the actual fault is found: One of the high-pressure steam control valve servo cards had a problem, which caused the valve to close completely due to abnormal voltage. Feedback monitoring of the valve showed that it was in normal condition, but the valve was found to be completely closed on site. Based on the above fault mechanism, this paper establishes a fault diagnosis model, and realizes the effective identification of such faults based on the fusion of actual running big data. Finally, an effective solution for this fault is proposed, which improves the fast and accurate load-changing capacity of high-power steam turbines, and has certain reference significance for similar units."
9280585,Applying Big Data and Machine Learning Approach to Identify Noised Data,"Everyday, amount of data is growing up very fast and users are faced to work with different kinds of data such as photo, video, audio. Sometimes, condition of some piece of data is not appropriate to work with this data. it may happen if data has been corrupted by some factors that are not related to user. Since amount of data has become enough large it is better to use some approaches that allow user to handle data for reasonable time. So, applying big data and machine learning was reviewed in this article. As big data approach usually uses cluster computation therefore time for computing depends on specification of each node and number of nodes. Also, it is possible to use the same machine learning model within all nodes that leads to reduce time of identifying noised data. Combining both approaches shows pretty good results, that are acceptable to set down as reasonable for user."
9532949,Innovation of Chronic Disease Management Mode of Household Medical Devices based on the Perspective of Big Data,"The increasing aging of the population and the changing spectrum of diseases have caused chronic diseases to become a major public health problem in our country. This article first cleans up the original data, removes single users and crawler users, and observes the distribution of purchase conversion rates over time through data visualization. The main feature of explicit feedback data is that users clearly express their preferences, and such preferences can be quantified. One of the most representative is the user's rating of the content, because the user knows that they are expressing their attitude. Therefore, this article applies big data analysis to chronic disease management."
9134292,Study on the Evaluation Module of Ship Operation Management under Big Data View,"This paper introduces the development of intelligent ships, then analyzes the types of big data collected by ships. Finally, the author puts forward the data analysis process for the intelligent ship operation management module, points out the main aspects affecting ship operation management. The process makes the direction for the intelligent modeling of ship operation management, and lays the research foundation for intelligent ship operation management."
8776717,Multi-Resolution Hierarchical Structure for Efficient Data Aggregation and Mining of Big Data,"Big data analysis is essential for modern applications in areas such as healthcare, assistive technology, intelligent transportation, environment and climate monitoring. Traditional algorithms in data mining and machine learning do not scale well with data size. Mining and learning from big data need time and memory efficient techniques, albeit the cost of possible loss in accuracy. We have developed a data aggregation structure to summarize data with large number of instances and data generated from multiple data sources. Data are aggregated at multiple resolutions and resolution provides a trade-off between efficiency and accuracy. The structure is built once, updated incrementally, and serves as a common data input for multiple mining and learning algorithms. Data mining algorithms are modified to accept the aggregated data as input. Hierarchical data aggregation serves as a paradigm under which novel data representations and algorithms work together for analysis and mining of big data. To evaluate its performance, we have implemented a multi-resolution Naive Bayes Classifier on the data aggregation structure. Experimental results show that the proposed structure helps the classifier to reduce computation time to 25% on average and reduce the memory usage while preserving the accuracy of results."
9362697,Application research of unmanned ship route dynamic planning based on meteorological big data,"In order to realize that unmanned cargo ship can move forward according to the optimal route and reduce the risk in the harsh environment of wind and wave, a D* algorithm for dynamic route planning based on A* static route planning is proposed. Firstly, spark big data processing platform is built. The big data platform is used to preprocess data, extract effective features and build weather forecast models. In the construction of weather forecast model, the commonly used forecasting models are used to predict and optimize the optimal model parameters. Select the F1 value of each model for comparison, and then select the model with the highest F1 value in each period as the prediction model of the period according to the characteristics of weather data. Finally, the results of multiple models are summarized to form the final weather forecast data set. Then, according to the starting point and terminal point, combined with D* dynamic programming algorithm, a safe and shortest route is planned when the threat changes constantly."
8920786,Iterative Encryption Method of Transmission Data Anti-Tampering Based on Big Data,"In order to improve the security of transmission data storage in supercomputer network, a supercomputer network transmission data encryption technology based on elliptical hyperbolic iterative coding is proposed. The elliptical hyperbolic differential equation is constructed, and the big data of the supercomputer network is loaded into the elliptical hyperbolic differential equation. A set of high-order statistical characteristic solutions describing the frequency of the quantitative coding symbol are obtained. The tamper-proof iterative encryption cipher design and the public key coding configuration are carried out. The random quantitative coding fusion method is used to carry out the tampering proof iteration of the computer network transmission data. The anti-tampering encryption, secure storage and transmission of data transmission in supercomputer network are realized under Logistics chaotic mapping system. The simulation results show that the encryption technology has good tamper proof performance, strong anti-attack ability and good secure transmission performance for supercomputer network transmission data encryption."
8950481,A missing power data filling method based on improved random forest algorithm,"Missing data filling is a key step in power big data preprocessing, which helps to improve the quality and the utilization of electric power data. Due to the limitations of the traditional methods of filling missing data, an improved random forest filling algorithm is proposed. As a result of the horizontal and vertical directions of the electric power data are based on the characteristics of time series. Therefore, the method of improved random forest filling missing data combines the methods of linear interpolation, matrix combination and matrix transposition to solve the problem of filling large amount of electric power missing data. The filling results show that the improved random forest filling algorithm is applicable to filling electric power data in various missing forms. What's more, the accuracy of the filling results is high and the stability of the model is strong, which is beneficial in improving the quality of electric power data."
7937830,Semantic-Based and Entity-Resolution Fusion to Enhance Quality of Big RDF Data,"Within an organisation, the quality in big data is a cornerstone to operational, transactional processes and to the reliability of business analytics for decision making. In fact, as organizations are harnessing multi-sources data to rise the benefits of their business, the quality of data becomes important and crucial. This paper presents a new approach to query big data sources using Resource Description Framework (RDF) representation to ensure data quality by harvesting more relevant and complete query results. Our approach handles two important types of heterogeneity over multiple data sources: semantic heterogeneity and URI-based entity identification. It proposes (1) a semantic entity resolution method based on inference mechanism using rules to manage the misunderstanding of data, in real world entities (2) Data Quality enhancement using MapReduce-based query rewriting approach includes the entity resolution results to infer and adds implicit data into query results (3) a parallel combination of MapReduce jobs of saturation and query rewriting inferences to handle transitive and cyclic rules for a richer rules' expression language (4) experiments to assess the efficiency of the proposed approach over real big RDF data originating from insurance and synthetic data sets."
9378423,Performance Evaluation of Tree-based Models for Big Data Load Forecasting using Randomized Hyperparameter Tuning,"In this paper machine learning (ML) models have been developed for the application of big data load forecasting using parallel computation. The load forecasting models' performance is directly linked to system execution capacity, memory, thread count, balancing the load, and available resources. This paper is focused on two main challenges. The first challenge is to reduce the execution time of the ML models and the second one is to choose the suitable tree-based model for effective load forecasting. The paper conducts a comprehensive evaluation of the load forecasting using real-world data on energy consumption. Comprehensive results are obtained to show that the performance of random search to tune the ML models exhibits competitive performances whilst not losing the accuracy of the models and gaining a competitive advantage on the run time."
8845054,Research on Individualized Teaching Based on Big Data Mining,"Big data is a valuable resource of Internet education platform and an important technology to provide individualized service for learners. This paper discusses the application of four kinds of big data mining techniques, clustering, classification, association analysis and specific group, in individualized teaching, and puts forward a set of individualized education method system based on big data and data mining methods. It also analyzes the four levels of the overall framework and the specific methods of individualized education based on big data."
9047449,Financial Big Data Hot and Cold Separation Scheme Based on HBase and Redis,"In the era of big data, HBase has been widely used in scenarios of massive unstructured data. For the financial big data, due to the integrity and timing of it, unreasonable data storage and management usually lead to hot spots that decreases the query performance. In practice, the separation of hot and cold financial data will improve data query performance and utilization rate of cluster resources. In this paper, a hot and cold data separation scheme is designed, to store infrequently queried financial data to HBase, and frequently queried one to Redis. The cold data is reasonably planned and managed through pre-partitioning and row key design for HBase. A hot data cache based on Redis is realized to improve the query speed and reduces the pressure of HBase. In addition, due to the lack of Redis's inherent cache elimination strategy, we propose a caching strategy based on the frequencies of updating and querying operations. The experimental results show that the scheme can effectively avoid the hot storage problem, and improve the query performance, and improve the cache hit ratio of Redis. Therefore, the number of cold data access requests can be effectively reduced."
9297106,Clustering Analysis for Big Data in Network Security Domain Using a Spark-Based Method,"Considering the problem of network security under the background of big data, the clustering analysis algorithms can be utilized to improve the correctness of network intrusion detection models for security management. As a kind of iterative clustering analysis algorithm, K-means algorithm is not only simple but also efficient, so it is widely used. However, the traditional K-means algorithm cannot well solve the network security problem when facing big data due to its high complexity and limited processing ability. In this case, this paper proposes to optimize the traditional K-means algorithm based on the Spark platform and deploy the optimized clustering analysis algorithm in the distributed architecture, so as to improve the efficiency of clustering algorithm for network intrusion detection in big data environment. The experimental result shows that, compared with the traditional K-means algorithm, the efficiency of the optimized K-means algorithm using a Spark-based method is significantly improved in the running time."
9094892,Based on the OSGi framework LIS isomers Big data collection practice,"The collection and utilization of big data information is changing the concept and method of collecting data. For the new situation map information acquisition, the challenge than the greatest collection of vast amounts of heterogeneous information from the network, extraction, analysis and other operations. Heterogeneous network information such as blogs, news and user behaviors are gradually becoming an important part of the attention and collection in the field of graphics. At the same time, the collection of heterogeneous big data information is a difficult problem for the graphic workers. In this paper, through the heterogeneous big data collection mechanism of OSGi framework, the application of graph-related big data is practiced, and it is hoped that it can provide a heterogeneous graph information collection idea for peers."
9533143,Situation and lessons of application of NBA big data technology,"This study probes into application of big data technology in NBA events, analyzes the impacts of big data on NBA players, the teams, the team’s performance and media audience. The research result shows that elaborate statistics of NBA events not only allows search of information of individual players, but enables comparison of two players and their respective performance in attack-defense. The Sport VU big data system makes the sports data a hot cake again. Big data technology provides a tool for coaches to guide and train the players and NBA trade. NBA can also share the information with broadcasters to bring in marketing benefits. Big data will go a long way to international communication of NBA."
9360990,Research on the Development Strategy of Guangfu Traditional Music Culture Based on Big Data,"China is a country with vast territory, rich resources and prosperous nation. Its traditional culture is rich and colorful and has a long history. As an important part of Chinese traditional music culture, Guangfu traditional music has a long history, profound cultural accumulation and rich music reserves, which has a high value of music culture. The restoration of traditional music is a model of Lingnan Music Culture. The blending of northern and southern cultures and the collision of Chinese and Western cultures has formed the characteristics of ancient, young and colorful national music. Under the background of the diversified development of global economy and culture, the development of music culture industry is also facing great challenges and opportunities. Based on big data, this paper investigates and studies the traditional music culture of Guangfu, analyzes the basic situation of Guangfu traditional music culture, and finally puts forward some suggestions for the development of Guangfu traditional music culture, hoping to promote the development of Guangfu traditional music culture."
8964836,Constructing Knowledge Graph from Big Data of Smart Grids,"The big data of grid is characterized by a large amount of data and complex structure. There are many kinds of grid equipment in the grid and smart grid, and their relationships are complicated. Therefore, it is necessary to analyze and visualize the grid equipment information and relationships reasonably to improve and develop the grid information system. The power equipment information in the data center is relatively complex and does not reflect the relationships between the equipment well. In order to manage and use grid equipment information better, we propose a grid equipment knowledge graph to solve the problem of ""information island"" of smart grid equipment. A knowledge graph has been constructed according to the grid equipment big data from the grid domain data center, which reflects the multifaceted information of the equipment as well as inter-equipment relationships."
9371818,A review of data analytics techniques for effective management of big data using IoT,"IoT and big data are energetic technology of the world for quite a time, and both of these have become a necessity. On the one side where IoT is used to connect different objectives via the internet, the big data means having a large number of the set of structured, unstructured, and semi-structured data. The device used for processing based on the tools used. These tools help provide meaningful information used for effective management in different domains. Some of the commonly faced issues with the inadequate about the technologies are related to data privacy, insufficient analytical capabilities, and this issue is faced by in different domains related to the big data. Data analytics tools help discover the pattern of data and consumer preferences which is resulting in better decision making for the organizations. The major part of this work is to review different types of data analytics techniques for the effective management of big data using IoT. For the effective management of the ABD solution collection, analysis and control are used as the components. Each of the ingredients is described to find an effective way to manage big data. These components are considered and used in the validation criteria. The solution of effective data management is a stage towards the management of big data in IoT devices which will help the user to understand different types of elements of data management."
9378118,Adopting Agile Software Development Methodologies in Big Data Projects – a Systematic Literature Review of Experience Reports,"During the last decade, agile software development methodologies have been widely adopted in various project contexts. Big data projects are different from software engineering projects in all three aspects - people, processes and technologies. Recent research has shown that agile approaches are suitable and beneficial when applied in big data projects. The aim of the current study is to investigate which of the agile software development methodologies are currently applied in big data projects and what are the key considerations for their application. As a first step towards achieving this aim, the paper presents a systematic literature review of research articles reporting real-world experience of adopting agile methodologies in different big data science contexts. The findings of the study are beneficial to both practitioners and researchers to define and adopt agile approaches which are well suited for their big data projects."
9245460,A Big Data Lake for Multilevel Streaming Analytics,"Large organizations are seeking to create new architectures and scalable platforms to effectively handle data management challenges due to the explosive nature of data rarely seen in the past. These data management challenges are largely posed by the availability of streaming data at high velocity from various sources in multiple formats. The changes in data paradigm have led to the emergence of new data analytics and management architecture. This paper focuses on storing high volume, velocity and variety data in the raw formats in a data storage architecture called a data lake. First, we present our study on the limitations of traditional data warehouses in handling recent changes in data paradigms. We discuss and compare different open source and commercial platforms that can be used to develop a data lake. We then describe our end-to-end data lake design and implementation approach using the Hadoop Distributed File System (HDFS) on the Hadoop Data Platform (HDP). Finally, we present a real-world data lake development use case for data stream ingestion, staging, and multilevel streaming analytics which combines structured and unstructured data. This study can serve as a guide for individuals or organizations planning to implement a data lake solution for their use cases."
7962184,Achieving Efficient and Privacy-Preserving Cross-Domain Big Data Deduplication in Cloud,"Secure data deduplication can significantly reduce the communication and storage overheads in cloud storage services, and has potential applications in our big data-driven society. Existing data deduplication schemes are generally designed to either resist brute-force attacks or ensure the efficiency and data availability, but not both conditions. We are also not aware of any existing scheme that achieves accountability, in the sense of reducing duplicate information disclosure (e.g., to determine whether plaintexts of two encrypted messages are identical). In this paper, we investigate a three-tier cross-domain architecture, and propose an efficient and privacy-preserving big data deduplication in cloud storage (hereafter referred to as EPCDD). EPCDD achieves both privacy-preserving and data availability, and resists brute-force attacks. In addition, we take accountability into consideration to offer better privacy assurances than existing schemes. We then demonstrate that EPCDD outperforms existing competing schemes, in terms of computation, communication and storage overheads. In addition, the time complexity of duplicate search in EPCDD is logarithmic."
9650308,Research on Network Communication Model and Network Security Technology through Big Data,"Based on my country’s current cyberspace security situation and defense requirements, this article analyzes the shortcomings of traditional cybersecurity defense systems and the advantages of applying big data technology for network security analysis, and on this basis, proposes a collection of security data, A security situational awareness platform that integrates processing, analysis, and security risk discovery, monitoring, alarming, and pre-judgment. Experimental results show that the accuracy rate of the evaluation technology is up to 96%, and users can use the network driven by big data to ensure the safety of users’ personal information."
9006465,A graph construction study for graph-based semi-supervised learning: Case study on unstructured text data,"A study is presented on how the distance/similarity metrics impact the graph construction and the subsequent classification task in the cases of unstructured text data. Two unstructured text datasets, a E-com. and the 20 newsgroups data are considered and three distance/similarity metrics are evaluated. State-of-the-art metrics are observed to be more effective for graph construction metrics and prediction accuracy for the LP ZGL classification algorithm. Experimental results are promising given the scalable nature of graph-based SSL techniques, and scope of big data processing for text datasets."
9418960,Optimization of Teaching Content and Reform of Teaching Methods on the Course of Coal-Geology Based on Big Data Analysis,"Coal-geology course is one of the core courses of resource exploration engineering major in most universities of geology, mining and petroleum. In the process of teaching, we should constantly improve the optimization design of course content, optimize course content and reform teaching methods through big data technology analysis. On the basis of the training goal, requirement, the study purpose and the emphasis difference of resource exploration engineering major, the course has relatively fewer class schedule, obviously, fewer theoretical and experimental classes, it increases the difficulty of teachers to master the teaching content of the course. Since the content of the course is the basis of ensuring the teaching goal, talent training and implementation process, therefore, the content of the course should be targeted and selected, we should grasp flexibly the big data features of systematicness, scientificalness and progressiveness of courses content, improving students' learning motivation and active participation, making full use of information technology, constantly innovating teaching methods, improving teaching quality, promoting teaching level and students' comprehensive quality, in this way, we can ensure the unity of teaching process, optimization design and teaching efficiency."
8759919,Online Incremental Machine Learning Platform for Big Data-Driven Smart Traffic Management,"The technological landscape of intelligent transport systems (ITS) has been radically transformed by the emergence of the big data streams generated by the Internet of Things (IoT), smart sensors, surveillance feeds, social media, as well as growing infrastructure needs. It is timely and pertinent that ITS harness the potential of an artificial intelligence (AI) to develop the big data-driven smart traffic management solutions for effective decision-making. The existing AI techniques that function in isolation exhibit clear limitations in developing a comprehensive platform due to the dynamicity of big data streams, high-frequency unlabeled data generation from the heterogeneous data sources, and volatility of traffic conditions. In this paper, we propose an expansive smart traffic management platform (STMP) based on the unsupervised online incremental machine learning, deep learning, and deep reinforcement learning to address these limitations. The STMP integrates the heterogeneous big data streams, such as the IoT, smart sensors, and social media, to detect concept drifts, distinguish between the recurrent and non-recurrent traffic events, and impact propagation, traffic flow forecasting, commuter sentiment analysis, and optimized traffic control decisions. The platform is successfully demonstrated on 190 million records of smart sensor network traffic data generated by 545,851 commuters and corresponding social media data on the arterial road network of Victoria, Australia."
8817152,Evaluation of Big Data Governance - Combining a Multi-Criteria Approach and Systems Theory,"The main objective of Big data is to meet business competitiveness and facilitate decision-making. To achieve this goal, the implementation of a governance plan is necessary. In this article, we propose a big data governance evaluation approach based on the fact that big data governance is seen as an artifact having the characteristics of a system. We develop a multi-criteria hierarchy organized according to the main dimensions of systems theory. The approach is illustrated on a practical case."
8938944,Research on the Course System of Data Science and Engineering Major,"With the convergence and integration of information technology and human production and life, data has grown rapidly, and data has become the basic strategic resources of the country. It is followed by the construction of data science and engineering major in various universities, and this major is related to the disciplines of data science, computer science, mathematics and engineering management, and also a practice-oriented discipline. These reasons make very high demands on the training of talents in the data science and engineering major. Based on analysis features of the data science and engineering major and the goals that the professional needs, in this paper we discusses the basic skills that the talents should have, and pushes back to the construction of the professional curriculum system of data science and engineering major. Through the analysis method of this paper, we have completed to setting the course system of data science and engineering major and discussed the methods and the ways in the implementation of the curriculum system."
9468752,Application of Big Data in Improving College Students'Happiness,"The scientific application of big data technology can significantly improve college students'well-being, combine big data with student safety management, form student safety database, combine big data with student life service, form student life database, combine big data with student learning, and form student safety database. Academic database. If students' safety data, life data and academic data are collected and analyzed effectively, it can become a platform for diagnosis and improvement of students' work."
9108826,Big Data: Current Challenges and Future Scope,"Big Data encompasses huge amounts of raw material which influence multitude of research fields as well as different industries performance such as business, marketing, social network analysis, educational systems, healthcare, IoT, meteorology, fraud detection. It aimed to uncover hidden trends and has prompted a development from a model-driven perspective to a data-driven approach. Among numerous properties of Big Data, datasets of Big Data are identified primary as 3Vs attributes which have high variety, velocity and volume. These provide an invaluable insight and assist in making precise decisions. Analyzing this information and outlining the outcome into helpful data is the method for extricating an incentive from these enormous volumes of datasets. Nevertheless, Big Data containing unique features that cannot be handled and processed using the conventional methods. This has presented a significant challenge to the industry. This research paper presents a general outline of the characteristics of Big Data as well as expounds on the present challenges and limitations in this area. It further discusses the future scope in particular the future direction for Big Data research."
9360963,Preschool Education Model based on big data era,"With the development of Internet, cloud computing and big data technology, more and more attention has been paid to the intellectualization and informationization of preschool education. Big Data Technology plays an important role in the reform and development of education model in the new era, and has made great progress in the application research of preschool education model. In the era of big data, the Internet and other platforms can help teach children to learn, cultivate children's learning interest and enthusiasm, expand children's digital life and learning space. Based on this, this paper mainly uses the data mining technology and the neural network model to carry on the big data analysis to the present preschool education teaching way as an example, studies the application of the big data technology in the present preschool education model reform, some suggestions on the application of domestic big data in preschool education are put forward. Research shows that the pre-school education model in the era of big data has been extended and expanded to online education, which broadens the channels for pre-school children to acquire knowledge and stimulates their interest in learning, it can be seen that big data is of far-reaching significance to the reform of preschool education model."
8785871,Research progress on network public opinion based on rough sets from the big data perspective,"In the era of big data, the features of online public opinion give some serious challenges for existing data analysis methods and it's necessary to find new ways to deal with these challenges. Granular computing can simulate human thinking mode to think about and solve large-scale and complex problems. This pattern provides an effective tool for meeting the challenges in online public opinion. This paper focus on rough sets to give a review on granular computing based online public opinion. Some existing problems are analyzed and the future research direction of this filed are looked ahead."
9498787,Application of Big Data Technology in Economic Statistics,"With the rapid development of Internet, database, intelligent equipment, produce a large amount of information on tax policy uncertainty, large data with vast, real-time, and unstructured data more superiority than traditional statistical data, the economists began to start based on big data technology to obtain the real-time data measure policy uncertainty. This paper mainly studies the application of big data technology for economic statistics. China's tax policy system in this paper combed the different periods of uncertainty are reviewed at home and abroad about tax policy uncertainty measure method, frequency method, the frequency of web search method based on news reported, subjective perception deviation method three big data respectively to measure the China's tax policy uncertainty and subdivision tax policy uncertainty."
8875352,Big Data Analysis and Services: Visualization on Smart Data to Support Healthcare Analytics,"In this era of big data, high volumes of a wide variety of valuable data can be easily generated or collected at a high velocity. As such, big data analysis is in demand in various real-life applications and services (e.g., healthcare) as it helps to find useful information and valuable knowledge that are embedded in the big data. The resulting information and knowledge is usually in textual or tabular forms. Given that ""a picture is worth a thousand words"", visualization and visual analytics helps. In this paper, we present a system for visualizing smart data-as well as their related information and knowledge-from health data, which in turn supports healthcare analytics."
9442495,EPIC Collab: Supporting Asynchronous Collaboration in Big Data Analysis Systems,"The rise of big data has led to the creation of large datasets that require teams to collaborate to analyze data effectively. Unfortunately, the software systems that collect and analyze large datasets are not often designed to support this kind of collaboration. Accordingly, our work investigates issues related to supporting collaboration in big data analysis systems. We use the domain of crisis informatics and the software infrastructure of Project EPIC as a case study to gain insight into the features that analysts need to effectively perform analysis at scale. This paper focuses on supporting asynchronous collaboration among analysts who work in small distributed teams on big data software systems. It describes the challenges faced by researchers who work collaboratively to analyze large crisis datasets (consisting, typically, of Twitter data). It then describes the work performed to redesign an existing big data analysis environment to substantially improve its support for collaboration. The impact of this research lies in its ability to improve the work of similar teams performing large-scale data analysis. While our work is based on insights gleaned from crisis informatics, we believe that our design, results, and lessons learned are broadly applicable to other application domains."
8873519,Research on the Application of Agricultural Big Data Processing with Hadoop and Spark,"Numerous terminal equipment in the agricultural park collect environmental data that affects crop growth every day. Proper analysis of these massive amounts of data can acquire useful information on the status of crop growth. In this paper, two cloud computing frameworks, Apache Hadoop and Apache Spark are used to study agricultural big data analysis. This paper developed applications for real agricultural park big data analysis in both frameworks and implemented a yield prediction model based on multiple linear regression using Spark MLlib. The performance of the two frameworks in agricultural big data processing was studied and compared through various experiments. The experiments show that the comprehensive performance of Spark is higher than Hadoop, and the model can obtain better prediction results."
9514240,Incorporation of Big Data in Methodology of Identifying Corrosion Factors in the Semiconductor Package,"The semiconductor packaging industry driven by packaging complexity and product miniaturization. Hence, the problem identification methodology in semiconductor industries is a critical interest, and a basis of continuous improvement where the lesson learned is an integral part of it. Nevertheless, the problem identification approach is stagnant at the traditional method, such as the statistical-based methodology. There are several studies on the problem identification process in semiconductor through the six-sigma methodology and statistical approach, however, the scope is limited to the inferential statistic. Therefore, the focus of this paper is proposing using big data approach which grounded on the information theory. The big data analysis approach is utilizing the algorithm and data visualization. Big data methods, such as MINE and clustering was applied to data from hundreds of variables that contain essential and undiscovered relationship. The big data analysis enables the potential factors that contributed to the root causes and provided significant input to the design of experiment and reliability analysis."
9463366,Technologies of distributed data stream processing based on big data,"In the big data environment, data stream processing requires high real-time performance, and data calculation requires persistence and high reliability. Distributed Data Stream Processing System (DDSPS) can solve the problem of data stream processing in the big data environment. In addition to the advantages of scalability and fault tolerance of distributed systems, it also has high real-time processing capabilities. This article introduces three open source distributed streaming data processing systems, and compares and analyzes these three streaming frameworks. The research content can provide technical reference for the theoretical research and application technology development of data stream processing in the big data environment."
8996332,Air quality data analysis and forecasting platform based on big data,"Nowadays, with the continuous development of big data technology, various industries use big data technology to process and mine massive data, and realize the value of data efficiently. In terms of air quality data processing, big data technology can also play a certain advantage. The platform is based on big data technology to design an air quality data analysis and prediction platform including data layer, business layer, interaction layer and visualization platform. Data is cleaned, calibrated, and stored in the data layer to ensure data consistency, integrity, and security. The air quality data is analyzed and predicted at the business layer. The interaction layer includes the functions of algorithm management, data query, and the data visualization platform provides intuitive information display. This design is a significant application for fully exploiting environmental data information. It has powerful data processing functions and scalability, which is a reliable data analysis and prediction platform."
8486794,"Big data analytics for healthcare industry: impact, applications, and tools","In recent years, huge amounts of structured, unstructured, and semi-structured data have been generated by various institutions around the world and, collectively, this heterogeneous data is referred to as big data. The health industry sector has been confronted by the need to manage the big data being produced by various sources, which are well known for producing high volumes of heterogeneous data. Various big-data analytics tools and techniques have been developed for handling these massive amounts of data, in the healthcare sector. In this paper, we discuss the impact of big data in healthcare, and various tools available in the Hadoop ecosystem for handling it. We also explore the conceptual architecture of big data analytics for healthcare which involves the data gathering history of different branches, the genome database, electronic health records, text/imagery, and clinical decisions support system."
9196279,Using Big Data to Analyze Relationship between post-95 College Students’ Advanced Consumption View and Employment View,"The post-95 college students' have gradually entered the society and become an important force in employment and consumption. As the other side of the labor market - enterprises, it is necessary to understand the main force of the future labor market, that is, the employment concept of the post-95 generation, in order to better guide enterprise HR to carry out human resource management, and further increase efficiency for enterprises. This study starts with the post-95 college students' advanced consumption view and explores whether it has an impact on the post-95 college students' employment view, which is also conducive to the enterprise HR to better understand the post-95 college students' view of these aspects. Finally, this study finds that the post-95 college students' concept of advanced consumption and employment is significantly related."
9321202,Hybrid recommender system for tourism based on big data and AI: A conceptual framework,"With the development of the Internet, technology, and means of communication, the production of tourist data has multiplied at all levels (hotels, restaurants, transport, heritage, tourist events, activities, etc.), especially with the development of Online Travel Agency (OTA). However, the list of possibilities offered to tourists by these Web search engines (or even specialized tourist sites) can be overwhelming and relevant results are usually drowned in informational ""noise"", which prevents, or at least slows down the selection process. To assist tourists in trip planning and help them to find the information they are looking for, many recommender systems have been developed. In this article, we present an overview of the various recommendation approaches used in the field of tourism. From this study, an architecture and a conceptual framework for tourism recommender system are proposed, based on a hybrid recommendation approach. The proposed system goes beyond the recommendation of a list of tourist attractions, tailored to tourist preferences. It can be seen as a trip planner that designs a detailed program, including heterogeneous tourism resources, for a specific visit duration. The ultimate goal is to develop a recommender system based on big data technologies, artificial intelligence, and operational research to promote tourism in Morocco, specifically in the Daraa-Tafilalet region."
8717484,Big Data Impacts and Challenges: A Review,"Data is everywhere, organizations, governments, clicks, web server, business partner, and even our body. Big Data comes to life with insights to improve the technology fashion and lifestyle with calling for readiness to change. Big Data has become a significant factor that could be a material asset for both business and government organizations. As such, it is important to understand the definition of Big Data, their key characteristics, and the challenges surrounding the concept and characteristics. The implementation of Big Data brings new critical challenges that need to be addressed before starting the Big Data journey. The main challenges that are commonly faced by organizations are the implementation of Big Data alongside the critical challenges that involve the challenges related to technology, organization, process, data management, and skills. The challenges are difficult and the growth in terms of Big Data is increasing exponentially which calls for further investigation. This paper reviewed the existing literature on Big Data to achieve three objectives: first, to highlight the definitions and characteristics of Big Data and to summarize the most common definitions of existing works; second, to identify the impacts and the opportunities for the Big Data; third, to present and identify the main critical challenges related to Big Data and categorize these challenges as (People, Technology, Organization, Process, and Data management) challenges."
8997699,Multi-dimensional Index Construction of Electric Power Multi-source Measurement Data considering Spatio-temporal Correlation,"The operation of complex AC/DC power grid changes rapidly and dynamically, which objectively puts forward higher requirements for on-line analysis, and it is urgent to improve the basic data quality of power grid. Because of low quality and poor synchronization of the basic data of power grid, it is impossible to accurately map the actual operation of the power grid. At the same time, the cross-system data matching degree is low and the data correlation is poor, so it can not support the multi-scale data analysis for all kinds of applications. In this paper, the associated method of multi-source heterogeneous data in the power grid is studied. Combined with big data's access characteristics, big data storage, big data retrieval and artificial intelligence technology, the high-speed data storage and index architecture of power big data are constructed, and a multi-dimensional index reflecting the associated relationship of operating data is established from the dimensions of time, space, application, device and so on. It is easier to analyze multi-source data, to improve the basic data quality of power grid, which provides effective support for accurate data analysis and evaluation of power grid."
9384593,Using Big Data to Monitor the Impact of the COVID-19 Epidemic on Notifiable Diseases Reported in China,"Coronavirus disease 2019 (COVID-19) outbreak in 2020 had a great impact on society, and comprehensive prevention and control measures were taken to contain the disease. The purpose of this paper was to evaluate the impact of these measures to other common diseases by describing the characteristics of notifiable diseases reported in mainland China. The data from January to August of 2017-2020 were collected from the web of China Health Department. Notification numbers in January for the period 2017-2020 increased year by year, from 482019 in 2017 to 1402839 in 2020, but numbers in February-August 2020 showed a significantly reduction of 55.04% compared with the same period in 2019. Notification numbers of Class C infectious diseases in February-August 2020 was 921495, a decrease of 76.19%, 67.13%, and 60.42% compared with the same period in 2019, 2018, and 2017. Moreover, the number of respiratory diseases, intestinal diseases, natural focus and vector borne diseases, and blood-borne and sexually transmissible diseases in February-August 2020 declined 68.06%,67.14%, 18.18%, and 13.51% compared with the same period in 2019. The results showed the number of notifiable infectious diseases significantly reduced in the COVID-19 epidemic, the measures were taken to control the outbreak of COVID-19, which would also be effective in reducing the incidence of intestinal and other respiratory diseases."
9004305,Hybrid Machine Learning-Based Intelligent Technique for Improved Big Data Analytics,"The average volume of data produced daily is estimated to be over 2.5 quintillion byte. Moreover, by year 2020, it is estimated that 1.79MB of data will be created every second by each person in the world. Apparently, big datasets contain tremendous amount of valuable information that can be used for improved decision making. However, big data requires incredible amount of storage and computational resources for effective processing. Machine Learning (ML) algorithms are effective tools popularly used to analyze and extract concealed insights from datasets. However, some ML algorithms were not originally designed to handle big datasets, hence their computational complexity decreases with increase in data size. Consequently, this makes big data analytics extremely slow or unrealistic. Therefore, there is an obvious need for fast and effective techniques for big data analytics. This paper introduces an intelligent hybrid ML-based technique suitable for big data analytics (called EDISA_ML). EDISA_ML is a boundary detection and instance selection algorithm, inspired by edge detection in image processing. It was evaluated on four ML algorithms and big datasets, and the results show that it achieved a storage reduction of over 50% and simultaneously improved the training speed of the evaluated ML algorithms by over 93% (in some cases), without meaningfully affecting their prediction accuracy."
8944495,Big Data in IoT,"The Internet of Things is generating an enormous amount of data. Analyzing and managing that data requires programming and statistical approaches. Big Data technology operates on this massive data and pushes new products, applications, future research and developments to improve decision making. In this paper, we explore Big data in IoT driven technologies and the issue of the four V's in Big Data. This paper also highlights the importance of pre-processing, metadata, data storage formats, data management and how big data is closely associated with IoT technologies. Today, with the rapid growth of IoT, everything is connected. To stay ahead of demands, new technologies such as Cloud Computing and Edge Computing are transforming IoT organizations. This paper discusses in which layers edge computing operates in the IoT reference model to achieve low-latency and greater efficiency solutions. This paper also reviews the IoT reference model layers that are associated with cloud computing, the structure of cloud computing architecture, data acquisition and data cleaning. This paper also discusses on various cloud-based IoT platforms such as AWS, Google Cloud IoT, Microsoft Azure, and Cisco IoT Cloud. We examined the importance of Big Data visualization, gives insights on various visualization tools and techniques. Lastly, this paper also addresses various significant challenges of Big Data in IoT, security issues and future research directions."
9404745,AFSA: A comprehensive analysis of Educational Big Data using the Advanced Feature Selection Algorithm,"The collection of the necessary information for predicting the academic progress of students can be an exhausting process due to inconsistencies and redundancies present in the data. Traditional machine learning algorithms as discussed in the literature contain certain drawbacks in terms of lack of accuracy, prediction analysis, and hence unable to establish the results of student performance. The objective of this paper is to propose an Advanced Feature Selection Algorithm to effectively apply educational data mining for performance. The algorithm is based upon Hadoop and Map Reduce framework. This study also consists of a comparative analysis of various feature selection algorithms such as jrip, naïve Bayes, decision table, etc., which evaluates the correctness of the data based on three parameters: memory, accuracy, and f-metrics. Overall, as per results received from comparative analysis, our proposed algorithm is a faster, accurate, and efficient way for administering educational data mining when compared to other algorithms."
9005955,An Informative Base of Positive and Negative Association Rules on Big Data,"The concept of informative base for association rules is the subject of many approaches. However, these approaches are based on positive rules but not on negative rules, and this with the less selective support-confidence pair. So that, these positive rules are not enough to cover all needs in context of Big Data, it also needs the negative association rules. In order to overcome these limitations, we propose a new approach for positive and negative association rules using the new selective pair, support -M GK . We also introduce NONREDRULES algorithm for mining all informative association rules. The experimental evaluation on the reference databases presents the extensive feasibility of our approach on the context of Big Data."
9115136,A Big Data Analysis Based System for the Comprehensive Evaluation of the Cultivation Quality of the Innovation and Entrepreneurship Skills among Chinese College Students,"The big data analysis based model for tracking the cultivation quality of college students’ innovation and entrepreneurship skills relies on the matching and synergy between elements such as diversified participants, funding, technology and network design, and institutional systems to achieve its swift and efficient operation. The creation and integration of these elements would be the future focus of this project. Through diversified data collection from existing systems and other databases, we employ the indigenously developed data scheduling system (DataX) to carry out centralized scheduling of data extraction, thereby building a big data analysis based system for the comprehensive evaluation of the cultivation quality of innovation and entrepreneurship skills."
9050421,Research on the Collection of Microcosmic Warning Indicators of Systematic Financial Risk Based on Big Data,"In the process of acquiring relevant early-warning index data, the collection efficiency of microcosmic early-warning index of financial risk is low due to the slow speed of data processing. To this end, a method of collecting microcosmic early warning index of systemic financial risk based on big data is proposed. Determine the principle of early warning of systemic financial risk, use big data technology to obtain systematic financial risk data, and establish the corresponding hierarchical structure. For each indicator of different hierarchical structure, membership degree is calculated, and the weight of warning indicator is finally determined, so as to complete the design of collecting method of micro warning indicator of systemic financial risk based on big data. Through comparative experiments, the proposed method has faster data processing speed and can improve the efficiency of collecting micro-warning indicators of systemic financial risks."
9268727,The decision trees and the optimization of resources in Big Data solutions,"every day, we see that a quantitative explosion of digital data has forced researchers to find new strategies to collect, store, analyze and visualize data. In the context of storage and processing of a large massive amount of data we find a lack of powerful tools to master and control them. Also, during the process of executing tasks in real time in clustered IT platforms, we encounter the problem of optimizing parallel tasks. So we will propose in this article a method based on the algorithm of decision trees as an interpretable machine learning algorithm which can allow us to evaluate the impact of certain characteristics on the variable of the task execution time. This decision tree algorithm is useful and it helps us understand how we can optimize the different parameters that affect workloads in clustered applications. We can thus optimize the number of tasks in Big Data clustered applications without failure and performance degradation."
9498813,Research on the Optimization Algorithm of Big Data Computing System,"With the social progress and development, the scale of data continues to expand, in order to realize the processing and analysis of large-scale data, graph computing system came into being. At present, with the continuous maturity of graph computing system, graph computing has been widely used in various fields, such as social field, Internet of things field and neural network field. In recent years, different graph computing models have emerged, and some typical distributed graph computing models show good expansibility in the formulation of graph data for big data processing. However, in order to further expand the expansibility, many graph calculation models are studied by algorithms. At present, the SFA algorithm is mostly used in the graph calculation system. However, with the continuous development of graph calculation, many inadaptability of the SFA algorithm appear which restricts the further development of graph calculation. Therefore, it is an urgent problem to optimize the algorithm of graph computing system. On the basis of scholars' research, this paper firstly gives a simple overview of graph calculation and graph calculation model. On this basis, it analyzes the specific formula and significance of SFA algorithm, puts forward the specific scheme of algorithm optimization, and carries out experimental detection of optimization algorithm."
9407680,Research on Intelligent Mode of Public Service Driven by Big Data,"Big data is the key to building a intelligent public service mode and a technical means to promote the modernization of national governance. However, the public service mode driven by big data has problems such as inefficient government purchases and failure to achieve multi-level and cross-departmental information interaction, which directly affects the quality of public service work. This article takes the “5V” characteristics of big data as the background, discusses the “5N” feature of optimizing public services, and proposes a intelligent mode of public services driven by big data, thereby enhancing the awareness of big data at all levels of public services."
9366648,2813-2020 - IEEE Standard for Big Data Business Security Risk Assessment,"This standard can be applied to internet-based business scenarios, and can also be served serve as a practical guide to achieve help assess business security risk control through the big data technology. This standard can be applied in other types of organization, including public or privately-owned or state-owned enterprises, associations, or organizations, or by individuals, to improve assessment of their protection capability against business security risks based on big data technology.
Scope:
This standard describes security risk assessment methodologies of user behavior, the applicable analysis layer and the fundamental analysis layer for big data.
Purpose:
The purpose of this standard is to standardize the reference framework and technical measures of Internet business security risk assessment based on big data technology, summarize and abstract internet business event data, and determine and quantify Internet business security risk through rule model and artificial intelligence model, covering the fields of text recognition, video recognition, voice recognition, picture recognition, URL identification, behavior identification and other aspects, including service provider's organization and personnel management, system and process development, data protection and other strategies, provide reference guide and technical support for security planning, security construction and security operation of big data business security risk assessment."
8757088,An overview and comparison of free Python libraries for data mining and big data analysis,"The popularity of Python is growing, especially in the field of data science. Consequently, there is an increasing number of free libraries available for usage. The aim of this review paper is to describe and compare the characteristics of different data mining and big data analysis libraries in Python. There is currently no paper dealing with the subject and describing pros and cons of all these libraries. Here we consider more than 20 libraries and separate them into six groups: core libraries, data preparation, data visualization, machine learning, deep learning and big data. Beside functionalities of a certain library, important factors for comparison are the number of contributors developing and maintaining the library and the size of the community. Bigger communities mean larger chances for easily finding solution to a certain problem. We currently recommend: pandas for data preparation; Matplotlib, seaborn or Plotly for data visualization; scikit-learn for machine leraning; TensorFlow, Keras and PyTorch for deep learning; and Hadoop Streaming and PySpark for big data."
9378024,Predicting Escalations in Customer Support: Analysis of Data Mining Challenge Results,"We summarize IEEE Big Data Cup: Predicting Escalations in Customer Support - a data mining competition organized jointly by companies Information Builders and QED Software at the KnowledgePit platform, in the frame of the 2020 IEEE International Conference on Big Data. We discuss the motivation for organizing this event and highlight the factors that make it such a challenging topic. We describe the data provided to participants and formulate the competition task. We also provide an overview of competition results with a detailed analysis of a few selected solutions. Finally, we present a novel functionality of the KnowledgePit platform - an analytic module that allows organizers to investigate selected solutions using a convenient GUI and provides in-depth insights about their quality."
9451749,A Review on Big Data: Privacy and Security Challenges,"In the age of technological innovations, the amount of data is increasing to a great extent. With this, an increasing trend is observed in the field of big data in industries as well as science. The scientific and industrial values of big data are growing high up to large magnitude. The technology of big data can be derived in many applications, but the main concern is the issue of security as well as privacy of data. This paper discusses the dimensions of big data and surveys the current research carried out on security as well as privacy of big data. The issues and the factors affecting the security are discussed. Furthermore, privacy-preserving approaches are also discussed and elaborated."
9442556,A Solution Framework for All-to-All Comparison Data Distribution Strategy Based on Tabu Search,"All-to-All Comparison (ATAC) is a key computing mode to improve computing performance and is applied in many disciplines. Through the research on the data distribution strategy of the ATAC calculation, a novel solution framework of the ATAC data distribution strategy based on tabu search is proposed for the first time. An ATAC data distribution model is constructed, and the related algorithms of the model are designed based on the tabu search, and it is implemented on MATLAB. The framework consists of three parts: 1) the driver module responsible for interacting with users; 2) the load balancing module that solves the data distribution strategy that meets the load balancing situation; 3) the storage optimization module that solves the data distribution strategy that meets the load balancing and optimized storage. Experiments prove that the framework for solving the ATAC data distribution strategy based on tabu search has the following advantages: A) The data distribution strategy obtained by the framework enables the nodes of the distributed system participating in the ATAC calculation to achieve load balancing and complete data localization. B) The data distribution scheme can reduce 40%-50% of the storage space in the distributed system. C) The framework is more advanced than the existing ATAC data distribution algorithm in calculation speed."
9410194,Denoising Control Method of Abnormal Signals in Communication Networks Based on Big Data Analysis,"In order to improve the denoising control effect of abnormal signals in communication network, a new denoising control method of abnormal signals in communication network based on big data analysis is designed in this paper. The linear prediction model and big data analysis method are used to sample and process the communication network signals, and the abnormal signals in the signal acquisition results are identified. The abnormal signals in communication network are decomposed into multiple IMF components of different time scales by using the empirical mode decomposition method. The IMF dominant component is used to reconstruct the signals, and the reconstructed signals are SWT transformed and median filtered. In this way, the SWT inverse transformation is used to obtain the denoising signals, and the denoising control of abnormal signals in communication network is realized. The simulation results show that the method has high accuracy of abnormal signal identification and denoising control, and the control time is short, and the control effect is better."
8805885,Summary of Research on the Application of Big Data in Auditing,"Audit refers to the independent economic supervision activities conducted by special organs in accordance with the law to examine the major projects and financial revenues and expenditures of governments at all levels, financial institutions, enterprises and institutions pre and post the event. The traditional method of auditing makes the audit work time not free, and the audit work cannot be carried out flexibly, accurately and efficiently. The application of big data in audit solves the problems existing in the traditional audit method. Big data audit is the inevitable choice of the development from traditional audit to modern audit and the transformation from traditional data to electronic data. Under the support of big data technology, auditors can directly obtain data information and analyze and verify it with only one computer and corresponding authority, thus enhancing audit flexibility and improving efficiency."
9358878,Big Data Privacy Breach Prevention Strategies,"Over the length of time, there has been an exponential increase in the number of netizens throughout the world. The surge in internet users has been especially prominent in times of the Covid-19 pandemic. Consequently, there has been a rise in social data collection from social media sites and apps. In addition to it, there is machine data generated by the sensors and other industrial and medical equipment and finally, transactional data generated from transactions performed online as well as offline. The big data collected from these principal sources provides invaluable insights to various small as well as leading organizations. Hence, these organizations and researchers direct considerable attention and efforts towards the high volume, velocity and variety (referred to as the “3V”) challenges. However, due to the sheer volume of the big data, high computing power and substantial storage are needed. This feat is achieved by the use of a network of distributed systems. Since multiple systems are involved in this process, the risk of privacy breach is increased manifold. The prevention of such breaches is crucial as it may result in leakage of highly sensitive data and impose a severe threat to the privacy of individuals. The primary objective of this paper is to provide a detailed synopsis of countermeasures that can be adopted against possible data breaches at the several stages of the big data life cycle (i.e., data generation, data storage and data processing) to ensure better security of the exabytes of big data generated each day."
9545972,A Log Analysis Technology Based on FP-growth Improved Algorithm,"With the continuous popularity of the Internet, network security has received more and more attention. Compared with intrusions from outside the network, abnormal operations of internal users often pose a greater threat to system security. Audit log analysis can discover abnormal behaviors or illegal operations of internal users through technologies such as data mining and pattern comparison, thereby adjusting security policies to ensure system security. Based on the FP-growth algorithm, this paper proposes an improved algorithm NEFP (New Efficient FP-growth) that does not generate conditional frequent pattern tree, and proposes an implementation plan for audit log analysis based on NEFP algorithm. Experimental results show that NEFP algorithm can perform log audit analysis more efficiently."
9373666,How to Effectively Infiltrate Emotional Education in Primary School Chinese Teaching from Perspective of Big Data,"Cultural inheritance and education is an important part of social development, primary school is an important period for children to receive cultural education, we should not only pay attention to the study of cultural courses but also pay attention to the infiltration of emotional education. With the development of the Internet, cloud technology and big data information in the field of education, the establishment of various education platforms and learning platforms has an increasing impact on primary school Chinese teaching. Based on this background, the purpose of this study is to combine the advanced technology of big data information with the efficient Chinese teaching in primary schools to improve the teaching quality. The research idea of this paper is to use big data information analysis and calculation in the emotional infiltration education of primary school Chinese teaching, analyze and demonstrate the data through the form of questionnaire and interview, and design the research scheme of how to effectively infiltrate emotional education in primary school Chinese teaching from the perspective of big data from the perspective of theory and practice. The research results of this paper show that in the emotional penetration education of Chinese teaching in primary schools, the proportion that the learning quality is affected by big data technology accounts for 67%, and the proportion that the emotional education has a positive impact on students accounts for 63%. The research results indicate that the active application of big data technology can effectively improve the quality of education and benefit the physical and mental health development of students. However, most teachers have little understanding and application of big data, and there is also the irrational phenomenon of emphasizing cognition and ignoring emotion."
8733046,Survey and Analysis of Current End-User Data Analytics Tool Support,"There has been a very large growth in interest in big data analytics to discover patterns and insights. A major challenge in this domain is the need to combine domain knowledge – what the data means (semantics) and what it is used for – with advanced data analytics and visualization techniques to mine and communicate important information from the huge volumes of raw data. Many data analytics tools have been developed for both research and practice to assist in specifying, integrating and deploying data analytics applications. However, delivering such big data analytics applications requires a capable team with different skillsets including data scientists, software engineers and domain experts. Such teams and skillsets usually take a long time to build and have high running costs. An alternative is to provide domain experts and data scientists – the end users – with tools they can use to create and deploy complex data analytics application solutions directly with less technical skills required. In this paper we present a survey and analysis of several current research and practice approaches to supporting data analytics for end-users, identifying key strengths, weaknesses and opportunities for future research."
9004073,Research on Scheduling Strategy of Information Coordination Mechanism for Big Data Storage and Computing,"The scheduling algorithm generally only considers the factors that directly affect the computing performance, such as processor, internal and external storage, and network, but ignores the data itself. In data-intensive computing applications, data deployment takes a long processing time and becomes Restrict the bottleneck of efficiency. In this paper, the data storage and computing information are exchanged and applied reasonably at the right time. A scheduling strategy based on the information coordination mechanism of big data storage and computing is proposed. This strategy makes full use of the advantages of distributed storage, and introduces the replica location into the scheduling parameters. The experimental results are compared with the typical computing capability scheduling strategy, and there are advantages in data preparation time and total operation time."
9451128,Big Data Storage Technology for Smart Distribution Grid Based on Neo4j Graph Database,"In the smart distribution grid, deep integration of power system and information system is the development direction. In order to effectively excavate the potential value of massive data generated in planning and operation phases, the storage of big data is one of the key technologies. This paper proposes a big data storage method for smart distribution grid based on neo4j graph database. Use the common information model (CIM) of power system for reference to establish topology model of smart distribution grid. The storage method of multivariate heterogeneous data is presented integrated the advantages of graph database and relational database. Simulation results on the IEEE standard test systems show that the proposed big data storage method is able to effectively improve data storage and analysis efficiency of smart distribution grid, and a practical citizen power grid is adopted to verified the effectiveness."
9443963,Multi-dimensional Analysis of Industrial Big Data Based JSON Document,"Industrial big data analysis and mining are extremely complicated since it has complex correlations and heterogeneous structure from multiple data source. The growing industrial big data makes data analysis and mining extremely complicated. However, the traditional analysis approach based on relational databases or data warehouses are not flexible enough to deal with multi-source heterogeneous data and are less efficient to do search and analysis operation. Based on Spark and Elasticsearch, this paper presents a multi-dimensional analysis method and system for industrial big data. An OLAP model architecture based on JSON document structure is proposed, which can use Key-Value structure to flexibly define diverse industrial data, and the multi-dimensional structure model is easy to query and analyze. The table structure in the dimension information is converted into a JSON-based document structure, and the dimension information contained in the fact table is stored by the nested document. Elasticsearch is used to store the document structure tree and build an inverted index, which can improve the efficiency of the data analysis query. The query and analysis operations are transformed into the traversal and query operations in the document content. The time efficiency of the multi-dimensional analysis system based on Elasticsearch is much better than the analysis efficiency based on Hive."
8879579,A Big Data Mining Approach of PSO-Based BP Neural Network for Financial Risk Management With IoT,"In recent years, the technology about IoT (Internet of Things) has been applied into finance domain, and the generated data, such as the real-time data of chattel mortgage supervision with GPS, sensors, network cameras, mobile devices, etc., has been used to improve the capability of financial credit risk management of bank loans. Financial credit risk is by far one of the most significant risks that commercial banks have to face, however, when confronting to the massively growing financial data from multiple sources including Internet, mobile networks or IoT, traditional statistical models and neural network models might not operate fairly or accurately enough for credit risk assessment with those diverse data. Hence, there is a practical need to establish more powerful risk prediction models with artificial intelligence based on big data analytics to predict default behaviors with better accuracy and capacity. In this article, a big data mining approach of Particle Swarm Optimization (PSO) based Backpropagation (BP) neural network is proposed for financial risk management in commercial banks with IoT deployment, which constructs a nonlinear parallel optimization model with Apache Spark and Hadoop HDFS techniques on the dataset of on-balance sheet item and off-balance sheet item. The experiment results indicate that this parallel risk management model has fast convergence rate and powerful predictive capacity, and performs efficiently in screening default behaviors. In the meanwhile, the distributed implementation on big data clusters largely reduces the processing time of model training and testing."
9551058,Big Data Analysis of Intellectual Property Service Agencies,"Intellectual property service agencies mainly provide services such as intellectual property agency or management for enterprises or individuals. There are a large number of intellectual property service agencies in the Beibu Gulf City Cluster, but the research and analysis on them are still relatively few. Based on the Beibu Gulf City Cluster, this paper analyzes the information of the provinces, cities, establishment time, staff size, registered capital and other information of the intellectual property rights service agencies. The first step of big data analysis is to pre-process and store the data of intellectual property service agencies to the data warehouse, and then conduct visual analysis on them through R language. Through visual analysis, enterprises or individuals can have a relatively comprehensive grasp of information related to intellectual property service agencies, and then choose appropriate agencies to provide intellectual property services for them."
9148224,Construction of Big Data Monitoring Platform for Teaching Quality under Intelligent Education,"To a great extent, the quality of teaching determines the level of trained talents. Now it has entered the era of intelligent education, coupled with the rapid development of the Internet, has produced a large number of teaching data, which also makes the monitoring and evaluation of teaching quality become particularly difficult. In view of the above problems, this paper proposes the construction of big data monitoring platform for teaching quality under intelligent education. In this paper, the OPC UA unified architecture is used for communication between devices, and the information configuration is based on the spring boot framework to achieve data collection. Then, data processing is based on GRU neural network, and spark distributed computing framework is used to improve the efficiency of data operation. Finally, the monitoring effect is realized by constructing the evaluation system."
9552662,Improved heuristic job scheduling method to enhance throughput for big data analytics,"Data-parallel computing platforms, such as Hadoop and Spark, are deployed in computing clusters for big data analytics. There is a general tendency that multiple users share the same computing cluster. The schedule of multiple jobs becomes a serious challenge. Over a long period in the past, the Shortest-Job-First (SJF) method has been considered as the optimal solution to minimize the average job completion time. However, the SJF method leads to a low system throughput in the case where a small number of short jobs consume a large amount of resources. This factor prolongs the average job completion time. We propose an improved heuristic job scheduling method, called the Densest-Job-Set-First (DJSF) method. The DJSF method schedules jobs by maximizing the number of completed jobs per unit time, aiming to decrease the average Job Completion Time (JCT) and improve the system throughput. We perform extensive simulations based on Google cluster data. Compared with the SJF method, the DJSF method decreases the average JCT by 23.19% and enhances the system throughput by 42.19%. Compared with Tetris, the job packing method improves the job completion efficiency by 55.4%, so that the computing platforms complete more jobs in a short time span."
8038820,Data-Pattern Enabled Self-Recovery Low-Power Storage System for Big Video Data,"The growing popularity of powerful mobile devices such as smart phones and tablet devices has resulted in the exponential growth of demand for video applications. However, due to the large video data size and intensive computation, mobile video applications require frequent embedded memory access, which consumes a large amount of power and limits battery life. In this paper, we present a low-cost self-recovery video storage system by investigating meaningful data patterns hidden in big video data, by introducing data mining techniques to the hardware design process. We propose a two-dimensional data-pattern approach to explore horizontal data-association and vertical data-correlation characteristics. Such data relationship discovery and pattern identification enable a new dimension for the hardware design space and bring self-recovery ability to memories in the presence of bitcell failures. Based on the identified optimal data patterns, we present a low-cost and efficient SRAM design to enable data self-recovery at low voltages. A 45nm 32 kb SRAM is implemented that delivers good video quality at near-threshold voltage (0.5 V) with negligible area overhead (7.94 percent)."
9421699,A Comparative Study of Static Law and Dynamic Law in the Context of Big Data,"In this paper, through an in-depth comparative study of static law and dynamic law in the context of big data, we analyse the personality rights, property rights, intellectual property rights, and data rights attributes of big data rights and interests respectively, and study the content of big data rights from four stages: original data owner's rights, big data collector and miner's rights, big data processor and analyser's rights and big data applicator's rights, and analyse the attribution of big data rights in each stage separately. It is believed that the rights can be attributed to the owner of the data and the collector of big data, and the rights can be confirmed by contract law and autonomy in the processing and analysis stage, and the principle of sharing the results of big data application is adopted. In practice, big data frequently becomes the infringement object of personal information rights, copyright, and enterprise trade secrets. This chapter analyses the attribution principles, constitutive elements, and behavioural manifestations of personal information rights, copyright, and trade secret infringement types, and evaluates the advantages and disadvantages of different empowerment models to protect the rights and interests of big data."
9390011,Teaching Design and Implementation Based on R Language Under the Background of Big Data,"With the rapid development of big data, R language course has become one of the important data processing courses offered by colleges and universities at home and abroad. The development of R language foundation course combines the needs of post and industry development, and reorganizes the teaching contents and methods of the course. It can change the traditional cramming teaching, adopt the student-centered teaching mode, and strengthen the cultivation of students' professional ability."
9418957,Research On The Application of Big Data In Education Industry,"As a new high-tech product of the 21st century, big data has been widely used in various industries, affecting people's daily life. Nowadays, big data has officially entered the education industry, changing the original traditional education model, and realizing education informatization. The combination of education and big data technology is conducive to in-depth mining of education data, making it develop in a personalized and modem direction."
9551336,Research on Network Big Data Security Integration Algorithm Based on Machine Learning,"In order to improve the big data management ability of IOT access control based on converged network structure, a security integration model of IOT access control based on machine learning and converged network structure is proposed. Combined with the feature analysis method, the storage structure allocation model is established, the feature extraction and fuzzy clustering analysis of big data are realized by using the spatial node rotation control, the fuzzy information fusion parameter analysis model is constructed, the frequency coupling parameter analysis is realized, the virtual inertia parameter analysis model is established, and the integrated processing of big data is realized according to the machine learning analysis results. The test results show that the method has good clustering effect, reduces the storage overhead, and improves the reliability management ability of big data."
9418887,Teaching exploration of piano playing and singing based on big data analysis,"Under the background of “Internet”, cloud computing and big data technology have been applied in various fields, including piano teaching, which can show better teaching effect. With the help of big data piano “playing” teaching software and previous practical work experience, this paper expands the piano playing time and space for students to develop a greater platform. It is precisely because of the characteristics of big data that the application of modern technology becomes a reality and promotes the students' learning motivation of piano singing."
8731560,Hybrid.Poly: A Consolidated Interactive Analytical Polystore System,"Anecdotal evidence suggests the Variety of Big data is one of the most challenging problems in Computer Science research today [1]. First, Big data arrives from a myriad of data sources, hence its shape and flavor differ. Second, hundreds of different Big data management systems support different APIs, storage/indexing schemes, and expose data to the users through their data model lens, each specific to their own system. All of these offer a significant impediment for Big data users who just want an easy to use interface to all relevant data regardless of its shape, format, size, and a back-end system used to store it. Naturally, these differences also complicate development of any analytical algorithms on top of large-scale, heterogeneous datasets. Here we describe HYBRID.POLY- a consolidated in-memory polystore engine [2], designed to support heterogeneous large-scale data and interactively process complex analytical work-loads. We execute and evaluate several popular analytical work-loads including Data Fusion, Machine Learning, and Music search at scale."
9675989,Analysis and practice of key technologies for e-commerce talent training online platform under the background of big data,"Analysis and practice of key technologies for e-commerce talent training online platform under the background of big data is designed in this study. The simulation of the training environment is the well simulation of the working environment of the software company, which allows students to personally experience the “real” environment, work pressure, management system and corporate culture of the platform through the cloud computing training platform. For the efficient analysis, the data mining model is optimized with the sparse analysis. The platform is implemented with the efficient data coding model. The experiment is implemented through the core function. The proposed model is efficient based on results."
9381370,Compression for Very Sparse Big Social Data,"Technological advancements in the current era of big data have led to rapid generation and collection of very large amounts of valuable data from a wide variety of rich data sources. As rich data sources, social networks consist of social entities that are linked by some social relationships (e.g., kinship, colleagueship, co-authorship, friendship, followship). Usually, these networks are very big but also very sparse. Embedded in the very sparse but very big networks are implicit, previously unknown and potentially useful information and knowledge that can be discovered by social network analysis and mining. In this paper, we aim to discover interesting social relationships from very sparse but very big social network data. Due to the sparsity of the data, we effectively compress bitmaps representing social entities in the data, from which useful information can be mined and interesting knowledge can be discovered. Evaluation results show the effectiveness of our compression scheme for very sparse but very big social network data."
9460510,Argus: Efficient Job Scheduling in RDMA-assisted Big Data Processing,"Efficient job scheduling is an important and challenging issue in big data processing systems. Traditional designs commonly give priority to data locality during scheduling and follow a network-optimized principle to avoid costly data moving across the network. The emergence of the high-performance Remote Direct Memory Access (RDMA) network brings new opportunities for big data processing systems. However, the existing RDMA-assisted designs ignore the dependency among stages during scheduling and this can result in unsatisfied system efficiency. In this work, we propose Argus, a novel RDMA-assisted job scheduler which achieves high resource utilization by fully exploiting the structure feature of stage dependency. Argus prioritizes the stages whose completion can enable more schedulable stages. We implement Argus on top of RDMA-Spark, and conduct comprehensive experiments to evaluate the performance using large-scale traces collected from real-world systems. Results show that compared to state-of-the-art designs, Argus reduces the job completion time and makespan by 38% and 31%, respectively."
9096725,ArrowSAM: In-Memory Genomics Data Processing Using Apache Arrow,"The rapidly growing size of genomics data bases, driven by advances in sequencing technologies, demands fast and cost-effective processing. However, processing this data creates many challenges, particularly in selecting appropriate algorithms and computing platforms. Computing systems need data closer to the processor for fast processing. Traditionally, due to cost, volatility and other physical constraints of DRAM, it was not feasible to place large amounts of working data sets in memory. However, new emerging storage class memories allow storing and processing big data closer to the processor. In this work, we show how the commonly used genomics data format, Sequence Alignment/Map (SAM), can be presented in the Apache Arrow in-memory data representation to benefit of in-memory processing and to ensure better scalability through shared memory objects, by avoiding large (de)-serialization overheads in cross-language interoperability. To demonstrate the benefits of such a system, we propose ArrowSAM, an in-memory SAM format that uses the Apache Arrow framework, and integrate it into genome pre-processing pipelines including BWA-MEM, Picard and Sambamba. Results show 15x and 2.4x speedups as compared to Picard and Sambamba, respectively. The code and scripts for running all workflows are freely available at https://github.com/abs-tudelft/ArrowSAM."
9065491,Deriving Big Data insights using Data Visualization Techniques,"Exponential growth rate in the data generation in diverse fields revolutionized the way the analytics tools and machine learning algorithms applied in the Big Data. Considering the pace at which data is generated and the variety of data, identifying the right data at the right time and the relationship is crucial to make decisions. Identifying the data type and the relationship between the parameters is challenging as the size of the real time data is massive and dynamic in nature. Data Visualization as part of Big Data Exploratory analysis helps to identify the relationship and to understand the characteristics of big data in an effective way. In other words, data visualization is the graphical representation of data, it links the data availability and data analysis, organizes and presents important findings from the data. As plenty of visualization packages and tools are available, choosing the right tool is very important. gglot2 is one among the statistical graphics tool for data visualization as the working model is entirely based on grammar of graphics. The unique feature of ggplot is the layered approach, as the each component is highly interdependent on the other and so it helps in the step by step analysis of the data. With this feature available ggplot2 was used in the Real time Public Distribution System data to identify the relationship between various parameters and to understand the behavior pattern."
9358503,A big Data Analytics Framework for the Integration of Heterogeneous Federated Data Centers,"Big Data is a collection of data sets that are enormous and complex to store and process using conventional data storing and processing techniques. The emergence of data in different domains causes significant challenges in data manipulation and decision making. In recent years, the requirement for the analysis of heterogeneous data on distributed data storages has been increased and has gained a lot of researchers' attention. With the rapid growth of data, a single cluster environment becomes inadequate to manage this data. At the same time, there are heterogeneous data sources on different platforms, which need to inter-connect to derive meaningful analysis. The MapReduce software paradigm has surfaced to fill the gap, and it has been successfully operating on systems. However, only single cluster environments are supported by the current implementation of MapReduce and this framework cannot be applied to federated heterogeneous data centers. Hence, it does not have enough capabilities to process heterogeneous data sources. This research presents a big data analytic framework that supports the integration of heterogeneous data sources on distributed computing models across multiple data centers. Besides, the performance of the proposed framework is measured under different cluster configurations, and experimental evaluations had shown promising results for the proposed framework compared to a single cluster environment."
9526717,Adaptive Sorting Method of Big Data with Scattered Defects Based on Cloud Computing,"In order to better sort the massive scattered defect data and ensure the effect of data processing, an adaptive sorting method based on cloud computing is proposed. In order to improve the convergence of data, multi-objective processing is carried out in the cloud computing environment. Combined with the fuzzy adaptive sorting algorithm, the difference value of multi-objective variation is calculated to achieve the balanced adjustment of variation data. In order to speed up the data convergence, balance the local optimal sorting value, obtain the initial value of scattered defect data, and complete the adaptive sorting of scattered defect big data. Finally, experiments show that the adaptive sorting method based on cloud computing can better repair and accurately sort the scattered data, and improve the data convergence effect."
8912147,Research on Scale-Free Network User-Side Big Data Balanced Partition Strategy,"In view of the time-consuming problem of traditional scale-free network user-side big data balanced partitioning strategy; a new scale-free network user-side big data balanced partitioning strategy is proposed. A scale-free network user-side big data balanced partition model is built, and the iterative rules of the scale-free user-side big data evolutionary game are calculated according to the model. The above rules are used to determine the influence of network size on the evolution of user-side big data, and the traffic balance partition of user-side big data is realized. The experiment was carried out around the problem of time consumption. Comparative experiments show that the proposed scale-free network user-side big data balanced partitioning strategy can effectively solve the problem of time consuming."
8962452,Research on Evaluation of Flipped Classroom Based on Big Data,"Class teaching evaluation based on data analysis technology has been applied in traditional classes. As a new teaching evaluation method, the teaching quantitative behavior implemented in flipped classroom provides a good data base for the construction of big data analysis model of teaching evaluation, it is much important to the teachers. At present, the assessment model of flipped classroom based on big data analysis is rare. Based on collecting large data, this paper builds or applies relevant big data analysis models and then implements them in the flipped classroom evaluation of the students. It pays close attention to data connotation information and reflects reasonable evaluation. We have achieved good data analysis results after experimental verification. The evaluation of flipped classroom based on big data is feasible."
9591126,3D Big Data Modeling of Untouchable Research Results,"Interactive 3D is the next step in development and opens the door for even greater value to be restored. For example astronomy researches are able to send back samples and 3D slides for astronomy research and lot of IT applications puts 3D pictures to its maps. It means that for untouchable research results is 3D visualization, virtual reality or augmented reality the best presentation form. Currently, there are many tools to visualize big data. These tools provide a set of functions. A big benefit is the ability to process many types of dating and apply different filters. Next one benefit is to provide collaboration, or to attach to a number of different software. Our paper describe the new one developed tools for 3D big data modeling. We are interesting before on modeling and visualization tools for untouchable research or no-physics results as are for example astronomical research results or underground, as is water system simulation. Benefit of our system is possibility to display research results in virtual reality and possibility to display the water system and research results transparently, or display them on the ground instead of under the ground. In astronomical research we are able to fly between the stars by virtual ship."
9377902,CNN Model & Tuning for Global Road Damage Detection,"This paper provides a report on our solution including model selection, tuning strategy and results obtained for Global Road Damage Detection Challenge. This Big Data Cup Challenge was held as a part of IEEE International Conference on Big Data 2020. We assess single and multi-stage network architectures for object detection and provide a benchmark using popular state-of-the-art open-source PyTorch frameworks like Detectron2 and Yolov5. Data preparation for provided Road Damage training dataset, captured using smartphone camera from Czech, India and Japan is discussed. We studied the effect of training on a per country basis with respect to a single generalizable model. We briefly describe the tuning strategy for the experiments conducted on two-stage Faster R-CNN with Deep Residual Network (Resnet) and Feature Pyramid Network (FPN) backbone. Additionally, we compare this to a one-stage Yolov5 model with Cross Stage Partial Network (CSPNet) backbone. We show a mean F1 score of 0.542 on Test2 and 0.536 on Test1 datasets using a multi-stage Faster R-CNN model, with Resnet-50 and Resnet-101 backbones respectively. This shows the generalizability of the Resnet-50 model when compared to its more complex counterparts. Experiments were conducted using Google Colab having K80 and a Linux PC with 1080Ti, NVIDIA consumer grade GPU. A PyTorch based Detectron2 code to pre-process, train, test and submit the Avg F1 score to is made available at https://github.com/vishwakarmarhl/rdd2020."
9516862,Analysis on the Quality Model of Big Data Software,"With the rapid development of the big data system, The big data system has the characteristics of large data scale, diverse data and high computational complexity. Its testing method has to be constantly improved. By analyzing the general software quality model, and combining the characteristics of the big data software, a set of quality model for the big data software is formed."
9002302,Sensor Data Fusion and Big Mobility Data Analytics for Activity Recognition,"The widespread use of mobile devices, such as smart phones, smart watches, bracelets, equipped with plenty of integrated sensors, provides collection of massive amounts of data and their processing and analysis on edge and cloud computing infrastructures. For the purpose of monitoring of health and activities of people, such Big mobility and IoT data must be properly processed and analyzed. In this paper, the RemoteHealth platform is presented, developed using contemporary mobile, IoT and Big Data technologies. The application implemented on RemoteHealth platform is based on sensor fusion and provides processing and analysis of Big mobility and IoT data originated from smart personal devices with the aim to detect and recognize human activities and behavior. The experimental evaluation shows that the sensor fusion increase the accuracy of activity recognition comparing to single sensor use."
9526094,A Prediction System for the Distribution of Epidemic Patients and Asymptomatic Infected Persons Based on Big Data Technology,"In order to analyse and overcome the enormous impact of coronaviruses on people around the world, this paper presents a predictive model for epidemic and asymptomatic patients based on big data techniques. The prediction model chooses a sampling method to optimise the prediction of the main factor of the prevalent order of asymptomatic patients. Based on this, the prediction model is also able to summarise the current epidemiological problems facing the world’s population and generate a prediction report and a recommendation report. The results of the study show that the prediction model can efficiently and scientifically address the quantitative conditions that define epidemics and pandemics and can accurately predict the distribution of asymptomatic patients, which can help medical professionals to better confront and address epidemic problems."
9121064,"A Survey of Algorithms, Technologies and Issues in Big Data Analytics and Applications","In today’s era, a very large and massive data is generating by different government sectors, private ltd companies, healthcare organizations, etc. A major source of data is social networking sites like Twitter, Facebook, LinkedIn, etc. Several terabytes and petabytes of data are collected by these organizations and companies. Forget analyzing, simply capturing a huge volume of data is impractical. Several reports can be prepared from this data. The process behind this reports preparation is also a challenging task for the software developers. On average, the data capturing technologies are not as sufficient as the data is generated. All the 4V’s of data i.e, Volume, Velocity, Variety, and Veracity are taken into considerations while handling such data. This paper simply focused on several issues like challenges in data, challenges in the process, and challenges in data management. The challenge relates to how to manipulate an impressive volume of data that can reach its destination intact. In short, this work treats all the challenges that Big Data creates. In further studies, we will review some related papers and will suggest some possible solutions to the existing problems. Along with this, some of the used algorithms are surveyed in this study."
9403755,How to analyze the openness of WeChat circle of friends in the era of big data?,"As one of the most rapidly developing social networking platforms, WeChat circle of friends is becoming increasingly important in young people's lives. In 2019, WeChat official active users exceeded 1.1 billion, becoming an eternal hot spot in the network circle and deeply loved by college students. However, most of the current studies on WeChat focus on the use frequency and published content, while few studies explore the openness of WeChat friend circle. Our study is a positive step to evaluate this phenomenon. In this study, the degree of openness of WeChat friend circle is combined with gender, and the personality dimension is introduced as a variable, aiming to reveal whether the personality dimension plays a mediating role between gender and openness of WeChat friend circle. The sample included 699 self-selected Chinese Internet users (273 men) aged between 18 and 25. Participants were asked to complete a paper questionnaire, including the WeChat circle of friends open questionnaire and a simplified NEO five-factor scale. The results showed that WeChat openness was positively correlated with neuroticism and negatively correlated with agreeableness. These results suggest that people of different genders and personalities tend to differ in how open they are to friends."
8912124,Analysis and Visualization of Website Log Data from the Perspective of Big Data,"Human society has entered the era of big data in which everything can be digitized, how to efficiently analyze massive data through limited resources is the common requirement of current enterprises to obtain valuable information from complex data. This paper takes the website log data of a consulting company as the research object. SOM and FCM double layer clustering model are used to analyze massive log data efficiently. At the same time, T-sne algorithm is used to reduce the dimensionality of high-dimensional data, and data visualization is realized in the form of two-dimensional graph coordinate diagram. For website maintenance staff more easily understand the network security situation, identify abnormal access and further data analysis to provide ideas."
9524275,Hot Spot Mining and Analysis Model of Sports Microblog Culture Public Opinion Based on Big Data Environment,"By analyzing the development characteristics of sports microblog cultural public opinion under the big data environment and the specific needs of automatic public opinion monitoring, the paper designs a sports microblog cultural public opinion hotspot mining system structure model, and describes the main functions and implementation methods of each layer. The paper first uses tools such as ICTCLAS and AntConc to extract hot words, then describes the standardized data representation, and finally uses the Chameleon clustering algorithm to achieve clustering and topic extraction of hot blog posts. This method will provide information support for timely discovering sensitive information and grasping the hot spots of sports microblog culture and public opinion."
9458864,The Logarithmic Dynamic Cuckoo Filter,"The emergence of big data applications makes efficient representation for large-scale dynamic data sets a challenge. The state-of-the-art design, i.e., the dynamic cuckoo filter (DCF), provides extensible approximate set representation by employing a novel chain based data structure which allows appending new building cuckoo filter blocks. However, such a design needs linearly increasing computation costs and memory space when a set scales. This makes it inefficient for big data sets. In this paper, we propose a novel data structure for dynamic big data sets, called logarithmic dynamic cuckoo filter (LDCF). LDCF uses a novel multi-level tree structure and reduces the worst insertion and membership testing times from O(N) to O(1), where N is the size of the set. At the same time, LDCF reduces the memory cost of DCF as the cardinality of the set increases. Comprehensive experiment results show that LDCF significantly reduces the membership checking time and the memory space cost for large-scale datasets compared to state-of-the-art designs."
9709085,Construction of short video marketing model based on big data technology,"Based on large-scale database technology, use data mining system to fully explore a large amount of data information in short video. With the wide popularity of short video, the huge amount of short video information is full of all kinds of complex data and models. In short video marketing, database technology can process a large amount of information and store and manage it at the same time. Data mining technology will the complexity, diversity and potential of information in short video database, and use the integrated analysis of computer algorithm and data model to provide relevant data information, provide technical decision-making and management for short video marketing, and can accelerate the intelligent development of short video marketing. This paper systematically analyzes the marketing characteristics of short video based on big data technology, so as to deeply explore the practical role of database technology and data mining technology in short video marketing, and further provide technical support for the development and innovation of short video marketing."
9533080,Application of Big Data Analysis in the Physical Fitness Monitoring of Chinese Students,"Social and economic development has significantly improved people's living standards, but the overall physical health of Chinese students has shown a downward trend. Therefore, various departments of the country pay more and more attention to physical fitness testing, and the physical health of students has become the focus of attention of the whole society. Only by paying attention to the physical monitoring of students, can we judge the health status of students from various data and give targeted guidance. This article focuses on big data analysis and makes an in-depth exploration of the application of the Chinese student fitness monitoring system. In this paper, combined with data mining algorithms, the realization of the storage, comparison, analysis and other functions of the student's physical health data in the monitoring system is studied, and the intelligence of the monitoring system is improved through the big data analysis and processing technology, and scientific guidelines are used to promote health. Provide direction support for the development of the project. From the experimental data, the comprehensive physical test excellent rate of freshman students is 46.7%, while the excellent rate of junior students is only 27.315%. Physical exercise plays a vital role in improving the physical fitness of students. Schools should play a correct guiding role to allow students to participate in physical exercise more actively, so as to improve their comprehensive physical fitness."
9050383,Research on Network Information Trajectory Risk Perception Method Based on Big Data,"The leakage of network information tracks often brings huge personal data and privacy risks. In order to better protect the leakage of information trajectory, this paper establishes a network information trajectory risk perception method based on the advantages of big data. This paper defines the behavior set function of network trajectory risk, and combines the information trajectory features to optimize the learning of the algorithm. The system model is trained and optimized by big data method, and the network information trajectory risk perception method based on big data is obtained. Through experiments, the method can predict and sense the risk behavior of network information trajectory well, improve the protection of user network information trajectory, and provide a new method for risk control of network information trajectory."
9373659,Analysis and Research on University Financial Decision Based on Distributed Big Data Sharing Mechanism,"With the rapid development of computer and network technology, in order to meet the needs of financial management, the financial management information system has been gradually improved. In this paper, the advantages of big data sharing based on distribution are analyzed in depth, and a data connection model based on distribution and distributed file system is established. It not only combines the actual working conditions of the financial departments of colleges and universities, but also simplifies the amount of data and information in the system, and designs the system flow completely according to the actual work flow, which strengthens the convenience and application effect of financial information management and decision-making in colleges and universities. Promote the integration of collective wisdom and data rationality in the decision-making process, thus breaking the limitations brought by traditional decision-making and establishing a democratic decision-making mechanism in colleges and universities."
9378487,Facilitating the HPC Data Center Host efficiency through Big Data Analytics,"Quality of service is important feature for a High Performance Computing Center (HPC) center like Partnership for an Advanced Computing Environment (PACE) center in Georgia Institute of Technology (Georgia Tech). The user's job fails running on a HPC center may due to a spectral of reasons, one of major contributor is the hardware and network failure. Reducing the hardware failure rate can significantly increase a data center's quality of service as well as reducing the cost of human intervention. This is critical during PACE's transition to a fee-based service model in which uptime correlates directly with revenue. PACE has around 9 millions jobs each year with 12% of job failure rate. In order to extend service life of hardware and reduce the potential failure and data center's cost, we present a machine learning method to understand the center's host usage pattern. By clustering the hosts based on multiple features, we reshuffle the host list to avoid the hosts being overused over time. We build a test framework which runs the complex combination of experiments, and presents the ad hoc comparisons. We intend to make the machine learning method in a rack aware fashion, and show the meaningful result with rack information included."
9422001,Research on Smart Home Care Model Under the Background of Big Data,"At present, the situation of China's population aging is increasing, and various social problems caused by oldage care are becoming increasingly prominent. In the context of the era of big data, people's beautiful needs for home care are gradually diversified. Based on this, a brand-new home care model must be explored as soon as possible. This article will combine the current situation of home care in China and combine big data with home care services to construct a smart home care service model. At the same time, the combination of big data and home care services will also realize information and data sharing, constructing a unified and standardized platform to provide personalized and diversified services for the needs of home care in my country. In the process of using big data for smart home care, the lack of development of the smart terminal equipment market, the lack of industry development support, the lack of standardized standard systems, the hidden dangers of data and information security, and the professionalism of data analysis platforms are all facing a certain degree Challenges. After indepth understanding and analysis of this model, the government will play a leading role to realize data sharing and data protection; the improvement of professional talent training programs; the cultivation and development of the smart terminal equipment market are proposed to promote the healthy development of home care services in China."
8706466,Outlier Detection Technique for IoT Sensor-Driven Big Data Systems,"With the development of big data analysis technologies and the utilization of sensor data through Internet of Things (IoT) and wireless sensor networks (WSNs), users can easily analyze and use huge amounts of data. However, occasional sensor errors can lead to failures in maintaining optimum conditions, and also smart systems without user intervention are likely to be vulnerable to intrusions via external networks. Therefore, in this paper, a method to maintain the optimal state is proposed even when the sensor network fails due to sensor failure or external intrusion in big data systems."
9355349,Application of Big Data Technology in New Energy Vehicle Networking Platform,"The rapid growth of the number of vehicles and drivers in China has brought new challenges to road traffic safety and automobile related supporting services. At the same time, the combination of new energy vehicles and vehicle networking technology will bring more development opportunities to enterprises. The Internet of Vehicles (IoV), which integrates the in-depth application of modern information technology, has become the changing direction of automobile service Industry development in the future. The Internet of Vehicles is a huge interactive network composed of bus parameters such as vehicle position and speed interconnected with peripheral system information. The data of vehicles is very large, especially for new energy vehicles, whose data are divided into peripheral and internal. It is difficult to analyze and process such massive, real-time and low value density vehicle information only relying on a limited number of manpower and traditional statistical methods. Only with the help of big data technology can we realize the monitoring and mining of massive data. Combined with the Internet of vehicles and big data analysis technology, this paper expounds the connotation and application of new energy vehicle networking platform based on big data."
9014987,Study and Application on Data Center Infrastructure Management System Based on Artificial Intelligence (AI) and Big Data Technology,"At present, the safety, high-efficiency, green are becoming the key issues of system networking for data center infrastructure management. Meanwhile, some communications technolgies have been utilized into it. Therefore, the data center infrastructure management system based on AI and big data technology is analyzed in this paper, including the architecture of the whole networking system, different functions in mangement system, the implement cases using data center infrastructure management system, the international and domestic standardization activities and future trend of research, etc."
9162335,Big Data Series Analytics in the Context of Environmental Crowd Sensing,"The new mobile crowd sensing (MCS) paradigm leads to the generation of a large amount of data originated from different sources. The inhomogeneous nature of produced data turns the process of data analytics and knowledge extraction extremely challenging and complicated. More specifically, mining such data needs special care and processing. In this paper, we focus on the analysis, processing, and exploration of such data. We advocate this process should benefit from the diverse data sources in the MCS context, including user's annotation and various ambient data collected through sensors."
9140921,Use of Big Data at Anatel : A Case Study at National Telecommunications Agency,"The growth in the volume of data generated by applications affects both public and private institutions. In the National Telecommunications Agency (Anatel), problems related to the Big Data scenario, such as degradation in the performance of these environments, high costs for maintaining the infrastructure and low performance, are commonly observed. Distributed processing solutions, such as Hadoop, has emerged as a way to circumvent this problem. This study presents research on the issue of textual searching in Anatel, aiming to bring answers to the degradation of the environment, poor performance of queries and increased costs to maintain the current structure used to process the large volume of data. which is the best cost-benefit of the current station of Anatel. The results are presented in this paper."
9095637,Research on Intelligent Security Protection of Privacy Data in Government Cyberspace,"Based on the analysis of the difficulties and pain points of privacy protection in the opening and sharing of government data, this paper proposes a new method for intelligent discovery and protection of structured and unstructured privacy data. Based on the improvement of the existing government data masking process, this method introduces the technologies of NLP and machine learning, studies the intelligent discovery of sensitive data, the automatic recommendation of masking algorithm and the full automatic execution following the improved masking process. In addition, the dynamic masking and static masking prototype with text and database as data source are designed and implemented with agent-based intelligent masking middleware. The results show that the recognition range and protection efficiency of government privacy data, especially government unstructured text have been significantly improved."
9470404,Innovative Ideas of Enterprise Human Capital Value Evaluation under The Background of Big Data,"To overcome the problems of low evaluation accuracy and efficiency existing in traditional human capital value evaluation methods, this paper proposes a new innovative research method of enterprise human capital value evaluation under the background of big data. In order to improve the accuracy of human capital data mining, information extraction method is used to extract the features of human capital information. Eliminate the extreme value of human capital data at both ends of the enterprise to complete the mining of human capital data. The human capital value evaluation of enterprises is divided into four grades. According to the grade division results, combined with the human capital value evaluation index, the correlation degree between the human capital data and the evaluation grade is obtained. The human resource data ontology model is constructed, and the human capital data output control vector set is obtained by ontology mapping. Finally, the relative fuzzy approach method is used to complete the evaluation of human capital value. The experimental results show that compared with the traditional evaluation method, the evaluation accuracy and efficiency of the proposed method are greatly improved, and the highest evaluation accuracy reaches 99.7%. Therefore, the practical application performance of the proposed method is strong."
9432165,Analysis of the Development of Chinese Children's Animation Products on Mobile Terminals in the Context of Big Data,"From the perspective of practical application, there is a relationship of mutual promotion and coordinated development between the animation industry and the public cultural service system. The public cultural service system provides a platform for the animation industry and defines the content and objectives of the animation industry. Animation industry provides technical support for the public cultural service system. Big data has great economic and social value. The huge economic and social changes caused by big data also make more and more enterprises realize the importance and necessity of developing big data. Combined with the application requirements of big data center system, this paper systematically studies the implementation method of data retrieval from two aspects of spatial data and non spatial data, aiming to achieve the rapid and accurate acquisition of target data, and provide reference and basis for users' decision analysis."
9260272,Analysis of Heat Loss Control Method for Building Heating Transmission and Distribution based on Big Data Analysis,"The phenomenon of leakage is serious and the heat loss is large in the heating network of North China. A heat loss control method for building heating transmission and distribution based on big data analysis is proposed. The adaptive coverage and network structure model of the information acquisition node of heat energy loss control for building heating transmission and distribution are constructed. The data of heat energy loss of building heating transmission and distribution collected by building heating energy sensor are processed by information fusion. The big data processing algorithm for heat energy loss control of building heating transmission and distribution is constructed, and the data control of heat energy loss in building heating transmission and distribution is realized by the method of information feedback adjustment. The embedded integrated control technology is used to optimize the heat loss control system of building heating transmission and distribution. The test results show that the system has good reliability, intelligence and big data analysis ability."
8819500,Privacy Protection Oriented Video Data Hiding Method,"With the advent of the era of big data, enterprise big data, government big data, and network users big data have played great value in various industries. But at the same time, any behavior of people may be tracked and recorded. People's demand for privacy protection is also growing. In this paper, a HEVC reversible video data hiding algorithm combined with encryption technology is proposed for video big data to realize privacy protection. A monoalphabetic substitution cipher algorithm is used for encryption, then the encrypt data is embedded into the proposed multivariate array of the 4 × 4 luminance DST blocks to avert the distortion drift. With the inverse operation of multivariate array in decoder, the embedded video is perfectly reconstructed as the original encoded video. It is proved analytically and shown experimentally that the proposed algorithm can achieve high embedding capacity, security and low visual distortion. Performance comparisons with other existing schemes are provided to demonstrate the superiority of the proposed scheme."
9095695,Finding Next High-Quality Passenger Based on Spatio-Temporal Big Data,"Finding high-quality passenger can provide timely recommendations for taxi drivers, thus decreasing the waiting time of passengers and increasing the cab driver's efficiency. This paper proposes a high-quality passenger recommendation model which combines the value evaluation formula of non-occupied status and clustering. Firstly, the GPS big data of taxi is preprocessed to get the trajectory data by Map Reduce, which is simple, clean and labeled with status. Then, every trajectory pick-up point is extracted, and the profits of pick-up point set is calculated by using the formula considering non-occupied status. At the same time, the density based clustering method DBSCAN clustering is used for different value of pickup points. Finally, the top high probability passenger area with high value is extracted as the recommended result. In this paper, the real 10357 taxis equipping GPS in Beijing collected the big trajectory data as the experimental dataset, using our method to calculate and recommend, the results show that it can accurately predict the high-quality passenger area, further to significantly improve the income of taxi drivers and reduce the waiting time of passengers."
9544814,Big data artificial intelligence in the direction of tourism social media: a systematic study,"This paper conducts the systematic study on big data artificial intelligence in the direction of tourism social media. At present, the focus of smart city should be the central city and big city. At the same time, the overall quality of citizens should be high, there should be a suitable living environment, including good culture and public services, convenient transportation services, reasonable living costs, and good city management. For the intelligent analysis, firstly it is required to design the big data model, which is combined for the AI frameworks as the theoretical basis, and then, the social network is modeled with the topology analysis and the data connection analysis. Furthermore, the application scenario of the smart tourism is tested. The designed platform is implemented based on software structure optimization."
9479657,Assessment Mechanism of Class Construction in Colleges and Universities Based on Big Data Technology,"With the rapid development of large data technology, large data related applications have penetrated every corner of people's lives. The world is not producing a large amount of data at any time. At the same time, effective and reasonable processing of these massive data has become the key to the application of large data technology. Thanks to the development of big data technology, the concept of digital campus has been further promoted and realized. Through the analysis of a large number of data generated by college students'daily life, the effective management of college students can be realized and the better development of the school can be promoted. This paper will analyze and study the class assessment system of university based on big data technology and formulate the weight of the evaluation index of the construction of class style of study in university. Finally, this paper will establish the state model of the evaluation index of the construction of class style of study in university based on SWOT quantitative strategy matrix, so as to help university managers to clarify the specific distribution of the evaluation index of class construction. Therefore, this paper can improve the pertinence, scientificity and effectiveness of University work."
8940317,Design of MICE service platform based on big data,"The era of big data bring out new opportunities for many businesses. However, big data has not been properly applied in the MICE (Meetings, Incentives, Conferences and Exhibitions) industry. Through the investigation of 20 MICErelated institutions, and fully understanding the needs and current situation of the existing industry, the author puts forward a suitable MICE service platform design for the MICE industry.."
9006166,A Framework of Applying Kelly Stationary Index to Stock Trading in Taiwan Market,"Portfolio management and money management have always been important issues for investors and researchers in the financial field. The Kelly criterion is a theoretical approach of money management, and is a mathematical method for optimizing long-term expected return. Kelly criterion requires the future outcomes distribution as input, which can be predicted through the techniques of machine learning (ML). With the revolutionary growth of the amount of information, big data is the key to boost ML prediction, therefore, we introduce a general Kelly framework, including the strength of Kelly, ML, and big data. In addition, we propose the Kelly stationary index (KSI) to quantify the stationarity of the stock's outcomes distribution, which will affect the trading period and forecasting frequency. We calculate the KSI of each constituent stock of Taiwan's 50, and apply the Kelly criterion strategy to verify the effectiveness of KSI. The experimental results show that there is a moderate downhill relationship between the strategy performance and KSI with the -0.591 of correlation coefficient. It also indicates that the closer the estimated distribution is to the actual distribution, the higher the expected profit. In the future, we will use KSI for money management, strategy development, and apply KSI into the general Kelly framework."
9479629,Research on the Audit of Natural Resources Assets from the Perspective of Big Data Cloud Computing,"With the rapid development of information technology in the era of big data, cloud computing technology is applied to all aspects of social life. There are many kinds of natural resource assets, and the formulation of audit standards and the selection of audit methods are difficult. This paper studies the application of big data cloud computing in the audit of natural resource assets, which plays an important role in mining the useful information carried by audit data, in order to solve various practical problems faced by natural asset audit, improve audit efficiency, reduce audit risk and ensure the quality of audit At the same time, it analyzes and discusses the problems of data and information security in the current cloud audit. The application of big data cloud computing technology is the development trend of the times, which has a huge role in promoting the audit of natural resources assets, and will also provide experience for the historical change of full audit coverage."
9213406,Big Data Platform for Faults Prediction Diagnosis of CBI,"Safety and reliability have always been the most concerned research of computer based interlocking system(CBI). With the rapid development of computer technology, information network technology, new material technology and digital technology, CBI system itself produces massive and complex data, which has become an important resource for innovation and development of CBI system. How to use these massive data to help the system complete automatic or semi-automatic fault diagnosis, and then ensure the safe operation of the system, has become the focus for various interlocking manufacturers. This paper introduces Fail-Safe, several fault model analysis methods, and introduces a big data platform which can be used for fault prediction and diagnosis analysis methods."
8886291,Research and Application of Smart Grid Early Warning Decision Platform Based on Big Data Analysis,"In this paper, the key work of smart grid equipment fault prediction and early warning, dynamic operation and maintenance strategy research is studied by using large data mining analysis method. Spark, Hive, HDFS(Hadoop Distributed File System), MapReduce and other technologies are used to build a large data analysis and early warning decision-making platform for smart grid. In this paper, taking big data technology as the core, the BP neural network algorithm is optimized by using self-developed proprietary algorithm, which improves the accuracy of fault prediction model. The algorithm can realize the functions of intelligent inspection, intelligent research and judgment, intelligent early warning, intelligent decision-making and intelligent dispatch of substation equipment. Through a lot of practical verification, the accuracy of fault prediction of the platform is 93.98%, which is in the leading international level . In the field of smart grid, it has strong application value."
9403799,Research on Data Association Rules Mining Method Based on Improved Apriori Algorithm,"With the advent of the era of big data, how to efficiently process massive data has become a hot research direction in the field of computer science. The existing data mining technology mainly uses the association rules mining method. Aiming at the shortcomings of the Apriori algorithm in the classic association rule mining method, this paper proposes an improved Apriori algorithm. This paper describes the processing flow of classic Apriori algorithm, describes the main improvement ideas of improved Apriori algorithm, and then analyzes and evaluates the improved algorithm. The experimental results show that the efficiency of the improved Apriori algorithm is much higher than that of the traditional Apriori algorithm."
9005596,Time Series Classification: Lessons Learned in the (Literal) Field while Studying Chicken Behavior,"Poultry farms are a major contributor to the human food chain. However, around the world, there have been growing concerns about the quality of life for the livestock in poultry farms; and increasingly vocal demands for improved standards of animal welfare. Recent advances in sensing technologies and machine learning allow the possibility of monitoring birds, and employing the lessons learned to improve the welfare for all birds. This task superficially appears to be easy, yet, studying behavioral patterns involves collecting enormous amounts of data, justifying the term Big Data. Before the big data can be used for analytical purposes to tease out meaningful, well-conserved behavioral patterns, the collected data needs to be preprocessed. The pre-processing refers to processes for cleansing and preparing data so that it is in the format ready to be analyzed by downstream algorithms, such as classification and clustering algorithms. However, as we shall demonstrate, efficient preprocessing of chicken big data is both non-trivial and crucial towards success of further analytics."
9633479,Research on Air Conditioning Performance Monitoring and Trend Prediction of A320 Aircraft Based on Big Data Analysis,"This paper compares the WQAR (Wireless Quick Access Recorder) data of nearly 2.6 million flights of an airline's A320 fleet in the past five years by TELEDYNE decoding software AirFASE and big data analysis platform EMS (Event Measurement System), explores the impact of single and multiple parameters on the key parameters TP (Pack outlet temperature) and COT (compressor outlet temperature) of aircraft air conditioning system performance. An abnormal data monitoring model based on dynamic time series data is proposed, and an air conditioning performance prediction health evaluation model is established. It enriches the content of predictive maintenance research based on data analysis, and widens the work scope and digital development field of aircraft maintenance."
9479584,Design of Student Data Acquisition and Extraction Platform Based on Big Data Technology,"Today, with the rapid development of network, the integration of artificial intelligence and education has become the need of the times. How to collect and extract students' data accurately and efficiently is a test for higher education. This paper introduces the design system of student data acquisition and extraction platform. By using the idea of artificial intelligence and big data clustering analysis technology, it realizes information extraction, normal monitoring, clustering analysis and information decision-making, so as to achieve the intelligence of data acquisition and extraction. Through the system research and development significance, the formation of the basic framework, the construction of education model and other aspects of the platform are explained, and effectively provide an effective scheme for college education and individual development."
9522330,Software-Defined Modeling Method of Cyber-Physical System Driven by Big Data,"The way humans interact with the physical world has been changed by the cyber-physical system (CPS) emergence. However, as an embedded system, CPS has limitations in its processing and storage of data. In addition, with the advancement of technology, the scale of the system progresses to extend and the data generation increases exponentially, the original vehicular cyber-physical system(VCPS) can no longer meet the current needs. In order to enhance the data analysis and processing capabilities of the system, this paper proposes a five-layer VCPS that including Application Layer, Cloud Computing Layer, Control Layer, Roadside Unit Layer and Vehicle Unit Layer. Besides, using Architecture Analysis & Design Language (AADL) performs software-defined modeling and overall security analysis to verify the effectiveness of this modeling method. The architecture model deeply integrates big data technology and software definition ideas, has a good effect on upgrading the traditional VCPS low level of automation, insufficient on data processing and storage capacity."
7920374,PPHOPCM: Privacy-Preserving High-Order Possibilistic c-Means Algorithm for Big Data Clustering with Cloud Computing,"As one important technique of fuzzy clustering in data mining and pattern recognition, the possibilistic c-means algorithm (PCM) has been widely used in image analysis and knowledge discovery. However, it is difficult for PCM to produce a good result for clustering big data, especially for heterogenous data, since it is initially designed for only small structured dataset. To tackle this problem, the paper proposes a high-order PCM algorithm (HOPCM) for big data clustering by optimizing the objective function in the tensor space. Further, we design a distributed HOPCM method based on MapReduce for very large amounts of heterogeneous data. Finally, we devise a privacy-preserving HOPCM algorithm (PPHOPCM) to protect the private data on cloud by applying the BGV encryption scheme to HOPCM, In PPHOPCM, the functions for updating the membership matrix and clustering centers are approximated as polynomial functions to support the secure computing of the BGV scheme. Experimental results indicate that PPHOPCM can effectively cluster a large number of heterogeneous data using cloud computing without disclosure of private data."
9006378,Towards Faster Distributed Deep Learning Using Data Hashing Techniques,"Nowadays, deep learning is a crucial part of a variety of big data applications. Both the vast amount of data and the high complexity of the state-of-the-art neural networks have led to perform the network training in a distributed manner accross clusters. Since synchronization overheads are usually fatal for the training's performance, asynchronous training is usually preferred in such cases. However, this training mode is sensitive to conflicting updates. Such updates most commonly occur when the workers train on a totally different part of the data. To reduce this phenomenon, in this paper, we propose the use of hashing schemes when distributing training data across workers."
9526152,Application Model of China’s Governance Method Based on Big Data,"In order to research and explore China's international governance system and strengthen the approach to the application of big data in the national governance system, this paper presents a novel application model of China's governance method based on big data. The application model is based on 829 Big Data policy texts in China from 2012 to 2018, and scientifically employs social network analysis methods to study and explore the evolutionary characteristics of Big Data policy thematic networks. The research results show that in this application model, big data policy themes are diverse and continuous, and they have three main forms, namely policy innovation, policy continuity and policy cohesion."
9534601,Insights.Wisdom.Leadership: A Study of Talent Cultivation of Big Data,"With the continuous progress and innovation of information technology, Big Data has become one of the most discussed topics in recent years. It alters how the new knowledge is learned and provides opportunities and unprecedented challenges for big data talent training in the educational field. Traditional talent training objectives are not clear and lack curriculum resources and practical teaching insufficiency. This paper analyzes how to cultivate innovative big data talents under the information environment. Our approach is based on three tenets: (1) INSIGHTS: Combine international theories and China's social development characteristics to build a big data technology curriculum system, focusing on the cultivation of insight skills. (2) WISDOM: Establish a ""WISDOM"" co-sharing learning space that focuses on Ubiquitous learning, which combines online + offline (3) LEADERSHIP: Cultivate students' innovation ability, leadership, and teamwork through project-based learning. It has been proved that the innovation of the big data talent training model has improved the quality of talent training and cultivate integrated talents with excellent teaching effects to meet the needs of modern society."
9591833,Optimization Design of Computer Information Management Software under the background of Big Data,"With the increasing growth and progress of the big data science, information management software has been widely used, but also highlights the security risks. At present, it is particularly easy to have information theft, information leakage and many other situations. This will have a serious negative impact on the overall system application efficiency and application effect. In the set preprocessing, this paper uses the filling method for the missing values in the collected data, and establishes an effective evaluation mechanism for the missing value filling scheme. By comparing various filling schemes, this paper finally chooses the fitting method based on Gaussian distribution to fill the missing values. Experimental data reflect the usefulness of the proposed method."
9101999,The Spatio-Temporal Modeling and Integration of Manufacturing Big Data in Job Shop: An Ontology-Based Approach,"Manufacturing big data provide the factory with a tremendous opportunity for transforming the current manufacturing paradigm to smart manufacturing. However, the multi-source data modeling and integration problems are the existing gaps between the collected big data and the data-driven smart applications. With the large-scale deployment of Internet of things on the shop floor, it is essential to develop adequate data modeling and integration methods to manage and organize the generated manufacturing big data. In this study, the spatiotemporal modeling is firstly presented to organize the data in temporal, spatial and attributive dimensions respectively. Furthermore, the ontology-based big data integration approach is proposed to manage the multisource manufacturing data and ensure the data can be easily indexed and conveniently reused for different subsequent applications. Finally, the proposed data modeling and integration methods are implemented and verified through the developed manufacturing big data-driven analysis and decision-making system."
9650284,Research on the Application of Computer Big Data Technology in Cloud Storage Security,"In view of the continuous progress of current science and technology, cloud computing has been widely used in various fields. This paper proposes a secure data storage architecture based on cloud computing. The architecture studies the security issues of cloud computing from two aspects: data storage and data security, and proposes a data storage mode based on Cache and a data security mode based on third-party authentication, thereby improving the availability of data, from data storage to transmission. Corresponding protection measures have been established to realize effective protection of cloud data."
9182640,Research on Freight Big Data Application Based on Railway Data Service Platform,"According to the current status of railway freight data assets, the overall architecture of railway freight big data application based on the railway data service platform is proposed, including the processing flows of data acquisition and access, assets directory construction, data modeling and management, data storage and analysis, etc. Besides, the key technologies, e.g. the construction of data model based on source and paradigm approaches, Greenplum-based Ad Hoc queries of data, freight-specific data models are also studied. Based on the data of some existing freight business systems and the distributed computing architecture of the railway data service platform, this paper conducted Ad Hoc queries case analysis and the application practice of freight-specific algorithm library, thus verified the feasibility of key technologies, and provided data and technical support for the comprehensive analysis and mining application of freight big data."
9544802,Data Security and Privacy Preserving with Augmented Homomorphic Re-Encryption Decryption (AHRED) Algorithm in Big Data Analytics,"The process of Big data storage has become challenging due to the expansion of extensive data; data providers will offer encrypted data and upload to Big data. However, the data exchange mechanism is unable to accommodate encrypted data. Particularly when a large number of users share the scalable data, the scalability becomes extremely limited. Using a contemporary privacy protection system to solve this issue and ensure the security of encrypted data, as well as partially homomorphic re-encryption and decryption (PHRED). This scheme has the flexibility to share data by ensuring user's privacy with partially trusted Big Data. It can access to strong unforgeable scheme it make the transmuted cipher text have public and private key verification combined identity based Augmented Homomorphic Re Encryption Decryption(AHRED) on paillier crypto System with Laplacian noise filter the performance of the data provider for privacy preserving big data."
9006057,Sharp Frequency Bounds for Sample-Based Queries,"A data sketch algorithm scans a big data set, collecting a small amount of data - the sketch, which can be used to statistically infer properties of the big data set. Some data sketch algorithms take a fixed-size random sample of a big data set, and use that sample to infer frequencies of items that meet various criteria in the big data set. This paper shows how to statistically infer probably approximately correct (PAC) bounds for those frequencies, efficiently, and precisely enough that the frequency bounds are either sharp or off by only one, which is the best possible result without exact computation."
9453076,Smart Management System of Employment in Universities Based on Big Data Collection and Intelligent Analysis,"With the rapid development of information technology, college enrollment expansion has become more and more common. A large number of students to expand the source of employment of college graduates in recent years, so the university began to use the system software to achieve intelligent management of employment information. In the actual statistical process, statisticians are required to establish a scientific and effective data screening mode, which includes intelligent screening and manual screening. At the same time, intelligent screening has been called the inevitable choice of data statistics work. As big data covers more and more extensive fields and deals with more and more in-depth businesses, data types become more and more complex and diverse. With the help of big data tools and data intelligent analysis methods, this paper constructs an intelligent employment management system in colleges and universities."
8371209,Redundancy Avoidance for Big Data in Data Centers: A Conventional Neural Network Approach,"As the innovative data collection technologies are applying to every aspect of our society, the data volume is skyrocketing. Such phenomenon poses tremendous challenges to data centers with respect to enabling storage. In this paper, a hybrid-stream big data analytics model is proposed to perform multimedia big data analysis. This model contains four procedures, i.e., data pre-processing, data classification, data recognition and data load reduction. Specifically, an innovative multi-dimensional Convolution Neural Network (CNN) is proposed to assess the importance of each video frame. Thus, those unimportant frames can be dropped by a reliable decision-making algorithm. In order to ensure video quality, minimal correlation and minimal redundancy (MCMR) are combined to optimize the decision-making algorithm. Simulation results show that the amount of processed video is significantly reduced, and the quality of video is preserved due to the addition of MCMR. The simulation also proves that the proposed model performs steadily and is robust enough to scale up to accommodate the big data crush in data centers."
8819499,Attack Models for Big Data Platform Hadoop,"Hadoop is a very popular big data processing framework, however, due to its distributed and large-scale characteristics, its security problems have not been solved very well. Existing research does not systematically analyze attacks in big data platforms. This paper proposes four innovative hadoop attack models. Through adjusting heartbeat time, tampering intermediate data, blocking network, attackers prolong the execution time of jobs, and damage the correctness of job result. We implemented these attacks in hadoop and evaluate the effects of them through experiments. The experimental results show that our attacks are effective and harmful."
8695373,A Big Data Platform for Surface Enhanced Raman Spectroscopy Data with an Application on Image-Based Sensor Quality Control,"Surface-enhanced Raman spectroscopy (SERS) significantly enhances the Raman scattering by molecules, enabling detection and identification of small quantities of relevant bio-/chemical markers in a wide range of applications. In this paper, we present a big data platform with both a local client and cloud server built for acquiring, processing, visualizing and storing SERS sensor data. The local client controls the hardware (i.e., spectrometer and stage) to collect SERS spectra from HP designed sensors, and offers the options to analyze, visualize and save the spectra with meta-data records, including relevant experimental conditions. The cloud server contains remote databases and web interface for centralized data management to users from different locations. Here we describe how this platform was built and demonstrate its use for automated sensor quality control based on sensor images. Sensor quality control is a common practice, employed in sensor production to select high performing sensors. Image-based approach is a natural way to perform sensor quality control without destructing the sensors. Automating this process using the proposed platform can also reduce the time spent and achieve consistent result by avoiding human visual inspection."
9377886,Transfer learning for decision support in Covid-19 detection from a few images in big data,"The novel coronavirus (Covid-19) has spread rapidly amongst countries all around the globe. Compared to the rise in cases, there are few Covid-19 testing kits available. Due to the lack of testing kits for the public, it is useful to implement an automated AI-based E-health decision support system as a potential alternative method for Covid-19 detection. As per medical examinations, the symptoms of Covid-19 could be somewhat analogous to those of pneumonia, though certainly not identical. Considering the enormous number of cases of Covid-19 and pneumonia, and the complexity of the related images stored, the data pertaining to this problem of automated detection constitutes big data. With rapid advancements in medical imaging, the development of intelligent predictive and diagnostic tools have also increased at a rapid rate. Data mining and machine learning techniques are widely accepted to aid medical diagnosis. In this paper, a huge data set of X-ray images from patients with common bacterial pneumonia, confirmed Covid-19 disease, and normal healthy cases are utilized for AI-based decision support in detecting the Coronavirus disease. The transfer learning approach, which enables us to learn from a smaller set of samples in a problem and transfer the discovered knowledge to a larger data set, is employed in this study. We consider transfer learning using three different models that are pre-trained on several images from the ImageNet source. The models deployed here are VGG16, VGG19, and ResNet101. The dataset is generated by gathering different classes of images. We present our approach and preliminary evaluation results in this paper. We also discuss applications and open issues."
9442518,Opportunities and Challenges of Macroeconomic Analysis in Big Data Era,"This paper analyzes the opportunities and challenges faced by macro-economic analysis in big data era, and implement several important optimization ways, such as strengthening the construction of macro-economic analysis environment, accurately implementing information data security supervision, and strengthening the construction of macroeconomic analysis environment. This paper focuses on the cultivation of big data analysis professionals and the construction of a diversified big data platform. Then, this paper expounds the opportunities and analyzes the current challenges with macroeconomic analysis in big data era, and formulates corresponding countermeasures."
9363838,Research on Fashion Design Based on Human-Computer Interaction Technology in the Era of Big Data,"With the rise of big data, big data technology has been widely used in many industries and fields. However, there are not many related technology applications in the field of fashion design. Considering the characteristics of fashion design information in the era of big data, this paper establishes the information database of fashion design, introduces data mining technology to deeply mine the information of various elements of fashion design, and designs the information query system of fashion design by using human-computer interaction tools, which provides reference for the design ideas of fashion designers and realizes the exchange and sharing of big data. The human-computer interaction system can provide objective design basis and scientific design method for fashion design. It is a bold attempt to combine advanced information technology with traditional fashion design field, and is helpful to promote the liberation of thinking in fashion design field."
9603729,Research on the Construction of Collaborative Governance Audit Big Data Platform,"Currently, the traditional audit model has been gradually replaced by collaborative governance auditing. The effective development of collaborative governance auditing requires the construction of a big data audit platform to ensure. This article combines cloud computing related technologies, using CEPH distributed storage system, MapReduce parallel computing framework, heterogeneous computing and other technologies to try to establish a collaborative governance auditing big data platform, and analyze from the three aspects of the motivation, measures and system of the construction of the collaborative governance audit big data platform. The article divides the audit big data platform into five systems: data collection, preprocessing, storage center, analysis and visualization. The combination of collaborative governance audit and big data technology is a new attempt, with epoch-making significance and broad imagination, and provides a technical foundation for the collaborative governance audit cloud sharing platform, and provides theoretical support for the development of future big data audit work."
9457461,Research on Dynamic Monitoring of Third Language Teaching Quality Based on Big Data,"The traditional teaching quality monitoring in colleges and universities has drawbacks such as long data collection time, difficulty in summarizing, feedback lag, one-sided evaluation, lack of systematization and integrity, especially the third language teaching has been hovering in the ""gray zone"" of monitoring due to its own characteristics. With the concept of ""Internet plus"" extending in the field of higher education, big data technology can be used to choose the appropriate teaching cloud platform, collect and analyze the data generated in the teaching process comprehensively. It can also be used to recommend personalized learning sources by capturing the click rate, retention time, stay location and learning mood of learners; to set up questionnaires for different evaluation objects, customize diversified indicators of teaching and learning evaluation; to form an efficient feedback and improvement mechanism among students, teachers, supervisors, secondary colleges and teaching management institutions, which can bring a new perspective for college third language teaching, and also provide a new path for teaching quality monitoring."
9545040,The Current Situation and Future Development Trend of Computer and Chip Applications in the Era of Big Data,"Nowadays, with the rapid development of society, information technology is also developing rapidly. Driven by technologies such as big data, chip design and computer architecture must conform to the new development ideas of information technology, and it is necessary to understand various information in different applications and operating platforms, so as to face the various issues brought about by big data in advance. Kind of challenge. Based on big data technologies such as data collection, data mining, and data processing, this paper understands the application status of computer architecture and chip design, and analyzes future development trends."
9400382,Rapid Resolution of Parametric Failures in the Process Development Period by Integrating Device Physics and Big Data,"This paper describes a method for rapid resolution of parametric failure during the development period. Since the number of samples is small, it is not possible to carry out general big data analysis of white defect failures of CMOS image sensors (CISs) during the development period in the same way as can be done during the mass production period. Our feature value analysis of white defects based on device physics revealed that both a development product and mass products using big data show similar fluctuations in dark current spectroscopy and in-plane distribution in the wafer. Process step/tool identification and tool sensor data analysis revealed the degree of vacuum within the implantation tool to have a strong correlation with white defect count. We developed a virtual metrology (VM) model for white defect count and varied the degree of vacuum. As a result of our experiments, we were able to reduce white defect count during the development period by 75%. The time required for resolution of failures was 10% that of the conventional method. This paper describes a detailed explanation of how the potential causative process step/tool was identified in addition to the conference paper presented in ISSM2020."
9352886,Regional Electricity Sales Forecasting Research Based on Big Data Application Service Platform,"Regional monthly electricity sales forecast is an important basis for regional power grid planning and construction, evaluation of regional economic development and operation, and protection of residents' lives. It is also an important work of regional power regulation and management, decision-making of power generation and purchase, improvement of power supply equipment utilization rate and deepening of power system reform. Based on the current situation of power supply enterprise information development, distribution network business status and characteristics, this paper analyzes the factors affecting electricity sales. According to the characteristics of annual changes in electricity sales and data quality factors, the recurrent neural network model is selected based on the big data application service platform. The long short term memory neural network model performs multi-step multivariate prediction on time series, and uses the attention mechanism to combine two independent models for prediction. Experiments conducted on the historical electricity sales data set of a power supply company show that compared with traditional machine learning methods, this method has advantages in accuracy and efficiency."
9004264,"Artificial Intelligence and the Privacy Paradox of Opportunity, Big Data and The Digital Universe","Artificial Intelligence (AI) can and does use individual's data to make predictions about their wants, their needs, their influences on them and predict what they could do. The use of individual's data naturally raises privacy concerns. This article focuses on AI, the privacy issue against the backdrop of the endless growth of the Digital Universe where Big Data, AI, Data Analytics and 5G Technology live and grow in The Internet of Things (IoT)."
8723839,Real-time machine learning for early detection of heart disease using big data approach,"Over the last few decades, heart disease is the most common cause of global death. So early detection of heart disease and continuous monitoring can reduce the mortality rate. The exponential growth of data from different sources such as wearable sensor devices used in Internet of Things health monitoring, streaming system and others have been generating an enormous amount of data on a continuous basis. The combination of streaming big data analytics and machine learning is a breakthrough technology that can have a significant impact in healthcare field especially early detection of heart disease. This technology can be more powerful and less expensive. To overcome this issue, this paper propose a real-time heart disease prediction system based on apache Spark which stand as a strong large scale distributed computing platform that can be used successfully for streaming data event against machine learning through in-memory computations. The system consists of two main sub parts, namely streaming processing and data storage and visualization. The first uses Spark MLlib with Spark streaming and applies classification model on data events to predict heart disease. The seconds uses Apache Cassandra for storing the large volume of generated data."
9623002,Three Classifications of Big Data-based Software Testing,"The paper reviews three classifications of big data-based software testing in the last 10 years. Testing for big data system, big data evaluation benchmarks, and the application of big data technology to software testing are studied in the paper. This research helps readers understand the development and classification of big data-based software testing."
9434482,Research and Application on the Governance of Passenger Car Product Data Resources,"With the development of digital economy and big data technology, data resources owned by enterprises have become one of the important production factors in the era of digital economy. Via data empowerment, enterprises analyze the intrinsic value of data, and then realize their own business transformation and innovation and development. After more than ten years of rapid development, China is now the world's largest automobile production country. Behind the huge automobile market, there are a lot of data resources related to the market and products. However, due to the problems of scattered data sources, inconsistent statistical caliber and untimely updating, it brings great inconvenience to the researchers engaged in automobile industry. This paper proposes a set of passenger car product data governance framework, which aims to provide high-quality passenger car product database for enterprises in the process of studying the market and technology of passenger car products, mining the value of data assets, and assisting managers in decision-making."
8821752,Hyperparameters Optimization in Scalable Random Forest for Big Data Analytics,"With the tremendous growth of big data, the issue of how to get valuable knowledge from these data becomes the main attention for researchers. The traditional analytic platforms and methods are not fit for processing such big data. Big data analytics plays a vital role in the research area for processing the unrelated, structured, and unstructured data. Machine learning algorithms are needed to improve for exploiting the opportunities hidden inside in big data. In this paper, the performance of Scalable Random Forest algorithm (SRF) is improved by hyperparameters optimization and dimension reduction technique. Big data analytics platform is developed using the Hadoop Distributed File System and Spark processing engine. The performance evaluation of improved SRF is conducted over real-world data center workload traces and model validation process is carried out to obtain the reliable error estimation for big data analytics. Our findings show that the tuning of hyperparameters is critical for different datasets, and optimization of these parameters significantly enhances prediction accuracy than the default parameters."
9523975,Construction of Free Trade Pilot Zone Based on Big Data Technology,"In order to overcome the problems existing in the construction and development of the traditional pilot free trade zone, such as asymmetric information, slow data transmission and difficult real-time monitoring, this paper proposes a novel construction of free trade pilot zone based on big data technology. The method is combined with big data technology, which makes full use of the advantages of big data technology in collecting and processing data. Based on this, the method also aims at the construction and development status of China's pilot free trade zone, and improves the construction level of the pilot free trade zone from multiple dimensions, such as infrastructure, service system, etc. The experimental results show that this method can break through the limitations of the traditional construction mode of free trade zone, strengthen the interaction of free trade zone, and realize real-time monitoring and management."
9006229,Estimation of Transactional Network Data Between Branch Offices using Transactional Big Data Throughout Japan,"When conducting agent economic simulation for supply chains, inter-company transaction data are essential. However, the current inter-firm transaction data are network data in which branch office information is aggregated into headquarters transaction data. This study proposes a method to estimate branch office transactions from inter-company transaction data aggregated among headquarters by using a gravity model. We also confirm the method's reliability by comparing the estimated transaction data with the inter-regional input-output tables. We analytically considered the transition for all network configurations, demonstrating that the transaction quantity depends on the amount of labor and distance. We also demonstrated that our model fits well with data from business transactions, implying that the whole network structure can be used to model money flow in the real world."
9036426,Anatomy of Big Iot Data analytics,"A large quantity of statistics is generated because of the explosive boom inside the wide variety of devices connected to the Internet of Things. However, such data large amount of data is not useful without the power of analytics. Different IOT, big data, and analytics have enable individuals to get significant understanding into vast measure of information produced by IoT gadgets. Nonetheless, these arrangements are still in their underlying state, and the area comes up short on a far reaching overview. The contribution of this paper is to purpose a five layer architecture for big IOT data. The functionality of five different layers of big IOT data architecture is explained. The opportunities for big IoT data architecture are discussed. Further more challenges face by the architecture are also explained."
9587232,Research on Accurate Identification of Poor Students in Colleges Based on Big Data Analysis,"In recent years, colleges have greatly expanded their enrollment and the number of college students has increased dramatically, which has greatly increased the difficulty and workload of poor student funding. It is urgent to use big data information to accurately identify which students are from poor families. In this way, the scientific nature of funding for poor students can be enhanced, and the subjective factors of democratic voting and identification of personnel can be eliminated, which will make the funding work more objective and efficient. This article proposes a poor student identification model based on student family information and big data analysis of campus card consumption. We use the optimized K-means clustering analysis algorithm and big data technology to establish a poor student identification model based on cluster analysis, which is a good way to help schools identify poor students. The experimental results show that the model has a high accuracy rate, and it is of great significance for standardizing the funding of poor students and the targeted poverty alleviation policies of education."
9093868,"Big Educational Data & Analytics: Survey, Architecture and Challenges","The proliferation of mobile devices and the rapid development of information and communication technologies (ICT) have seen increasingly large volume and variety of data being generated at an unprecedented pace. Big data have started to demonstrate significant values in higher education. This paper gives several contributions to the state-of-the-art for Big data in higher education and learning technologies research. Currently, there is no comprehensive survey or literature review for Big educational data. Most literature reviews from a few authors have focused on one of these fields: educational mining, learning analytics with discussions on one or two aspects such as Big data technologies without educational focus, social media data in education, etc. Most of these literature reviews are short and insufficient to provide more inclusive reviews for Big educational data. In this paper, we present a comprehensive literature review of the current and emerging paradigms for Big educational data. The survey is presented in five parts: (1) The first part presents an overview and classification of Big education research to show the full landscape in this field, which also gives a concise summary of the overall scope of this paper; (2) The second part presents a discussion for the various data sources from education platforms or systems including learning management systems (LMS), massive open online courses (MOOC), learning object repository (LOR), OpenCourseWare (OCW), open educational resources (OER), social media, linked data and mobile learning contributing to Big education data; (3) The third part presents the data collection, data mining and databases in Big education data; (4) The fourth part presents the technological aspects including Big data platforms and architectures such as Hadoop, Spark, Samza and Big data tools for Big education data; and (5) The fifth part presents different approaches of data analytics for Big education data. This part provides a more in...
(Show More)"
8725668,Research on Wide-area Distributed Power Quality Data Fusion Technology of Power Grid,"With the advancement of the ""big operation"" system construction, the online monitoring system for power quality has been integrated, and various power quality data have been incorporated into relevant organizations for unified management. Power quality management has a larger range of data, more types, and higher frequency. It needs to realize the unified storage management and efficient access of massive heterogeneous power quality data for the characteristics of data applications and the collection and aggregation of these effective data. This paper proposes a new type of grid wide-area distributed power quality data integration architecture, which is designed for multi-source, heterogeneous, distributed data integration technology and wide-area distributed data storage technology to solve the big data source problem and realize the sharing of power quality data information of the whole network."
9050375,The Construction of Financial Aid System for Poor Students in Big Data Environment,"Based on the analysis of the status quo of college student financial aid work in China under the background of big data, this paper points out that the research on the construction of university's precision funding system is the need to speed up the precision funding work. In order to protect the personal development of poor students, this paper puts forward the problem analysis of the construction of college students' financial aid work under the background of big data. The clustering algorithm is used to classify according to the characteristics of poor students, and provide reference for education precision poverty alleviation and precision funding. The system integrates the data of the poverty alleviation department, the enrollment examination department and the education funding department, and realizes the accurate information transmission of poor students through data comparison, which solves the problem of data inaccuracy faced in the education funding work."
8920804,Design of Practical Information Multidimensional Integration System for Higher Vocational Ideological and Political Courses Facing Big Data,"In view of the fact that the current information integration system can not quickly integrate a large number of chaotic practical information, this paper designs a multi-dimensional integration system of practical information for ideological and political courses in higher vocational colleges. The main control chip, TMS320C6748, is used to control the whole operation of the system. The physical server stores the information data and communicates with the serial port to transfer the data. Through the method of FPGA, the cluttered practical information data is filtered. According to the principle of Bayesian algorithm, the filtered information data is classified and the information data is preprocessed. In the SQL database, XML technology is used to parse and transform the pre-processed information and data. The data transformed into XML format is unified. According to the set multi-dimensional integration rules, data streams are split in the middle layer of the database and then merged is omorphically and heterogeneously. The data is loaded and stored in the integrated database, and finally the integration of information and data is completed. The design of multi-dimensional integration system is completed through hardware and software design. Comparing with the current information integration system, the experiment verifies the speed of information integration time of the designed multi-dimensional integration system. When integrating different amounts of practical information, the integration time of the designed multi-dimensional integration system is about one third of that of the current information integration system."
9671349,Intersection Representation of Big Data Networks and Triangle Counting,"Triangles are an essential part of network analysis, representing metrics such as transitivity ratio and clustering coefficient Because of its diverse applications, enumeration and counting of triangles in large networks has been extensively studied, and continues to draw much interest from many different fields. This has only increased with the introduction of approximate counting, parallel and distributed implementations, and restricted and streaming data access scenarios. We propose a compact and efficient representation of network data based on the intersection of edge labels, and use sparse matrix data structures for its computer implementation. We then present a scalable algorithm that uses this structure to count triangles. On a set of large (the largest with more that 3.6 billion edges) real-world and synthetic networks, our algorithm performs significantly better than the reference implementation miniTri [1]."
8843451,Towards Federated Learning Approach to Determine Data Relevance in Big Data,"In the past few years, data has proliferated to astronomical proportions; as a result, big data has become the driving force behind the growth of many machine learning innovations. However, the incessant generation of data in the information age poses a needle in the haystack problem, where it has become challenging to determine useful data from a heap of irrelevant ones. This has resulted in a quality over quantity issue in data science where a lot of data is being generated, but the majority of it is irrelevant. Furthermore, most of the data and the resources needed to effectively train machine learning models are owned by major tech companies, resulting in a centralization problem. As such, federated learning seeks to transform how machine learning models are trained by adopting a distributed machine learning approach. Another promising technology is the blockchain, whose immutable nature ensures data integrity. By combining the blockchain's trust mechanism and federated learning's ability to disrupt data centralization, we propose an approach that determines relevant data and stores the data in a decentralized manner."
9620761,Mechanism of a big-data platform for residential heat energy consumption,"Although the solar energy industry is becoming widespread, it is necessary to manage the charging and generating scheduling of solar power generation according to the ever-changing climate environment. In order to do this, a judgment criterion that can give timely charge / discharge instructions is needed and it needs to be actively performed. In this paper, we define a big-data platform for residential heat energy consumption. As a technology to secure thermal energy data of apartment houses, collect thermal energy data by dividing it into supply/equipment/usage. In order to secure standardized thermal energy data from the calorimeter installed. Equipped with data classification and processing, LP storage and management, data quality measurement and analysis functions. Develop a data adapter, from several multiunit dwellings with different calorimeter types. We will collect thermal energy data with an integrated big data system."
9557566,A Study of Big Data and Classification of NoSQL Databases,"Today, Big Data is the main topic of discussion everywhere due to its huge popularity as its getting generated in a huge volume in every second. It is getting huge consideration and gratitude because of its wide research area and application scenarios. Large scale, bulky, quick changes, huge growth in data is generally stated as Big Data. Data that is obtained from a wide variety of sources are usually in a format of structured, unstructured or semi-structured data. Many times big data is collected from multiple application sources, so there is a presence of structural heterogeneity. This problem of structural heterogeneity is one of the major challenges for researchers around the world and can be overcome using big data Integration. As big data refers to the data in large volumes, available in different formats and generated at extraordinary speed so to capture, process and analyze this kind of data becomes difficult using traditional data processing tools. These difficulties can be overcome using big data management tools and techniques. Big Data Integration and Management are very crucial, revolutionizing the industries and has many applications in all sectors of human life. This paper discusses brief information about big data, its history, integration issues, and available management methods and tools."
8787520,Comparing Data Base Engines for Building Big Data Analytics in Obesity Detection,"Obesity is a growing problem that has reached a pandemic dimension. Diagnosis of obesity is based on the body mass index, regardless other important indicators related to metabolic impairments. One of the main problems is the difficult identification of obese subjects or in risk of developing obesity. New health information systems supporting massive amounts of physiological, treatments and lifestyle data have been proposed elsewhere, however these have also introduced a significant data and decision overload problem. In this paper we present a comparative study on data base management engines for supporting big data analytics for the identification of obese subjects based on Electronic Health Records. We compared relational and non-relational approaches to address scalability and performance in a tertiary hospital. The experiments have evaluated data from five different hospital services on a data-mart containing 20,706,947 records from the University Hospital La Fe of Valencia (Spain). Experiments where based on data load and query with different configurations and restrictions. NoSQL approach yielded better results when compared to relational engines for all the proposed experiments."
9675905,Comparison of Semantic Web Data Performance Using Virtual and Cloud Services,"The term “big data” refers to the rapid development and availability of incredibly massive data collections that can be computationally processed to reveal patterns, trends, and relationships. The term “big data” refers to a compilation of vast amounts of data produced by various sources. Data collection and retrieval are becoming more complicated as the volume of data grows. Big Data Techniques refers to a modern wave of technologies and architectures that are designed to derive information from massive amounts of data in a number of formats. Hadoop uses a massively parallel computing strategy to process data that is scattered through a commodity cluster instead of being processed sequentially. The Hadoop MapReduce Model's mapper and reducer phases aid in the processing of vast volumes of data in a distributed environment, which has an impact on efficiency. Each portion of the data can be separated into smaller bits and stored on a different node within the cluster. With various data loading sizes, nodes were organised using the Amazon web service and the virtual environment. When compared to both frameworks, Hadoop designed in the cloud plays a critical role in data warehousing and clustering to achieve the highest results. As a result, the semantic web data are divided into pre- processing and clustering in this analysis to boost accuracy."
9215395,Multimedia Intervention and Big Data Analysis Framework of English Online Guiding Connection under the Internet Background,"Multimedia intervention and the big data analysis framework of the English online guiding connection under the Internet background is designed in this paper. Novelties are focused on two aspects. (1) In the multimedia player, users can add one or more media files to the playlist. The program traverses all the added files, checks the legality of each file, and then saves all valid media sources in the media source queue, this is used to optimize the structure. (2) In the multimedia player, users can add one or more media files to the playlist. The program traverses all the added files, checks the legality of each file, and then saves all valid media sources in the media source queue. The novel system is designed for assistance tasks. The experiment compared with the latest models have proven well performance."
9092466,Research of the Integration of Humanistic Quality in Education under the Background of Intelligent Big Data,"In the context of the new era, it is very indispensable to integrate humanistic quality education into college and university. However, there are still some problems because of the impact of big data information, which is not conducive to students' humanity and even affects their future development. The following is an in-depth analysis of the integration of humanistic quality in education under the background of big data information. The purpose of this paper is to effectively promote the integration of humanistic quality between college and university education, in order to improve the humanistic quality of students as well as better development of students."
9108782,Search by Image Engine for Big Data Warehouse,"The paper discusses promising ways to build an invariant model and an efficient image search algorithm in Big Image Warehouse. Based on open data using the appropriate Python prototype, Search by Image Engine, a series of experiments is conducted to search for images in Big Data Warehouses. Estimates of the effectiveness of the search using the developed prototype, taking into account valid image transforms are given."
9596423,Big Data Analysis for Data VisualizationA Review,"Complexity is one of the main characteristics of measuring data. Heterogeneous data contributes to data integrity and the process of big data problems. Both are essential and difficult to visualize and interpret large-scale databases because they require large capacity for data processing and storage. The data age, in which data is growing exponentially, is a huge struggle to extract data in a way that the human mind can assimilate. This paper reviews and presents data visualization and description of heterogeneous distributed storage and its challenges using different methods from some previous research. Besides, the results of the reviewed research work are compared, and the fundamental transformation in the world of big data visualization for virtual reality is discussed."
9456537,Design and Implementation of Regional Food Distribution Platform Based on Big Data,"In recent years, the rapid development of big data has made people's daily life very convenient, and at the same time, tasting all kinds of food has become an important activity for people to travel. Due to the vast territory of China, there are many types of cuisines with great differences, it is very important for travelers to understand the special regional cuisines in the area. This project aggregates regional food data based on big data, and provides tourists with efficient, stable and professional data retrieval and analysis services through a visual data interface, and provides intuitive, accurate, and real-time data support for the decision-making of finding characteristic regional food. This thesis first conducted a relevant understanding of big data and the overall situation of regional cuisine, analyzed the distribution of food in the sub-provincial city of Xi'an, explored the research methods and implementation methods of related projects at home and abroad, based on this, summarized the research of this project the goal. At the same time, the focus of this project is to analyze the price, score and popularity of regional food data analysis in my country, and to summarize, proofread and organize the data obtained before into standard and standardized data. Through the classification of basic information, the visual analysis and display of data is realized, and the key data urgently needed by decision makers are extracted from it. To analyze the needs of decision makers, establish corresponding strategies and measures to improve the quality of data services. The establishment of this system provides a useful supplement and improvement to the existing industry data analysis system. The system is mainly divided into six modules, which are data collection, data review, data summary, and visual data display modules. Among them, data collection includes crawling relevant data from the Internet and retrieving key data. The data audit function includes classifyi...
(Show More)"
8897811,Mapping Spatial-Temporal Forest Heterogeneity in the Tropical Belt by ALOS-2/PALSAR-2 Big Data Analysis,"Insufficient knowledge about spatial-temporal forest heterogeneities in the tropics is a major impediment to better estimation of carbon storage and prevention of deforestation by remote sensing. While the differences between the dense evergreen rainforest and the open (semi-) deciduous dry forest is obviously large, variations caused by seasonal changes can easily introduce fluctuations in the same order of magnitude within the same forest class. In this study, we present a comprehensive analysis of the variability of tropical forests based on homogeneous big data analysis on multitemporal ALOS-2 dual-polarized ScanSAR data. The first, easy to understand global forest variability maps provide unseen insights into forest structures for the entire tropical belt. Based on these results, we discuss the development of a new global classification scheme for tropical forests. Preliminary results demonstrate how the use of various statistical parameters obtained from the long-term systematic L-band SAR forest monitoring data, including the average γ 0 , its temporal standard deviation and the γ 0 range, can improve the classical global-scale forest classifications. In addition to the basic separation into the three main forest types i) rainforest, ii) moist forest and iii) dry forest, the results provide a detailed mapping of the seasonally flooded forest areas."
9410170,Design of university archives resource integration system based on big data mining,"In order to improve the effect of college archives resource integration, this paper designs a college archives resource integration system based on big data mining. System hardware consists of data storage module, a shared database module, user authentication module, resource integration module and resource retrieval module, on the basis of the hardware design to software development. First of all, the university archives resources big data preprocessing, attribute the training sample set for each attribute of information gain rate, on the basis of this general has the maximum attribute of information gain rate as a decision-making tree root node, and through the class attribute distribution, merging, and reduction operation, realize the university archives resources data mining. The experimental results show that the system has higher recall and precision, and shorter response time."
9022853,Effective Analytics on Healthcare Big Data Using Ensemble Learning,"Healthcare big data is a collection of record of patient, hospital, doctors and medical treatment and it is so large, complex, distributed and growing so fast that this data is difficult to maintain and analyze using some traditional data analytics tools. To solve this difficulties, some machine learning tools are applied on such big amount of data using big data analytics framework. In recent years, many researchers have proposed some machine learning approaches on healthcare data to improve the accuracy of analytics. These techniques were applied individually and compared their results. To get better accuracy, this paper proposes one machine learning approach called ensemble learning, in which the results of three machine learning algorithms are combined. Soft voting method is used for combining accuracies. From these results, it is observed that ensemble learning can obtain maximum accuracy."
9457399,On Crowdsourcing Mode and Its Timing Strategy— —Based on big data analysis,"Crowdsourcing is a new model that helps companies solve problems with the help of external network intellectual resources. How to attract more solvers to participate is not only a problem in the practical application of crowdsourcing, but also the key to crowdsourcing research. Based on the social learning theory, this paper empirically studies the effect of scheduling on the numbers of submitted solution, as well as the moderating role of bonus and task category. This article applied 386 thousands real crowdsourcing projects' secondary data to test the hypothesis. The results show that: scheduling has a positive effect on the numbers of submitted solutions. Based on task category, a suitable scheduling can effectively more solvers. And for time-critical tasks, corporates can set a higher prize quantity to attract more participants."
8912106,Research on Multidimensional Information Security Assessment Based on Big Data,"In order to ensure the security of multi-dimensional information, this paper proposes a research on key technologies of multi-dimensional information security risk assessment based on big data framework. According to the characteristics of multi-dimensional information security data, security division is carried out, intrusion data impact parameters are collected, and intrusion risk budget is carried out according to different impact parameter values and divided security levels, so as to realize accurate evaluation of multi-dimensional information security risks. Finally, the experiment proves that the key technology of multidimensional information security risk assessment based on big data framework has higher practicability and accuracy, and meets the research requirements."
8755178,PABED – A Tool for Big Education Data Analysis,"Cloud computing and big data have risen to become the most popular technologies of the modern world. Apparently, the reason behind their immense popularity is their wide range of applicability as far as the areas of interest are concerned. Education and research remain one of the most obvious and befitting application areas. This research paper introduces a big data analytics tool, PABED (Project - Analyzing Big Education Data), for the education sector that makes use of cloud-based technologies. This tool is implemented using Google BigQuery and R programming language and allows comparison of undergraduate enrollment data for different academic years. Although, there are many proposed applications of big data in education, there is a lack of tools that can actualize the concept into practice. PABED is an effort in this direction. The implementation and testing details of the project have been described in this paper. This tool validates the use of cloud computing and big data technologies in education and shall head start development of more sophisticated educational intelligence tools."
8645607,A Probability based Model for Big Data Security in Smart City,"Smart technologies at hand have facilitated generation and collection of huge volumes of data, on daily basis. It involves highly sensitive and diverse data like personal, organisational, environment, energy, transport and economic data. Data Analytics provide solution for various issues being faced by smart cities like crisis response, disaster resilience, emergence management, smart traffic management system etc.; it requires distribution of sensitive data among various entities within or outside the smart city,. Sharing of sensitive data creates a need for efficient usage of smart city data to provide smart applications and utility to the end users in a trustworthy and safe mode. This shared sensitive data if get leaked as a consequence can cause damage and severe risk to the city's resources. Fortification of critical data from unofficial disclosure is biggest issue for success of any project. Data Leakage Detection provides a set of tools and technology that can efficiently resolves the concerns related to smart city critical data. The paper, showcase an approach to detect the leakage which is caused intentionally or unintentionally. The model represents allotment of data objects between diverse agents using Bigraph. The objective is to make critical data secure by revealing the guilty agent who caused the data leakage."
9050235,Research on Automatic Search of Internet of Things in Big Data Era Based on Merge Sorting Method,"As we enjoy these emerging technologies, we also face the risk of information being leaked. The information security problem has been plaguing us all the time. This is also the era of big data. Due to the continuous development of science and technology, the society has also caused the strong wind of the Internet of Things, and it is increasingly understood by ordinary consumers. As a consumer, it is necessary and necessary to understand the related security issues of the Internet of Things. According to this situation, this article makes a general analysis of the security holes in the Internet of Things, and proposes some prevention and control measures in light of the current network conditions. Based on the analysis of data processing of Internet of Things technology and logistics unified information system, and according to the characteristics of Internet of Things technology and unified information, an improved Shell ranking optimization algorithm in data processing of logistics unified information system is proposed."
9387671,Big Data Architectures for the Climate Change Analysis: A Systematic Mapping Study,"Despite the volume of data generated, scientists cannot accurately predict how climate change will manifest itself locally and what measures should be applied to mitigate it effectively. On the other hand, Big Data is a new technology that faces the challenge of collecting, characterizing and analyzing a large amount of data, taking into account data from multiple sources, multiple variables and multiple scales with different spatial and temporal attributes. To do this, we review and synthesize the current state of research of Big Data architectures that help solve the problems caused by climate change in health (16%), agriculture(8%), biodiversity(16%), energy(8%), water resources(4%) and clima(48%). To achieve the objective, we have carried out a systematic mapping study, which includes four research questions, including 25 studies, published from 2013 to 2019. The architectures found have been classified according to their use, which can be for statistical analysis, monitoring and simulations; helping researchers to integrate knowledge into the practical use of Big Data in the context of climate change."
9278783,Modelling and Simulation of Big Data Networks,"Modelling and simulation of Big data (BD) networks used to be technical problem before years, but now is opportunity. BD processioning and analytics are developing every day, useful teletraffic models describe and suggest decisions in such networks. Some of the untapped data are coming from sensors, devices, third parties, Web applications, and social media. Some BD sources feed data unceasingly in real time. Combining this, BD is not just about giant data volumes, it is also about an extraordinary diversity of data types, delivered at various speeds and frequencies. In this paper we analyzed the teletraffic models, modelling and analytical solutions for BD networks and are simulated heavy traffic models."
9311096,Research and Application of Power Think Tank Platform Driven by Internet Plus and Big Data,"The popularization and application of big data technology and data mining technology provide support for the efficient circulation of information and scientific decision-making of enterprises, while also bringing new challenges and thinking to the operation and construction of new power think tanks. This article first analyzes the needs for the construction of electric power think tanks, summarizes the experience and practices of typical Chinese think tanks, and puts forward a method for building electric power think tanks based on Internet plus and data. According to the proposed method, the case of electric power think tanks we constructed is shown, and a new situation in the construction of electric power think tanks in the new era is well proposed, which provides a reference for future research on electric power think tanks."
9096305,"A Comprehensive Analysis of Healthcare Big Data Management, Analytics and Scientific Programming","Healthcare systems are transformed digitally with the help of medical technology, information systems, electronic medical records, wearable and smart devices, and handheld devices. The advancement in the medical big data, along with the availability of new computational models in the field of healthcare, has enabled the caretakers and researchers to extract relevant information and visualize the healthcare big data in a new spectrum. The role of medical big data becomes a challenging task in the form of storage, required information retrieval within a limited time, cost efficient solutions in terms care, and many others. Early decision making based healthcare system has massive potential for dropping the cost of care, refining quality of care, and reducing waste and error. Scientific programming play a significant role to overcome the existing issues and future problems involved in the management of large scale data in healthcare, such as by assisting in the processing of huge data volumes, complex system modelling, and sourcing derivations from healthcare data and simulations. Therefore, to address this problem efficiently a detailed study and analysis of the available literature work is required to facilitate the doctors and practitioners for making the decisions in identifying the disease and suggest treatment accordingly. The peer reviewed reputed journals are selected for the accumulated of published research work during the period ranges from 2015 - 2019 (a portion of 2020 is also included). A total of 127 relevant articles (conference papers, journal papers, book section, and survey papers) are selected for the assessment and analysis purposes. The proposed research work organizes and summarizes the existing published research work based on the research questions defined and keywords identified for the search process. This analysis on the existence research work will help the doctors and practitioners to make more authentic decisions, which ultimately will he...
(Show More)"
9393907,Big Data Platform for Educational Analytics,"Huge amounts of educational data are being produced, and a common challenge that many educational organizations confront, is finding an effective method to harness and analyze this data for continuously delivering enhanced education. Nowadays, the educational data is evolving and has become large in volume, wide in variety and high in velocity. This produced data needs to be handled in an efficient manner to extract value and make informed decisions. For that, this paper confronts such data as a big data challenge and presents a comprehensive platform tailored to perform educational big data analytical applications. Further, present an effective environment for non-data scientists and people in the educational sector to apply their demanding educational big data applications. The implementation stages of the educational big data platform on a cloud computing platform and the organization of educational data in a data lake architecture are highlighted. Furthermore, two analytical applications are performed to test the feasibility of the presented platform in discovering knowledge that potentially promotes the educational institutions."
9516660,Big Data architecture proposal for vehicular traffic detection,"Currently, IT solutions that detect situations of vehicle congestion use isolated technologies, which are not part of an ecosystem that manages them together, made it difficult to gear the tools used by affecting the operation of the solutions.This study aims to present a Big Data architecture proposal for the implementation of vehicle traffic detection software. The research is presented based on the base architecture established for Big Data systems, as well as established studies identifying the particular phases identified for the processing of vehicle traffic records collected in the city of Quito-Ecuador."
9524042,Computer E-commerce Security System Under the Background of Big Data,"In order to solve various problems of the current computer e-commerce platform, such as low security, poor interaction, low quality of service personnel, low level of information technology, this paper proposes a new computer e-commerce security system under the background of big data. The system combines big data technology, gives full play to the function of mining information and collecting information of big data technology, strengthens the combination of big data technology and Internet technology, realizes the interaction between buyers and sellers, and improves the satisfaction of users. Based on this, the system can also make full use of big data technology to solve the security problem of e-commerce platform, ensure the security of users' personal information, and reduce the risk of transaction activities. The experimental results show that the system can solve most of the current computer e-commerce platform problems, such as low security, poor interaction, and so on, so as to provide a good trading environment for buyers and sellers."
9470270,Innovation System of Preventive Medicine Based on Big Data Technology,"In order to overcome a series of difficulties faced by the preventive medicine industry, such as the small number of doctors and the difficulty for patients to get comprehensive and systematic rehabilitation treatment, this paper proposes a novel innovation system of preventive medicine based on big data technology. The innovation system fully combines the characteristics of big data technology and introduces big data thinking into the preventive medicine industry. Based on this, the innovation system can also build medical big data of patients, which can not only make patients and their families clearly understand the condition, reduce the workload of doctors, but also improve the efficiency of medical treatment. At the same time, the innovative system not only considers the patients, but also fully considers the physical problems of healthy people, and implements the concept of disease prevention. The results show that the innovation system can fundamentally improve the intelligence and scientificity of preventive medicine industry, and then realize the transformation from traditional preventive medicine to modern preventive medicine."
9559536,Auxiliary Basketball Training System Based on Big Data,"With the rapid development of computer technology, the world has entered the era of big data. “Big data” needs new processing mode to have stronger decision-making power, insight and process optimization ability to adapt to massive, high growth rate and diversified information assets. The combination of big data and sports events is becoming more and more popular. People have begun to combine big data technology to assist basketball training. The purpose of this paper is to study the design of the auxiliary basketball training system based on big data, so as to improve the success rate of slam dunk by using data. In this paper, the shooting posture parameters of athletes and coaches are obtained by the method of body posture estimation. Firstly, based on the basic principle of Kinect three-dimensional sensor, the sequence color image and its depth map information are collected. Then, a background modeling method based on vibe modeling is proposed. The domain pixels are used to create the background model to study the image features. Finally, a human pose estimation method based on contour features and image processing is proposed to realize the pose estimation of human joints. The experimental investigation shows that the background modeling algorithm based on vibe modeling overcomes the shortcomings of traditional methods, and can achieve better detection effect for dynamic background; the model-based human posture estimation algorithm and the model-free attitude estimation algorithm can extract the main joint data of human body more accurately; and the obtained human body data can guide basketball players to train well, and after the guidance of data information, the success rate of boys increased to 63.33%, and that of girls increased to 62.15%,."
9470337,Financial Innovation System of Commercial Banks Based on Big Data Technology,"In order to overcome the difficulties encountered in the transformation of commercial banks in the context of big data, this paper proposes a novel financial innovation system of commercial banks based on big data technology. The innovation system makes full use of big data technology and proposes different financial innovation directions and financial innovation approaches according to the different characteristics of traditional commercial banks and newly established commercial banks. The research result shows that the innovation system can indeed comprehensively and systematically point out how commercial banks should scientifically use big data technology and Internet platform to achieve institutional innovation, management innovation and product innovation in the context of big data."
9368818,Research on Computer Vision Image Multimedia Technology Based on Big Data,"With the development of the times, the progress of society, and the continuous improvement of science and technology, people's daily production and life have changed greatly compared with before. Internet, Internet of things, deep algorithm and other technologies are widely used in people's life, which makes big data technology trigger a new round of development trend. In this era of big data, many industries and technology research also ushered in great development opportunities. In order to better study the multimedia technology of computer vision image in the new era; this paper analyzes the application of big data technology, so as to better and more efficient research on computer vision image multimedia technology. The rapid development of the current era has brought great challenges to computer vision image multimedia technology. Therefore, this paper makes an in-depth study of computer vision image multimedia technology under the background of big data. In the research, this paper systematically describes the current computer vision image multimedia technology, as well as the future development direction of computer vision image multimedia technology. Through the analysis, the big data analysis method proposed in this paper plays a key role in the research of computer vision image multimedia technology."
9213712,Cybersecurity and Data Privacy in the Cloudlet for Preliminary Healthcare Big Data Analytics,"In cyber physical systems, cybersecurity and data privacy are among most critical considerations when dealing with communications, processing, and storage of data. Geospatial data and medical data are examples of big data that require seamless integration with computational algorithms as outlined in Industry 4.0 towards adoption of fourth industrial revolution. Healthcare Industry 4.0 is an application of the design principles of Industry 4.0 to the medical domain. Mobile applications are now widely used to accomplish important business functions in almost all industries. These mobile devices, however, are resource poor and proved insufficient for many important medical applications. Resource rich cloud services are used to augment poor mobile device resources for data and compute intensive applications in the mobile cloud computing paradigm. However, the performance of cloud services is undesirable for data-intensive, latency-sensitive mobile applications due increased hop count between the mobile device and the cloud server. Cloudlets are virtual machines hosted in server placed nearby the mobile device and offer an attractive alternative to the mobile cloud computing in the form of mobile edge computing. This paper outlines cybersecurity and data privacy aspects for communications of measured patient data from wearable wireless biosensors to nearby cloudlet host server in order to facilitate the cloudlet based preliminary and essential complex analytics for the medical big data."
9384673,The Construction of “Dual-qualified” Teachers in Applied Colleges Based on Big Data,"Big data mainly refers to large-scale or ultra-large-scale data sets, which are called “massive data” or “massive data”. Nowadays, with the development of information technology, such as mobile Internet, cloud computing, Internet of Things, and data mining, a variety of information is gradually being widely used in various industries. Moreover, they can provide important forces to promote national innovation, scientific development, economic take-off, and educational reform. The characteristics of big data are mainly manifested as massive, fast, diversified and high value. Based on the quality requirements of “double-qualified” teachers in applied colleges, schools need to strengthen the construction of the teaching team and create good conditions to actively cultivate high-quality talents."
9533048,Research on School Sports Training under the Background of Big Data,"China has witnessed the wide application of big data technology in school education in recent years. Applying big data technology to school sports training can not only improve the scientificity of training, but realize personalized training and improve students’ enthusiasm to participate in training. As a physical education teacher, we should increase our awareness and thinking of big data, and make full use of big data technology to assist sports training. In this paper, the writer first briefly introduces the application of big data technology in school sports training, and then puts forward its application strategy."
9270480,Research and Application of BIM Engineering Management Platform Combining Big Data,"Big data and BIM technology are the key to realize the informationization of construction industry. Therefore, the research on BIM project management platform of big data is conducive to solving the problems of loss of building parameters, incomplete information expression, inaccuracy and difficult to improve the operation and maintenance of traditional two-dimensional projects. Based on this background, this paper studies the BIM engineering management platform combined with large data."
9002019,Big Data: Evaluation of the Basic Trends of the Russian Market,"The modern world is at a new stage in its development, which is due to the large-scale and massive introduction of innovative digital technologies. The introduction of information and communication technologies led to the digital transformation of the entire world economic system and the formation of a new type of economy - a digital one based on the use of the most advanced digital technologies. Under digital transformation within traditional sectors, new directions began to emerge that became the drivers of the development of an innovative economy. This is Industry 4.0 in industry and Fintech in the financial sector, which allows the formation of new approaches to management and organization within their areas. The introduction of innovative technologies in today's world is happening with great acceleration: something that used to take years, today take a few months. Technologies that used to be in the field of research and experimentation have moved into practical implementation; big data processing technologies have become one of these technologies in recent years. The basic concepts and principles of big data are analyzed in the paper; their participation and integration into the third technology platform are considered. The development of big data is proceeding rapidly. Many countries joined the race in this area, in connection with which the development of the Russian big data market was evaluated: a financial analysis of the market was carried out, growth rates were determined, and the main players were identified. As part of the study, an industry analysis of the Russian big data market was made. Particular attention within the analysis was paid to the reasons and barriers that stand in the way of the development of big data in Russia. Based on a comprehensive analysis, the main trends were identified for the further development and application of these technologies in the Russian economy."
9459056,A Novel Algorithm Using Content-Based Filtering Technology in Apache Spark for Big Data Analysis,"Big data has been one of the fastest-growing research areas that many researchers are into, with large amounts of data being uploaded to the internet every minute analyzing this data can benefit businesses and content creators. Big companies are already making good use of customer data and can predict what customers might need and want based on their recent activities. In this paper, I am going to propose a novel algorithm that makes the process of analyzing big data much faster and easier by using content-based filtering on structured data in Apache Spark. We used models such as the classification model to classify the data in relevant categories that we need and find the relationship between days it takes to trend with views then use a predictive model to predict what type of content is good to produce. We used this on an existing realworld dataset and we were able to get good results. The results are encouraging and it proves that this is an improvement over traditional dig data analysis methods that uses unstructured data and deep learning for big data analysis when working on a very big dataset."
9338755,Time-controlled Regular Language Search over Encrypted Big Data,"The rapid development of cloud computing and the arrival of the big data era make the relationship between users and cloud closer. Cloud computing has powerful data computing and data storage capabilities, which can ubiquitously provide users with resources. However, users do not fully trust the cloud server's storage services, so lots of data is encrypted and uploaded to the cloud. Searchable encryption can protect the confidentiality of data and provide encrypted data retrieval functions. In this paper, we propose a time-controlled searchable encryption scheme with regular language over encrypted big data, which provides flexible search pattern and convenient data sharing. Our solution allows users with data's secret keys to generate trapdoors by themselves. And users without data's secret keys can generate trapdoors with the help of a trusted third party without revealing the data owner's secret key. Our system uses a time-controlled mechanism to collect keywords queried by users and ensures that the querying user's identity is not directly exposed. The obtained keywords are the basis for subsequent big data analysis. We conducted a security analysis of the proposed scheme and proved that the scheme is secure. The simulation experiment and comparison of our scheme show that the system has feasible efficiency."
9373665,English Multimedia Teaching Resources Integration System Based on Big Data Technology,"In the era of big data, the integration and development of English teaching resources is faced with the challenge of large amount, diversity and hidden value of resources and data. Under the new situation, multimedia teaching has great practical significance. This requires contemporary English teachers to master the requirements and basic operations of multimedia teaching and integrate modern information technology with English teaching methods. Advanced network technologies such as cloud computing must be applied to multimedia teaching resources in colleges and universities to solve the problems of security and hardware resources encountered in the integration process. In the face of the arrival of the big data era, English teachers should change their teaching concepts in time, actively adapt to the requirements of big data era for teachers and students, reasonably use network data resources to develop English teaching resources, and achieve English teaching objectives. This paper analyzes the characteristics and application of big data, expounds the difficulties in the process of English multimedia teaching resources integration, and expounds the ways of school education resources integration and transformation."
9010188,A LBS Method for Student Behavior Based on Hybrid Positioning by using big data Analyzation,"This topic is based on the hybrid positioning technology of Internet of Things wifi and satellite, researching the methods of big data collection, analysis and processing for students' behaviors in colleges and universities, and then using the classification statistics and logical reasoning to carry out artificial intelligence refining and pushing. The aim is to explore an accurate and real-time campus behavioral data system that is accessible to students, parents, and education management at all levels."
8709651,"Big Data, Smart Data in Effective Communication Strategies Development","The modern Digital Society is characterized by a high level of internet communications penetration in everyday life of any social object. The level of information noise is rising dramatically, and it tosses communication practitioners a challenge they have to cope with (Joseph Turow, Couldry, N.). The problem of communication hygiene is also reviewed in the article. Case studies of Big Data and Smart Data put forth as tools to formulate effective communication strategy in Digital Society communication pattern are represented."
9095872,Big Data Analytics in Healthcare,"Big data is a new area of computer science. The concept of big data gained momentum in the early 2000s. Big data is so large, complex and fast. Analytics is very much related to big data. It has the ability to provide useful acumen in healthcare. Big data nevertheless impending manifestation in its jurisprudence and assumption, similar as like diversity, celerity, honestly, and merit, exactness, fairness, and semantic illustration are of bigger anxiety in medical applications. Big Data has changed lead, explore data in many craft, especially in healthcare. The good news is we can use big data to change the healthcare industry. By using big data it is very much possible to make a better healthcare industry. Healthcare analytics can abate the treatment cost, foretell outbreaks of murrain, get off preventable illness also exaggerate the attribute of breath in ordinary. People live longer now than ever before. Nowadays doctors use new advance technology to predict patient's diseases. Among this article, we would like to clue the importance of big data in healthcare, big data analytics advantages in the healthcare system, big data applications and examples in healthcare, challenges of big data analytics. At the end, applying proficient and streamlined analytics to big data will set to swift and exact diagnosis, apposite treatment, abate charges, and elevated aggregate healthcare virtue."
9323615,A Machine Learning Approach for Data Quality Control of Earth Observation Data Management System,"In the big data era, innovative technologies like cloud computing, artificial intelligence, and machine learning are increasingly utilized in the large-scale data management systems of many industry sectors to make them more scalable and intelligent. Applying them to automate and optimize earth observation data management is a hot topic. To improve data quality control mechanisms, a machine learning method in combination with built-in quality rules is presented in this paper to evolve processes around data quality and enhance management of earth observation data. The rules of quality check are set up to detect the common issues, including data completeness, data latency, bad data, and data duplication, and the machine learning model is trained, tested, and deployed to address these quality issues automatically and reduce manual efforts."
9457469,Innovative Research and Exploration of Auditing under the Big Data,"With the advent of the information age, the development of big data has been accelerating, and the application of cloud computing in the auditing industry has also been increasing. This has had a huge impact on the development of our country's auditing industry and presented new challenges. How to use big data technology to conduct cloud audits, adapt to changes in the current environment, and reduce audit risks has become an urgent issue in the auditing community. Based on the background of big data, this paper studies the main difficulties faced by audit development, analyzes the causes of the problems, and finally proposes to use big data technology for cloud audi, innovate audit organization methods, focus on the training of audit talents, strengthen audit business training, hire expert consultants to improve audit quality, and optimize the staff structure, etc."
9432383,Visualization of Big Data with Augmented Reality,"In the current scenario, huge amount of data is produced every now and then. A large number of machines, devices and people are connected with each other through different communication frameworks. Since the data is huge in amount and takes a large storage space, it is named as big data. Such big amount data cannot be analyzed using the traditional methods of data analysis. Big data analysis needs new methods and approaches to handle their complexities. Numerous methods have been developed in the recent years to process this large amount of data. The data can be stored in cloud anytime and can also be retrieved from cloud anytime based on the requirements. As an alternative for data analysis and computing various attempts have been made using new tools. Augmented reality (AR) is an extended feature of virtual reality and it is helpful in visualizing huge amount of data obtained from heterogeneous sectors in a simpler manner. There are a few digitized tools available these days with the help of which process of visualization can be made faster. The scheme of convergence of both the tools (i.e., big data and AR) results in productive applications that are better than a few of existing technologies. This article provides a detailed study on big data, AR, and the utilities of big data using AR. Also, this research work has gone through the foreseeable future scopes and the main issues and challenges associated with AR based big data analysis."
9609322,Performance evaluation index system of provincial government information resources integration and sharing based on big data,"In recent years, with the rise of a new generation of information technology such as big data and cloud computing, as well as the growing demand for services from citizens, inefficiency, non-sharing and non-linkage in government management have gradually emerged. It is necessary to accelerate the institutional reform of government information construction to meet the development needs of modernization of government management. Sustainable management of government data resources is the primary task of government information governance in the era of big data, and is an important component of information environment governance for smart city construction. Combining relevant policy requirements and also drawing on the performance indicators of relevant government information platforms, this paper constructs an evaluation index system for the integration and sharing of government information systems, which helps clarify the content and scope of open sharing of government information resources and is important for improving the big data governance capability of government departments."
9258802,Research on Higher Vocational Teaching Quality Improvement Based on Educational Big Data,"The vigorous development of educational big data already has great potential to promote educational reform, which provides conditions and opportunities for the improvement of teaching quality. Education big data has the characteristics of real-time, multi-dimensionality, authenticity and so on. This paper analyzes the current problems in the teaching quality of higher vocational education, and with the continuous improvement of data mining and learning analysis technology, puts forward the path of educational big data to promote the quality of teaching."
9006520,Building the National Radio Recordings Database: A Big Data Approach to Documenting Audio Heritage,"This paper traces strategies used by the Radio Preservation Task Force of the Library of Congress's National Recording Preservation Board to develop a publicly searchable database documenting extant radio materials held by collecting institutions throughout the country. Having aggregated metadata on 2,500 unique collections to date, the project has encountered a series of logistical challenges that are not only technical in nature but also institutional and social, raising critical issues involving organizational structure, political representation, and the ethics of data access. As the project continues to expand and evolve, lessons from its early development offer valuable reminders of the human judgment, hidden labor, and interpersonal relations required for successful big data work."
9050241,Analysis on the Evaluation Model of the Teaching Effect of Innovation and Entrepreneurship Course Based on Big Data,"In order to improve that effect of the teaching of the innovation and start-up course, through the analysis of the effect of the teaching of the innovative start-up course, the quantitative evaluation of the effect on the teaching of the innovative start-up course is realized, and a method for evaluating the effect of the innovation and start-up course teaching based on the big data analysis is put forward. To analyze the problems and countermeasures of the teaching of the innovation and start-up course. a large-data statistical average analysis model of the effect of building an innovative entrepreneurship course teaching is constructed, a sample regression analysis method is combined to carry out the high-effect data analysis on the teaching of the innovative start-up course, and the decision-making objective function of the effect evaluation on the teaching of the innovative start-up course is constructed, The quantitative regression analysis of the effect of the innovative start-up course teaching is carried out by adopting the method of convergence rule evaluation, and the large-data feature extraction and the relevance description are carried out in combination with the descriptive statistical analysis result. The statistical feature of the effect of the innovative start-up course teaching is applied to the pattern recognition and feature selection by means of the average mutual information clustering method, and the effect evaluation of the innovation and start-up course teaching based on the big data analysis is realized. The simulation results show that the confidence level of the effect evaluation is high, and the evaluation result is accurate and reliable."
8644276,A Patient Oriented Framework using Big Data & C-means Clustering for Biomedical Engineering Applications,"Big data and Machine Learning have changed the healthcare research in recent years. Data generated from Electronic Health Records (EHRs) and other clinical sources now can be used further to help the patients. By applying Big Data Analytics (BDA) into healthcare data, it is possible to predict the outcome or the effects of drugs or risk of developing disease on human body. Several machine learning algorithms such as clustering, classification are used to analyze healthcare data. In this article, a framework is proposed using C-means Clustering for Biomedical Engineering applications. The framework can be used to help both the clinicians and the patients. For example, using this framework, a clinician can make a decision to prescribe suitable drug to a particular patient. In order to develop this framework, data has been collected from UCI machine learning repository. The data then analyzed using a well known big data framework Hadoop."
9057928,Rainfall Prediction Using Data Visualisation Techniques,"The volume of big data has opened up great opportunities for prediction and analysis of different aspects of weather. Data Visualisation is common in day to day life. Various charts and graphs are used to illustrate the practical approach towards the classification of rainfall with the help of data visualisation methods. Since it was impossible to analyze the large datasets earlier, the data visualisation techniques has made easier to plot the graphs for the better understanding of the weather. With the help of data visualisation patterns such as the highest, lowest and average rainfall in the States/Union Territories the weather of India has been visualised. In this paper, the rainfall pattern in the States/Union Territories of India was successfully visualised. The pattern identifies drought prone region in India, decrease in the annual rainfall over the century and heavy rainfall in the coastal regions of India."
9457477,Research on the Dilemma and Countermeasures of Employees' Right to Privacy Based on Big Data,"In the context of big data, while human resource management has obtained management optimization brought about by information technology, the issue of leakage and abuse of laborers' privacy has drawn more and more attention. Personal information of employees exists on the Internet in various forms of data during the process of collecting, storing and analyzing. Massive and diverse information is obtained through log files, web crawlers and other means. The original fragmented and non-sensitive information will be quickly identified after comprehensive analysis of data clustering, correlation analysis and cross-validation through data mining technology. More and even sensitive information will be quickly identified. Privacy authorization is becoming more and more formal, and the risk of privacy leakage caused by technical vulnerabilities is also increasing. The current dilemmas faced by employees' right to privacy include: unclear definitions of employees' right to privacy, lack of labor legislation, and high costs of information protection. Measures should be taken from labor legislation, industry self-discipline, employer self-management and employees' awareness of privacy protection to establish a healthy working environment and harmonious labor relations, and promote the sustainable and healthy development of the economy and society."
8750951,Implementing Big Data Lake for Heterogeneous Data Sources,"Modern connected cities are more and more leveraging advances in ICT to improve their services and the quality of life of their inhabitants. The data generated from different sources, such as environmental sensors, social networking platforms, traffic counters, are harnessed to achieve these end goals. However, collecting, integrating, and analyzing all the heterogeneous data sources available from the cities is a challenge. This article suggests a data lake approach built on Big Data technologies, to gather all the data together for further analysis. The platform, described here, enables data collection, storage, integration, and further analysis and visualization of the results. This solution is the first attempt to integrate a diverse set of data sources from four pilot cities as part of the CUTLER project (Coastal urban development through the lenses of resiliency). The design and implementation details, as well as usage scenarios are presented in this paper."
9730996,Research on Automatic Online Analysis Method of Data Hotness in Big Data Scenario,"With the development of Big Data technology, data volume has reached a massive level, and the types of data have become more complex, while the access characteristics of data by different applications vary widely, resulting in significant differences in the frequency of different data being accessed. In order to efficiently manage massive amounts of data, more and more data management and deployment systems are considering policies based on the hotness of data access. Therefore, how to define the hotness of data and extract the hotness of data online becomes a pressing problem nowadays. To address this problem, this paper proposes an online method to calculate data hotness, which takes into account both the creation time of data (called age in this paper) and the frequency of data access. In order to verify the above method, this paper focuses on the application scenario of Amazon product review data analysis. Through analyzing the review data on HDFS cluster, the universality of different hotness data distribution of HDFS cluster is verified, and it shows better advantages by comparing with other work."
9005450,Travel Pattern Extraction from Smart Card Data using Data Polishing,"With the development of ICT (Information and Communication Technology), interest in using the large amount of accumulated data for traffic policy planning has been increasing. In recent years, data polishing has been proposed as a new methodology for big data analysis. Data polishing is one of the graphical clustering methods. This method can be used to extract patterns that are similar or related to each other by clarifying the cluster structures in the data. The purpose of this study is to reveal travel patterns of railway passengers by applying data polishing to smart card data collected in Kagawa Prefecture, Japan. This study uses 9,008,709 data points collected during the 15 months from December 1st, 2013 to February 28th, 2015. This data set includes such information as trip histories and types of passengers. The study uses the data polishing method to cluster 4,667,520 combinations of information about individual rides: day of the week, time of day, passenger type, origin station, and destination station. As a result, 127 characteristic travel patterns were specified from those combinations."
8935759,A Comparative Study on Performance and Resource Utilization of Real-time Distributed Messaging Systems for Big Data,"In the past few years, data continuously increase and in various forms called Big Data. Besides, data analytics play an important role more and more in most organizations. From these reasons, many efficiently distributed messaging systems have been introducing to handle Big Data in real-time. However, choosing the appropriate and efficient methods and tools to transfer Big Data is still challenging. Therefore, this paper purposes of comparing the architecture, performance, and resource utilization between Apache Kafka which is one of the favorite tools for Big Data and Apache Pulsar which is similar to Kafka and become one of the latest tools for big data. After we implemented both systems in the same environment, the results show that Pulsar outperforms in throughput, latency, and average resource utilization especially when the size of messages is small (such as 1 KB and 1MB)."
9151596,Construction Status and Prospect of the China Fire Rescue Command Big Data Platform,"Improving the level of intelligent fire protection construction is an important issue facing the current Chinese emergency rescue department. Among them, the fire rescue command platform is an important part of the intelligent fire protection This paper analyzes the current situation of big data platform of fire rescue command in China from the aspects of its connotation, data collection method, data transmission method and multi-source data fusion. Taking the “3.21” explosion accident in Yancheng, Jiangsu Province as an example, the application of fire rescue command big data technology in the emergency rescue of the explosion accident was analyzed. Finally, two methods of software and hardware construction are used to forecast the next step of China's fire rescue command platform."
9377883,Integrating Polystore RDBMS with Common In-Memory Data,"A polystore system is composed of multiple heterogeneous databases which are used to store data that best suites its features for faster processing and querying. A single database does not fit all data formats, which has resulted in the development of a polystore system that leverages databases belonging to different categories such as relational, NoSQL, and NewSQL. Retrieving data from relational databases for analytics is a costly operation. This paper presents an extension to a polystore system which queries data from different relational databases using a standard in-memory data format for analytical queries with low latency."
9262490,Application of Artificial Intelligence and Big Data in Modern Financial Management,"This paper summarizes the related contents of artificial intelligence and big data, analyzes the development of financial field comprehensively, and presents the application of artificial intelligence and big data in the field of finance and taxation. This paper presents a risk estimation method of financial information management system in the context of big data. This method sets up logical nodes according to the system module, and builds a risk estimation model by looking for the logical relationship between the data. Based on the background of big data, the batch and flow calculation methods of big data are selected to calculate the system program risk index and financial data dishonesty risk index."
9421201,Research on Cloud Parking System Based on Big Data,"With the development of social networking, the focus of people's production and life has gradually shifted to the network. At the same time, the development of social economy is also showing high speed, people's living standards have also changed significantly. As an important means of transportation for people's daily travel, vehicles are more and more popular, and the number of vehicles in the city is also increasing. This phenomenon is particularly prominent in the first and second tier cities. The contradiction between the limited parking space and the sharp increase of vehicles is gradually highlighted. Based on the application research of big data technology in the parking system, the parking information is collected through a large number of parking data in the cloud, and then the data is classified and analyzed by using data mining algorithm. It can realize the reservation of parking and reasonable planning of routes, and provide scientific services for car owners according to the habits of car owners, so as to improve people's travel satisfaction to a greater extent."
8919530,Financial Quantitative Big Data Platform Based on High Performance Computing,"A big data platform to for financial quantitative data is designed and implemented on HPC system. Key technologies including data storage mechanism and distributed computing framework are resolved. Based on the platform, several important feature for financial quantitative strategy research is developed, which are indicator computing, large scale backtest and distributed hyperparameter tuning. Tests shows that the platform can achieve much higher performance than single PC program, and can be used to design strategy base on large scale financial data."
9006155,A Scalable Graph Analytics Framework for Programming with Big Data in R (pbdR),"Many disciplines such as biology, economics, engineering, physics, and the social sciences represent their data as graphs to capture patterns, trends, and associations. There are are many commercially available graph libraries in different programming languages to analyze these complex graphs. But there is no distributed graph library package in R - the popular statistical programming language to analyze graphs that bigger than a single machine's memory. Many domain experts prefer R over the numerous other alternatives. Towards this, we present a distributed graph analytics framework for R called programming with big graph using R (pBGR.) Our proposed framework leverages the Programming with Big Data in R (pbdR) ecosystem that provides scalable R packages for distributed computing in data science. We present an early prototype implementation of this framework using the distributed-memory parallel graph library CombBLAS and evaluate the framework's performance on leadership class computing platforms. Our experimental results demonstrate that the proposed framework is capable of performing large-scale parallel graph mining through the easyto-use R language. This enhanced graph processing capability coupled with other statistical tools already available in R, should be valuable to many domain experts."
9498798,The Application of Financial Analysis Based on the Perspective of Big Data,"Accounting is an important part of enterprise management, which has an important impact on enterprise operation. Financial work is the basis of business activities, and covers all aspects of enterprise operation. At present, the demand for accounting talents has changed. The original accounting personnel are not welcome by the market, while the accounting personnel with data editing are welcome by the market. For financial personnel, how to efficiently organize and analyze the financial data, and use the effective analysis results to help enterprises locate themselves and avoid potential risks, is the advanced requirement of financial analysts in the new era. Since 2014, big data technology has gradually gained the attention of government agencies, and government agencies pay more and more attention to the application of big data technology. In 2020, the central network information office of the national development and Reform Commission issued the notice on promoting the implementation plan for the new economic development of the action training of “using data to endow intelligence in the cloud”, and digitalization of enterprises has become an inevitable trend of development. Big data financial analysis is a set of specialized techniques and methods for collecting, preparing, analyzing and acting on the huge financial and business-related data inside and outside the organization. It is the product of the cross-border integration of accounting and information disciplines."
9378196,A Genetic Optimization Physical Planner for Big Data Warehouses,"Workload-driven approaches for partitioning and tuning traditional Parallel Database systems are well studied in the literature. Unfortunately, in the context of new generation ""Big Data"" warehouses, these approaches are not correctly adapted to Business Intelligence 2.0, where the analyst is at the heart of decision support systems. This ""disconnect"" situation strongly impacts both data partitioning and fragment allocation processes, which are essential to achieve good query performance. To overcome this problem, recent studies proposed online data partitioning and fragment allocation using AI techniques to improve query performance with adaptive behavior. Nevertheless, they have important limitations: they add significant overhead and they tend to focus on the current workload, ignoring query logs. With such motivation in mind, we first formulate the problem of optimizing database partitioning subject to feasibility constraints, based on a query workload. We then introduce a proactive partitioning approach combining offline and online processing phases, inspired by closed-loop control (used in engineering disciplines) and genetic algorithms (from AI). We present an experimental validation on a big data cluster that shows promising results on typical OLAP workloads."
9005613,Two-Stage Framework for Big Spatial Data Analytics to Support Disaster Response,"During disaster response, large volumes and diverse types of data sets are often continuously generated, and in many case these data sets create overwhelming burdens to data processing infrastructure and teams. At the same time, decision making during disaster response requires timely and relevant information which has to be extracted as expeditiously as possible from these large data sets. Therefore, processing of disaster related data sets is often time sensitive and requires coordination and prioritization. To accomplish this, we propose a two-stage approach to facilitate efficient and effective data processing for disaster decision support. In the first stage, a Data Envelope Analysis (DEA) model is introduced to model the articulation process about information needs such that providing a formal way of prioritizing data processing task. In the second stage, the prioritized data processing workflow is implemented on an Apache Storm based streaming processing platform in the EC2 cloud, with a focus on computational resource optimization. To validate the proposed approach, a Hurricane Sandy based use case was used to evaluate the performance of the proposed approach. Results show that our approach can compute up to 69% (three supervisor nodes) faster than a conventional serial processing approach."
9378222,Adaptive Lazy Compaction with High Stability and Low Latency for Data-Intensive Systems,"Data-intensive systems are typical applications in the big data era. Most data-intensive systems employ LSM (Log-Structured Merge)-tree-based key-value stores, such as RocksDB and LevelDB. The LSM-tree has a multi-level data structure and can transform random writes into sequential ones by a special operation called compaction. However, compaction operations are costly and will increase the processing latency and lower the throughput of the LSM-tree. In this paper, we propose an adaptive lazy compaction method called ALC for the LSM-tree. The main idea of ALC is to delay compactions operations when the current workload is high, and to perform compactions when the system is low-loaded. With this mechanism, we can lower the impact of compactions on the system's performance and achieve high stability and low latency. Our preliminary experiments show that ALC outperforms RocksDB and the state-of-the-art method SILK in latency and throughput-stability."
8561241,A Big Data Enabled Channel Model for 5G Wireless Communication Systems,"The standardization process of the fifth generation (5G) wireless communications has recently been accelerated and the first commercial 5G services would be provided as early as in 2018. The increasing of enormous smartphones, new complex scenarios, large frequency bands, massive antenna elements, and dense small cells will generate big datasets and bring 5G communications to the era of big data. This paper investigates various applications of big data analytics, especially machine learning algorithms in wireless communications and channel modeling. We propose a big data and machine learning enabled wireless channel model framework. The proposed channel model is based on artificial neural networks (ANNs), including feed-forward neural network (FNN) and radial basis function neural network (RBF-NN). The input parameters are transmitter (Tx) and receiver (Rx) coordinates, Tx-Rx distance, and carrier frequency, while the output parameters are channel statistical properties, including the received power, root mean square (RMS) delay spread (DS), and RMS angle spreads (ASs). Datasets used to train and test the ANNs are collected from both real channel measurements and a geometry based stochastic model (GBSM). Simulation results show good performance and indicate that machine learning algorithms can be powerful analytical tools for future measurement-based wireless channel modeling."
9389822,Analysis and discussion of component in the ecosphere of Hadoop from HuaWei’FusionInsight,"In the paper, based on the description of the key technologies and the facing problems of big data. Firstly, a special platform tools named FusionInsight for dealing with big data was introduced. Then, Focusing on the analysis and discussion of the core components of the platform FusionInsight Hadoop ecosphere in the composition and function. Finally, according to the process of large data analysis process from bottom to top, a detailed analysis and discussion on these components was given. So as to select a large data processing tools to provide a practical reference."
8713212,The Impact of Sentiment Analysis on Social Media to Assess Customer Satisfaction: Case of Rwanda,"Customer satisfaction is an essential area of the industry in this 21st century sometimes as known as the information age. However, the perception of customer expectation remains a problem in today's businesses. The internet has enabled people to spread out their thoughts through Social Media (SM) platforms, forums, news comments, and blogs. Consequently, those platforms are generating exponentially the immense amounts of data. The extraction of opinions from those big data can actively allow to rate organizations, learn the consumer needs, and adjust the business's strategies. This paper presents a concept of building a rating system, using Big Data Analytics (BDA) techniques, that apply the existing Sentiment Analysis (SA) algorithms to gain insight into reviews gathered from SM applications. The system will allow to list the various categories of services and evaluate them based on the obtained the customers' reactions. Also, this study aims to manage a large volume of information to rank the institutions and provide a practical solution for competitive, marketing analysis, and track the improvement of customer satisfaction within both the public and private sectors to boost the excellent service delivery in Rwanda."
9526772,Research on Data Preprocessing and 3D Matrix Model,"In order to overcome the problems existing in the current big data mining platform, this paper proposes a novel construction method of three-dimensional matrix model based on big data mining technology. This construction method uses the massive data mining function and massive data storage function provided by big data cloud platform, starting from the needs of users, in order to solve the problems existing in big data mining platform, for example, lack of scientific and efficient data model, lack of scientific and reasonable high-dimensional data association algorithm, dealing with the thorny problems of big data link, tedious and complex association rules, and so on. The construction method takes big data extended data mining technology as the center, combining data analysis technology, data extraction technology and so on. On this basis, based on the three-dimensional matrix model, the construction method completes the scientific and efficient preprocessing of data information from different sources. The research results show that this construction method can improve the efficiency and quality of association principle mining on the basis of massive high-dimensional data, and effectively alleviate the tedious and complex problem of association rules in the process of dealing with big data."
8713581,BIM Big Data Storage in WebVRGIS,"In the context of big data and the Internet of Things, with the advancement of geospatial data acquisition and retrieval, the volume of available geospatial data is increasing every minute. Thus, new data-management architecture is needed. We proposed a building information model (BIM) big data-storage-management solution with hybrid storage architecture based on web virtual reality geographical information system (WebVRGIS). BIM is associated with the integration of spatial and semantic information on the various stages of urban building. In this paper, based on the spatial distribution characteristics of BIM geospatial big data, a data storage and management model is proposed for BIM geospatial big data management. The architecture primarily includes Not only Structured Query Language (NoSQL) database and distributed peer-to-peer storage. The evaluation of the proposed storage method is conducted on the same software platform as our previous research about WebVR. The experimental results show that the hybrid storage architecture proposed in this research has a lower response time compared to the traditional relational database in geospatial big data searches. The integration and fusion of BIM big data in WebVRGIS realizes a revolutionary transformation of city information management during a full lifecycle. The system also has great promise for the storage of other geospatial big data, such as traffic data."
9210311,Toward stopping spread of coronavirus with the help of Big Data density Management,"At this hour, Coronavirus is a threat to our life and especially to our close family and the elderly person, who have more or less poor health, it will harm human beings and economics, so we have to find a method to limit the risk of this devastating virus and to discover a way to decrease its propagation. Our concern is to compute people density on many different locations of interest in the whole city with intention of dispatching people to different areas by avoiding as much as possible congestions. The support of using big data technologies is very crucial to process data with a fast manner and in real time. Today traditional database management tools is unable to manage the voluminous data generated by different system sources, that's why big data technologies will give us its support to manage this mass of data to extract crucial information from this enormous data, and without big data technologies, the process turn out very difficult to control. In the present paper, we first propose a method that will calculate densities of people in different city's places in real time, this will allow us to prevent people locations to avoid where there are congestions and reorient them to another lightened safe locations. And then we will store in a database all human contacts that have taken place to warn people who have been in contact or who have been close to the contaminated ones."
9523902,Villagers' Individual Organization Mode Based on Transition Model Based on Artificial Intelligence and Big Data,"In order to explore the path of villagers' individual organization mode in the “excited state-action state” model, and to provide new development ideas for the path of rural governance, this paper puts forward villagers' individual organization mode based on transition model based on artificial intelligence and big data. The mode starts from three dimensions, namely the individualization of the concept of service concept, the organization of public participation and the legalization of organization. Based on this, the mode gives full play to the mining role of big data technology, mining villagers' self-organization intention from multiple dimensions, including personal psychology, personal behavior and personal cognition. In addition, the mode also gives full play to the interaction of artificial intelligence, strengthens the communication and exchange between villagers, and improves the enthusiasm of villagers to participate in public governance activities. The results show that through the mode, villagers have the ability to participate in rural public governance activities, form organizational identity within the organization, and also have the ability to become the bearer and propagandist of public service concept."
8969446,Research on Mobile User Behavior Mining Model Based on Big Data,"With the development of mobile Internet, the research of mobile user behavior based on big data has become one of the hotspots in the field of mobile Internet. Based on the analysis of the characteristics of mobile user's big data and Hadoop system, an analysis model of mobile user's behavior pattern based on big data is constructed, it includes data acquisition module, data preprocessing module, user behavior analysis module, application of mobile user behavior model and data visualization module, and the function of each module is explained in detail. Recommendation algorithm based on user behavior analysis is discussed at last."
8789667,A Survey on Big Data for Network Traffic Monitoring and Analysis,"Network Traffic Monitoring and Analysis (NTMA) represents a key component for network management, especially to guarantee the correct operation of large-scale networks such as the Internet. As the complexity of Internet services and the volume of traffic continue to increase, it becomes difficult to design scalable NTMA applications. Applications such as traffic classification and policing require real-time and scalable approaches. Anomaly detection and security mechanisms require to quickly identify and react to unpredictable events while processing millions of heterogeneous events. At last, the system has to collect, store, and process massive sets of historical data for post-mortem analysis. Those are precisely the challenges faced by general big data approaches: Volume, Velocity, Variety, and Veracity. This survey brings together NTMA and big data. We catalog previous work on NTMA that adopt big data approaches to understand to what extent the potential of big data is being explored in NTMA. This survey mainly focuses on approaches and technologies to manage the big NTMA data, additionally briefly discussing big data analytics (e.g., machine learning) for the sake of NTMA. Finally, we provide guidelines for future work, discussing lessons learned, and research directions."
9636961,Research on Data Classification of Intelligent Connected Vehicles Based on Scenarios,"The intelligent connected vehicle industry has entered a period of opportunity, industry data is accumulating rapidly, and the formulation of industry standards to regulate big data management and application is imminent. As the basis of data security, data classification has received unprecedented attention. By combing through the research and development status of data classification in various industries, this article combines industry characteristics and re-examines the framework of industry data classification from the aspects of information security and data assetization, and tries to find the balance point between data security and data value. The intelligent networked automobile industry provides support for big data applications, this article combines the characteristics of the connected vehicle industry, re-examines the data characteristics of the intelligent connected vehicle industry from the 2 aspects as information security and data assetization, and eventually proposes a scene-based hierarchical framework. The framework includes the complete classification process, model, and quantifiable parameters, which provides a solution and theoretical endorsement for the construction of a big data automatic classification system for the intelligent connected vehicle industry and safe data open applications."
8245861,MemepiC: Towards a Unified In-Memory Big Data Management System,"In-memory data management systems have recently gained a lot of attraction due to cheaper and faster DRAM and other hardware advancement. However, these systems are either pure storage systems with online data query service, or just offline batch processing systems with data analytics functionality. Heavy data movement (e.g., data loading) occurs in order to analyze the data. In this paper, we propose an innovative in-memory data management system-MemepiC, which unifies both online data query and data analytics functionality, allowing low-latency storage service and efficient in-situ data analytics. We also explore the emerging RDMA technique in the context of in-memory data management systems, by designing an RDMA-based communication protocol for message delivery inside MemepiC, and proposing to overlap execution and RDMA communication. Extensive experiments are conducted to show the superior performance of MemepiC in terms of both the storage and the data analytics services, compared against other in-memory systems."
9384641,Research on Innovation-Profession Integration Skills Compass Design under Big Data,"The advent of the big data era has brought about radical changes in all aspects of society. In this paper, theoretical system for the investigation and evaluation of entrepreneurial talents' abilities in the innovation-profession integration education is studied by big data. Focusing on the analysis of the existing difficulties in the lack of top-level design in innovation-profession education, this paper puts forward a skills compass model of innovation-profession skills based on big data technology to provide research value for the establishment of entrepreneurial talent training and evaluation system."
9237653,Application Methodology of Big Data for Emergency Management,"Based on operational requirements of emergency management (EM), and combing the overall planning of big data system for EM with safety science theories, a set of methods for applying big data in EM are extracted. The feasibility of those methods is further verified using the safety risk monitoring and early warning system of hazardous chemicals set up by the Ministry of Emergency Management, PRC. Results show that those methods are reproducible and generalizable, through which big data technology can be widely applied in the construction of operational applications in various EM industries."
9213593,A Standard Architecture of Agricultural Big Data for Deep Learning,"Agricultural big data has become a key resource for the development of modern agriculture, and has occupied an important role in the field of agricultural scientific and technological innovation. With the development of deep learning in recent years, we can effectively improve agricultural production efficiency by existing agricultural data sets to build deep learning algorithm models. There are new ideas to explore the standard architecture of agricultural big data. By formulating standard and standardizing agricultural data process, we established a standard architecture of agricultural big data for deep learning. The result can promote the implementation of deep learning application, and support standardization of technological achievements transformation in agricultural big data."
9142529,Research on the Algorithm of Education Data Mining Based on Big Data,"In recent years,research on Educational Data Mining (EDM) has developed rapidly. However, most researches focus on data source issues, and ignore the importance of data preprocessing and data mining algorithms. This paper has studied EDM, with a special focus on educational big data mining algorithms. Firstly, it analyzed the relevant elements of EDM and introduces big data technology based on the requirements of educational data application. Then it introduced the common educational big data mining algorithms and their applications, and finally discussed the development trend of educational big data mining algorithms."
9545918,Summary of Data Mining and Analysis of Launch Vehicle Test Based on Small Sample Learning Method,"The data generated by the launch vehicle test launch system has the characteristics of big data and small samples. Using small sample learning to start from a small amount of faulty data, and learning and processing sample data through data enhancement and metric learning strategies can greatly improve the effect of data mining. In view of the current situation that the deep learning method in the launch vehicle test system has not been used on a large scale, the characteristics of the data generated by the launch vehicle test launch are analyzed, and the method of small sample learning based on the deep neural network is combined with the data analysis of the launch vehicle test. And expounded the potential value and significance of this method to the development of launch vehicle test system."
8478347,Cost-Effective Cloud Server Provisioning for Predictable Performance of Big Data Analytics,"Cloud datacenters are underutilized due to server over-provisioning. To increase datacenter utilization, cloud providers offer users an option to run workloads such as big data analytics on the underutilized resources, in the form of cheap yet revocable transient servers (e.g., EC2 spot instances, GCE preemptible instances). Though at highly reduced prices, deploying big data analytics on the unstable cloud transient servers can severely degrade the job performance due to instance revocations. To tackle this issue, this paper proposes iSpot, a cost-effective transient server provisioning framework for achieving predictable performance in the cloud, by focusing on Spark as a representative Directed Acyclic Graph (DAG)-style big data analytics workload. It first identifies the stable cloud transient servers during the job execution by devising an accurate Long Short-Term Memory (LSTM)-based price prediction method. Leveraging automatic job profiling and the acquired DAG information of stages, we further build an analytical performance model and present a lightweight critical data checkpointing mechanism for Spark, to enable our design of iSpot provisioning strategy for guaranteeing the job performance on stable transient servers. Extensive prototype experiments on both EC2 spot instances and GCE preemptible instances demonstrate that, iSpot is able to guarantee the performance of big data analytics running on cloud transient servers while reducing the job budget by up to 83.8 percent in comparison to the state-of-the-art server provisioning strategies, yet with acceptable runtime overhead."
9567229,ENIAD: A Reconfigurable Near-data Processing Architecture for Web-Scale AI-enriched Big Data Service,"To meet the surging demands required by AI-enriched Big Data services, cloud vendors are turning toward domain specific accelerators for improved efficiency, scalability and performance. ENIAD, the first end-to-end infrastructure for AI-enriched Big Data serving in real time, accelerates both deep neural network inferencing and billion-scale indexing at the data-center scale. Exploiting near- data computation, reconfigurable computing and rapid/agile hardware deployment flow, ENIAD serves state-of-the-art, online built indexing service with high efficiency at low batch sizes. A high-performance, index (data)-adaptable FPGA soft processor is at the heart of the system and able to serve 10x larger index size with 14x lower latency compared to state-of-the-art CPU and GPU architectures."
8912122,Research on Prediction of Dynamic Load Complementarity Based on Big Data,"To solve the problem of unstable prediction results of traditional power load forecasting methods, a power dynamic load complementary coefficient forecasting method based on big data technology is proposed. The prediction method is mainly divided into the following four parts. The data caliber and density are collected to determine the reasonable data range. Then, according to the big data technology, the curve function of charge movement is calculated to calculate the complementary coefficient, and the complementary coefficient is combined to complete the prediction. The experimental results show that the power dynamic load complementarity coefficient prediction method based on big data technology proposed for the traditional charge prediction method is more stable, so this method is more effective."
9317292,Managing Big Data using Model Driven Engineering: From Big Data Meta-model to Cloudera PSM meta-model,"In the era of Big Data, all our actions generate digital traces. A huge amount of data is generated daily. They are extremely related to personal life and they can be exploited in different fields. There is also internally generated data known as offline data that is created by the operations of organizations. The processing of this big data plays a key role in decision making. After the definition of generic meta-model in previous work for the processing layer. This paper presents a shift from the generic processing layer meta-model within Big Data (PIM) to a processing layer meta-model for the Cloudera distribution (PSM) through the use of the ATL transformation language. The result of the ATL transformation represents the PSM (Platform-Specific Models) according to the architecture of the MDA."
9497187,Towards Improved Data Analytics Through Usability Enhancement of Unstructured Big Data,"A high volume of unstructured data is being generated from diverse and heterogeneous sources. The unstructured data analytics process is used to extract valuable insights from these unstructured data sources but unlocking useful and usable information is critical for analytics. Despite advancements in technologies, data preparation requires an inordinate amount of time in unstructured data manipulation into a usable form. Although several data manipulation and preparation techniques have been proposed for unstructured big data, relatively limited research has addressed the usability issues of unstructured data. This study identifies the usability issues of unstructured big data for the analytical process to bridge the identified gap. The usability enhancement model has been proposed for unstructured big data to facilitate the subjective and objective efficacy of unstructured big data for data preparation and manipulation activities. Moreover, concept mapping is an essential element to improve the usability of unstructured big data incorporated in the proposed model with usability rules. These rules reduce the usability gap between data availability and its usefulness for an intended purpose. The proposed research model will help to improve the efficiency of unstructured big data analytics."
9633473,Visualization Analysis of Meteorological Big Data through Deep Learning and Network Model,"With the continuous progress of meteorological data observation technology, meteorological data showed explosive growth, which brought new opportunities and challenges to the development of meteorological forecasting technology. In view of the complexity of multidimensional visualization analysis of meteorological big data resources, the business object model, visual analysis dimension and visual monitoring index of meteorological big data resources are constructed. In this paper, RBM, CNN and network model based on long and short memory are used to predict the refined temperature in the next 24 hours, and the prediction results of the models are compared and analyzed. The results show that compared with traditional RBM, the deep learning algorithm model can show good prediction ability and can be used as a common structure for refined temperature prediction."
9109941,Research on the Impact of Active Finance on Household Consumption Based on Big Data Analysis,"Under the influence of slowing economic growth and other factors, the growth rate of China's household consumption has been declining. Fiscal and taxation policies are an important means of regulating residents 'income. Levying more taxes and fees on links with lower production efficiency will increase residents' actual income and have a positive impact on the consumer market. How to judge the level of production efficiency has long been the subject of controversy in the economic field. Based on the data of all 30 provinces, this article uses the return on investment as the main basis for judging production efficiency. Based on the analysis of consumer demand, this paper proposes specific ways to optimize fiscal and taxation policies. Measures such as reducing the tax of small and medium-sized enterprises and increasing the threshold for individual taxes should be adopted to increase the actual income of residents, which will help promote the growth of residents' consumption"
9378448,Automated Indexing of Structured Scientific Metadata Using Apache Solr,"Scientific datasets are continuously growing with the amount of raw data being collected worldwide. This amount of data poses the biggest challenge to web search engines on how to retrieve them efficiently. This paper discusses how major scientific data centers are using popular open-source search platforms such as Solr [1] to retrieve structured data stored in data sources such as relational database management systems using its import handler mechanisms [2]. Additionally, we will also focus on how we can configure Solr to serve advanced full-text, faceted search capabilities, along with its key features, which simplify representing and delivering better performance to the scientific search interfaces."
9110099,"Subglacial Lakes, Drainage Pathways and Basins Beneath the Antarctic Ice Sheet Based on the Remote Sensing Big Data","Antarctic subglacial lakes which form an important component of the subglacial hydrological system have the potential to study the history of the ice sheet and the global climate change. In order to detect the potential subglacial lakes beneath the Antarctic ice sheet. A dynamic threshold filtering algorithm has been applied on the CryoSat-2 satellite altimetry remote sensing data to derive the Antarctic potential subglacial lakes including the quantities, areas as well as drainage pathways. And we have compared the difference of the experimental results obtained by CryoSat-2 and Bedmap2 datasets. Our results show the superiority by using the CryoSat-2 data, which have filled the gap in the central area of the Antarctic. Besides CryoSat-2 Altimetry data can generate a rather accurate DEM of the Antarctic ice sheet by this algorithm. As a result, we have detected many more lakes covering about 3% of the total bed of Antarctic than were observed before. There are some direct hydrological connections between a large number of subglacial lakes beneath the Antarctic ice sheet."
9373621,Problems and Reform Ideas in Law Theory Teaching in Universities Based on Big Data Analysis,"As an important part of the development of science and technology, big data analysis has been applied in many fields. While big data analysis has brought revolutionary influence to the legal industry, universities, as the primary source of legal talents, will inevitably bring invisible pressure to the traditional law teaching. In order to change this situation, we can reform the legal theory education from the aspects of law teaching mode, teaching system and talent training to adapt to the new mode of law education in the big data environment. The teaching research of law theory in universities under big data analysis not only increases the mode of law education, but also expands the development space of law theory teaching. Big data analysis will play an important role in the improvement of legal education, which will make it possible to realize the fairness of education and cultivate more excellent legal talents needed in the new era. According to the survey results, the learning effect of big data analysis on legal professional knowledge has been slightly improved by 31.13%, and the number of people who use websites to query relevant knowledge is as high as 85.71%. Aiming at the problems in law teaching process, this paper explores the reform of law theory teaching mode under the background of big data analysis."
9115119,Study on Stocks Based on Big Data Methods and Computer Programs,"Recently big data is a hot topic in many fields. Here we use distributed algorithms to treat big data in Chinese stock market. First the two stock indexes (Shanghai Composite and Shenzhen Composite indexes) from 1990-2019 are collected. Then the data are divided to several subsets and are analyzed separately via computer programs. Finally the results for every subset are combined due to distributed algorithms theory. In addition to big data scheme, we adopt stochastic processes theory and moment equations methods."
9592506,From Big Data to Smart Data-centric Software Architectures for City Analytics: the case of the PELL Smart City Platform,"Applications of Big Data to smart cities are nearly limitless. However, challenges emerged with handling data with new magnitude of dimensionality, heterogeneity, required processing timeliness, and the lack of reported development experiences on how to turn Big Data into Smart Data may hinder the adoption of Big Data technologies in delivering smarter city services.This paper reports our experience in developing a Smart Big Data-centric software platform for tracking city performance. Here we examine how to design such a platform by exploiting architectural styles and open source technology for Big data management. We describe the actual development of an instance of it, the PELL Smart City Platform, for processing and managing urban data in the domain of public lighting. In particular, we focus on the formulation and evaluation of key performance indicators related to energy consumption to derive Smart Data from Big Data in the context of public street lighting."
9137501,Processing of Airport Passenger Flow Abnormal Data Based on K Nearest Neighbor,"The big data accumulated during the operation of the airport has important research value. However, these data often have the characteristics of clutter, redundancy, incompleteness, and noise, and cannot be used directly. The original data needs to be pre-processed. This paper designs an interpolation algorithm based on K nearest neighbors (KNN), which is used to solve the passenger flow statistical error caused by abnormal time data of passenger check-in, and the feasibility of the method is verified by experiments. Experimental results show that this method can effectively solve the problem of abnormal passenger flow data."
9150241,Causes for Personal Information Disclosure of College Students in the Big Data Age,"With the advent of the big data age, college students are enjoying the convenience of digitalization, but meanwhile suffering from risks of personal information disclosure. This survey investigates the reasons of personal information leakage of college students through questionnaires. The survey results show that there is a general situation of personal information leakage among College Students. And the reasons for the personal information leakage of college students are various. It is necessary to effectively improve the information security management ability of college students."
9362621,Computer network security countermeasures based on big data,"With the rapid development of science and technology in China, high-tech information technology is constantly developing and exploring, and is widely used in human work and life. Among them, computer technology based on big data is more representative. Big data technology is a technology of searching and analyzing collected information, which can solve many problems. Nowadays, big data technology plays an important role in construction, finance, trade and other fields. The increasingly innovative social demand puts forward new challenges to the development and application of computers, as well as new requirements for computer users. Network security is the basis of good application of computer technology. At the same time, “the wind of big data” also leads to many security problems. In view of the problems existing in the computer network in the era of big data, this paper studies how to effectively solve these problems, and uses data encryption technology to prevent them. The experimental results show that the data encryption technology can be effectively applied in the field of computer network security protection, and the accuracy rate of data information is as high as 95.3%. Hope to provide some help to the staff and users in related fields."
9671297,Random Sample Partition-Based Clustering Ensemble Algorithm for Big Data,"A novel random sample partition-based clustering ensemble (RSP-CE) algorithm is proposed in this paper to handle the big data clustering problems. There are three key components in RSP-CE algorithm, i.e., generating the base clustering results on RSP data blocks, harmonizing the based clustering results with maximum mean discrepancy (MMD) criterion, and refining the RSP clustering results. RSP data blocks have the consistent sample distributions with the whole big data and thus provide the possibility for using base clustering results on different data subsets to approximate the clustering result on whole big data. The experimental results in comparison with other 5 well-known clustering ensemble algorithms on 4 big data sets show that RSP-CE algorithm obtains the better normalized mutual information (NMI) values and Fowlkes-Mallows Index (FMI) values with the less training time consumptions and thus demonstrate that RSP-CE algorithm is a viable approach to deal with the big data clustering problems."
9202050,Research on network advertisement precise delivery system based on big data technology,"The emergence of big data technology makes the dissemination of online advertising not only rely on design and media, but firmly combine data, users, platforms, businesses and even industries, so as to promote the continuous update and development of the advertising industry towards the direction of information and technology. This paper constructs an accurate online advertising delivery system based on big data technology, analyzes the core issues of online advertising delivery under the technology of big data, and expounds the connection between media, data, users and platforms, as well as the realization logic of accurate online advertising delivery, so as to provide reference for relevant researches on online advertising delivery."
7949053,Survey on Improving Data Utility in Differentially Private Sequential Data Publishing,"The massive generation, extensive sharing, and deep exploitation of data in the big data era have raised unprecedented privacy threats. To address privacy concerns, various privacy paradigms have been proposed to achieve a good tradeoff between privacy and data utility. Particularly, differential privacy has been well accepted as one of the de facto standard for privacy preservation, and numerous schemes guaranteeing differential privacy have been proposed. Nonetheless, most of the existing works claiming a superior utility-privacy tradeoff only present specific methods, with distinct perspectives, and a complete comparative analysis and evaluation study has not been fully investigated. To this end, in this paper we review and investigate existing schemes on providing differential privacy from a broad and encompassing perspective to provide a comprehensive survey with respect to both the privacy guarantee and the effectiveness and efficiency in utility improvement. We categorize the existing schemes into distribution optimization, sensitivity calibration, transformation, decomposition, and correlations exploitation, based on their mechanisms in improving data utility. We also conduct some analysis and comparison of their various concepts and principles, focusing on improvements to data utility. Finally, we outline some challenges and provide future research directions."
9526831,Research on Delivered Logistics Management Information System Based on Big Data,"The delivery logistics management information system is an intelligent platform for express delivery industry supervisory departments to realize real-time monitoring of express delivery data. The major functions of using big data technology include four major functions: data management, data intelligence investigation, data statistical analysis, and security management area. This article is based on the construction of a logistics management system for delivering large data, and describes the process from requirements analysis, system design to implementation. Based on the basic introduction of big data and the analysis of the express delivery industry and express delivery system, the project that we strive to complete is a delivery logistics supervision system that uses big data technology and is targeted at the express delivery industry supervisors and can conduct intelligent analysis. This approach has more practical significance than the system based on the express delivery industry itself."
9352376,Research on Data Acquisition System of Electric Heat Storage Boiler Supporting Big Data,"With the rapid development of big data technology, new requirements are put forward for data acquisition of electric heat storage boiler, especially for the function completeness, networking flexibility, system stability and maintainability of the data acquisition system rise to a new height, so it is necessary to carry out a new design for the data acquisition system. The functional modules of the system are constructed through modularization, including system configuration software module, communication management module, database management module and man-machine access interface module, and each module is designed and verified. The expected effect is achieved as a whole and integrated into the ecosystem of big data."
9563406,The Research and Application of the Improved Prediction Model for Big Data,"With the development of big data technology, the application of data fusion in different disciplines and fields is the hot spot of big data research and application in the future, and more industries are facing the problem of massive data prediction. In this paper, a new improved prediction model is proposed. In the prediction process, PCA algorithm is used to process the data. Gaussian process regression model is used to fit the basic prediction data and residual series. The residual series modified by BP neural network is combined with the basic prediction data to obtain the prediction results. Compared with the single model, this model is more applicable and accurate."
9523962,Safety Monitoring Platform for Deep Excavation Based on BIM and Big Data Technology,"In order to overcome the monitoring problems and difficulties in the process of deep excavation construction, this paper proposes a new safety monitoring platform for deep excavation based on BIM and big data technology. The platform is based on BIM model of visual security monitoring web platform, building a lightweight model. Based on this, the platform is also combined with big data technology, which can visualize the data information of Egypt, collect and analyze the monitoring data. In addition, the platform can control and sort out the real-time input and real-time storage data information. The result of this experiment shows that combined with engineering examples, the platform meets the needs of rapid processing and feedback of deep foundation pit monitoring data, and intuitively reflects the overall picture of the safety risk points of foundation pit engineering, allowing different parties to handle online and offline inspections, thereby improving work efficiency and information sharing, it has reference significance for the BIM application of deep foundation pit engineering."
9470332,Thinking of College Students' innovation and Entrepreneurship Education under the background of big data,"In order to solve the problem of insufficient effectiveness of traditional college students' innovation and entrepreneurship education, this paper proposes a new method of College Students' innovation and Entrepreneurship Education under the background of big data. In order to achieve more effective innovation and entrepreneurship education of College Students under the background of big data, K-means clustering method is needed to deeply mine the innovation and entrepreneurship data of college students. Mining more accurate entrepreneurial data of college students, based on the above mining entrepreneurial data of college students as the basis of index construction, the maximum eigenvalue of College Students' entrepreneurial risk evaluation index is calculated, and the consistency test of evaluation index is completed according to the calculation results. According to the test results, calculate the correlation degree of College Students' entrepreneurial risk evaluation index, screen out the evaluation index of College Students' entrepreneurial risk, and construct the evaluation function of College Students' entrepreneurial risk according to the evaluation index. The experimental results show that, compared with the traditional methods, the proposed method can achieve higher accuracy of data mining for college students' entrepreneurship, and the risk evaluation results are more accurate."
8862913,A Survey on Data Collection for Machine Learning: A Big Data - AI Integration Perspective,"Data collection is a major bottleneck in machine learning and an active research topic in multiple communities. There are largely two reasons data collection has recently become a critical issue. First, as machine learning is becoming more widely-used, we are seeing new applications that do not necessarily have enough labeled data. Second, unlike traditional machine learning, deep learning techniques automatically generate features, which saves feature engineering costs, but in return may require larger amounts of labeled data. Interestingly, recent research in data collection comes not only from the machine learning, natural language, and computer vision communities, but also from the data management community due to the importance of handling large amounts of data. In this survey, we perform a comprehensive study of data collection from a data management point of view. Data collection largely consists of data acquisition, data labeling, and improvement of existing data or models. We provide a research landscape of these operations, provide guidelines on which technique to use when, and identify interesting research challenges. The integration of machine learning and data management for data collection is part of a larger trend of Big data and Artificial Intelligence (AI) integration and opens many opportunities for new research."
9360997,Research on Chinese Translation of Multivariate English Passive Structure Based on Big Data,"The passive phenomenon is a common phenomenon in English language structure and Chinese language structure. Although both of them are called passive phenomena, there are some differences in expression between them. This article analyzes the content of the ""English-Chinese Parallel Corpus"" of a school from the multivariate perspective of big data, and deeply studies the characteristics and forms of passive structure. The author discovered the linguistic features in the passive structure of the original English language and some influencing factors that may be ignored by the translator during the translation process. This article hopes to provide some help to future English translators."
9101345,The Real-time Big Data Processing Method Based on LSTM for the Intelligent Workshop Production Process,"With the wide application of intelligent sensors and the Internet of things in the intelligent workshop, a large number of real-time production data are collected. Accurate analysis of the collected data can help producers to make effective decisions. Compared with the traditional data processing methods, artificial intelligence, the main method of big data analysis, has been applied in the manufacturing industry increasingly. However, it is different for Artificial Intelligence models to process real-time data from intelligent workshop production. Thus, this paper proposes a real-time big data processing method based on long short term memory (LSTM) for the workshop production process. This method takes the historical production data extracted by the Internet of things workshop as the original data set, preprocesses the data, and uses the LSTM model to train and predict the real-time data of the workshop. Finally, the experimental results are compared with K-NearestNeighbor (KNN), Decision Tree (DT) and traditional neural network model. The results show that the prediction accuracy of the LSTM model is 126.9%, 21.1%, and 14.7% higher than that of the traditional neural network, KNN, and DT respectively."
9148146,Analysis on the Impact of Information Network on the Sustainability of Poverty Alleviation in Ethnic Minority Areas in the Era of Big Data,"With the advent of the era of big data and the continuous development of information technology, the Internet, the Internet of Things, and cloud technologies came into being. The continuous development of information technology has brought many conveniences to people's lives.2020 is the year to end poverty alleviation and an important period to eradicate absolute poverty. Minority areas are regions with deeper poverty levels and face severe work tasks. It is even more necessary to build up enthusiasm, win the fight against poverty, and consolidate the results of the fight against poverty. Facing the new situation and fighting poverty require new strategic measures, and the application of information technology has played a huge role."
8657115,Prospects For Using Big Data To Improve The Effectiveness Of An Education Organization,"Today, teaching methods have changed significantly. With new innovations in the field of information technology, work in the classroom becomes virtual, and cloud knowledge. Although these new technologies have been adopted in the field of education, the informative organizations still face the challenge of improving the quality of education and reducing dropout rates. This article will examine the analysis of big data that can be used in education and how it affects the improvement of the quality of education."
9532708,Design and Implementation of Tourism Big Data Analysis Platform,"Since the advent of the Internet, the main parts of tourism information processing and transaction are processed by electronic means. Therefore, on the Internet, there will be many electronic traces of tourists related to tourism, including tourism decision-making, tourism process and tourism feedback. In recent years, many scholars in China have carried out some theoretical studies on the suitability of national park recreation and ecotourism, recreation planning and recreation management mechanism. However, the literature on the concept, classification and structural elements of recreation space is still insufficient. The traditional way of data collection and collation is far from meeting the requirements of big data. The urgent task is to upgrade and optimize the existing system and database."
8965572,Open-Source Big Data Analytics Architecture for Businesses,"Unaware of existing big data technologies, organizations fail to develop a big data capability despite its disruptive impact on today's competitive business environment. To determine the shortcomings and strengths of developing a big data architecture with open-source tools from technical and managerial perspectives, this study (1) systematically reviews the available open-source big data technologies to present a comprehensive picture, and (2) proposes an open-source architecture for businesses to take as a reference while developing big data analytics capabilities. Lastly, we discuss technical, domain-specific, and firm-specific soft challenges related to establishing a big data architecture in an organization, and how these challenges are reshaping the big data research domain."
8805981,Research on Kindergarten Science Field Teaching Based on Big Data Analysis,"With the rapid development of information and communication technology, human society began to enter the era of big data. We can perceive and record more large-scale and diverse data through the analysis and processing of these data. We can deeply excavate the intrinsic information and core values contained therein through big data. Big data is becoming a powerful driving force to promote organizational innovation, industrial upgrading and economic development. It has strong application needs and broad application prospects in many fields of modern society. Among them, the field of education is considered as an important application area of big data. Firstly, this paper analyses the function mechanism of big data and kindergarten science field teaching. Then, this paper analyses the current situation of science teaching in rural kindergartens. Finally, some suggestions are put forward for kindergarten science teaching."
9103885,Research on Situation Awareness of Universities’ Network Information Security in the Big Data Environment,"Recently network threats faced by universities are constantly escalating, and the traditional means of protection have been unable to meet the current network information security situation. Big data technology can integrate massive logs data and analyze network security risks in real time, so as to implement functions such as network assets management, massive logs management, security events analysis, attack events tracing, dangerous events warning, and security situation awareness, and consequently building up a comprehensive network information security system to provide decision support for network information security in universities."
8350301,A Searchable and Verifiable Data Protection Scheme for Scholarly Big Data,"Scientific research achievements play a positive role in the promotion of social development. Scholarly big data include scholars' scientific research, experimental data, and their own identity information. The security of scholarly big data relates to the authors' reputation and the copyright of their works. This paper proposes a trusted third-party-aided searchable and verifiable data protection scheme that utilizes cloud computing technology. For a better description of the the protocol, we first present a user-differentiated system model and a cube data storage structure. On the basis of the novel system model and data structure, the scheme helps the users review the integrity of their uploaded or downloaded data at any time and search the online scholarly data with encrypted keywords. The security analysis and performance simulation demonstrate that the novel scheme is a secure and efficient scheme for scholarly big data applications."
9221056,An Algorithmic Solution for Storing Big Data on the DNA Sequence,"The Storing Big Data on the DNA Sequence is an important aspect of Data Science Research, yet there is a need for entirely new, scalable approaches and methodologies for storing Big Data on the DNA Sequence. This can ultimately provide more insight into the structure and function of this complex storing. To explain more, we need to find a methodology to develop a solution to storing information on the DNA. Despite the expanding significance of investigating and extensively of storing Big Data on the DNA Sequence, the traditional way of storing on the DNA has difficulties scaling up and typically ends up these to stop researching in this area. We will use every single letter (ACGT) [5] of the DNA to storing one letter of the Big Data in the order. The contribution of ""An Algorithmic Solution for Storing Big Data on the DNA Sequence"" is to obtain a larger space for storage instead of the traditional means of storage. The traditional methods of storage work on a mechanical basis, which is expensive. If hard disk crashes, the computer will not work, you lose your work. Another disadvantage that the old technology that we use it to storage data is so slow. [1]. As well as the electronic storage (e.g. Solid-state drive) which has a short Lifespan, Storage (limited storage space) and so on. Oppositely, the limitations in the other approaches that there is no more explanation of how they store data in the DNA (no explain how information is stored in the DNA). [15]."
8836982,Big Data Driven Smart Agriculture: Pathway for Sustainable Development,"Increasing agricultural production is top most solution in the face of rapid population growth through digitalization of agriculture by using most developed technology like big data. There is a long debate on the application of big data in agriculture. This study is an attempt to explore the suitability of the big data technologies for increasing production and improving quality in agriculture. The study uses an extensive review of current research works and studies in agriculture for exploring the best and compatible practices which can help farmers at field level for increasing production and improving quality. This study reveals a number of available big data technologies and practices in agriculture for solving the current problems and challenges at field level. A conceptual model is developed for proper implementation of available big data technologies at farmer's field level. The study highlights data generation procedure, availability of technology, availability of hardware, software, data collection techniques, method of analysis and suitability of application of big data technologies for smart agriculture. The article explores that there are still some challenges exists in this field as a new domain in agriculture like privacy of data, data quality, availability, initial investment, infrastructure and related expertise. The study suggests that government initiatives, public-private partnership, openness of data, financial investment and regional basis research work are necessary for implementing the big data technologies in agriculture at large scale."
9544668,System and Method for Detecting Anti-Kidney Fibrosis Drugs Based on Big Data,"Renal fibrosis (including glomerulosclerosis and renal interstitial fibrosis) is the common pathological pathway for chronic renal disease to develop into end-stage renal disease. The drug detection system of anti renal fibrosis has become a hot research object for many scholars. With the development of computer and big data technology, it is possible to establish an anti renal fibrosis drug detection system by using data mining and knowledge discovery. Based on big data technology, this paper attempts to establish the detection system of anti renal fibrosis drugs."
9382524,Analysis on Financial Management of Small and Micro Enterprises Based on Cloud Accounting in Big Data Age,"With the strengthening of national support for small and micro enterprises, the development speed of small and micro enterprises in the market economy is getting faster and faster. The arrival of the big data era has brought unprecedented business models to all enterprises in the market. Relying on data platforms and cloud computing platforms, small and micro enterprises can effectively solve their own economic development problems and constantly enhance their market competitiveness."
8718609,Big Data Opportunities: System Health Monitoring and Management,"The concept of a system, generally defined as an organized set of detailed methods, procedures, and routines that are created to carry out a specific activity or solve a specific problem, has been successfully applied to many domains, ranging from mechanical systems to public health. System health monitoring and management (SHMM) refers to the framework of continuous surveillance, analysis, and interpretation of relevant data for system maintenance, management, and strategic planning. This framework is essential to ensure that an entire system is stable and under control. A fundamental problem in SHMM is the optimal use of correlated active and passive data in tasks including prediction and forecasting, monitoring and surveillance, fault detection and diagnostics, engineering management, and supply chain management. In this paper, we provide a new perspective on SHMM in a big data environment, discuss its relationship with other disciplines, and present several of its applications to complex systems."
9709041,Application of Big Data Technology in Students’ Sports Risk Control,"This paper mainly analyzes the application of big data technology in the risk control of student sports. Big data technology uses data mining and cluster analysis to carry out physical education teaching, training and management. Data analysis is one of the core functions of big data technology. It monitors students’ sports status through data and integrates sports data systematically. This paper analyzes the potential risks of students’ sports dynamically through the operation of data mining. Using big data technology to deal with the occurrence of students’ sports accidents, and take corresponding measures. With the advantages of big data technology, the risk degree of students’ sports activities will be finally reduced, a comprehensive sports risk system will be established, and the risk control system of school sports will be improved."
8754071,Big Data Analytics in Telecommunication using State-of-the-art Big Data Framework in a Distributed Computing Environment: A Case Study,"Predictive Analytics is of great interest when it comes to enhancing Business Intelligence. Businesses have already started to use Big Data Analytics, particularly predictive and prescriptive analytics, to strengthen and increase their business yields. Not only has analytics resulted in business growth, but has also provided a significant competitive edge over others. The voluminous data generated from various resources is highly unstructured in nature and adding a structure to it would leverage the actual potential of the data. New techniques and frameworks should serve as human aids in automatically and intelligently analyzing large datasets in order to acquire useful information. In this paper, we attempt to perform Big Data Analytics on data from one of the most important and growing sources, namely, Telecommunication. To keep pace with the growing telecommunication market and ever increasing demands of the consumers for quality service, the telecom service providers are required to observe and estimate various trends in customer's usage to plan future upgrades and deployments driven by real data. We have attempted to use several data mining techniques to find hidden and interesting patterns from the telecom data generated by Telecoms Italia cellular network for the city of Milano, Italy. K-means clustering is used to categorize the usage statistics while several machine learning algorithms like Decision Tree, Random Forest, Logistic Regression and SVM are used for predicting the usage of telecom services. In the end, a performance comparison matrix is generated to rate the performance of these algorithms for the given dataset. All these experiments are performed on the big data environment set up at the supercomputing infrastructure of C-DAC. Given such a matrix, the result can be applied to similar dataset pertaining to other domains as well."
8782595,Active Data Replica Recovery for Quality-Assurance Big Data Analysis in IC-IoT,"QoS-aware big data analysis is critical in Information-Centric Internet of Things (IC-IoT) system to support various applications like smart city, smart grid, smart health, intelligent transportation systems, and so on. The employment of non-volatile memory (NVM) in cloud or edge system provides good opportunity to improve quality of data analysis tasks. However, we have to face the data recovery problem led by NVM failure due to the limited write endurance. In this paper, we investigate the data recovery problem for QoS guarantee and system robustness, followed by proposing a rarity-aware data recovery algorithm. The core idea is to establish the rarity indicator to evaluate the replica distribution and service requirement comprehensively. With this idea, we give the lost replicas with distinguishing priority and eliminate the unnecessary replicas. Then, the data replicas are recovered stage by stage to guarantee QoS and provide system robustness. From our extensive experiments and simulations, it is shown that the proposed algorithm has significant performance improvement on QoS and robustness than the traditional direct data recovery method. Besides, the algorithm gives an acceptable data recovery time."
9360942,Kindergarten Big Data System Solution Architecture,"The kindergarten big data system is designed based on the practical problems of insufficient pre-school education resources, inadequate regulatory systems and mechanisms, and the need to improve the quality of childcare, and the management needs of the kindergarten urgently need to improve the science, flexibility, efficiency, and safety, developing. It includes three major aspects of network system architecture, environment system and management system. The kindergarten big data system is based on modern information technology and can eventually achieve ""intelligent connection with government authorities"" to facilitate supervision. The kindergarten big data system can ""integrate intelligently the various affairs of the kindergarten"" for effective management; ""monitor children's health information at all times"" to ensure safety. It also can ""real-time interact with parents and share children's information"" to achieve home-school co-education; ""develop games, learning environment and resources"" to provide personalized services and other functions for kindergarten teachers."
9361006,Design of municipal solid waste intelligent supervision Platform based on big data,"With the development of municipal modernization, the governance and supervision of municipal solid waste become more and more complicated. New supervision methods are required. From the perspective of big data chain, this paper designs the specific application scheme of municipal solid waste smart supervision, introduces the background, overall design, generation source supervision, collection process supervision, GIS application, real-time event tracking, information management, decision support and other subsystems of municipal solid waste smart supervision platform based on big data, and further demonstrates the role and benefits of big data in municipal solid waste smart supervision."
9377521,Rapid Resolution of Parametric Failures in the Process Development Period by Integrating Device Physics and Big Data,"This paper describes a method for rapid resolution of parametric failure during the development period. Since the number of samples is small, it is not possible to carry out general big data analysis of white defect failures of CMOS image sensors (CISs) during the development period in the same way as can be done during the mass production period. Our feature value analysis of white defects based on device physics revealed that both a development product and mass products using big data show similar fluctuations in dark current spectroscopy and in-plane distribution in the wafer. Process step/tool identification and tool sensor data analysis revealed the degree of vacuum within the implantation tool to have a strong correlation with white defect count. We developed a virtual metrology (VM) model for white defect count and varied the degree of vacuum. As a result of our experiments, we were able to reduce white defect count during the development period by 75%. The time required for resolution of failures was 10% that of the conventional method."
9006043,A Hybrid Approach to Dynamic Enterprise Data Platform,"Today, corporations aim to make maximum use of the data produced in business applications. One of the most important goals is to convert the data to the commercial benefit in the fastest way. For this purpose, it is critical to receive the data from source systems, process this data and use it as a support for business decisions. There are many approaches to the proceeding of acquiring, processing and making the data useful. In this study, we took advantage of most of the existing approaches and produced a hybrid solution. This solution can be integrated with new data sources very quickly and reduces the amount of time for data integration, preprocessing, deduplication and entity mapping by using open source software components."
8898893,A Cloud-Enabled Geospatial Big Data Platform for Disaster Information Services,"Geospatial technologies have been widely used to support decision making in natural disaster responses. There have been various efforts from multiple disasters to use geospatial information and models for disaster preparation, response, and resilience. These separated efforts can be shared and re-used across various sectors using a sustained platform. This paper presents how a platform layered on big data and cloud computing technologies can help achieve this goal. The big data platform enables the accumulation of disaster data, models, services, and applications in spatial information infrastructures (SDI), and improves the capabilities of SDI in supporting disaster risk reduction."
9489188,"Prediction of Pneumonia Using Big Data, Deep Learning and Machine Learning Techniques","Using big data for prediction analysis along with machine learning or deep learning techniques or algorithms is one the most active areas of research in order to improve the health and the medical science. There is a significant increase in the size of the medical data as well as the complexity in the diagnosis of various diseases. With this being said, the diagnosis or the prediction of many terminal or fatal diseases has seen huge success through deep learning. Among those fatal diseases, pneumonia is one of the greatest threats to the life of a man affecting the lungs leading to lung failure. To diagnose a man with pneumonia, the x-ray of chest is needed, and an expert in the prediction is also required. Hence, it is more convenient to build an automated predictor to predict the pneumonia using the big data deep learning methods. Among all the other techniques, CNN (Convolutional Neural Networks) stand tall and high in this prediction along with other classifiers. Also, pre-training the CNN models for very large datasets that is for big data of healthcare units stands a high chance for accurate classification. A CNN model which is pre-trained along with an efficient feature extraction technique and various classifiers to classify the positive from negative is considered to give highly accurate results. This research work represents the Prediction of Pneumonia using Big Data, Deep Learning and Machine Learning Techniques."
9375807,How Big Data Phenomenon Impact and Improve the e-Learning Process,"With the emergence of Big Data, the exploitation of information has become such a direct and rapid action that many questions arise about the reliability and value of data. However, the data raised by online search engines is based on a varied and massive environment, which includes varied data and from different sources of information. Indeed, in the field of distance education (e-Learning) and in particular during online research, the learner is faced with a massive mixture of data which does not exist in an ordered format and which is not easy to operate. This variety of data represents the second V in Big Data. In order to support learners in their search for information, it is proposed to design a specialized tool to combine these massive and varied data so that they can provide the appropriate result to the learner. This article deals with the descriptive study of the current state of the use of online research in the Big Data environment by the students of the UAE (Abdelmalek Essaadi University), and to highlight the advantages and impacts of this phenomenon on learning and scientific research."
9243527,Big Data Privacy and Challenges for Machine Learning,"The field of Big Data is expanding at an alarming rate since its inception in 2012. The excessive use of Social Networking Sites, collection of Data from Sensors for analysis and prediction of future events, improvement in Customer Satisfaction on Online S hopping portals by monitoring their past behavior and providing them information, items and offers of their interest instantaneously, etc had led to this rise in the field of Big Data. This huge amount of data, if analyzed and processed properly, can lead to decisions and outcomes that would be of great values and benefits to organizations and individuals. Security of Data and Privacy of User is of keen interest and high importance for individuals, industry and academia. Everyone ensure that their Sensitive information must be kept away from unauthorized access and their assets must be kept safe from security breaches. Privacy and Security are also equally important for Big Data and here, it is typical and complex to ensure the Privacy and Security, as the amount of data is enormous. One possible option to effectively and efficiently handle, process and analyze the Big Data is to make use of Machine Learning techniques. Machine Learning techniques are straightforward; applying them on Big Data requires resolution of various issues and is a challenging task, as the size of Data is too big. This paper provides a brief introduction to Big Data, the importance of Security and Privacy in Big Data and the various challenges that are required to overcome for applying the Machine Learning techniques on Big Data."
9360992,A Research on Battlefield Situation Analysis and Decision-making Modeling based on a Hadoop Framework,"The researches on modern military sectors are stepping into a big data-driven age. The evolution of wars and tactics leads to new warfare techniques, yet their practical application upgraded the war into a new generation, which represents a spiral development mode. In an exploration of intelligent methods in application to intricate systems with large data scale and break grounds in the area of battlefield situation analysis and decision issue, the paper first aims at designing an analysis and decision making model based on Hadoop architecture. The model focuses on using techniques such as Hadoop distributed platform architecture, HDFS distributed file system coupling, MapReduce parallel computing model and Hbase distributed database in order to provide core support for overall combat data mining. Moreover, the paper provides technical reference paths and methods for the elimination of war ""fog"" and ""resistance"". It also aims to merge ""isolated fragments"" into general ""panoramic puzzles"", which can be interpreted by the assistant commander, so as to make accurate real-time judgment on the battlefield situation and operate the combat pivots."
9457372,Reading Promotion Model for Local Digital Documentation Platforms Based on Big Data,"Local digital documentation platforms refer to the online platforms that cater to the people's needs of browsing through, reading and obtaining knowledge. Libraries create the platforms by collecting local literature, classics and related research results, among others, and then convert and process them with digital humanities technology, as assisted by the Internet dispatch system. As Internet technologies develop rapidly and local literature data grows exponentially, digital documentation platforms based on cloud computing, wireless transmission, sensor networks and reading terminals have become an important option for readers to obtain reading services. Local libraries should take full advantage of Internet technologies and contribute to the promotion of local reading and cultural development. This paper analyzed the current local digital documentation platforms and their reading promotion models. In combination with digital humanities technologies such as information statistics, data mining and semantic analysis, and drawing on Lasswell's communication model, the author then explored the construction of and possible innovations in the reading promotion models for local digital platforms."
9681104,Construction of China’s Sports Tourism Information Data Model Based on Big Data Technology,"Now sports tourism is very popular, but there is still a lack of platform for integrating sports tourism information data in the market. Big data technology can solve this problem. This paper uses big data technology to build a sports tourism information data model. Big data technology can help the model collect structured, semi-structured and unstructured data, use Hadoop and PMP engine to initially calculate and process these data, and then reprocess the processed data. Finally, the processed data is provided to the high-level by resource scheduling and service interface. This model can integrate the sports event information released by the official information on the network, recommend it to users, help users understand the information data related to sports tourism, and help the development of sports tourism."
9006313,Deep Neural Networks as Similitude Models for Sharing Big Data,"The amount of data grows rapidly with time and shows no signs of stopping. Ubiquitous computing continues to collect and generate more and more data as both the number of devices grows and the capabilities of devices increase. We suggest processing the data on end devices by building a representative model of the data (“similitude” model). Sharing a smaller model instead of the entire data allows for saving computing power, network time, processing time and also, keeping the collected data private. In the past research, we suggested the use of similitude models, as compact models of data representation instead of the data itself. In this paper, we suggest the use of deep neural networks (DNN) as a data model to answer different types of queries. More specifically, we show that by building two models (generative network and auto-encoder) it is possible to answer approximately both statistical queries and membership queries without exposing the entire dataset."
9526080,Dilemma and outlet of Public Security Management in Big Data Environment,"With the rapid development of economy, informatization has become a trend of global development. Big data is used in public security management, which can manage public security efficiently, prevent related criminal activities effectively, and create an intelligent public security management mode, thus promoting the economic and social development of our country. In view of this, this paper analyzes the relevant connotation of big data, based on the current situation of public security management, analyzes the difficulties encountered by big data in public security management. At the same time, this paper further expounds the influence and function of big data on public security management. Finally, this paper discusses the innovative ideas of big data in public security management from the aspects of innovation consciousness, talent training and data disclosure."
8664133,Haery: A Hadoop Based Query System on Accumulative and High-Dimensional Data Model for Big Data,"Column-oriented stores, known for their scalability and flexibility, are a common NoSQL database implementation and are increasingly used in big data management. In column-oriented stores, a “full-scan” query strategy is inefficient and the search space can be reduced if data is well partitioned or indexed; however, there is no pre-defined schema for building and maintaining partitions and indexes at lower cost. We leverage an accumulative and high-dimensional data model, a sophisticated linearization algorithm, and an efficient query algorithm, to solve the challenge of how a pre-defined and well-partitioned data model can be applied to flexible and time-varied key-value data. We adapt a high-dimensional array as the data model to partition the key-value data without additional storage and massive calculation; improve the Z-order linearization algorithm, which map multidimensional data to one dimension while preserving locality of the data points, for flexibility; efficiently build an expansion mechanism for the data model to support time-varied data. The result is Haery, a column-oriented store, based on a distributed file system and computing framework. In experiments, Haery is compared with Hive, HBase, Cassandra, MongoDB, PostgresXL, and HyperDex in terms of query performance. With results indicating Haery on average performs 4.57x, 4.23x, 3.55x, 1.79x, 1.82x, and 120.6x faster, respectively."
9671741,Distributed file system for rewriting Big Data files using a local-write protocol,"With the exponential volume growth of the data available for scientific and commercial use, more and more Big Data technologies are gaining focus and importance. Directly related to the efficiency of these techniques is the distributed file system used for data persistence, generally based on low-cost computer clusters. However, the environments used today for Big Data are based on file systems restricted to the WORM pattern (write once, read many) lacking POSIX compatibility. This work uses distributed lock management techniques to create a file system that allows random writing for both HPC and Big Data tools. A local write protocol is implemented to leverage the use of local copies of the data during the write process. Experiments were carried out to evaluate the performance of the proposed write protocol and the scalability of the developed file system. From the experimental results, it is possible to conclude that the achieved performance and scalability improvements were obtained by eliminating limitations imposed by HDFS and leveraging local writes."
9373130,Big Data Visualization and Visual Analytics of COVID-19 Data,"In the current era of big data, a huge amount of data has been generated and collected from a wide variety of rich data sources. Embedded in these big data are useful information and valuable knowledge. An example is healthcare and epidemiological data such as data related to patients who suffered from epidemic diseases like the coronavirus disease 2019 (COVID-19). Knowledge discovered from these epidemiological data helps researchers, epidemiologists and policy makers to get a better understanding of the disease, which may inspire them to come up ways to detect, control and combat the disease. As “a picture is worth a thousand words”, having methods to visualize and visually analyze these big data makes it easily to comprehend the data and the discovered knowledge. In this paper, we present a big data visualization and visual analytics tool for visualizing and analyzing COVID-19 epidemiological data. The tool helps users to get a better understanding of information about the confirmed cases of COVID-19. Although this tool is designed for visualization and visual analytics of epidemiological data, it is applicable to visualization and visual analytics of big data from many other real-life applications and services."
9360999,Research on Real Estate Marketing Innovation System in the Era of Big Data,"This article analyzes the importance of real estate marketing in the era of big data. The content of this article includes how to enhance the value of data application, the important means of reconstructing marketing strategies, and the inevitable trend of changes in the marketing system. Combining the content of real estate marketing strategy, the author studies how to analyze customer needs, do a good job of customer segmentation and clustering, optimize marketing strategy distribution models, improve the real estate marketing system, strengthen marketing effect evaluation, and improve the overall quality of personnel. The purpose of this article is to improve the applicability of the content of the system and accelerate the development of the real estate economy."
9418910,A Scientific Quantitative Analysis of Occupation Training and Education Driven by Information Technology Based on Big Data Analysis Technology and Visualization Software,"At present, the information technology service industry is showing a good development trend. The rapid development of information technology has a significant impact on various fields. Driven by information technology, vocational training and education also enjoy the dividend brought by the development of information technology. In this context, vocational training provides more workers with endless opportunities, promotes the development of the labor market, and brings help to the wage problem of young people, especially some children. At the same time, vocational training is closely related to employment and education, which has brought certain changes to the youth and the labor market. Moreover, the state's attention to vocational training is also increasing, and vocational training is of great significance to the transformation of employment and education. However, there is a gap in the bibliometric analysis of this topic. Based on 694 articles retrieved from the web of science database from 1950 to 2020, this paper mainly reviews the highly cited literature on ""vocational training"", ""employment"", ""education"", ""Youth"", ""labor market"". By using big data analysis technology and visualization software, the author's key points such as keywords, main research institutions, countries, and publication sources are analyzed in detail. This paper makes a contribution to the literature of vocational training, employment, and education from the perspective of scientific measurement, to understand the impact of vocational training, education, and employment on youth and the labor market."
9421818,Research on Application of University Student Behavior Model Based on Big Data Technology,"Based on the collection and sorting of data on the study and life of college students, a student behavior model is constructed. The model covers several dimensions of data such as clothing, food, housing, transportation, and extracurricular entertainment during school. Heterogeneous and multidimensional data containing student behavior information is cleaned, integrated, mined and applied, and potentially, valuable, and potentially application-valued information is extracted from it for the school's teaching, research, logistics, catering, security, and enrollment provide scientific data support for various tasks, so as to serve the education, service and management of college students. In the process of building a big data analysis platform, firstly, effectively integrate the basic data of higher vocational colleges and build various standard databases, including the integration of basic data such as college information management system data, all-in-one card consumption data, and library borrowing data. Broken the information separation between the various functional departments in the school, establish a standardized data sharing and coordination mechanism, and optimize the transfer and sharing of resources between departments."
9442514,A Cloud-Enabled Collaborative Hub for Analysis of Geospatial Big Data,"Geospatial big data are analyzed for addressing a specific research or management problem on global scale, and science gateways or Hub, have been widely adopted in recent years as an effective platform for an entry to computational resources, research collaboration, dissemination of data, applications and publications, and community engagement. However, replicating deployment and setup is a non-trivial task. Cloud computing provides an attractive alternative, simplifying resource provision and enabling reliable and scalable replication. This paper describes ongoing efforts to a cloud-enabled Geospatial Hub hosting general-purpose software building blocks, which provides geospatial data access, processing, analysis, and visualization capabilities. The technologies underlying these components, the automation of deployment and configuration on cloud with the Elastic Compute Service (ECS) and Object Storage Service (OBS) are described. This work builds geospatial big data analysis capabilities into web-based Hub platform and empower it by cloud computing. This will open a way for easy development of a variety of online tools for probing and presenting geospatial big data and digital information."
8776910,Big Data Analytics of Inpatients Flow with Diabetes Mellitus type 1 : Revealing new awareness with Advanced Visualization of Medical Information System Data,"Big Data Analytics with Advanced Data Visualization of Medical information system qMS records is presented. The inpatients with Diabetes Mellitus type 1 were chosen for analysis. The various methods of analysis and visualization were implemented: Gray reflected binary code (Java), Cluster analysis (iPython), Graph analysis (iPython, Gephi), 3D Visualization (Java), as well as supercomputer ""Uran"" was used. The connected pathogenetic Continuum of Diabetes Mellitus type 1 was built. The Continuum of Diabetes Mellitus type 1 progression allows assume that Parathyroid hormone-related protein (PTHrP) plays the critical role in multi-organ pathogenetic cascade in this disease, including the development of Lung cancer. Based on our study we suggest considering PTHrP in terms of pharmacological treatment. Big Data Analytics including Cluster and Graph Analysis of Medical information system's data flow can be used to study pathogenesis of the disease and for new drugs creation proposal."
8758091,In Search of Big Medical Data Integration Solutions - A Comprehensive Survey,"In recent years, the radical advancement of technologies has given rise to an abundance of software applications, social media, and smart devices such as smartphone, sensors, and so on. More extensive use of these applications and tools in various industrial domains has led to data deluge, which has fostered enormous challenges and opportunities. However, it is not only the volume of the data but also the speed, variety, and uncertainty, which are promoting a massive challenge for traditional technologies such as data warehouse. These diverse and unprecedented characteristics have engendered the notion of “Big Data.” The data-intensive industries have been experiencing a wide variety of challenges in terms of processing, managing, and analysis of data. For instance, the healthcare sector is confronting difficulties in respect of integration or fusion of diverse medical data stemming from multiple heterogeneous sources. Data integration is critically important within the healthcare sector because it enriches data, enhances its value, and more importantly paves a solid foundation for highly efficient and effective healthcare analytics such as predicting diseases or an outbreak. Several data integration technologies and tools have been developed over the last two decades. This paper aims at studying data integration technologies, tools, and applications within the healthcare domain. Furthermore, this paper discusses future research directions in the integration of Big healthcare data."
9002857,Adaptation of Classical Machine Learning Algorithms to Big Data Context: Problems and Challenges : Case Study: Hidden Markov Models Under Spark,"Big Data Analytics presents a great opportunity for scientists and businesses. It changed the methods of managing and analyzing the huge amount of data. To make big data valuable, we often use Machine Learning algorithms. Indeed, these algorithms have shown, in the past, their processing speed, efficiency and accuracy. But today, with the complex characteristics of big data, new problems have emerged and we are facing new challenges when developing and designing a new Machine Learning algorithm for Big Data Analytics. Therefore, it is essential to review the classical algorithms to adapt them to this new context. One of the methods of adaptation is the coupling between new technologies (i.e., distributed computing by GPU, Hadoop, Spark) and the Machine Learning algorithms to reduce the computational cost of data analysis. This paper highlights main challenges of adaptation of Machine Learning algorithms to the Big Data context and describes a novel method to make these algorithms efficient and fast in Big Data processing by taking as a case study the Hidden Markov Models using Spark framework. The results of complexity comparison of classical algorithms and those adapted to the Big Data context using Spark show a great improvement."
9603467,Research on Precision Marketing Strategies of Real Estate Companies Based on Big Data,"The current sloppy marketing channels and high cost-efficiency ratio of real estate companies make the sales performance of real estate companies poor. How real estate companies can eliminate inventory, reduce marketing costs and raise away from sales performance is the main problem facing real estate companies at present. Based on big data technology, this paper first analyzes the real estate big data precision marketing steps as well as processes. Then, through the analysis of real estate customers' purchase process decision, the design framework of big data precision marketing for real estate companies is proposed. Finally, the current status of real estate marketing is combined with the current market rules to study the marketing strategies that meet the current market rules."
9476515,Digital Marketing and Big Data: a bibliometric analysis of scientific production from the Scopus database,"To identify the most frequently developed topics in the area of Big Data and Digital Marketing, a quantitative analysis was developed in December 2020. This analysis was focused on 750 publications and later on 67 publications on Big Data and Digital Marketing from the Scopus database. A bibliometric analysis was developed using the VOSviewer software and the technique of term co-occurrence and author co-authorship. Clusters were found for each of the analyzed situations."
9421870,"Management Innovation of Party Building Work in Higher Vocational Colleges under the Background of ""Internet +"" and Big Data","In the process of increasing the level of informatization technology, the development speed of Internet technology is also getting faster and faster. Big data technology and Internet technology have become important types of technology used in various industries. In the context of ""Internet +"" and big data, innovative management of the current party building work in higher vocational colleges can improve the efficiency and quality of party building work. In the management of party building in higher vocational colleges, we need to study the actual application of network technology and the actual requirements of party building work. The author of this article puts forward the key points of the application of Internet + and big data technology in campus party building innovation management."
9194896,Research on Computer Network Information Security Based on Big Data Technology,"Internet big data is related to our personal privacy and property security. In serious cases, it also affects the security of confidential information of related companies. Therefore, big data must be protected to prevent criminals from stealing our personal privacy, property information and corporate secrets. Based on this research background, the paper designs the design of computer network security defines system. After the system design is implemented, the system is tested accordingly. According to the test results, the computer network security defines system designed in this paper can actively detect and effectively prevent security threats in the network, thereby ensuring that the network can Normal and safe operation. The computing network security defines system can also provide effective ideas for future network security protection and achieve further expansion of security defines."
9006441,iEnvironment: Perspectives on Metadata-Oriented Testing of Research Software,"As a research software platform, iEnvironment has been proposed to support open and big data sharing and reuse for researchers working on surface water issues. Research software refers to software development tools that accelerate discovery and simplify access to digital infrastructures. Although research software platforms are becoming increasingly more innovative and powerful, this increasing complexity hides a greater risk of failure as unplanned and untested program scenarios arise. As systems age and are maintained by different programmers the risk of a change impacting the overall system increases. In contrast, systems that are built with less emphasis on program code and more emphasis on the metadata that describes the application can be more readily changed and maintained by individuals who are less technically skilled but are often more familiar with the application domain. Such systems can also be tested using automatically generated testing regimes."
9390151,Smart University: Big Data adoption model,"New technologies foster a variety of smart solutions in university settings to improve the quality of life and performance for both teachers and students. Research on information governance shows the importance of the alignment between information and communication technologies (ICTs) and strategic objectives. From this perspective, the adoption of smart technologies is the result of strategic management deliberations that address the application, the risk, the use of resources and the feasibility of technology. The main challenge is to predict how this technology is adopted through overcoming the barriers that affect, for example, your perception of usefulness or your intention to use it. This has led to the concept of an Intelligent University where Big Data has proven to be very important. This article reviews technology adoption models and proposes a specific model for Big Data based on three factors: Individual perception; security and risk; and organizational support."
9463386,The application of artificial intelligence in computer network technology in the era of big data,"At this stage,with the continuous development of science and technology, artificial intelligence has been applied in many fields, this also includes computer network technology, which strengthens the work efficiency of the entire computer system and better meets the needs of individuals and the times. Based on the previous work experience, this paper summarizes the application advantages of artificial intelligence, and from the establishment of intelligent firewall, application in data information management, artificial immunity and data fusion, generation of intelligent intrusion detection,establishing rule production expert system in the era of big data , system maintenance in the six areas of application, it discusses the specific application of artificial intelligence in computer network technology in the era of big data."
9418829,Big Data Mining and Analysis of Hot Issues in International Education—Based on K-means algorithm of cluster analysis,"In the era of big data, international education has accumulated a lot of relevant data, which can produce various research values. The Corona Virus Disease 2019 (COVID-19) seriously affects the development of international education. This paper starts with the hot spots of international education and international higher education. Moreover, based on xinhuanet.com database and CSSCI database, and through K-means algorithm in data mining clustering analysis algorithms, the Cite Space visual software is used to make keywords analysis, emotional color analysis, and centrality analysis, thus getting the hot issues in international education and the frontier focus. Furthermore, combined with COVID-19 spread globally, these problems are analyzed, the future direction and development of international education are discussed, and reasonable and scientific suggestions and thinking are proposed."
8891948,Semantic (Big) Data Analysis: an Extensive Literature Review,"For many years, companies have exploited the data registered in their everyday operations by their transactional systems to obtain useful information and assist in decision-making. To this end, different data analysis techniques and business intelligence strategies have been applied. In recent years, the increase in the volume of data, along with variety in data and the velocity at which data is being produced, has led to the conception of novel processing mechanisms capable of dealing with such huge amount of data, namely, Big Data. The main difficulties associated with Big Data management are linked to its collection and storage, search, sharing, analysis and visualization. The formal underpinnings of Semantic Web technologies enable the automated processing of data through sophisticated inference and reasoning techniques. Semantic technologies have been successfully applied in a number of scenarios for the integration of heterogeneous data, data analysis at the knowledge level, and visualization of Linked Data. In the last few years, a large number of published research papers have explored the benefits in using semantic technologies in data analysis and Big Data. In this paper, we provide a systematic review of the literature in this research area, highlighting the main benefits obtained by the integration of semantic technologies in data analysis and the most challenging aspects that remain to be addressed."
9553957,Hydrological Big Data Prediction Based on Shared Weight Long Short-Term Memory,"Hydrological big data was characterized by complexity and comprehensibility, There are massive data association relationships to be mined in hydrological big data. Hydrological forecasting is primary to flood prevention in China, and how to use hydrological big data to make accurate and efficient prediction has become the primary study. This study starts with the analysis of hydrological big data association relationship, captures the characteristics of hydrological data, and proposes shared weight Long Short- Term Memory(SWLSTM) to reduce the number of optimized variables, shorten the training time of SWLSTM, and improve prediction accuracy of hydrological big data. Taking the daily water level data of Tunxi Hydrological Station of Tunxi Basin in China in 2016 as experimental data, experimental results demonstrate that our approach is efficient and accurate."
9599201,Challenges of Big Data and Vehicle Data,"In this short paper, we outline the challenges of Big Data processing for vehicle data, considering different use cases as well as different locations. On an architectural level, we show the benefits and possible limitations of the different approaches for in-vehicle processing, edge computing as well as cloud processing. We also discuss different approaches for Big Data Processing, including batch processing as well as distributed stream processing."
8667300,Big Data Quality Assurance Through Data Traceability: A Case Study of the National Standard Reference Data Program of Korea,"In the era of big data, the scientific and social demand for quality data is aggressive and urgent. This paper sheds light on the expanded role of metrology of verifying validated procedures of data production and developing adequate uncertainty evaluation methods to ensure the trustworthiness of data and information. In this regard, I explore the mechanism of the national standard reference data (SRD) program of Korea, which connects various scientific and social sectors to metrology by applying useful metrological concepts and methods to produce reliable data and convert such data into national standards. In particular, the changing interpretation of metrological key concepts, such as “measurement,” “traceability,” and “uncertainty,” will be explored and reconsidered from the perspective of data quality assurance. As a result, I suggest the concept of “data traceability” with “the matrix of data quality evaluation” according to the elements of a data production system and related evaluation criteria. To conclude, I suggest social and policy implications for the new role of metrology and standards for producing and disseminating reliable knowledge sources from big data."
9141732,Research on Two-way Integration Business Process Reengineering under Big Data,"Big data is bringing great changes to enterprise management, which has a great impact on modern enterprise operation concept, business model, organizational business process, etc. After expounding the concept and characteristics of big data, this paper introduces the basic connotation and main methods of BPR of enterprise business process reengineering. Combined with the characteristics of big data, it puts forward the overall framework and idea of bi-directional integration of Enterprise Business Process Reengineering under big data, which is beneficial for the implementation of BPR of enterprise under big data."
9045835,Controllable Correlation Big Data Dynamic Prediction Model for Mobile Communication,"At present, there were many mobile communication deviees in China. In order to improve the prediction effect of mobile communication and realize the scalability and dynamic evolution of the prediction system, a dynamic prediction model of controllable correlation big data for mobile communication was proposed. The application experiment was carried out, and the experimental results of various models were compared and analyzed. The experimental results showed that the model fully integrated the openness, extensibility and big data dynamic prediction advantages of mobile communication. The communication quality, total duration and quantitative qualitative prediction of con trollable correlation big data based on mobile communication in big data environment were realizedÇ4bstract)."
9434446,Big data mining in public service demand positioning,"In recent years, big data has been more and more widely and deeply applied, showing great technological advantages and innovative effects. The fundamental reason lies in its ability to hedge various uncertainties inherent in human society, so as to improve economic forecasting, enhance the accuracy and effectiveness of public services, and mitigate policy uncertainty and its negative impact. In the field of public services, big data technology provides strong technical support for optimizing public service supply, meeting people's public service demand, improving government service efficiency and innovating social governance. Mining data, integrating data and applying data will become one of the core tasks of government service departments in the future. Therefore, big data should be better served in public services to maximize the application value of big data technology in the field of public services."
9671463,DaaS: Internet-perception big data systems based on AI,"The DaaS (Data as a Service) is an Internet-perception big data system based on AI, which is built by ""Think Tank 2861 Project Team"". This is an Internet-area, data-based, and neural feedback system for the Internet information in China. It takes Internet activities as the input, and processes through AI algorithms and machine learning framework to generate the output, based on which building the real-time macro economics and society big data for about 9.8 million grids in China and its intelligent applications. DaaS covers all 2,861 administrative districts and counties in the country and is refined to geography grid of one square kilometer granularity. The real-time objective information generated by distributed AI algorithms, that are constantly trained and calibrated, is of great value in scientific research and commercial applications."
9489108,Big Data Driven E-Commerce Application Management System,"Over the last few years, the impact of internet applications has been constantly evolving, as has the amount of data generated by all of these in various varieties, large sizes, and complexity, as well as a large volume of structured and unstructured data known as big data. Big data refers to large volumes of data that are subjected to analytics and different computations in order to reveal patterns and trends in the data, as well as certain associations in the data, so big data analytics play an important role in turning these data into useful knowledge. In the coming years, big data analytics is strategically poised to revolutionize e-commerce applications. Big Data analytics has quickly emerged as a critical component of a successful e-commerce management system. The primary goal of this paper is to discuss big data, issues, and challenges, as well as various Big Data tools."
9671441,TemPredict: A Big Data Analytical Platform for Scalable Exploration and Monitoring of Personalized Multimodal Data for COVID-19,"A key takeaway from the COVID-19 crisis is the need for scalable methods and systems for ingestion of big data related to the disease, such as models of the virus, health surveys, and social data, and the ability to integrate and analyze the ingested data rapidly. One specific example is the use of the Internet of Things and wearables (i.e., the Oura ring) to collect large-scale individualized data (e.g., temperature and heart rate) continuously and to create personalized baselines for detection of disease symptoms. Individualized data, when collected, has great potential to be linked with other datasets making it possible to combine individual and societal scale models for further understanding the disease. However, the volume and variability of such data require novel big data approaches to be developed as infrastructure for scalable use. This paper presents the data pipeline and big data infrastructure for the TemPredict project, which, to the best of our knowledge, is the largest public effort to gather continuous physiological data for time-series analysis. This effort unifies data ingestion with the development of a novel end-to-end cyberinfrastructure to enable the curation, cleaning, alignment, sketching, and passing of the data, in a secure manner, by the researchers making use of the ingested data for their COVID-19 detection algorithm development efforts. We present the challenges, the closed-loop data pipelines, and the secure infrastructure to support the development of time-sensitive algorithms for alerting individuals based on physiological predictors illness, enabling early intervention."
8728351,Review on Securing Medical Big Data in Healthcare Cloud,"E-health is one of an emerging field in health industry. In order to diagnose a patient, doctors need the medical record of the patient which contains multimedia big data. For efficient access EMR (Electronic Medical Record) should be placed in cloud which also supports mobility.In having many advantages, it faces many security issues as well, of which hacking is considered to be the most serious of healthcare data in cloud. In this paper, a survey on different methods for securing medical big data in cloud is done. The healthcare data can be stored and accessed using a decoy technique."
9123041,Affinity Propagation Initialisation Based Proximity Clustering For Labeling in Natural Language Based Big Data Systems,"A key challenge for natural language based large text data is automatically extracting knowledge, in terms of entities and relations, embedded in it. State of the art relation extraction systems requires large amounts of labeled data, which is costly and very difficult, especially in industrial settings, due to time constraints of subject matter experts. Techniques like distant supervision require the availability of a related knowledge base, which is rarely possible. We have developed a novel model for automatically clustering textual Big Data, based on techniques inspired from Active Learning and Clustering, that can derive powerful insights and make the data ready for machine learning with minimal manual effort. Our approach differs from Active Learning as we operate under weak supervision, where all the instances provided for training are not manually labeled. Secondly, This differs from any prevailing clustering algorithms as we adopt a whole new approach of proximity clustering based on affinity propagation. Due to the extrapolation of the labeling efforts, our model makes it easier to adopt deep learning approaches with minimal manual effort. In this paper, we describe our algorithm in detail, along with the experimental results obtained for them."
8893261,Applications of Deep Learning and Big Data Technologies,"Today, Big Data and Deep Learning concepts are the most frequently studied subjects. The coexistence of the concept of Deep Learning, which is another technology that emerged after the study of large data, has been a topic of revelation. Because the experience obtained due to the excess and the size of the data examined is expected to be used more quickly and efficiently by using Deep Learning technology. In this study, the concepts of Big Data and Deep Learning will be explained and some applications will be mentioned."
8713254,Review and Prospect of Data Asset Research: Based on Social Network Analysis Method,"Background: Data assets are an important engine for the operation of the digital economy. However, research on this emerging field is scattered, and the research framework, research context and research direction are still unclear. Process: taking 278 articles in the past 20 years as a sample, social network analysis method is used to summarizes the research status of data assets from three research themes: how to define the connotation of data assets, how to accurately measure the value of data assets and how to complete data asset transaction. On the basis of summarizing the limitations of existing research, the future research directions are proposed: firstly, data commodity standardization research; secondly, externalization construct index system of data asset value evaluation; thirdly, intelligent dynamic pricing mechanism and system development. Meaning: This theoretical reference is provided for the related follow-up research of data assets, and has certain practical significance for releasing the data assets in the trading environment of the network platform."
9211239,Big Data Security and Privacy: Current Challenges and Future Research perspective in Cloud Environment,"Cloud computing is an Internet-based technology that emerging rapidly in the last few years due to popular and demanded services required by various institutions, organizations, and individuals. structured, unstructured, semistructured data is transfer at a record pace on to the cloud server. These institutions, businesses, and organizations are shifting more and more increasing workloads on cloud server, due to high cost, space and maintenance issues from big data, cloud computing will become a potential choice for the storage of data. In Cloud Environment, It is obvious that data is not secure completely yet from inside and outside attacks and intrusions because cloud servers are under the control of a third party. The Security of data becomes an important aspect due to the storage of sensitive data in a cloud environment. In this paper, we give an overview of characteristics and state of art of big data and data security & privacy top threats, open issues and current challenges and their impact on business are discussed for future research perspective and review & analysis of previous and recent frameworks and architectures for data security that are continuously established against threats to enhance how to keep and store data in the cloud environment."
9558938,Single Label Model for Confidentiality in Big Data,"Data security is defined as preventing actions such as accessing, using, changing, and eliminating information without authorization and consists of specific basic elements called confidentiality, integrity and accessibility. Many studies have been carried out in the literature to ensure information security. However, no study has been carried out to provide these basic elements together. In this study, we created a model that provides three basic elements of information security for large data. With the single labeling model we propose, a more practical and flexible structure has been realized for all operations performed in the database (reading, writing, updating, deleting) on actual data. In previous studies with the labeling model, a separate label was used for only reading or writing only and a structure that will ensure both confidentiality and integrity at the same time has not been established. In our study, we have shown how to perform an authorization and access control between which operation and which user by looking at a single label for all operations performed on the data. In this way, unlike the studies in the literature, data confidentiality, data integrity and data consistency were provided for all processes. The results of the proposed single-label model have been shown in comparison with the application and experimental study we have carried out. The results obtained are promising for future studies."
9457361,Research on the Application of Building Information Model in Interior Design Under the Background of Big Data,"Designers in the era of big data not only use computers as modern design media, but more importantly, they must have the ability to grasp, control and use various information quickly and accurately. With the rapid development of digital technology and the construction market, the concept of BIM came into being. At present, BIM is gradually accepted by the construction industry. As a new technical concept, BIM is promoting the development of architectural design and other industries. At the same time, big data has become a hot topic and a starting point for solving problems. This article introduces the specific concept and development trend of the new computer information technology-building information model. This article focuses on analyzing the revolutionary changes brought about by the application of BIM in interior design, and further elaborates the advantages of building information modeling technology in interior design through two examples."
9587261,Research on digital audit of electric waste materials based on big data platform,"The audit of waste materials can reduce the loss of state assets and strengthen the construction of clean government. With the construction of large data platform in power grid, the generation of massive data has provided convenience for audit supervision, but the identification and extraction of key information has also brought difficulties to the traditional audit work. Fistly,the article classified the waste materials of electricity, and used data mining technology to carry out important data association and processing for the equipment after classification, got the state information before abandonment, and made reasonable audit for scrap. Then, got the information of volume and weight under normal condition, compared with the scrapped, carried out the audit of “accounts and things” consistency after scrapping. The engineering practice shows that the use of digital audit can effectively improve audit efficiency and discover problems in time, and is worthy of further popularization and application."
9532444,Research on Massiveness Characteristics Weights of Big Knowledge Based on the Big Data,"Faced with massive, heterogeneous, and autonomous data resources, the term of “Big Knowledge (BK)” has been proposed to deal with challenges in the era of Big Data. Researchers have defined the “BK”, and studied the massiveness characteristics of BK But no specific weight reference value is given for the rules of each characteristic. Therefore, by combining qualitative and quantitative research, this paper explores five basic massiveness characteristics of big knowledge: massive concepts, massive connectedness, massive clean data resources, massive cases and massive confidence. This paper mainly explores the weight of five massiveness characteristics related to “big knowledge” based on the Grey Relation Analysis (GRA) combined Analytic Hierarchy Process (AHP) and Data Envelopment Analysis (DEA). Simultaneously, it explores the correlation between the Five Large-scale Knowledge Engineering Projects and Big Knowledge. The obtained reference relevance which provides a certain reference for measuring large-scale knowledge engineering projects in the future. Finally, the research perspective of BK is analyzed."
9435701,Journey to a Big Data Analysis Platform: Are we there yet?,"Data warehousing and analytics are going through a metamorphosis. Corporations are transforming their data warehousing capabilities, centralizing data analytics, and leveraging cloud technologies. Eight years ago, at ASMC 2013, we presented our approach to big data solutions and asked the industry leaders to help unify technologies to enable our big data transformations more seamlessly for the industry. This paper will cover what does, what did not, and what will not in the future work, where data and analytics are heading, and what the semiconductor industry needs to do to address big data challenges. The material will present clear reasons for leveraging big data solutions including up to 20× performance improvements analysis, cloud to cloud sharing options, ways to easily scale and handle data growth and centralizing information. There will also be a few areas where it will be shown how better integration from the factory floor to the modern data analysis platforms could be possible but cannot be fully addressed without the help from vendors."
8741818,Deep Learning Based Forecasting in Stock Market with Big Data Analytics,"In recent years, due to the technological improvements in computers' hardware and enhancements in the machine learning techniques, there are two increasing approaches for problem-solving as the use of “Big Data” and “Parallel Processing”. Especially with the emergence of Deep Learning algorithms which can be executed parallelly on multi-core computing devices such as GPUs and CPUs, lots of real-world problems are resolved with these approaches. One of the most critical application areas in the Financial Market especially sits on Stock Markets. In this area, the aim is trying to predict the future value of a specific stock by looking at its previous financial data on the exchange process in the market. In this paper, we proposed a system that uses a Deep Learning based approach for training and constructing a knowledge base on a specific stock such as “IBM”. We get time series values of the stock from the New York Stock Exchange which starts from 1968 up to 2018. Experimental results showed that this approach produces very good forecasting for specific stocks."
9325815,The application research of multi-source heterogeneous energy big data analysis,"With the rapid development of energy industry, more requirements are put forward for the processing of energy data. In order to extract more value from multi-source heterogeneous data, it is necessary to combine various sources and different forms of data to build a data analysis process. Therefore, data processing technology and energy data structure is combined; the analysis and processing of data are described from the perspectives of data aggregation, data processing, data analysis and data services. Precision storage, algorithm library, object analysis and intelligent services are also used in big data processing innovatively. Through the establishment of processing models and the realization of specific functions, the circulation, aggregation and sharing of energy big data can be achieved. Finally, the data value can be reflected through the business output of platform and behavior interaction of user. The energy production and consumption revolution will be promoted by analysis and the energy industry will upgrade and transform."
9339627,Research on the Application of Big Data and Visualization Technology in Power Video Monitoring System,"In the big data cloud platform system, users can share information instantly in different time and space, and the information transmission capability of the video surveillance system is greatly improved through the Internet. The application of big data visualization technology will be beneficial to large-scale data analysis efficiently. In this paper, the power big data and visualization technology are summarized firstly, and then the specific application of power big data in power video surveillance system is discussed, including data mining technology, customer classification analysis decision model and classification index system design, and the design and implementation of visualization platform are also discussed."
8945627,Data Analysis and Knowledge Discovery in Web Recruitment—Based on Big Data Related Jobs,"This paper mines and analyzes the post information of the online recruitment data, and discovers the knowledge in large-scale web data, so as to achieve the precise connection between professional job demand and supply. First, internet crawler technology is adopted to acquire data. Second, the authors digitalize polymorphic data and conduct Chinese word segmentation, stop word filtering and other operations on data records. Third, the cosine similarity is used to measure the similarity of the vector, and the K-means++ is used for post clustering. Then, latent dirichlet allocation and apriori are used for post correlation analysis. Last, the authors use auto-encoder to achieve job matching recommendation."
9530350,The Application on distributed geospatial data management based on Hadoop and the application in WebGIS,"GIS spatial big data presents the characteristics of massive, multi-source, heterogeneous, spatiotemporal, multiscale. The traditional GIS data storage technology can not meet the needs of GIS spatial big data management. In this paper, for the construction of lightweight WebGIS management system of Oilfield Engineering, aiming at the application requirements of 2D and 3D vector data in security, fault tolerance and scalability, the application strategy of distributed spatial data management technology in cloud environment is proposed, which has made progress in the aspects of high concurrent access of spatial data, fast data loading and high efficiency operation."
8456550,Cornac: Tackling Huge Graph Visualization with Big Data Infrastructure,"The size of available graphs has drastically increased in recent years. The real-time visualization of graphs with millions of edges is a challenge but is necessary to grasp information hidden in huge datasets. This article presents an end-to-end technique to visualize huge graphs using an established Big Data ecosystem and a lightweight client running in a Web browser. For that purpose, levels of abstraction and graph tiles are generated by a batch layer and the interactive visualization is provided using a serving layer and client-side real-time computation of edge bundling and graph splatting. A major challenge is to create techniques that work without moving data to an ad hoc system and that take advantage of the horizontal scalability of these infrastructures. We introduce two novel scalable algorithms that enable to generate a canopy clustering and to aggregate graph edges. These two algorithms are both used to produce levels of abstraction and graph tiles. We prove that our technique guarantee a quality of visualization by controlling both the necessary bandwidth required for data transfer and the quality of the produced visualization. Furthermore, we demonstrate the usability of our technique by providing a complete prototype. We present benchmarks on graphs with millions of elements and we compare our results to those obtained by state of the art techniques. Our results show that new Big Data technologies can be incorporated into visualization pipeline to push out the size limits of graphs one can visually analyze."
9006105,Extracting valid indoor semantic trajectories using movement constraints,"An indoor semantic trajectory is a sequence of timestamped semantic positions inside a building. However, its extraction depends on the erroneous indoor positioning. The error leads to an invalid trajectory that has distant consecutive positions. This invalid trajectory may lead to an issue of the non-sensical patterns when analyzing a big semantic trajectory data. To prevent extracting invalid trajectories, we apply the movement constraints to infer only close positions to the current position. We extend the constraints to several indoor positioning techniques, such as Hidden Markov Model, K-Nearest Neighbor, or Deep Neural Network. We show that our approach can effectively extract valid indoor semantic trajectories."
8944307,Online Distributed IoT Security Monitoring With Multidimensional Streaming Big Data,"Internet of Things (IoT) enables extensive connections between cyber and physical “things.” Nevertheless, the streaming data among IoT sensors bring “big data” issues, for example, large data volumes, data redundancy, lack of scalability, and so on. Under big data circumstances, IoT system monitoring becomes a challenge. Furthermore, cyberattacks which threaten IoT security are hard to be detected. In this article, we propose an online distributed IoT security monitoring algorithm (ODIS). An advanced influential point selection operation extracts important information from multidimensional time-series data across distributed sensor nodes based on the spatial and temporal data dependence structure. Then, an accurate data structure model is constructed to capture the IoT system behaviors. Next, hypothesis testing is carried out to quantify the uncertainty of the monitoring tasks. Besides, the distributed system architecture solves the scalability issue. Using a real sensor network testbed, we commit cyberattacks to an IoT system with different patterns and strengths. The proposed ODIS algorithm demonstrates promising detection and monitoring performances."
8791752,Yield Improvement Using Advanced Data Analytics,"We are living in an era in which data is growing in an exponential pace and coming from multiple sources. This type of data has been called ""Big Data"". Big data has large volume, variety of formats, high dimensionality and the need for a high speed processing. Those features differentiates it from traditional datasets. Hence data management, analysis, visualization and results communications are getting more complex. The potential of obtaining greater knowledge and more actionable conclusions makes it very attractive. Therefore a data-driven mindset is emerging in different industries and the semiconductor industry is not an exception. This paper describes the results for yield improvement of our silicon carbide technology using advanced data analytics. In doing so, the paper outlines how the data was collected, managed and preprocessed to make it suitable for analysis. It explains which methods and algorithms were used to explore the data, uncover patterns and identify the most important features/predictors.At the end, challenges and conclusions are presented."
9563537,Flight Test Intelligent Mission Planning System Based on Big Data Platform,"In order to improve the capability of aircraft flight test data, this paper proposes an intelligent flight test mission planning system which is based on a big data platform, combined with artificial intelligence algorithms, modeling and simulation technologies. This system can meet the flight test requirements of the new aircraft, and complete the test flight syllabus, decompose and integrate the test flight task, make the test flight plan for the specific sortie and verify the simulation. Finally, it can formulate a scientific and efficient test flight plan. The intelligence of the system runs through the entire workflow, including the design, validation and finalization of the flight test plan. This article will introduce the main principles and methods of this system."
9457330,Research on Social Networking Teaching Model Based on Data Technology,"The development of Internet and big data analysis technology has brought an opportunity for the reform of teaching model. Social network teaching based on data technology provides students with new social attributes and learning method. Through several links such as user data analysis, network system construction, data integration and matching, information recommendation, interactive social networking and feedback, social network can optimize the allocation of resources and expand the effect of traditional teaching. The application of data provides a stable foundation for the accurate recommendation and delivery of teaching content. This attempt will enrich and expand the connotation of higher education, increase innovation and optimize the teaching form, and improve the teaching effect."
9559566,Analysis and Prospect of the Development of TCM Theories under the Background of Big Data,"Traditional Chinese Medicine (TCM) theories, with a long history and distinctive features, are the combinations of thousands of years of clinical practice experience and academic thoughts in TCM. With the arrival of the era of big data, the development of TCM theories have met new opportunities and challenges. Based on the analysis of TCM theories and big data thinking characteristics, this study explored the commonalities between the two and summarized the opportunities and challenges for the development of TCM theoretical values under the background of big data. In order to promote the innovation and development of TCM theories, some suggestions were put forward from the aspects of constructing data sharing system, enriching the connotation of disciplines, strengthening the application of information technology, creating a good development environment, basing on the needs of modern society and paying more attention to personnel training."
8805062,Big Data Visualization in Cardiology—A Systematic Review and Future Directions,"The digital transformations and use of healthcare information system, electronic medical records, wearable technology, and smart devices are increasing with the passage of time. A variety of sources of big data in healthcare are available, such as biometric data, registration data, electronic health record, medical imaging, patient reported data, biomarker data, clinical data, and administrative data. Visualization of data is a key tool for producing images, diagrams, or animations to convey messages from the viewed insight. The role of cardiology in healthcare is obvious for living and life. The function of heart is the control of blood supply to the entire parts of the body. Recent speedy growth in healthcare and the development of computation in the field of cardiology enable researchers and practitioners to mine and visualize new insights from patient data. The role of visualization is to capture the important information from the data and to visualize it for the easiness of doctors and practitioners. To help the doctors and practitioners, the proposed study presents a detailed report of the existing literature on visualization of data in the field of cardiology. This report will support the doctors and practitioners in decision-making process and to make it easier. This detailed study will eventually summarize the results of the existing literature published related to visualization of data in the cardiology. This research uses the systematic literature protocol and the data was collected from the studies published during the year 2009 to 2018 (10 years). The proposed study selected 53 primary studies from different repositories according to the defined exclusion, inclusion, and quality criteria. The proposed study focused mainly on the research work been done on visualization of big data in the field of cardiology, presented a summary of the techniques used for visualization of data in cardiology, and highlight the benefits of visualizations in cardiology. The...
(Show More)"
8920730,Research on Construction of Evaluation Index System of Agricultural Professional Managers for Big Data,"The application of big data technology in agriculture is the core development direction to realize the maximum utilization of agricultural data information. It is an important task to cultivate high-quality agricultural talents to promote the sustainable and rapid development of intelligent agriculture. Based on the demand side and supply side of intelligent agricultural education system, the big data platform of evaluation index system for professional agricultural managers is constructed. Firstly, this paper studies the application of big data technology in the evaluation index system. Then a rational and effective evaluation index system of agricultural professional managers is constructed by using the network analytic hierarchy process and the grey theory model."
8307234,A Distributed Computing Platform for fMRI Big Data Analytics,"Since the BRAIN Initiative and Human Brain Project began, a few efforts have been made to address the computational challenges of neuroscience Big Data. The promises of these two projects were to model the complex interaction of brain and behavior and to understand and diagnose brain diseases by collecting and analyzing large quanitites of data. Archiving, analyzing, and sharing the growing neuroimaging datasets posed major challenges. New computational methods and technologies have emerged in the domain of Big Data but have not been fully adapted for use in neuroimaging. In this work, we introduce the current challenges of neuroimaging in a big data context. We review our efforts toward creating a data management system to organize the large-scale fMRI datasets, and present our novel algorithms/methods for the distributed fMRI data processing that employs Hadoop and Spark. Finally, we demonstrate the significant performance gains of our algorithms/methods to perform distributed dictionary learning."
8787431,EVOTION – Big Data Supporting Public Hearing Health Policies,"Hearing Loss (HL) is a highly prevalent chronic disease (the 5th cause of disability world-wide), which increases the risk of cognitive decline, mental illness, and depression, and furthermore leads to social isolation, unemployment/early retirement, loss of income and work discrimination. To enable successful holistic management of HL, appropriate public health policies for HL prevention, early diagnosis, long-term treatment and rehabilitation are required. In addition, HL management would benefit from detection and prevention of cognitive decline; protection from noise; and initiatives for socioeconomic inclusion of HL patients. However, the evidence for forming such policies and enabling true holistic HL management is lacking. Specifically, holistic HL management policies require access to and analysis of heterogeneous data sources. In EVOTION, such big data from five different clinical organizations are available and continuous acquisition of real-time data produced by sensors and hearing aids used by HL patients will support their continuous update. In order to utilize these data in forming holistic HL management policies, EVOTION is developing an integrated IT platform supporting: 1) the acquisition and analysis of heterogeneous big data related to HL; 2) policy decision making, i.e. selection of effective interventions related to the holistic management of HL based on the outcomes of 1) and the formulation of related public health policies; and 3) specification and continuous monitoring of the effects of such policies in a sustainable manner."
8969805,"Improving Data Security, Interoperability, and Veracity using Blockchain for One Data Governance, Case Study of Local Tax Big Data","Presidential Decree on One Data Indonesia is intended to govern data produced by central agencies and local agencies to support planning, implementation, evaluation, and development control, including one of them is the local tax. It is a Big Data development contains a lot of data from the central and local government of Indonesia. The defining factors of data collection on Big Data are volume, velocity, variety, and veracity. Volume and velocity state how much and how soon the data is generated. Variety states the condition of the data is structured or not, while veracity speaks the level of trust in data validity. Data veracity is a big problem on Big Data Analytics and using data integrity protection feature and other methods, Blockchain can offer solutions to improve data interoperability, security, and veracity."
9268684,Big Data Processing: Batch-based processing and stream-based processing,"With the exponential increase of the data amount in the past years, data analytics and data processing became essential to any organization. As Moore's law has been exceeded since several years ago, the excessive data hides indeed highly useful information. The real challenge is to successfully extract the information using an effective process and with a reasonable cost. Therefore, various processing techniques have emerged. Indeed, big data processing methods can be classified into several types like batch based, stream based, Graph based, DAG based, interactive based and visual based. All data processing techniques follow the same cycle: data collection, data preparation, data input, processing, data output/interpretation and data storage. Although having this similarity, these approaches have certainly different use cases, architectures and tools. This paper focuses on two types, namely: Batch-based processing and stream-based processing. After defining these two approaches, a comparative study is conducted and some key features are highlighted."
9633725,Research on the Application of Computer Big Data Technology in News Dissemination,"With the continuous advancement of science and technology, the development speed of information technology is getting faster and faster, and the amount of information and data in all walks of life in the society is increasing rapidly, which has an important impact on the development of the industry. Faced with such a huge amount of information, big data technology came into being. How to find news with more reportable value from this information has become the main force now. Predictive analysis can be carried out through big data technology, which has important guiding significance for the mastery of market conditions. The article applies evolutionary game big data theory into the research of this problem. We establish an evolutionary game model for news communication recipient groups and between news readers and news disseminators, and draw corresponding guiding significance based on the model."
9522259,Research on Path Selection Based on Moving Trajectory Big Data,"In the era of big data, the rapid development of mobile internet technology and the popularization of mobile terminals have produced massive amounts of moving object trajectory data. These data contain rich temporal and spatial characteristic information, depict the behavior information of individuals and groups, and use relevant technologies to process trajectory data. Can dig out the behavioral characteristics of individuals and groups, which has important value for crowd evacuation, vehicle navigation, atmospheric environment changes, urban planning and other applications. Aiming at the current path dynamic planning problem, this paper builds a Spark distributed computing platform with improved ant colony algorithm to realize the efficient mining and in-depth analysis of moving trajectory big data; through the improved ant colony algorithm as the basis to analyze the path selection, and then for urban traffic management and Control provides theoretical basis and decision-making reference."
9005717,A demonstration of B-EagleV Visualizing massive point cloud directly from HDFS,"The advent of Hadoop has inspired many researchers to conduct studies on big data. These studies have covered a wide range of aspects of big spatial data. However, they still face challenges in visualizing big spatial data on a distributed storage model since loading multi-resolution data is inefficient. For this reason, multi-resolution data are usually excluded from the distributed storage model to speed up the loading process. This limitation prompted the introduction of B-EagleV, a novel Hadoop-based solution that enables users to manage and visualize massive point cloud data on Hadoop Distributed File System (HDFS) without moving the multi-resolution data to a local server. This paper presents the achievements of B-EagleV in efforts to discover the values of Hadoop in visualizing massive point cloud data."
9442491,Functional Clustering Based on Weighted Partitioning around Medoid Algorithm with Estimation of Number of Clusters,"More and more data are recorded continuously in an interval or discretely only at finite time points nowadays due to the frequency of data collection. These data are functional data which belong to big data. This paper introduces functional clustering in functional data analysis. We propose a weighted partitioning around medoid algorithm with estimation of number of clusters for functional clustering, and use an example to prove its effectiveness."
9526169,Discussion on Time Teaching of Graphic Design Course in Big Data,"With the development of economy in recent years, China has made remarkable improvement in the field of big data, people's life in all fields has not been far from data technology, in the application, big data has gradually changed people's life footprint, life bit by bit has become scientific and intelligent, whether in work or life, big data has become an essential tool. This paper aims at the background of big data, studies the discussion of graphic design, understands the basic concept of graphic design and big data, the influence of big data on graphic design and the technical reform of graphic design under the background of big data. Through the case analysis, this paper makes a thorough study and discussion, obtains the relevant theory to carry on the prevention and provides the powerful basis for Chinese education reform."
7926341,CloudFinder: A System for Processing Big Data Workloads on Volunteered Federated Clouds,"The proliferation of private clouds that are often underutilized and the tremendous computational potential of these clouds when combined has recently brought forth the idea of volunteer cloud computing (VCC), a computing model where cloud owners contribute underutilized computing and/or storage resources on their clouds to support the execution of applications of other members in the community. This model is particularly suitable to solve big data scientific problems. Scientists in data-intensive scientific fields increasingly recognize that sharing volunteered resources from several clouds is a cost-effective alternative to solve many complex, data- and/or compute-intensive science problems. Despite the promise of the idea of VCC, it still remains at the vision stage at best. Challenges include the heterogeneity and autonomy of member clouds, access control and security, complex inter-cloud virtual machine scheduling, etc. In this paper, we present CloudFinder, a system that supports the efficient execution of big data workloads on volunteered federated clouds (VFCs). Our evaluation of the system indicates that VFCs are a promising cost-effective approach to enable big data science."
9182539,Big Data Analysis Model of Customer Appeal Based on Power Enterprise Service Platform,"Today is the era of Internet information. Affected by economic development and living standards, power users have higher and higher expectations for power supply services. Although customer complaints are inevitable, as an important part of customer feedback in high-quality services, how to use customer complaint information efficiently, reasonably, and scientifically has become a problem that every power grid company must face in the Internet + era. The purpose of this article is to study the big data analysis model of customer demands based on the electric power enterprise service platform. This article first introduces the meaning of customer satisfaction and customer demands, and then analyzes the development status of the power enterprise service platform, and proposes the need to improve customer demand management. Based on this, this article establishes a big data analysis model of customer demands. The experimental results prove that the analysis model designed in this paper can not only solve the needs of power enterprises, but also improve the economic benefits of enterprises. In this paper, the economic benefits obtained from the four indicators of failure repair service, power outage information management norms, business process norms and customer service representatives' work efficiency improvement, and the statistical results of a power company using the model one year later are 5.25 million yuan."
9384750,A Study on the Implementation Path of College English Classroom Culture Teaching Based on Big Data Analysis,"Collecting and analyzing big data from college students in Ordos Institute of Technology, is an effective way to improve college English teaching at present. This paper deeply analyzes the present situation and existing problems of college English teaching, and probes into how to collect and analyze big data in college English teaching, how to set up the teaching goal of college English classroom culture, and how to construct the teaching mode, in order to promote the process of ideological elements integrated into college English teaching reform in our college."
9202004,Design of Cross-border Network Crime Detection System Based on PSE and Big Data Analysis,"In order to speed up the detection of cybercrime worldwide, a new cross-border cybercrime detection system is designed by introducing the PSE theory and the principle of big data analysis. In the TFTP server, the U-boot network development board and OpenStack crime information detection component are connected to build the hardware running environment of the cross-border network crime detection system. On this basis, through the analysis of the characteristics of detection information, the calculation of cross-border network detection domain and the directional planning of network crime information, the software operating environment of the detection system is built, and the cross-border network crime detection system based on PSE and big data analysis is designed with the basis of hardware implementation. The comparative experimental results show that, compared with the conventional case detection situation, the average detection time of criminal cases is basically maintained between 3-5 days after the application of cross-border cyber crime detection system, and the accuracy of criminal location is maintained at more than 90%."
9103851,"Research on the optimization of the system for the identification, supervision and privacy protection of targeted poverty alleviation for poverty-stricken college students based on big data technology","Under the guidance of “ensuring that children do not drop out of school due to poverty China has established a broad and universal subsidy system for poverty-stricken students in colleges and universities, which has achieved phased results. However, during the implementation, there are still some bad phenomena such as “fake poverty-stricken students This paper will focus on the application of big data technology to solve the above problems through technical means. It also studies the optimization of the system from three aspects: logical structure design, physical structure design and flow chart design of the big data service platform for poverty-stricken college students."
9726963,Innovative application of big data technology in digital music copyright protection,"The current rapid development of science and technology has brought new development prospects for the innovation of big data technology. In the protection of digital music copyright, big data technology uses the exclusive music copyright platform to carry out innovative protection of music copyright in terms of storage technology, and analyzes the basic situation of digital music copyright on the Internet through data. Digital music copyright uses big data and copyright cloud to establish a digital music copyright protection system, which greatly promotes the innovative development of digital music copyright in China. Copyright cloud mainly stores a large amount of music data into the music system, and uses model statistics, data analysis, data mining and other technologies to analyze and study the information. By establishing a big data research-based learning platform based on digital music copyright protection, build a modern music copyright professional system. Based on the big data network, through the copyright cloud, it is verified that the data prediction under the big data technology has good analytical ability and data processing ability."
8672553,FTLADS: Object-Logging Based Fault-Tolerant Big Data Transfer System Using Layout Aware Data Scheduling,"The layout-aware data scheduling (LADS) data movement framework optimizes congestion for end-to-end data transfers. During data transfer, LADS can avoid congested storage elements by exploiting the underlying storage layout at each endpoint. This improves the I/O bandwidth and hence the data transfer rate across high-speed networks. However, the absence of fault tolerance (FT) in LADS results in data retransmission overhead and may lead to possible data integrity issues upon faults. In this paper, we propose object-logging FT mechanisms to avoid transmitting the objects that are successfully written into the parallel file system (PFS) at the sink end. Depending on the number of log files created for the whole dataset, we have classified our FT mechanisms into three different categories: file logger, transaction logger, and universal logger. Also, to address the space overhead, we have proposed different methods of populating the log files with the information of the successfully transferred objects. We have evaluated the data transfer performance and recovery time overhead of the proposed object-logging-based FT mechanisms on the LADS data transfer framework. Our experimental results show that FT mechanisms exhibit negligible overhead (<; 1%) with respect to the data transfer time. However, the fault recovery time is 10% higher than the total data transfer time at any fault point."
9339625,Research on Auxiliary System of Big Data Abnormality in Station Area Line Loss under Smart Grid,"The thesis takes the station parameters in the three systems of utilization, simultaneous line loss, and theoretical line loss as the analysis object and develops an auxiliary analysis and management system for abnormal line loss in the station area. The system starts to treat the line loss problem in the station area. Use data clustering to analyze the statistical line loss in the regular, economic, and high-loss intervals in the three sets of system parameters, form typical parameters as the results of big data analysis and apply them to the three systems. Data governance and line loss governance make decisions."
9321955,Methods of Big Vector Data Processing Under Toroidal Coordinate Systems,"Methods of big vector data (BVD) processing under toroidal coordinate systems for development of high performance vector information technologies with improving the quality indices of the technologies presents in this paper. These methods involve novel mathematical principle relating to the minimizing of structural elements in toroidal coordinate systems, including the appropriate algebraic constructions such as vector different sets of cyclic groups and ""GlorytoUkraineStar"" (GUS) combinatorial configurations, namely the concept of Perfect Toroidal Codes (PTC)s. These codes form binary coding system under two- or multidimensional ring axes of toroidal reference grid, which provides big data processing of multidimensional arrays, using the smallest possible basis."
9675907,Analysis of Intelligent Guidance System in English Speech Scenario Under the Background of Big Data,"Analysis of intelligent guidance system in English speech scenario under the background of big data is conducted in this study. The dimensionality of the state space reflects the number of variables required to describe the motion in the space. The dimension of a chaotic attractor is the amount of information necessary to describe the chaotic attractor. Hence, in our designed model, this technology is applied to the comprehensive analysis of the performance. Therefore, the speech database used for model training will have a great impact on the performance of the model. The most direct way to improve the speech recognition rate of non-native speakers is to use the speech training of non-native speakers to generate a recognition system. The system is applied from the data collection to the data processing. The scenario is built for the overall analysis."
9559661,Big Data-Based Dynamic Decision-Making Algorithm for Power Enterprise Operation Risk Management,"In the 21st century, with the continuous development of science and technology in our country, the explosive growth of data, big data has become an important resource acquisition channel at home and abroad with its massive data resources. De-importance can not only help small shops, but also The level of economic management of government organizations has spawned many unprecedented business models, which are more capable of promoting and promoting the sustainable development of our country's economy. For our country's power companies, each node such as the distribution network will generate massive amounts of data, and these cumbersome data in the past are now becoming a rare asset for the company. In the era of big data, the data generated by electricity can bring earth-shaking changes to enterprises. With the in-depth reform of all aspects of power companies, power companies in various places can only maintain a firm position in corporate competition if they closely follow the trend of big data, with lower costs, higher efficiency, and better power quality. Using the core technology of big data to seamlessly integrate it with enterprise risk management and realize the top-down application of big data mining and other information technologies within the enterprise will be an important way to build an information enterprise in an all-round way. Making full use of information technology in power production and management and actively promoting the application of big data in the power system will help improve the level of refined operation and management of power companies at all levels, improve operational efficiency, and promote the transformation and development of enterprises. The purpose of this paper is to research on the dynamic decision-making algorithm of power enterprise's operational risk management based on big data. In this paper, through in-depth research on big data, analyzing the current big data mining technology and combining with the operating envir...
(Show More)"
9671429,UPHO: Leveraging an Explainable Multimodal Big Data Analytics Framework for COVID-19 Surveillance and Research,"The coronavirus disease 2019 (COVID-19) is an infectious disease with high transmissibility and acquired through the severe acute respiratory syndrome coronavirus 2 (SARS-COV-2). Scientists, physicians, and health officials are seeking innovative approaches to understand the complex COVID-19 pandemic pathway and decrease its morbidity and mortality. Incorporating artificial intelligence and data science techniques across the health science domain could improve disease surveillance, intervention planning, and policymaking. In this paper, we report our effort on the deployment of multimodal big data analytics to improve pandemic surveillance and preparedness. A common challenge for conducting multimodal big data analytics in clinical and public health settings is the issue of the integration of multidimensional heterogeneous data sources. Additional challenges for developers are explaining decisions and actions made by intelligent systems to human users, maintaining interpretability between different data sources, and privacy of health information. We present Urban Population Health Observatory (UPHO), an explainable knowledge-based multimodal data analytics platform to facilitate CoVID-19 surveillance by integrating a large volume of multimodal multidimensional, heterogenous data including social determinants of health indicators, clinical and population health data."
8938951,Analysis of the Status Quo of Basic Education in Poverty Areas in Yunnan Based on the Big Data,"The precondition for targeted education poverty alleviation is to accurately identify the target audience of poverty alleviation and their status quo of education. Through the purposing data mining and comparative data analysis, this paper will analyse the status quo of primary education of children in poverty areas in Yunnan from the macro and micro levels, and raise reasonable doubts about the popular academic viewpoint, that is distance education narrowing the gap between urban and rural areas."
9599491,Visual Analysis of Multidimensional Big Data: A Scalable Lightweight Bundling Method for Parallel Coordinates,"Varied edge bundling methods have been used to reduce visual clutter in parallel coordinates plots (PCP). However, existing edge-bundled PCP do not scale well for visual analysis of multidimensional big data and often overplot the bundles in the area near the axes. In this study, we propose a scalable lightweight bundling method to support visual analysis of multidimensional big data in PCP. It helps the users discover trends and detect outliers in the data by bundling the edges between each two adjacent axes independently. We integrate human judgments into the two-dimensional data binning by novel interactions to accelerate the clustering process of the data. We use the frequency-based representation to render the clusters as histogram-like bundles to reveal the distribution of the data and eliminate the overplotting of the bundles. Based on our method, we build a lightweight web-based visual analytics system for exploring multidimensional big data in PCP. The scalability analysis of our method shows that its clustering time increases linearly with the size of the data. Its rendering time is independent of the size of the data. We conduct two case studies and a user study to compare our method with classic PCP and two state-of-the-art edge-bundled PCP."
9581491,A Streaming Data Collection and Analysis for Cryptocurrency Price Prediction using LSTM,"Big data analysis for accurate predictions requires adherence to systematic procedures. This study shows an entire data analysis phase from the data collection to model evaluation using the Long Short-Term memory(LSTM) for cryptocurrency price prediction. Three different coin prices are directly collected from the CoinMarketCap in nearly real-time by applying the web scraping technique. The LSTM model trained with this data varying random seed or static seed parameters to find optimal conditions, leading to better accuracy of the LSTM model. Our model evaluated their accuracy in terms of MAE, RMSE, and SMAPE indicators. As a result of this experiment, most of the best candidate parameters are classified at the fixed seed trail in terms of the RMSE for Bit coin, Ethereum, and Lite Coin."
9407003,Changes of the Customer Relationship Under the Big Data and the Concerned Management Paths,"The application of the big data in the business field makes the relationship between the enterprise and the customer closer and closer. The customer's influencing forces to the enterprise is now much more important than ever before. How to successfully manage the customer's relationship in the enterprise concerns whether the enterprise can survive and sustain or not. Therefore, to solve this problem, the paper first expounds the quick change of the customer relationship under the big data, then further explores the influence of the big data based on the internet upon the management and maintenance of the customer's relationship, and finally suggests some paths to manage the customer's relationship under the big data."
8725775,Big Data Analysis on Economical Urban Traffic in Beijing : Organize overlapping transportation though the underground diameter line of Beijing railway hub,"Big data technology to analyze transportation problems has become reliable and effective. Optimizing urban traffic by improving transportation organization has always been the focus of attention in the field of transportation. In order to deeply study the urban traffic saving that can be brought by the overlapping transportation organization, this paper relies on big data technology, scientific modeling, and combines big data analysis technology with traditional traffic four-stage method to quantify important indicators. At the same time, based on big data and simulation technology, the station carrying capacity and waiting organization capacity are discussed, which provides the basis for implementing the overlapping transportation organization plan."
9050171,Research on the Application of Big Data in Book Management,"There are some problems in the management of book materials under the background of big data. The collection of book materials is incomplete, the degree of information management of book materials is not high, and there are missing and duplicated books. Hidden information security hazards such as commercial theft, information theft, and malicious attacks have severely restricted the development of library information management. However, the number of infrastructure facilities cannot meet the actual needs of digital libraries. A management method of books and materials under the background of big data is put forward, that is, focusing on the innovation of knowledge services to maximize the value of knowledge services. Pay attention to the innovation of management mode and use big data technology to build electronic libraries. Under the background of big data, library managers can build an informatization management mode to increase the overall rate of book management."
9182607,Research on Computer Network Information Security System Based on Big Data,"In order to effectively improve the computer network security defence capability in the era of big data, a comprehensive analysis of the functions of big data centre applications is performed to create a comprehensive computing network security defence system. First of all, a comprehensive analysis of the hidden dangers of modern computer network security is carried out, and then corresponding technologies such as modern network security technology and solutions, intrusion detection technology are introduced to realize the design of computer network security defence system in the context of the big data era. After the system design is implemented, the system is tested accordingly. According to the test results, the computer network security defence system designed in this paper can actively discover and effectively prevent security threats in the network, thereby ensuring that the network can Normal and safe operation. The computing network security defence system can also provide effective ideas for future network security protection and achieve further expansion of security defence."
9239754,Establishment and Application of Big Data Processing Platform,"With the advent of the era of big data, more and more enterprises begin to use big data technology to deal with related analysis work. Hadoop is the dominant processing platform in the field of big data, an ecosystem that integrates distributed computing, storage, and management. The Spark framework, on the other hand, is a faster, more versatile distributed computing platform. However, it is only a computing platform and does not provide distributed storage and management per se, and computing remains dependent on distributed file system HDFS and cluster Resource Manager Yarn in the Hadoop ecosystem. Therefore, the combination of Spark and Hadoop to build a big data processing platform can better improve the algorithm efficiency and processing scale. This article explains the setup process and running state of Hadoop and Spark in detail, and verifies its feasibility through several ways."
9574265,Analysis of User Behavior through Network Big Data and Intelligent Information System,"At present, with the widespread application of Internet technology in e-commerce platforms, people's traditional consumption methods have been changed. As more and more users choose to consume online, this has effectively promoted the prosperity of the e-commerce economy. Based on the above-mentioned situation, the mutual competition among enterprises has also begun to shift from offline to online, and obvious changes in the way of competition have taken place. At present, many companies attach importance to in-depth analysis of users' consumption behavior based on network big data technology. The article mainly analyzes the characteristics of users' consumption behavior in the context of big data, the application of big data in consumer behavior research, and the network under big data. The influencing factors of user consumption behaviors are expected to play a role in promoting the development of large-scale and standardized online shopping market."
9258830,The Vocational Skills Competition Based on Big Data Analysis Promotes the Research of Students' Vocational Ability,"With the progress of information technology, big data gradually shows its extraordinary value. Big data is used in all walks of life, including education and teaching. The big data on the vocational Skills Competition can analyze the students' mastery of vocational ability. Through big data analysis, I was informed of the projects of China Vocational Skills Competition and the awards of various provinces and cities. It is concluded that the competition of vocational skills is difficult and can train students' various abilities. Therefore, it is proposed to take the vocational skill contest as an opportunity to improve students' vocational ability and teaching quality and promote the development of vocational education."
9523954,Agricultural Decision-Making System based on Big Data,"In order to improve the effectiveness of agricultural decision-making system, this paper proposes a new agricultural decision-making system based on big data. This paper establishes an agricultural big data mining architecture based on Hadoop firstly, and uses real-time data stream for real-time data monitoring mining. The classification regression tree (CART) algorithm combined with incremental learning is used to classify the collected data step by step. The experimental results verify the effectiveness of the method."
8784580,A Comparative Performance of Real-time Big Data Analytic Architectures,"Nowadays, many organizations pay attention to the relevant technologies of Big Data to analyze more accurately, quickly, and efficiently. Real-time Big Data analytics is challenging due to the massive volume of complex data needed to distribute in processing. Therefore, in this research, we investigate two state-of-the-art architectures: Lambda and Kappa. The Kappa architecture is simply the Lambda architecture without the batch layer. To help businesses decide on the right architecture, their processing time, and resource utilization in the same environment need to be found out. Experiments had been carried out with the data size 3 MB, 30 MB, and 300 MB. The results showed that Lambda architecture outperforms Kappa architecture around 9% for the accuracy test when using processing time approximately 2.2 times more than Kappa architecture. Lambda architecture also used more 10-20% of CPU usage and 0.5 GB of RAM usage than Kappa architecture."
9653484,Cloud Computing-Based Smart Grid Power Big Data Analysis Technology,"In data management, conventional data processing models cannot meet the demand for large amounts of data and complex data types. Therefore, a big data approach is proposed to analyze the collected data to mine the data support that is hidden in the big data and can be used to make strategic, tactical and operational decisions. This paper mainly introduces the function of Apache Spark in big data analysis from the grid data source, related data processing technology and application in the grid, with grid price as the application background, and proposes a data platform for unified processing and application."
9193894,Data Processing Model to Perform Big Data Analytics in Hybrid Infrastructures,"Big Data applications are present in many areas such as financial markets, search engines, stream services, health care, social networks, and so on. Data analysis provides value to information for organizations. Classical Cloud Computing represents a robust architecture to perform complex and large-scale computing for these areas. The main challenges are the user's unknowledge about Cloud infrastructure, the requirement needed for improving performance, and the resource management to maintain stable processing. In these difficulties, an inadequate solution can lead to users overestimate or underestimate the number of computational resources, which drives to the budget increases. One way to work around this problem is to make use of Volunteer Computing since it provides distributed computational resources at free monetary cost. However, a volatile machine behavior is a problem to address in Big Data data distributions. Thus, this work proposes a data distribution model composed of Cloud Computing and Volunteer Computing environments in a hybrid fashion for Big Data analytics. The contributions of this work are: i) the required evaluation to enable efficient deployment of Big Data in hybrid infrastructures; ii) the development of an HR_Alloc Algorithm for establishing the data placement to Big Data applications; iii) a model to resource allocation in hybrid infrastructures. The obtained results indicate the feasibility of using a hybrid infrastructure with up to 35% of unstable machines in the worst-case scenario, without losing performance and a monetary cost lower than 20% in comparison to Classical Cloud Computing. Also, communication costs decrease up to 57.14% in the best-case scenario due to load balancing."
9377797,Clustering-Based Predictive Analytics to Improve Scientific Data Discovery,"Given the sheer volume of scientific data archived within the data-intensive projects at the US Department of Energy's Oak Ridge National Laboratory, finding precisely what data we are looking for may not be a trivial task; conversely, we may also miss a more prominent data product. To address such issues, we propose improving the data discovery system and using data analytics methods to comprehend what specific users might be interested in based on their physiological state, search patterns, and past data usage history. This work's primary goal is to prune the complexity, increase the visibility of popular data products, and direct users toward the data that best meet their needs. The proposed algorithm constructs a user profile based on the user's explicit or implicit interactions with the system, such as items they are currently looking at on-site and the key metadata mappings related to the data set. The pattern is then used to build a training data set, which will help find relevant data to recommend to the user."
9237729,A Scheduling System for Big Data Hybrid Computing Workflow,"With the increasing usage of big data, the types of big data technologies have also become diverse. When solving a particular problem, it often involves many different types of big data tasks. How to realize the hybrid scheduling of different types of tasks is an urgent problem to be solved. Before this, the industry used crontab to schedule big data tasks regularly, it can conveniently execute system task scheduling and user task scheduling in Linux environment, but it cannot meet the scheduling needs of complex business scenarios and it requires users to write their own submission logic. Therefore, this paper designs a hybrid scheduling system for big data tasks based on Airflow. The system supports the construction of different types of big data tasks into a workflow, and scheduling these tasks based on workflow. At the same time, the scheduling module is independent of other modules, which reduces the coupling degree between the modules. The method proposed in this paper has been applied to big data platform, and the effectiveness of the method has been verified."
9402762,Application Analysis of Big Data Technology in Energy Internet,"The application of big data has been widely adopted today, but the exploration of Energy Internet based on the big data is in its early phase. In the paper, firstly, the basic concept, characteristic and method of big data is described, and the current situation of Energy Internet is investigated. Then, the importance and implementation means of big data in Energy Internet is pointed out. Several application scenarios of big data used for Energy Internet are presented, and the advantage of big data is summarized. Finally, the application technology system and research framework of big data in Energy Internet are proposed."
9002341,Evaluation of Development and Application of Big Data,"The development of the global economic system is accompanied by the massive introduction of innovative digital technologies in all sectors of the economy. The widespread introduction and use of information and communication technologies have led to the formation of a new direction in the development of the economy - digital, based on the use of the most advanced digital technologies. The most promising technologies of recent years are cloud computing, blockchain, neural network technologies, big data, and many others. The basic concepts and types of big data were analyzed in this paper; a comparative analysis was conducted between traditional databases and information storage in the field of big data. The global big data market is analyzed in this paper: financial volumes are determined, the dynamics of its development are assessed, and research is conducted on individual market sectors, in particular, infrastructure, software and services provided, the main market players are identified. Particular attention is paid to the development of the direction of cloud computing in the field of big data. The areas of application of big data in the industry context are analyzed, the main consumers are identified. Based on a comprehensive analysis in the field of big data, their further prospects for development and application are determined."
9166621,FDM: Fuzzy-Optimized Data Management Technique for Improving Big Data Analytics,"Big data analytics and processing require complex architectures and sophisticated techniques for extracting useful information from the accumulated information. Visualizing the extracted data for real-time solutions is demanding in accordance with the semantics and the classification employed by the processing models. This article introduces fuzzy-optimized data management (FDM) technique for classifying and improving coalition of accumulated information based semantics and constraints. The dependency of the information is classified on the basis of the relationships modeled between the data based on the attributes. This technique segregates the considered attributes based on similarity index boundaries to process complex data in a controlled time. The performance of the proposed FDM is analyzed using a real-time weather forecast dataset consisting of sensor data (observed) and image data (captured). With this dataset, the functions of FDM such as input semantics analytics and classification based on similarity are performed. The metrics classification and processing time and similarity index are analyzed for the varying data sizes, classification instances, and dataset records. The proposed FDM is found to achieve 36.28% less processing time for varying classification instances, and 12.57% high similarity index."
9603750,Personalized Film and Television Recommendation System Based on Big Data Platform,"The emergence of big data platforms has alleviated the restrictions of space and time on people's enjoyment of music information services. The need to improve user experience has become very urgent. One of the effective solutions to information overload is the recommendation system, which can help people discover interesting content from complex information. Therefore, the purpose of this article is to study a personalized film and television recommendation system based on a big data platform. This article first introduces the core technology of big data through an overview of the basic theory of big data. And combined with the traditional film and television recommendation method, analyze the existing problems and shortcomings, and analyze and discuss it with the core technology of big data. This article systematically expounds the overall process, system composition design and algorithm analysis of the personalized film and television recommendation system based on the big data platform. Experimental research shows that the algorithm proposed in this paper is better than the traditional User-basedCF strategy and Item-basedCF strategy under the same number of movies recommended by Hit-rate."
8848245,Investigating Random Undersampling and Feature Selection on Bioinformatics Big Data,"This paper aims to address a key research issue regarding the ECBDL'14 bioinformatics big data competition. The ECBDL'14 dataset was the big data target in the competition, and it consisted of 631 attributes and about 32 million instances, of which about 98% belonged to the negative class. The ECBDL'14 competition dataset has recently been used in the literature to assess the effect of class imbalance on big data analytics. The contribution of our paper is two-fold. First, a survey of several literature works that utilized the EDBDL'14 dataset, either fully or partially, is presented. Second, compared to the Random Oversampling approach used by the winning algorithm for the competition, we utilize a Random Undersampling approach in conjunction with a Feature Selection approach. Through Random Undersampling, different class distributions were generated, ranging from slightly imbalanced to balanced. Prior to sampling, we perform Feature Selection by computing Feature Importance with the Random Forest learner within the Apache Spark framework. Subsequently, classification performance is computed for Random Forest, Logistic Regression, and Gradient-Boosted Trees in the same big data analytics framework. The key results of our study indicate that our proposed solution had a higher prediction performance (minimally) compared to that of the highest value of the winning algorithm. However, it is important to note that Random Undersampling, compared to Random Oversampling, imposes a lower computational burden and results in a faster training time, which is beneficial to data analytics. We conclude that our solution clearly outperforms the ECBLD'14 winning algorithm."
9189477,Design of Big Data Compatible Storage System Based on Cloud Computing Environment,"Cloud computing is a hot technology all over the world and brings great changes to the people's production and life. Concerning the characteristics of massive network data heterogeneity and data real-time, this paper adopts the cloud computing method, analyzes the problem of data storage and parallel processing, proposes the innovative design of network data detection and storage system, and gives the processing model of the storage system. Finally, test the performance of the system through the simulation experiment. Test results show that the system has a huge superiority compared than the traditional one and effectively achieves the design goal."
8669608,Research on the Impact of Urban Land Use Structure Based on Big Data on Space Performance in Kunming,"Based on the big data of urban land use, this paper calculates and analyzes the changes in Kunming's urban land use structure in 2003, 2008 and 2014 respectively, constructs the index system of Kunming's urban space performance, and performs the linear regression analysis on the information entropy and performance value of the land use structure by SPSS software based on the space performance value calculated by comprehensive evaluation model after calculation of the weight of each index by AHP decision analysis method . The results show that Kunming's urban land use structure was constantly improving and tending to be balanced during the study period. With the change of urban land use structure, the value of urban space performance also increased accordingly, indicating that the information entropy of urban land structure has a certain pulling effect on space performance."
9005608,WordPrep: Word-based Preposition Prediction Tool,"As big data heads towards big knowledge, data management and machine learning techniques work together to address several interesting problems. In this paper, we address a problem in natural language processing that involves learning by mining from large text databases. More specifically, we deal with the problem of preposition prediction, especially for ESL (English as a second language) learners. Prepositions are function words that typically show a relationship between a noun or a pronoun and other elements of a sentence. They play a key role in determining the meaning of a sentence. Accurate prediction of correct prepositions in a sentence is a challenging job since preposition usage is one of the most subtle aspects of the English grammar, making it difficult for non-native speakers. This paper proposes an approach for preposition prediction called WordPrep based on which we build a tool. WordPrep relies on mining based on the words themselves rather than on their lexical or syntactic connotations. This addresses the challenges of prepositions appearing in idiomatic phrases or in different semantic contexts, due to which the actual words are better than their grammatical positions. Our proposed solution entails a direct data-driven approach to predict the missing preposition in a sentence by learning from matching tokens consisting of ngrams with words before and after the preposition. Using various searches and pattern-matching methods against a large number of database records from big text corpora, this approach predicts the missing preposition(s). We describe our pilot approach, tool implementation and experiments in this paper. This work is particularly helpful for pedagogical applications."
9524008,Network Public Opinion Crisis Management Mechanism Based on Big Data Technology,"In order to overcome the problems existing in the management of network public opinion crisis, such as asymmetric information, too much data, slow data processing and low work efficiency, this paper proposes a novel construction method of network public opinion crisis management mechanism based on big data technology. Combined with the characteristics of network public opinion crisis events and the advantages of big data technology, the construction method can improve the management level of network public opinion crisis from four dimensions, namely, the prevention of network public opinion crisis events, the preparation of network public opinion crisis events, the response of network public opinion crisis events, and the recovery of network public opinion crisis events. The research results show that the construction method can indeed realize the deep integration of network public opinion crisis management mechanism and big data technology, so as to improve the level of network public opinion crisis management in China."
9006190,"Kratos: A secure, authenticated and publicly verifiable system for educational data using the blockchain","Growing interest in educational data mining (EDM) and learning analytics (LA) to leverage big data and to benefit education and the science of learning has made data ownership an important focus point for institutions and students. While EDM and LA can provide important information that help enhance the quality of teaching and learning, it has become critical to ensure data privacy and student agency over data. In this paper, we introduce Kratos: an immutable and publicly verifiable data management system that enables EDM and LA, while maintaining data privacy and empowering students with a user interface for data governance and participation in school processes. The system aims to achieve data interoperability, which facilitates EDM and LA as incentives to educational stakeholders (policy makers, educators, developers of education technologies, etc.), while prioritizing student agency over their data. Our system gives students and schools an immutable log along with comprehensive access to data that is otherwise scattered across systems and vendors. The underlying set of rules of the system are defined in a set of smart contracts, codified from existing non-virtual agreements [1] between schools and education technology (edutech) vendors. We propose the smart contracts to be deployed on a public blockchain (like Ethereum or Bitcoin), for notarizing and time-stamping various interactions which users of Kratos may have with data. Third parties requesting access to school data have a unique virtual token assigned to them on the blockchain which helps keep track of data modifications, access and use."
9006187,"DQA: Scalable, Automated and Interactive Data Quality Advisor","Fueled with growth in the fields of Internet of Things (IoT) and Big Data, data has become one of the most valuable assets in today's world. While we are leveraging this data for analyzing complex systems using machine learning and deep learning, a considerable amount of time and effort is spent on addressing data quality issues. If undetected, data quality issues can cause large deviations in the analysis, misleading data scientists. To ease the effort of identifying and addressing data quality challenges, we introduce DQA, a scalable, automated and interactive data quality advisor. In this paper, we describe the DQA framework, provide detailed description of its components and the benefits of integrating it in a data science process. We propose a programmatic approach for implementing the data quality framework which automatically generates dynamic executable graphs for performing data validations fine-tuned for a given dataset. We discuss the use of DQA to build a library of validation checks common to many applications. We provide insight into how DQA addresses many persistence and usability issues which currently make data cleaning a laborious task for data scientists. Finally, we provide a case study of how DQA is implemented in a realworld system and describe the benefits realized."
9384549,Research on Evaluation Method of Radar Anti-jamming Effectiveness Based on Experimental Big Data,"In the complex electromagnetic environment of the battlefield, the reliability and accuracy of radar equipment are facing great challenges, and the anti-jamming ability of radar directly affects the function of radar. The evaluation of radar anti-jamming effectiveness based on experimental big data has also become an important research direction of radar operational use. This paper starts with analyzing the criterion of radar anti-jamming effectiveness evaluation, sorts out the indicators of radar anti-jamming effectiveness, uses the analytic hierarchy process to establish the index weight, and uses the weighted relative deviation distance method to establish the evaluation method of radar anti-jamming performance. The research results provide reference for the evaluation of radar anti-jamming effectiveness in the exercise."
8818017,Big-Data-Driven Dynamic Clustering and Load Balancing of Virtual Base Stations for 5G Fronthaul Network,A big-data-driven dynamic clustering and load balancing scheme of virtual base stations for 5G fronthaul network is proposed. The comparison of load balancing factor shows that the optimization effect of the scheme is obvious.
9150298,How Chinese University’s ideological and political education leads the trend of social ideological in the era of big data,"Colleges and universities are the main battlefield for ideological construction in many countries and political parties. They are also at the forefront of the fusion and confrontation of multicultural and various online social trends. In the era of big data, a variety of ideological trends in the network society are surging, and non-Marxist ideological consciousness is growing. All of these have brought huge challenges to the ideological and political education of Chinese universities. The way of Chinese universities using ideological and political education to lead the ideological trend of the Internet society is of great importance in practice. Chinese universities should speed up the construction of a socialist ideological discourse system with Chinese characteristics. Besides, they should improve the quality of ideological and political education. What's more, they must innovate ideological education methods. At the same time, Chinese ideological and political educators should lead the college student group to resist all kinds of erroneous trends in the Internet society and support the ideological and political education work of college students in China. This series of measures is of great significance for promoting the theme."
9457346,A Study on the Construction of Wisdom Classroom for Oral English Course in Higher Vocational College Based on Big Data and Artificial Intelligence,"With the development of the internationalization of the world economy, English is also playing a very important role in the field of today's disciplines. The innovation of artificial intelligence and information technology makes the university education change obviously. In the future English teaching, colleges and universities should integrate computer application technology and tools into the teaching process of English courses, which provides a huge material and information basis for enhancing students' English social communication ability and English subject literacy ability. Therefore, this paper takes the construction of wisdom classroom as the starting point, fully discusses the concept, construction conditions and functions of wisdom classroom. On this basis, this paper takes civil aviation professional oral English as an example to explore the construction path of oral English wisdom classroom in higher vocational colleges under the background of big data and artificial intelligence, so as to provide reform ideas for the teaching development of higher vocational English."
9457350,The Usages of Teaching Information Feedback of the College English Teaching from the Perspective of Educational Informationization on the Basis of Big Data,"Educational informationization provides both the teachers and the students with various real time medias of communication to exchange the feedback of teaching information in the teaching of college English, such as QQ, MSN, Wechat, Dingtalk, NetMeeting, in addition to some non-real time medias of communication, such as e-mail, BBS and Blog. On the basis of the big data, both the teachers and the students can get and exchange a large amount of the feedback of teaching information in the college English teaching, by which the teachers can make use of those feedback of teaching information to adjust their teaching plans, to improve their teaching methods and to guide the students to input the teaching information of college English more efficiently, while the students can realize their shortcomings and how to improve their learning of college English. Both the positive feedback of teaching information and the reverse feedback teaching information should be applied in the college English teaching."
9564308,Leveraging LightGBM for Categorical Big Data,"LightGBM is a popular Gradient Boosted Decision Tree implementation for classification and regression tasks. Our contribution is to answer a research question regarding LightGBM. We would like to know which alternative yields better performance for classifying highly imbalanced Big Data with high-cardinality categorical features: relying entirely on LightGBM’s Exclusive Feature Bundling as a way to encode categorical features, or using LightGBM’s built-in encoding for categorical features? Our study of LightGBM revealed two alternatives for a Big Data classification task to do anomaly detection. We may one-hot encode the data into a sparse representation, and then rely entirely on LightGBM’s Exclusive Feature Bundling to complete encoding of the categorical features. Exclusive Feature Bundling is LightGBM’s optimization technique that exploits sparsity in features for reducing the dimensionality of a dataset. On the other hand, also because our data has categorical features, it is a candidate for LightGBM’s built-in encoding technique for categorical features. Since we did not find a clear indication in a survey of related work for which direction to take – using Exclusive Feature Bundling or using LightGBM’s built-in encoding for categorical features – we experiment with these options to determine the best one for highly imbalanced Big Data. Furthermore, we show LightGBM’s built-in encoding is best in a statistically significant sense. Our work is important because it fills a gap in LightGBM-related literature on how to best handle categorical features in imbalanced Big Data with high-cardinality categorical features."
9006274,Coping with Big Data in Transfer Optimization,"Transfer optimization is an emerging concept that promises to enhance productivity of planning and decision-making processes by allowing for the adaptive reuse of knowledge (data) drawn from various “source” problems in a related ongoing “target” task of interest. Despite the recent advances in transfer optimization, however, a continuing challenge is the scalability of associated algorithms given big data of source problem instances. This paper tackles the scaling problem of an online adaptive knowledge transfer framework under big source data. We propose an efficient source selection algorithm based on the theory of multi-armed bandits such that the most related source task to the target is chosen for knowledge transfer, as opposed to extracting knowledge from all sources simultaneously. For this purpose, we introduce a novel and principled reward measure to reflect the source-target similarities. The efficacy of our proposed approach is assessed on the well-known knapsack problem that has practical implications in optimization of supply chain and manufacturing processes. Extensive experiments are conducted under big data of source problem instances. The numerical results clearly reveal that the incorporation of the proposed source selection mechanism in the existing adaptive knowledge transfer framework makes it successfully feasible for fast/real-time decision-making in the big data source setting."
9140855,Performance Evaluation of Big Data Applications in Cloud Providers,"Due to the amount of computational data generated each year and most often without standardization, the need arose for the development of specific Big Data tools. Currently cloud computing has been chosen as it is widely used in conjunction with Big Data due to its reduced cost and elasticity. Utilization of cloud services has increased over the years and many companies have migrated their computing services to the cloud to reduce the operational costs of maintaining the technology infrastructure. Due to the number of cloud providers available, benchmarking is now considered important for your choice, especially the performance of the specific application in the cloud environment. This paper aims to evaluate MongoDB database performance using the Yahoo Cloud Serving Benchmark tool, with 3 cloud application profiles from Google and Microsoft."
9240737,Research on the technology of artificial intelligence in computer network under the background of big data,"In order to create a safe computer network environment, the application of artificial intelligence in computer network technology issues under the background of big data is analyzed. First introduce artificial intelligence and understand its development in the big data environment. Secondly, analyze the application status of artificial intelligence technology, and clarify the application direction in the field of computer network technology problem solving. Finally, it analyzes the expert system, artificial neural network technology, data mining technology, autonomous agent technology, security management technology, problem solving technology, expert knowledge base technology, and computer network fuzzy information processing technology. The purpose is to give full play to the advantages of artificial intelligence to solve problems and provide guarantee for the safe and stable operation of computer systems."
9050274,Intelligent Travel Route Recommendation Algorithm Based on Big Data,"With the rapid development of mobile Internet technology, the number of customers has increased dramatically, and applications have become widespread. Using the big data generated by mobile network activities to analyze customer behavior and achieve accurate marketing has become a new demand in the field of mobile Internet. In this paper, the big data algorithm is used to analyze the characteristics of customers and match the classification, and obtain the customer requirements. The data extraction method based on customer characteristics is obtained. Through the analysis of customer characteristics, intelligent travel route recommendation based on customer interests is carried out. The experiment proves that the algorithm can better match and classify customer features, and conduct accurate travel route recommendation through customer interest."
9050400,Research on Ideological and Political Education in Universities in the Era of Big Data,"The rise of big data technology has not only provided new technical means and methods for social development, but also changed people's thinking and social environment. The development and change of new technologies have also brought many difficulties and challenges to ideological and political education in colleges and universities, including the dilemma bound by traditional fixed thinking, the weak technology and the lack of talents, the improper use of data storage, and so on. As the forefront of ideological and political education, universities must do a good job of ideological and political education in the era of big data. It is required that ideological and political educators in colleges and universities continue to innovate in teaching content, teaching methods, and research paradigms to promote the development of ideological and political education."
9410128,E-commerce Marketing Strategy Based on Big Data Statistical Analysis,"In order to improve the sales efficiency and operating benefits of the company, the paper presents an E-commerce marketing strategy based on big data statistical analysis. Through analysis of massive data existing in the network, the new method can provide decision-making basis for e-commerce platform and management of enterprise and effectively improve the competitiveness of e-commerce platform and enterprise."
9221657,Research on Fast Location Method of Network Fault Based on Big Data,"The stable and reliable operation of the power grid information system is the fundamental to ensure the safe production and optimal management of the power grid. In this paper, by obtaining the performance parameters of the system between load and response time, resource consumption, and introducing time, external time and other parameters for big data analysis, the performance trend analysis of throughput, error and response time is given, and the current situation and history of the system are analyzed Historical data comparison and performance bottleneck analysis can improve the level of information mining, quickly and accurately realize the location of network fault components and fault type and cause identification"
9179432,Big Data Framework for Incoming Calls Forecasting in a Call Center,"An accurate forecasting is essential for successfully managing the workforce in a call center. In order to meet call demand without under-staffing or over-staffing, a precisely forecasting method is needed. This paper proposes the Big Data framework for forecasting incoming calls to the mobile call center. The historical data is analyzed in the first step. In the second step, two time series forecasting models called Model Ex and Model Pr. are proposed. The forecasting in a web application is finally developed regarding the proposed forecast flow diagram by using Microsoft Visual Studio. The result demonstrates that Model Pr provides better forecasting accuracy than Model Ex."
9671696,Text Analytic Research Portals: Supporting Large-Scale Social Science Research,"Large-scale organic data generated from newspapers, social media, television, and radio require an expertise in infrastructure management, data collection, and data processing in order to gain research value from them. We have developed text analytic research portals to help social science researchers who do not have the resources necessary to collect, store, and process these large-scale data sets. Our portals allow researchers to use an intuitive point and click interface to generate variables from large, dynamic data sets using state of the art text mining and learning methods. These timely variables constructed from noisy text can then be used to advance social science research in areas such as political science, economics, public health, and psychology research."
9094817,The Method of Building SBOM Based on Enterprise Big Data,"The technology of SBOM generation based on enterprise big data improved the efficiency and accuracy of enterprise product file data when the product is delivered to the customer. Through system integration, EBOM is used to build SBOM of product type. Then, the order data from ERP is used to build SBOM of order after comparing with SBOM of product type. Finally, the actual installation data from MES are added to SBOM of order to form SBOM of instance. The system about ""Generation of SBOM"" was established based on this technology, which has engineering applied in some company about researching and developing construction machinery. Production cycle of the manual based on SBOM reduced from the original 10 to 20 days for 3 to 5 hours, generated accurate product electronic record, and achieved one machine correspondence with its manual. The accuracy of the technical file content improved significantly."
9141853,Based on big data of computer room monitoring and forecasting for Intelligent analysis,"With the rapid development of the Internet, the demand for electric power industry of our country has showed a trend of rising year by year, the construction scale and volume has been expanding, involving the number of servers is numerous, equipment management difficulty increases, therefore, how to avoid the happening of server equipment failure has become an important subject in power system. In this paper, according to the characteristic values of different equipment, big data technology is used to deeply mine the data, and the fault prediction model is built to realize the rapid fault location. This practice can ensure the normal operation of business, and can save the operation and maintenance cost of equipment."
9442536,A Method of Data Granulation and Indicators Standardization of Spreadsheet,"In this paper, a method of data granulation and indicators standardization is proposed, which is mainly used to solve the problems of two-dimensional spreadsheet data granulation and indicators standardization. By defining the classification and hierarchical of indicators, extracting the implicit relationship, and classifying and layering the indicators for storage, the problems of granulation, standardization and making implicit relationship explicit of two-dimensional spreadsheet data are solved at one time. It provides a feasible storage scheme for multi-source and large-scale data operation."
9068262,Sampling for Big Data Profiling: A Survey,"Due to the development of internet technology and computer science, data is exploding at an exponential rate. Big data brings us new opportunities and challenges. On the one hand, we can analyze and mine big data to discover hidden information and get more potential value. On the other hand, the 5V characteristic of big data, especially Volume which means large amount of data, brings challenges to storage and processing. For some traditional data mining algorithms, machine learning algorithms and data profiling tasks, it is very difficult to handle such a large amount of data. The large amount of data is highly demanding hardware resources and time consuming. Sampling methods can effectively reduce the amount of data and help speed up data processing. Sampling technology has been widely used in big data context. Data profiling is the activity that finds metadata of data set and has many use cases, e.g., performing data profiling tasks on relational data, graph data, and time series data for anomaly detection and data repair. However, data profiling is computationally expensive, especially for large data sets. Hence this article focuses on researching sampling for data profiling tasks in big data context and investigates the application of sampling in different categories of data profiling. From the experimental results of these studies, the results got from the sampled data are close to or even exceed the results of the full amount of data. Therefore, sampling technology plays an important role in the era of big data, and we also have reason to believe that sampling technology will become an indispensable step in big data processing in the future."
9272794,"Smart Grid Big Data Analytics: Survey of Technologies, Techniques, and Applications","Smart grids have been gradually replacing the traditional power grids since the last decade. Such transformation is linked to adding a large number of smart meters and other sources of information extraction units. This provides various opportunities associated with the collected big data. Hence, the triumph of the smart grid energy paradigm depends on the factor of big data analytics. This includes the effective acquisition, transmission, processing, visualization, interpretation, and utilization of big data. The paper provides deep insights into various big data technologies and discusses big data analytics in the context of the smart grid. The paper also presents the challenges and opportunities brought by the advent of machine learning and big data from smart grids."
